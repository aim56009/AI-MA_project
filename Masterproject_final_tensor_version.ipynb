{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Masterproject.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aim56009/AI-MA_project/blob/main/Masterproject_final_tensor_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ],
      "metadata": {
        "id": "SsyC2uB0KfaT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDUwCmeIW8i1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdfb0362-401d-4fa1-f774-140972f6f540"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import torchvision.transforms.functional as TF \n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import click\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install partitura\n",
        "import partitura\n",
        "import statistics"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: partitura in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: mido in /usr/local/lib/python3.7/dist-packages (from partitura) (1.2.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from partitura) (1.21.6)\n",
            "Requirement already satisfied: xmlschema in /usr/local/lib/python3.7/dist-packages (from partitura) (1.11.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from partitura) (1.4.1)\n",
            "Requirement already satisfied: lark-parser in /usr/local/lib/python3.7/dist-packages (from partitura) (0.12.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from partitura) (4.2.6)\n",
            "Requirement already satisfied: elementpath<3.0.0,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from xmlschema->partitura) (2.5.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsFs8dyqXBx2"
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/aim56009/AI-MA_project.git"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYpz1MOIOgtk"
      },
      "source": [
        "# Dataloader - Set the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygWXNSrCbRQi"
      },
      "source": [
        "#PATH_TO_DATA = \"AI-MA_project/bach_pr_fugues\"\n",
        "PATH_TO_DATA = \"AI-MA_project/pianoroll_88\"\n",
        "\n",
        "batch_size = 1 \n",
        "workers = 0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1-u8zYd-gyo"
      },
      "source": [
        "class MusicDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        labels = [\"voice_0\", \"voice_1\", \"voice_2\", \"voice_3\", \"voice_all\"]\n",
        "        self.labels = labels\n",
        "        self.pr_dict = {}\n",
        "        len_list = []\n",
        "\n",
        "        for iLabel in range(len(labels)):\n",
        "            \n",
        "            if iLabel == 4:   \n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\")))   \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: ### normal sollte es egal sein wenn voice_4 bei manchen nicht existiert - wenn nicht condition einführen damit das funktioniert\n",
        "                        loaded_obj = pickle.load(f)  \n",
        "                        voice_files.append(loaded_obj) \n",
        "                        len_list.append(len(loaded_obj.T))\n",
        "                        \n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                self.pr_dict[\"length\"] = len_list\n",
        "    \n",
        "            else:\n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: \n",
        "                        loaded_obj = pickle.load(f)     \n",
        "                        voice_files.append(loaded_obj)\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      \n",
        "        return len(self.pr_dict[self.labels[0]])\n",
        "  \n",
        "\n",
        "    def __getitem__(self, idx):          \n",
        "\n",
        "        out_list = []\n",
        "        for key, value in self.pr_dict.items():\n",
        "            out_list.append(self.pr_dict[key][idx])    \n",
        "\n",
        "        v0 = torch.tensor(out_list[0].T)\n",
        "        v1 = torch.tensor(out_list[1].T)\n",
        "        v2 = torch.tensor(out_list[2].T)\n",
        "        v3 = torch.tensor(out_list[3].T)\n",
        "        v_all = torch.tensor(out_list[4].T) \n",
        "        length = self.pr_dict[\"length\"][idx]\n",
        "\n",
        "\n",
        "        return (v0, v1, v2, v3, v_all, length)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicDataset_new(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        self.name_list = [\"1f01\",\"1f02\",\"1f03\",\"1f04\",\"1f05\",\"1f06\",\"1f07\",\"1f08\",\"1f09\",\"1f10\",\"1f11\",\"1f12\",\"1f13\",\"1f14\",\"1f15\",\"1f16\",\"1f17\",\"1f18\",\"1f19\",\"1f20\",\"1f21\",\"1f22\",\"1f23\",\"1f24\",\"2f01\",\"2f02\",\"2f03\",\"2f04\",\"2f05\",\"2f06\",\"2f07\",\"2f08\",\"2f09\",\"2f10\",\"2f11\",\"2f12\",\"2f13\",\"2f14\",\"2f15\",\"2f16\",\"2f17\",\"2f18\",\"2f19\",\"2f20\",\"2f21\",\"2f22\",\"2f23\",\"2f24\"]\n",
        "        self.name_list_voice_3 =  ['1f01', '1f05', '1f12', '1f14', '1f16', '1f17', '1f18', '1f23', '1f24', '2f02', '2f05', '2f07', '2f08', '2f09', '2f16', '2f17',  '2f22', '2f23']\n",
        "        labels = [\"voice_0\", \"voice_1\", \"voice_2\", \"voice_3\", \"voice_all\"]\n",
        "        self.labels = labels\n",
        "        self.pr_dict = {}\n",
        "        len_list = []\n",
        "        nbr_voices_list = []\n",
        "        file_names_list = []\n",
        "\n",
        "        for iLabel in range(len(labels)):\n",
        "            \n",
        "            if iLabel == 4:   \n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\")))   \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: ### normal sollte es egal sein wenn voice_4 bei manchen nicht existiert - wenn nicht condition einführen damit das funktioniert\n",
        "                        loaded_obj = pickle.load(f)  \n",
        "                        voice_files.append(loaded_obj) \n",
        "                        len_list.append(len(loaded_obj.T))\n",
        "\n",
        "                        file_names_list.append(name[-8:-4])\n",
        "\n",
        "                    if \"AI-MA_project/bach_pr_fugues/voice_3/voice_3_\" + name[49:53] + \".pkl\" in sorted(glob.glob(os.path.join(PATH_TO_DATA, \"voice_3\", \"*.pkl\"))):\n",
        "                        nbr_voices_list.append(4)\n",
        "                    else:\n",
        "                        nbr_voices_list.append(3)\n",
        "                        \n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                self.pr_dict[\"length\"] = len_list\n",
        "                self.pr_dict[\"nbr_voices\"] = nbr_voices_list\n",
        "                self.pr_dict[\"name\"] = file_names_list\n",
        "                #print(self.pr_dict[\"name\"])\n",
        "\n",
        "\n",
        "            if iLabel == 3:  \n",
        "                voice_files = []\n",
        "                file_names_3 = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                file_names_2 = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[2], \"*.pkl\")))   \n",
        "                \n",
        "                ###### loop over all filnames in voices_2 and if an element there is not present in voices_3: append \"missing\" to the voice_files of label=3 => important bc. self.pr_dict[voice_3] has then len 42 and otherwise it would only have len 18  .. these \"missing\" el are not considered later in the dataloader (if len=3 is a diff case of get_idx)\n",
        "                for name in file_names_2:\n",
        "                    if name[45:49] in self.name_list_voice_3:\n",
        "                      correct_name_3 = \"AI-MA_project/bach_pr_fugues/voice_3/voice_3_\" + name[45:49] + \".pkl\"\n",
        "                      with open(correct_name_3 ,'rb') as f:  \n",
        "                            loaded_obj = pickle.load(f)  \n",
        "                            voice_files.append(loaded_obj)\n",
        "                    else:\n",
        "                      voice_files.append(\"missing\")\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                \n",
        "\n",
        "                \n",
        "            else:\n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: \n",
        "                          loaded_obj = pickle.load(f)     \n",
        "                          voice_files.append(loaded_obj)\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pr_dict[self.labels[0]])\n",
        "\n",
        "    def __getitem__(self, idx):      \n",
        "        out_list = []\n",
        "        \n",
        "        if self.pr_dict[\"nbr_voices\"][idx] == 4:\n",
        "            for key, value in self.pr_dict.items():\n",
        "              out_list.append(self.pr_dict[key][idx])\n",
        "                              \n",
        "            v0 = torch.tensor(out_list[0].T)\n",
        "            v1 = torch.tensor(out_list[1].T)\n",
        "            v2 = torch.tensor(out_list[2].T)\n",
        "            v3 = torch.tensor(out_list[3].T)\n",
        "            v_all = torch.tensor(out_list[4].T) \n",
        "            length = self.pr_dict[\"length\"][idx]\n",
        "            nbr_voices = self.pr_dict[\"nbr_voices\"][idx]\n",
        "            file_name = self.pr_dict[\"name\"][idx]\n",
        "\n",
        "            voices = torch.stack([v0, v1, v2, v3, v_all], dim=2)\n",
        "            \n",
        "            return (voices, length, nbr_voices, file_name)\n",
        "        \n",
        "        if self.pr_dict[\"nbr_voices\"][idx] == 3:\n",
        "\n",
        "            for key, value in self.pr_dict.items():\n",
        "                if key != \"voice_3\":\n",
        "                  out_list.append(self.pr_dict[key][idx]) \n",
        "            \n",
        "            v0 = torch.tensor(out_list[0].T)\n",
        "            v1 = torch.tensor(out_list[1].T)\n",
        "            v2 = torch.tensor(out_list[2].T)\n",
        "            v3 = torch.zeros(v2.shape)\n",
        "            v_all = torch.tensor(out_list[3].T) \n",
        "            length = self.pr_dict[\"length\"][idx]\n",
        "            nbr_voices = self.pr_dict[\"nbr_voices\"][idx]\n",
        "            file_name = self.pr_dict[\"name\"][idx]\n",
        "            \n",
        "            voices = torch.stack([v0, v1, v2, v3, v_all], dim=2)\n",
        "\n",
        "            \n",
        "            return (voices, length, nbr_voices, file_name)\n",
        "        "
      ],
      "metadata": {
        "id": "3FxK6qr1FqIl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicDataset_chor(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        labels = [\"voice_0\", \"voice_1\", \"voice_2\", \"voice_3\", \"voice_all\"]\n",
        "        self.labels = labels\n",
        "        self.pr_dict = {}\n",
        "        len_list = []\n",
        "        nbr_voices_list = []\n",
        "        file_names_list = []\n",
        "\n",
        "        for iLabel in range(len(labels)):\n",
        "            \n",
        "            if iLabel == 4:   \n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\")))   \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: ### normal sollte es egal sein wenn voice_4 bei manchen nicht existiert - wenn nicht condition einführen damit das funktioniert\n",
        "                        loaded_obj = pickle.load(f)  \n",
        "                        voice_files.append(loaded_obj) \n",
        "                        len_list.append(len(loaded_obj.T))\n",
        "                        file_names_list.append(name[-7:-4])      # e.g. name = AI-MA_project/pianoroll_88/voice_all/voice_all_001.pkl\n",
        "\n",
        "                        \n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                self.pr_dict[\"length\"] = len_list\n",
        "                self.pr_dict[\"name\"] = file_names_list\n",
        "                #print(self.pr_dict[\"name\"])\n",
        "              \n",
        "\n",
        "            else:\n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: \n",
        "                        loaded_obj = pickle.load(f)     \n",
        "                        voice_files.append(loaded_obj)\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pr_dict[self.labels[0]])\n",
        "\n",
        "    def __getitem__(self, idx):      \n",
        "        out_list = []\n",
        "        \n",
        "        for key, value in self.pr_dict.items():\n",
        "            out_list.append(self.pr_dict[key][idx])\n",
        "                            \n",
        "        v0 = torch.tensor(out_list[0].T)\n",
        "        v1 = torch.tensor(out_list[1].T)\n",
        "        v2 = torch.tensor(out_list[2].T)\n",
        "        v3 = torch.tensor(out_list[3].T)\n",
        "        v_all = torch.tensor(out_list[4].T) \n",
        "        length = self.pr_dict[\"length\"][idx]\n",
        "        file_name = self.pr_dict[\"name\"][idx]\n",
        "\n",
        "        voices = torch.stack([v0, v1, v2, v3, v_all], dim=2)\n",
        "        \n",
        "        return (voices, length, 4, file_name)     # 4 bc nbr voices is always 4"
      ],
      "metadata": {
        "id": "3uQnok3VGngZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oTPIsBwPAJg"
      },
      "source": [
        "dataset = MusicDataset_chor(PATH_TO_DATA)\n",
        "#dataset = MusicDataset_new(PATH_TO_DATA)\n",
        "loader = torch.utils.data.DataLoader(dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for i, sample_batched in enumerate(loader):\n",
        "    all_voices, length, nbr_voices = sample_batched\n",
        "    if nbr_voices ==3:\n",
        "      print(i,nbr_voices,all_voices.shape)\n",
        "    else:\n",
        "      print(i,nbr_voices)\n",
        "\"\"\"\n",
        "for i, sample_batched in enumerate(loader):\n",
        "    if i == 1:\n",
        "        all_voices, length, nbr_voices, file_name = sample_batched\n",
        "        print(file_name[0],nbr_voices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXsRYzQSUuQU",
        "outputId": "a5e06933-81cc-4cd9-e8fc-6768e386e450"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "002 tensor([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pianoroll_0 = all_voices.squeeze()[:,:,0].numpy()\n",
        "pianoroll_1 = all_voices.squeeze()[:,:,1].numpy()\n",
        "pianoroll_2 = all_voices.squeeze()[:,:,2].numpy()\n",
        "pianoroll_3 = all_voices.squeeze()[:,:,3].numpy()\n",
        "pianoroll_all = all_voices.squeeze()[:,:,-1].numpy()\n",
        "\n",
        "time_unit = \"beat\"\n",
        "time_div = 12\n",
        "piano_range = True"
      ],
      "metadata": {
        "id": "fR2HaA_BqeHw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, figsize=(20, 10))\n",
        "ax.imshow(pianoroll_all, origin=\"lower\", cmap='gray', interpolation='nearest', aspect='auto')\n",
        "ax.set_xlabel(f'Time ({time_unit}s/{time_div})')\n",
        "ax.set_ylabel('Piano key' if piano_range else 'MIDI pitch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "sRoyBJJVqX_u",
        "outputId": "dd6e619c-906b-4b4a-dc8a-93a278446a97"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for i, sample_batched in enumerate(loader):\n",
        "    all_voices, length, nbr_voices = sample_batched\n",
        "    if nbr_voices ==3:\n",
        "      print(i,nbr_voices,all_voices.shape)\n",
        "    else:\n",
        "      print(i,nbr_voices)\n",
        "\n",
        "for i, sample_batched in enumerate(loader):\n",
        "  if i ==10:\n",
        "    all_voices, length, nbr_voices, _ = sample_batched\n",
        "    all_voices_pr = all_voices[0,:,:,-1].numpy()\n",
        "    \n",
        "    note_array = partitura.utils.pianoroll_to_notearray(all_voices[0,:,:,-1].numpy(), time_div=12, time_unit='beat')\n",
        "    print(note_array.shape)\n",
        "    print(note_array[:10])\n",
        "    print(note_array.dtype.names)\n",
        "\n",
        "    #print(i,nbr_voices,all_voices.shape)\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "b4QCaMEi3nw7",
        "outputId": "f1024368-c21b-4f59-ecdc-91b465b810bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor i, sample_batched in enumerate(loader):\\n    all_voices, length, nbr_voices = sample_batched\\n    if nbr_voices ==3:\\n      print(i,nbr_voices,all_voices.shape)\\n    else:\\n      print(i,nbr_voices)\\n\\nfor i, sample_batched in enumerate(loader):\\n  if i ==10:\\n    all_voices, length, nbr_voices, _ = sample_batched\\n    all_voices_pr = all_voices[0,:,:,-1].numpy()\\n    \\n    note_array = partitura.utils.pianoroll_to_notearray(all_voices[0,:,:,-1].numpy(), time_div=12, time_unit='beat')\\n    print(note_array.shape)\\n    print(note_array[:10])\\n    print(note_array.dtype.names)\\n\\n    #print(i,nbr_voices,all_voices.shape)\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Music - Model\n"
      ],
      "metadata": {
        "id": "JNqxeacDwxNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define UNET "
      ],
      "metadata": {
        "id": "QAIfIM69VHI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels=1, classes=1):\n",
        "        super(UNET, self).__init__()\n",
        "        self.layers = [in_channels, 64, 128, 256, 512, 1024]\n",
        "        \n",
        "        self.double_conv_downs = nn.ModuleList([self.__double_conv(layer, layer_n) for layer, layer_n in zip(self.layers[:-1], self.layers[1:])])\n",
        "        \n",
        "        self.up_trans = nn.ModuleList([nn.ConvTranspose2d(layer, layer_n, kernel_size=2, stride=2) for layer, layer_n in zip(self.layers[::-1][:-2], self.layers[::-1][1:-1])])\n",
        "            \n",
        "        self.double_conv_ups = nn.ModuleList([self.__double_conv(layer, layer//2) for layer in self.layers[::-1][:-2]])\n",
        "        \n",
        "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.final_conv = nn.Conv2d(64, classes, kernel_size=1)\n",
        "\n",
        "        \n",
        "    def __double_conv(self, in_channels, out_channels):\n",
        "        conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        return conv\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # down layers\n",
        "        concat_layers = []\n",
        "        \n",
        "        for down in self.double_conv_downs:\n",
        "            x = down(x)\n",
        "            if down != self.double_conv_downs[-1]:\n",
        "                concat_layers.append(x)\n",
        "                x = self.max_pool_2x2(x)\n",
        "        \n",
        "        concat_layers = concat_layers[::-1]\n",
        "        \n",
        "        # up layers\n",
        "        for up_trans, double_conv_up, concat_layer  in zip(self.up_trans, self.double_conv_ups, concat_layers):\n",
        "            x = up_trans(x)\n",
        "            if x.shape != concat_layer.shape:\n",
        "                x = TF.resize(x, concat_layer.shape[2:])\n",
        "            \n",
        "            concatenated = torch.cat((concat_layer, x), dim=1)\n",
        "            x = double_conv_up(concatenated)\n",
        "            \n",
        "        x = self.final_conv(x)\n",
        "        \n",
        "        return x "
      ],
      "metadata": {
        "id": "XMdlm0_Vyyhc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_0 = []\n",
        "loss_1 = []\n",
        "loss_2 = []\n",
        "loss_3 = []\n",
        "class MusicNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, network_type,output_dim=88, hidden_dim=300, rnn_depth=1, cell_type=\"GRU\"):                 \n",
        "        super(MusicNetwork, self).__init__()\n",
        "\n",
        "        self.network_type = network_type\n",
        "        self.n_out = output_dim\n",
        "        input_dim = output_dim \n",
        "        rnn_cell = nn.GRU\n",
        "        self.rnn = rnn_cell(input_size=input_dim, hidden_size=hidden_dim, num_layers=rnn_depth, batch_first=True)\n",
        "        self.cnn = UNET(in_channels=1, classes=4)\n",
        "        self.top_layer_voice_0 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_1 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_2 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_3 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.loss = nn.CrossEntropyLoss(reduction=\"mean\")                       # use weight parameters maybe take 1/88       \n",
        "\n",
        "    \n",
        "\n",
        "    def compute_outputs(self, sentences, sentences_len):\n",
        "        if self.network_type == \"RNN\":\n",
        "          rnn_out ,_= self.rnn(sentences)     \n",
        "          out_0 = self.top_layer_voice_0(rnn_out)\n",
        "          out_1 = self.top_layer_voice_1(rnn_out)\n",
        "          out_2 = self.top_layer_voice_2(rnn_out)\n",
        "          out_3 = self.top_layer_voice_3(rnn_out)\n",
        "\n",
        "          return torch.stack([out_0, out_1, out_2, out_3], dim=1)\n",
        "\n",
        "        else: \n",
        "          sentences = sentences[:,None]\n",
        "          out = self.cnn(sentences)\n",
        "          return out                      ### squeeze output here before returning                                       \n",
        "        \n",
        "\n",
        "    def forward(self, voices, sentences_len, nbr_voices):            \n",
        "\n",
        "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
        "        scores_comb = self.compute_outputs(voices[:,:,:,-1], sentences_len)\n",
        "\n",
        "        # Flatten the outputs and the labels, to compute the loss.\n",
        "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
        "        score_0  = scores_comb[:,0,:,:].view(-1, self.n_out)\n",
        "        score_1  = scores_comb[:,1,:,:].view(-1, self.n_out)\n",
        "        score_2  = scores_comb[:,2,:,:].view(-1, self.n_out)\n",
        "        score_3  = scores_comb[:,3,:,:].view(-1, self.n_out)\n",
        "\n",
        "\n",
        "        v0 = voices[:,:,:,0].squeeze()\n",
        "        v1 = voices[:,:,:,1].squeeze()\n",
        "        v2 = voices[:,:,:,2].squeeze()\n",
        "        v3 = voices[:,:,:,3].squeeze()\n",
        "\n",
        "        #print(\"nbr_voices\",nbr_voices)\n",
        "\n",
        "\n",
        "        if nbr_voices==4:\n",
        "            loss = self.loss(score_0, v0) +  self.loss(score_1, v1) +  self.loss(score_2, v2) + 1.5* self.loss(score_3, v3) \n",
        "            \n",
        "            loss_0.append(self.loss(score_0, v0).cpu().detach().numpy())\n",
        "            loss_1.append(self.loss(score_1, v1).cpu().detach().numpy())\n",
        "            loss_2.append(self.loss(score_2, v2).cpu().detach().numpy())\n",
        "            loss_3.append(self.loss(score_3, v3).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_0, v0)\",self.loss(score_0, v0).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_0, v1)\",self.loss(score_1, v1).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_0, v2)\",self.loss(score_2, v2).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_2, v3)\",self.loss(score_3, v3).cpu().detach().numpy())\n",
        "            print(\"loss\",loss)      \n",
        "        else:\n",
        "            loss = self.loss(score_0, v0) + self.loss(score_1, v1) + self.loss(score_2, v2) \n",
        "        \n",
        "        return loss   #change also to matrix version\n",
        "        \n",
        "\n",
        "\n",
        "    def predict(self, sentences, sentences_len,monophonic=True):\n",
        "\n",
        "        # Compute the outputs from the linear units.\n",
        "\n",
        "        scores_comb = self.compute_outputs(sentences, sentences_len)\n",
        "\n",
        "        if monophonic==False:\n",
        "            sum = scores_comb * sentences[:,None,:,:]\n",
        "            return np.squeeze(sum.cpu().numpy())\n",
        "            \n",
        "\n",
        "        else:\n",
        "            # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
        "            #predicted = scores_comb.argmax(dim=3)\n",
        "            #return np.squeeze(predicted.cpu().numpy())\n",
        "\n",
        "            sum_tensor = scores_comb * sentences[:,None,:,:]\n",
        "            prediction = np.squeeze(sum_tensor.cpu().numpy())                # prediction is of shape 4,T,88 and contains a probability for the result to belong to one of the 4 voices -> taking argmax: gives the voice with the highes probability\n",
        "            v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "            \n",
        "            mask_pred = np.squeeze(sentences)== 0\n",
        "            v_pred_argm[mask_pred] = -1\n",
        "\n",
        "            return v_pred_argm \n",
        "                       "
      ],
      "metadata": {
        "id": "CviiPTPOPW04"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= \"CNN\"\n",
        "lr = 0.0001  \n",
        "monophonic = True\n",
        "his = start_experiment(10, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "79cPe11WL6J0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c115ffef-bad3-457f-e26e-5eb3b6110b27"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= \"CNN\"\\nlr = 0.0001  \\nmonophonic = True\\nhis = start_experiment(10, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07I2QbRDbUlA"
      },
      "source": [
        "# Define Training Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHESuQEQbVRB"
      },
      "source": [
        "def train(epochs, lr, hidden_dim, momentum, rnn_depth, device, rnn_cell, weight_decay,network_type, train_dataloader, val_dataloader=None):\n",
        "    \n",
        "    output_dim = 88\n",
        "    model = MusicNetwork(network_type, output_dim, hidden_dim, rnn_depth, cell_type)              \n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = lr_scheduler.MultiStepLR(optimizer, [epochs // 2], gamma=0.1, verbose=True)\n",
        "\n",
        "    history = training_loop(model, optimizer, train_dataloader,monophonic, epochs=epochs, val_dataloader=val_dataloader, device=device, scheduler=scheduler)\n",
        "\n",
        "    return model, history"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG_ONds0bkt-"
      },
      "source": [
        "def training_loop(model,optimizer, train_dataloader, monophonic, epochs=50, val_dataloader=None, device=None, scheduler=None):\n",
        "    if device is None:\n",
        "        device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "        print(f\"Training on device: {device}\")\n",
        "\n",
        "    print(\"monophonic set to:\",monophonic)\n",
        "    model = model.to(device)\n",
        "    history = defaultdict(list)\n",
        "\n",
        "    for i_epoch in range(1, epochs + 1):\n",
        "        loss_sum = 0\n",
        "\n",
        "        accuracy_sum_list = [0 for i in range(5)]                                   ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "        val_accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "\n",
        "        accuracy_v_all_sum = 0\n",
        "        model.train()\n",
        "        accuracy_sum = 0\n",
        "        \n",
        "        \n",
        "        for idx, (voices, lens, nbr_voices, _) in enumerate(train_dataloader):  \n",
        "            \n",
        "            voices = voices.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            loss = model.forward(voices, lens, nbr_voices)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()    \n",
        "\n",
        "            if monophonic == False:\n",
        "                with torch.no_grad():\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                    mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                    \n",
        "                    single_voices = voices[:,:,:,:-1]             \n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "\n",
        "            if monophonic == True:\n",
        "                with torch.no_grad():\n",
        "                    ### before\n",
        "                    #prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                    #prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "                    #truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "                    #acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "                    #for i in range(len(prediction[0,:])):\n",
        "                    #  acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                    #  accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "\n",
        "                    #prediction = model.predict(voices, lens, monophonic)                    #for voice vise masking\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)         #for mixed voice masking        \n",
        "\n",
        "\n",
        "                    ## ground truth in shape 1280x88 -> mixed voice\n",
        "                    single_voices = voices[:,:,:,:-1]\n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    truth = v_ori_argm       \n",
        "\n",
        "                    # outsource accurcy to further down -> just a placeholder right now\n",
        "                    v_pred_flat = torch.flatten(prediction, start_dim=0, end_dim=-1)\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "\n",
        "\n",
        "        train_loss = loss_sum / len(train_dataloader)\n",
        "\n",
        "        # normalize according to the number of batches\n",
        "        if monophonic == True:\n",
        "\n",
        "            #train_acc_list = np.array(accuracy_sum_list) / len(train_dataloader)\n",
        "            #train_acc_list[3] = accuracy_sum_list[3] / 18                        ## bc only 18 pieces with len 3\n",
        "            #train_acc_list[4] = accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "            #history[\"train_loss\"].append(train_loss)\n",
        "            #history[\"train_acc\"].append(train_acc_list)\n",
        "            #print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}, Train Accuracy_4 : {}\".format(train_loss, train_acc_list[0], train_acc_list[1], train_acc_list[2], train_acc_list[3],train_acc_list[4])) \n",
        "            \n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "        if monophonic == False:\n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "\n",
        "        if monophonic == True:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for voices, lens, nbr_voices, _ in val_dataloader:\n",
        "                        voices = voices.to(device).float()\n",
        "                        ### before\n",
        "                        #prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        #prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "                        #truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "                        #acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "                        #for i in range(len(prediction[0,:])):\n",
        "                        #  acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                        #  val_accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "                    #val_acc_list = np.array(val_accuracy_sum_list) / len(val_dataloader)\n",
        "                    #val_acc_list[3] = val_accuracy_sum_list[3] / 18                         ## bc only 18 pieces with len 3\n",
        "                    #val_acc_list[4] = val_accuracy_sum_list[4] / 2                          ##### CHECK IF 2 or 3 pieces with len 4\n",
        "                #history[\"val_acc\"].append(val_acc_list)\n",
        "                #print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "\n",
        "                        #prediction = model.predict(voices, lens, monophonic)                #for voice vise masking\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)     # for masking with mixed voice\n",
        "\n",
        "\n",
        "\n",
        "                        ## ground truth in shape 1280x88 -> mixed voice\n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        truth = v_ori_argm       \n",
        "\n",
        "                        # outsource accurcy to further down -> just a placeholder right now\n",
        "                        v_pred_flat = torch.flatten(prediction, start_dim=0, end_dim=-1)\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "                    \n",
        "                history[\"val_acc\"].append(val_accuracy)\n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "\n",
        "        if monophonic == False:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_sum = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    for voices, lens, nbr_voices, _ in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "                        \n",
        "                        # Predict the model's output on a batch\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                        v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                        mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                        \n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "                        \n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "\n",
        "                history[\"val_accuracy\"].append(val_accuracy)  \n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "        \n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "    # save the model\n",
        "    #torch.save(model, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "    torch.save({'model_state_dict': model.state_dict()}, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "\n",
        "    return history"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= \"RNN\"\n",
        "monophonic = True\n",
        "his = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ge8pY70uHxF9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a154206-c022-44fe-d02b-241dcf1ff8bd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= \"RNN\"\\nmonophonic = True\\nhis = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= [\"CNN\",\"RNN\"]\n",
        "monophonic_list = [True,False]\n",
        "\n",
        "for net in network_type:\n",
        "    for monophonic in monophonic_list: \n",
        "        print(\"network set to:\",net,\"monophnic:\",monophonic)\n",
        "        start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, net, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2Bs6-iNEBu8o",
        "outputId": "5d734c0b-336c-4264-fbd5-0cd5206254b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= [\"CNN\",\"RNN\"]\\nmonophonic_list = [True,False]\\n\\nfor net in network_type:\\n    for monophonic in monophonic_list: \\n        print(\"network set to:\",net,\"monophnic:\",monophonic)\\n        start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, net, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sBoQnA6bo71"
      },
      "source": [
        "def start_experiment( epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell, decay,network_type, learn_all):\n",
        "    \n",
        "    trainer = partial(train,epochs, lr, hidden_dim, momentum, rnn_depth, device, cell, decay, network_type)\n",
        "\n",
        "    if learn_all == True:\n",
        "        print(\"Learning from full dataset\")\n",
        "        ### uncomment for fugues ###\n",
        "        #train_dataset = MusicDataset_new(PATH_TO_DATA) \n",
        "        ### uncomment for chorals ###\n",
        "        train_dataset = MusicDataset_chor(PATH_TO_DATA) \n",
        "\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "                \n",
        "        _, history = trainer(train_dataloader)\n",
        "\n",
        "    \n",
        "    else:\n",
        "        # Divide train and validation set\n",
        "        ### uncomment for fugues ###\n",
        "        #dataset = MusicDataset_new(PATH_TO_DATA) \n",
        "        ### uncomment for chorals ###\n",
        "        dataset = MusicDataset_chor(PATH_TO_DATA)\n",
        "        \n",
        "        \n",
        "        train_dataset, validation_dataset = sklearn.model_selection.train_test_split(dataset, test_size=0.15, random_state=10,)\n",
        "\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "        val_dataloader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "\n",
        "        print(\"train_dataloader\",len(train_dataloader),\"val_dataloader\",len(val_dataloader))\n",
        "\n",
        "        \"\"\"\n",
        "        path_train, path_validation = sklearn.model_selection.train_test_split(PATH_TO_DATA, test_size=0.15, random_state=10,)\n",
        "\n",
        "        print(\"Train and validation lenghts: \", len(path_train), len(path_validation))\n",
        "        #train_dataset = MusicDataset_new(PATH_TO_DATA) #MusicDataset(PATH_TO_DATA)\n",
        "        train_dataset = MusicDataset_new(path_train)\n",
        "        validation_dataset = MusicDataset_new(path_validation) #MusicDataset(path_validation)\n",
        "\n",
        "        \n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "        val_dataloader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "        \"\"\"\n",
        "        \n",
        "        _, history = trainer(train_dataloader, val_dataloader)\n",
        "\n",
        "    return history, val_dataloader"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgtn-a7bMTf7"
      },
      "source": [
        "# Hyperparameter choice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNI9b6jKLpOX"
      },
      "source": [
        "model = MusicNetwork\n",
        "epochs = 5\n",
        "lr = 0.00001 # was 0.001\n",
        "momentum = 0.9\n",
        "decay = 1e-4\n",
        "hidden_dim = 300\n",
        "bs = 1\n",
        "rnn_depth = 2 \n",
        "device = None                 #if None:  choses device automatically\n",
        "cell_type = \"GRU\"\n",
        "optimizer = \"Adam\"\n",
        "learn_all = \"False\"           # False -> uses train and valid set\n",
        "network_type= \"CNN\"\n",
        "\n",
        "monophonic = True"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the Experiment"
      ],
      "metadata": {
        "id": "bdetlQP-LoRX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1LTlFJddpwm",
        "outputId": "60917096-85f1-4b56-df1f-1201de4de9f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "his, val_dataloader = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "self.loss(score_0, v2) 0.20279644\n",
            "self.loss(score_2, v3) 0.0881656\n",
            "loss tensor(0.7994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.122259386\n",
            "self.loss(score_0, v1) 0.21723199\n",
            "self.loss(score_0, v2) 0.17095412\n",
            "self.loss(score_2, v3) 0.06462679\n",
            "loss tensor(0.6074, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08949609\n",
            "self.loss(score_0, v1) 0.15687954\n",
            "self.loss(score_0, v2) 0.13234724\n",
            "self.loss(score_2, v3) 0.071119085\n",
            "loss tensor(0.4854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.24192932\n",
            "self.loss(score_0, v1) 0.27442297\n",
            "self.loss(score_0, v2) 0.16331276\n",
            "self.loss(score_2, v3) 0.06952229\n",
            "loss tensor(0.7839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0949927\n",
            "self.loss(score_0, v1) 0.3324908\n",
            "self.loss(score_0, v2) 0.29044643\n",
            "self.loss(score_2, v3) 0.07077604\n",
            "loss tensor(0.8241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13892874\n",
            "self.loss(score_0, v1) 0.17983383\n",
            "self.loss(score_0, v2) 0.10319259\n",
            "self.loss(score_2, v3) 0.07950783\n",
            "loss tensor(0.5412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11072789\n",
            "self.loss(score_0, v1) 0.21787812\n",
            "self.loss(score_0, v2) 0.13874184\n",
            "self.loss(score_2, v3) 0.08293605\n",
            "loss tensor(0.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14750972\n",
            "self.loss(score_0, v1) 0.3142355\n",
            "self.loss(score_0, v2) 0.26997623\n",
            "self.loss(score_2, v3) 0.09054471\n",
            "loss tensor(0.8675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16281432\n",
            "self.loss(score_0, v1) 0.29460537\n",
            "self.loss(score_0, v2) 0.18797016\n",
            "self.loss(score_2, v3) 0.0811045\n",
            "loss tensor(0.7670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17787892\n",
            "self.loss(score_0, v1) 0.19186527\n",
            "self.loss(score_0, v2) 0.10292995\n",
            "self.loss(score_2, v3) 0.061500352\n",
            "loss tensor(0.5649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.116238356\n",
            "self.loss(score_0, v1) 0.181039\n",
            "self.loss(score_0, v2) 0.16277738\n",
            "self.loss(score_2, v3) 0.073135786\n",
            "loss tensor(0.5698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09917594\n",
            "self.loss(score_0, v1) 0.13332428\n",
            "self.loss(score_0, v2) 0.10569371\n",
            "self.loss(score_2, v3) 0.06786384\n",
            "loss tensor(0.4400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07656095\n",
            "self.loss(score_0, v1) 0.123473145\n",
            "self.loss(score_0, v2) 0.13485563\n",
            "self.loss(score_2, v3) 0.062129218\n",
            "loss tensor(0.4281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13770308\n",
            "self.loss(score_0, v1) 0.39504874\n",
            "self.loss(score_0, v2) 0.36693755\n",
            "self.loss(score_2, v3) 0.07802579\n",
            "loss tensor(1.0167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10804544\n",
            "self.loss(score_0, v1) 0.5021415\n",
            "self.loss(score_0, v2) 0.43609396\n",
            "self.loss(score_2, v3) 0.091708854\n",
            "loss tensor(1.1838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10661023\n",
            "self.loss(score_0, v1) 0.13401824\n",
            "self.loss(score_0, v2) 0.097441845\n",
            "self.loss(score_2, v3) 0.063874975\n",
            "loss tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10206574\n",
            "self.loss(score_0, v1) 0.31857967\n",
            "self.loss(score_0, v2) 0.32608992\n",
            "self.loss(score_2, v3) 0.059461366\n",
            "loss tensor(0.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1914889\n",
            "self.loss(score_0, v1) 0.23807842\n",
            "self.loss(score_0, v2) 0.18200247\n",
            "self.loss(score_2, v3) 0.18969703\n",
            "loss tensor(0.8961, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08140678\n",
            "self.loss(score_0, v1) 0.15681174\n",
            "self.loss(score_0, v2) 0.19302523\n",
            "self.loss(score_2, v3) 0.07370664\n",
            "loss tensor(0.5418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1998636\n",
            "self.loss(score_0, v1) 0.22723164\n",
            "self.loss(score_0, v2) 0.14631397\n",
            "self.loss(score_2, v3) 0.08090133\n",
            "loss tensor(0.6948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13853854\n",
            "self.loss(score_0, v1) 0.19232194\n",
            "self.loss(score_0, v2) 0.10455055\n",
            "self.loss(score_2, v3) 0.07217338\n",
            "loss tensor(0.5437, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16065277\n",
            "self.loss(score_0, v1) 0.22392279\n",
            "self.loss(score_0, v2) 0.131986\n",
            "self.loss(score_2, v3) 0.07374042\n",
            "loss tensor(0.6272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08721178\n",
            "self.loss(score_0, v1) 0.10330107\n",
            "self.loss(score_0, v2) 0.062495317\n",
            "self.loss(score_2, v3) 0.046272244\n",
            "loss tensor(0.3224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.092751786\n",
            "self.loss(score_0, v1) 0.17275013\n",
            "self.loss(score_0, v2) 0.17334108\n",
            "self.loss(score_2, v3) 0.06206976\n",
            "loss tensor(0.5319, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.080540426\n",
            "self.loss(score_0, v1) 0.13818008\n",
            "self.loss(score_0, v2) 0.09231272\n",
            "self.loss(score_2, v3) 0.06347476\n",
            "loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0689649\n",
            "self.loss(score_0, v1) 0.5852548\n",
            "self.loss(score_0, v2) 0.5303809\n",
            "self.loss(score_2, v3) 0.06687253\n",
            "loss tensor(1.2849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08789352\n",
            "self.loss(score_0, v1) 0.14368746\n",
            "self.loss(score_0, v2) 0.15696217\n",
            "self.loss(score_2, v3) 0.07105612\n",
            "loss tensor(0.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.20219445\n",
            "self.loss(score_0, v1) 0.26318064\n",
            "self.loss(score_0, v2) 0.10212522\n",
            "self.loss(score_2, v3) 0.06701376\n",
            "loss tensor(0.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13109352\n",
            "self.loss(score_0, v1) 0.16207701\n",
            "self.loss(score_0, v2) 0.09616991\n",
            "self.loss(score_2, v3) 0.083814375\n",
            "loss tensor(0.5151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.092970155\n",
            "self.loss(score_0, v1) 0.17002158\n",
            "self.loss(score_0, v2) 0.29430413\n",
            "self.loss(score_2, v3) 0.25167894\n",
            "loss tensor(0.9348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.099514395\n",
            "self.loss(score_0, v1) 0.1856755\n",
            "self.loss(score_0, v2) 0.11737385\n",
            "self.loss(score_2, v3) 0.07998518\n",
            "loss tensor(0.5225, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07796363\n",
            "self.loss(score_0, v1) 0.13132341\n",
            "self.loss(score_0, v2) 0.090395875\n",
            "self.loss(score_2, v3) 0.06880569\n",
            "loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13177924\n",
            "self.loss(score_0, v1) 0.17808756\n",
            "self.loss(score_0, v2) 0.100562245\n",
            "self.loss(score_2, v3) 0.06311077\n",
            "loss tensor(0.5051, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09220537\n",
            "self.loss(score_0, v1) 0.14185339\n",
            "self.loss(score_0, v2) 0.106946334\n",
            "self.loss(score_2, v3) 0.062174216\n",
            "loss tensor(0.4343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07952007\n",
            "self.loss(score_0, v1) 0.25867227\n",
            "self.loss(score_0, v2) 0.22909954\n",
            "self.loss(score_2, v3) 0.08210116\n",
            "loss tensor(0.6904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08335144\n",
            "self.loss(score_0, v1) 0.17254573\n",
            "self.loss(score_0, v2) 0.15216617\n",
            "self.loss(score_2, v3) 0.05670237\n",
            "loss tensor(0.4931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06779191\n",
            "self.loss(score_0, v1) 0.1802846\n",
            "self.loss(score_0, v2) 0.11510218\n",
            "self.loss(score_2, v3) 0.050644927\n",
            "loss tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10629512\n",
            "self.loss(score_0, v1) 0.40893272\n",
            "self.loss(score_0, v2) 0.30376276\n",
            "self.loss(score_2, v3) 0.07341051\n",
            "loss tensor(0.9291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15050837\n",
            "self.loss(score_0, v1) 0.26115415\n",
            "self.loss(score_0, v2) 0.15459795\n",
            "self.loss(score_2, v3) 0.08355173\n",
            "loss tensor(0.6916, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08528418\n",
            "self.loss(score_0, v1) 0.18126304\n",
            "self.loss(score_0, v2) 0.2207958\n",
            "self.loss(score_2, v3) 0.12509568\n",
            "loss tensor(0.6750, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10116961\n",
            "self.loss(score_0, v1) 0.13282493\n",
            "self.loss(score_0, v2) 0.1537305\n",
            "self.loss(score_2, v3) 0.067302145\n",
            "loss tensor(0.4887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11707886\n",
            "self.loss(score_0, v1) 0.14765444\n",
            "self.loss(score_0, v2) 0.08569281\n",
            "self.loss(score_2, v3) 0.05942837\n",
            "loss tensor(0.4396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.109566934\n",
            "self.loss(score_0, v1) 0.22580038\n",
            "self.loss(score_0, v2) 0.1905954\n",
            "self.loss(score_2, v3) 0.059193\n",
            "loss tensor(0.6148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.30366978\n",
            "self.loss(score_0, v1) 0.67938083\n",
            "self.loss(score_0, v2) 0.49004528\n",
            "self.loss(score_2, v3) 0.04167795\n",
            "loss tensor(1.5356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15406002\n",
            "self.loss(score_0, v1) 0.20447357\n",
            "self.loss(score_0, v2) 0.08326134\n",
            "self.loss(score_2, v3) 0.051753774\n",
            "loss tensor(0.5194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14432842\n",
            "self.loss(score_0, v1) 0.3067611\n",
            "self.loss(score_0, v2) 0.27104014\n",
            "self.loss(score_2, v3) 0.060414385\n",
            "loss tensor(0.8128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049698334\n",
            "self.loss(score_0, v1) 0.24102128\n",
            "self.loss(score_0, v2) 0.25078547\n",
            "self.loss(score_2, v3) 0.044257324\n",
            "loss tensor(0.6079, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1038089\n",
            "self.loss(score_0, v1) 0.21331011\n",
            "self.loss(score_0, v2) 0.17728083\n",
            "self.loss(score_2, v3) 0.067222744\n",
            "loss tensor(0.5952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.095446326\n",
            "self.loss(score_0, v1) 0.17221312\n",
            "self.loss(score_0, v2) 0.1298722\n",
            "self.loss(score_2, v3) 0.07235191\n",
            "loss tensor(0.5061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06647419\n",
            "self.loss(score_0, v1) 0.16847454\n",
            "self.loss(score_0, v2) 0.1135357\n",
            "self.loss(score_2, v3) 0.052746974\n",
            "loss tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09439888\n",
            "self.loss(score_0, v1) 0.162073\n",
            "self.loss(score_0, v2) 0.11807868\n",
            "self.loss(score_2, v3) 0.063755944\n",
            "loss tensor(0.4702, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10449599\n",
            "self.loss(score_0, v1) 0.19614531\n",
            "self.loss(score_0, v2) 0.19563359\n",
            "self.loss(score_2, v3) 0.055514347\n",
            "loss tensor(0.5795, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08104234\n",
            "self.loss(score_0, v1) 0.12584594\n",
            "self.loss(score_0, v2) 0.119190864\n",
            "self.loss(score_2, v3) 0.07963351\n",
            "loss tensor(0.4455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09502934\n",
            "self.loss(score_0, v1) 0.14822176\n",
            "self.loss(score_0, v2) 0.121668056\n",
            "self.loss(score_2, v3) 0.06040877\n",
            "loss tensor(0.4555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08016449\n",
            "self.loss(score_0, v1) 0.12428827\n",
            "self.loss(score_0, v2) 0.13788182\n",
            "self.loss(score_2, v3) 0.07239197\n",
            "loss tensor(0.4509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.105579235\n",
            "self.loss(score_0, v1) 0.30378237\n",
            "self.loss(score_0, v2) 0.2599318\n",
            "self.loss(score_2, v3) 0.06536409\n",
            "loss tensor(0.7673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.0977462306144132, Train Accuracy : 0.9986767073944656\n",
            " Validation Accuracy : 6.598744033918799\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.066157974\n",
            "self.loss(score_0, v1) 0.20461425\n",
            "self.loss(score_0, v2) 0.30252635\n",
            "self.loss(score_2, v3) 0.08039472\n",
            "loss tensor(0.6939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06018823\n",
            "self.loss(score_0, v1) 0.11059307\n",
            "self.loss(score_0, v2) 0.16670586\n",
            "self.loss(score_2, v3) 0.091282055\n",
            "loss tensor(0.4744, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2443959\n",
            "self.loss(score_0, v1) 0.37804767\n",
            "self.loss(score_0, v2) 0.18147059\n",
            "self.loss(score_2, v3) 0.05127493\n",
            "loss tensor(0.8808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1734637\n",
            "self.loss(score_0, v1) 0.29720762\n",
            "self.loss(score_0, v2) 0.1717121\n",
            "self.loss(score_2, v3) 0.06331194\n",
            "loss tensor(0.7374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08128632\n",
            "self.loss(score_0, v1) 0.25091207\n",
            "self.loss(score_0, v2) 0.25571308\n",
            "self.loss(score_2, v3) 0.046970017\n",
            "loss tensor(0.6584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07343841\n",
            "self.loss(score_0, v1) 0.11967319\n",
            "self.loss(score_0, v2) 0.08009772\n",
            "self.loss(score_2, v3) 0.051323444\n",
            "loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.069212995\n",
            "self.loss(score_0, v1) 0.114431724\n",
            "self.loss(score_0, v2) 0.07415304\n",
            "self.loss(score_2, v3) 0.05562487\n",
            "loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08858604\n",
            "self.loss(score_0, v1) 0.12179821\n",
            "self.loss(score_0, v2) 0.07357163\n",
            "self.loss(score_2, v3) 0.044782657\n",
            "loss tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08414129\n",
            "self.loss(score_0, v1) 0.13160491\n",
            "self.loss(score_0, v2) 0.12076464\n",
            "self.loss(score_2, v3) 0.06033255\n",
            "loss tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077586494\n",
            "self.loss(score_0, v1) 0.1217076\n",
            "self.loss(score_0, v2) 0.13484873\n",
            "self.loss(score_2, v3) 0.07015609\n",
            "loss tensor(0.4394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.111394785\n",
            "self.loss(score_0, v1) 0.45209518\n",
            "self.loss(score_0, v2) 0.34736258\n",
            "self.loss(score_2, v3) 0.061648298\n",
            "loss tensor(1.0033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09431538\n",
            "self.loss(score_0, v1) 0.152215\n",
            "self.loss(score_0, v2) 0.12997708\n",
            "self.loss(score_2, v3) 0.05110895\n",
            "loss tensor(0.4532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09684806\n",
            "self.loss(score_0, v1) 0.2341266\n",
            "self.loss(score_0, v2) 0.18297102\n",
            "self.loss(score_2, v3) 0.0497034\n",
            "loss tensor(0.5885, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1481803\n",
            "self.loss(score_0, v1) 0.20821996\n",
            "self.loss(score_0, v2) 0.19579177\n",
            "self.loss(score_2, v3) 0.053354308\n",
            "loss tensor(0.6322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.072105855\n",
            "self.loss(score_0, v1) 0.1281553\n",
            "self.loss(score_0, v2) 0.11621549\n",
            "self.loss(score_2, v3) 0.051868483\n",
            "loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21653771\n",
            "self.loss(score_0, v1) 0.24673462\n",
            "self.loss(score_0, v2) 0.09413761\n",
            "self.loss(score_2, v3) 0.07457127\n",
            "loss tensor(0.6693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.099168964\n",
            "self.loss(score_0, v1) 0.16129819\n",
            "self.loss(score_0, v2) 0.102153994\n",
            "self.loss(score_2, v3) 0.06018906\n",
            "loss tensor(0.4529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.087022685\n",
            "self.loss(score_0, v1) 0.14829156\n",
            "self.loss(score_0, v2) 0.119288675\n",
            "self.loss(score_2, v3) 0.05363469\n",
            "loss tensor(0.4351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.34254384\n",
            "self.loss(score_0, v1) 0.4271122\n",
            "self.loss(score_0, v2) 0.2643333\n",
            "self.loss(score_2, v3) 0.07430467\n",
            "loss tensor(1.1454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.099866055\n",
            "self.loss(score_0, v1) 0.19523375\n",
            "self.loss(score_0, v2) 0.20167592\n",
            "self.loss(score_2, v3) 0.06425841\n",
            "loss tensor(0.5932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1054864\n",
            "self.loss(score_0, v1) 0.15164945\n",
            "self.loss(score_0, v2) 0.11876369\n",
            "self.loss(score_2, v3) 0.059196275\n",
            "loss tensor(0.4647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14266025\n",
            "self.loss(score_0, v1) 0.17600489\n",
            "self.loss(score_0, v2) 0.08878319\n",
            "self.loss(score_2, v3) 0.06822632\n",
            "loss tensor(0.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06740489\n",
            "self.loss(score_0, v1) 0.125252\n",
            "self.loss(score_0, v2) 0.18195115\n",
            "self.loss(score_2, v3) 0.06465855\n",
            "loss tensor(0.4716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06421519\n",
            "self.loss(score_0, v1) 0.098308325\n",
            "self.loss(score_0, v2) 0.09291786\n",
            "self.loss(score_2, v3) 0.047244694\n",
            "loss tensor(0.3263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07637732\n",
            "self.loss(score_0, v1) 0.12069351\n",
            "self.loss(score_0, v2) 0.08755076\n",
            "self.loss(score_2, v3) 0.049042165\n",
            "loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08318705\n",
            "self.loss(score_0, v1) 0.1564348\n",
            "self.loss(score_0, v2) 0.11754194\n",
            "self.loss(score_2, v3) 0.06829277\n",
            "loss tensor(0.4596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09275402\n",
            "self.loss(score_0, v1) 0.19323361\n",
            "self.loss(score_0, v2) 0.12508789\n",
            "self.loss(score_2, v3) 0.059121765\n",
            "loss tensor(0.4998, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.074147835\n",
            "self.loss(score_0, v1) 0.13249189\n",
            "self.loss(score_0, v2) 0.10241135\n",
            "self.loss(score_2, v3) 0.065451615\n",
            "loss tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10301431\n",
            "self.loss(score_0, v1) 0.28918418\n",
            "self.loss(score_0, v2) 0.26049954\n",
            "self.loss(score_2, v3) 0.07019459\n",
            "loss tensor(0.7580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0734264\n",
            "self.loss(score_0, v1) 0.1240293\n",
            "self.loss(score_0, v2) 0.12539227\n",
            "self.loss(score_2, v3) 0.061572127\n",
            "loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09626167\n",
            "self.loss(score_0, v1) 0.38844144\n",
            "self.loss(score_0, v2) 0.28150764\n",
            "self.loss(score_2, v3) 0.056421753\n",
            "loss tensor(0.8508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.085303314\n",
            "self.loss(score_0, v1) 0.1207475\n",
            "self.loss(score_0, v2) 0.07483736\n",
            "self.loss(score_2, v3) 0.053552553\n",
            "loss tensor(0.3612, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.45749658\n",
            "self.loss(score_0, v1) 0.5196851\n",
            "self.loss(score_0, v2) 0.6662566\n",
            "self.loss(score_2, v3) 0.7590916\n",
            "loss tensor(2.7821, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09684217\n",
            "self.loss(score_0, v1) 0.117115356\n",
            "self.loss(score_0, v2) 0.08906214\n",
            "self.loss(score_2, v3) 0.06320598\n",
            "loss tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08256148\n",
            "self.loss(score_0, v1) 0.1403429\n",
            "self.loss(score_0, v2) 0.13902172\n",
            "self.loss(score_2, v3) 0.063118614\n",
            "loss tensor(0.4566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07961457\n",
            "self.loss(score_0, v1) 0.15849003\n",
            "self.loss(score_0, v2) 0.11152902\n",
            "self.loss(score_2, v3) 0.07185731\n",
            "loss tensor(0.4574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07428004\n",
            "self.loss(score_0, v1) 0.13258868\n",
            "self.loss(score_0, v2) 0.096145794\n",
            "self.loss(score_2, v3) 0.07284128\n",
            "loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.082180776\n",
            "self.loss(score_0, v1) 0.2131308\n",
            "self.loss(score_0, v2) 0.1936266\n",
            "self.loss(score_2, v3) 0.06574453\n",
            "loss tensor(0.5876, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15427974\n",
            "self.loss(score_0, v1) 0.21778883\n",
            "self.loss(score_0, v2) 0.10163457\n",
            "self.loss(score_2, v3) 0.07184855\n",
            "loss tensor(0.5815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.080913424\n",
            "self.loss(score_0, v1) 0.1592437\n",
            "self.loss(score_0, v2) 0.23463531\n",
            "self.loss(score_2, v3) 0.16999853\n",
            "loss tensor(0.7298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13978274\n",
            "self.loss(score_0, v1) 0.19343337\n",
            "self.loss(score_0, v2) 0.0652255\n",
            "self.loss(score_2, v3) 0.042291198\n",
            "loss tensor(0.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.26371104\n",
            "self.loss(score_0, v1) 0.6259887\n",
            "self.loss(score_0, v2) 0.3784009\n",
            "self.loss(score_2, v3) 0.05246867\n",
            "loss tensor(1.3468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09226586\n",
            "self.loss(score_0, v1) 0.14754467\n",
            "self.loss(score_0, v2) 0.11726062\n",
            "self.loss(score_2, v3) 0.06988865\n",
            "loss tensor(0.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061505876\n",
            "self.loss(score_0, v1) 0.11116517\n",
            "self.loss(score_0, v2) 0.10103554\n",
            "self.loss(score_2, v3) 0.055452127\n",
            "loss tensor(0.3569, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0858128\n",
            "self.loss(score_0, v1) 0.12910037\n",
            "self.loss(score_0, v2) 0.111504085\n",
            "self.loss(score_2, v3) 0.06127028\n",
            "loss tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07725077\n",
            "self.loss(score_0, v1) 0.14444442\n",
            "self.loss(score_0, v2) 0.10589736\n",
            "self.loss(score_2, v3) 0.05290099\n",
            "loss tensor(0.4069, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075652555\n",
            "self.loss(score_0, v1) 0.13647763\n",
            "self.loss(score_0, v2) 0.09617859\n",
            "self.loss(score_2, v3) 0.06877736\n",
            "loss tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0928497\n",
            "self.loss(score_0, v1) 0.26541436\n",
            "self.loss(score_0, v2) 0.24578798\n",
            "self.loss(score_2, v3) 0.05563709\n",
            "loss tensor(0.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.068443395\n",
            "self.loss(score_0, v1) 0.087775186\n",
            "self.loss(score_0, v2) 0.10165773\n",
            "self.loss(score_2, v3) 0.052815016\n",
            "loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08498457\n",
            "self.loss(score_0, v1) 0.17093515\n",
            "self.loss(score_0, v2) 0.15548207\n",
            "self.loss(score_2, v3) 0.068518616\n",
            "loss tensor(0.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17249975\n",
            "self.loss(score_0, v1) 0.5990708\n",
            "self.loss(score_0, v2) 0.44511038\n",
            "self.loss(score_2, v3) 0.07117696\n",
            "loss tensor(1.3234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073810145\n",
            "self.loss(score_0, v1) 0.12221139\n",
            "self.loss(score_0, v2) 0.08408271\n",
            "self.loss(score_2, v3) 0.058324516\n",
            "loss tensor(0.3676, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13294797\n",
            "self.loss(score_0, v1) 0.2768259\n",
            "self.loss(score_0, v2) 0.39064103\n",
            "self.loss(score_2, v3) 0.18080789\n",
            "loss tensor(1.0716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09931427\n",
            "self.loss(score_0, v1) 0.12784734\n",
            "self.loss(score_0, v2) 0.095228724\n",
            "self.loss(score_2, v3) 0.07003574\n",
            "loss tensor(0.4274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3537437\n",
            "self.loss(score_0, v1) 0.4489162\n",
            "self.loss(score_0, v2) 0.1606377\n",
            "self.loss(score_2, v3) 0.07713697\n",
            "loss tensor(1.0790, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10330043\n",
            "self.loss(score_0, v1) 0.17318082\n",
            "self.loss(score_0, v2) 0.15877986\n",
            "self.loss(score_2, v3) 0.0652074\n",
            "loss tensor(0.5331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13843529\n",
            "self.loss(score_0, v1) 0.21493088\n",
            "self.loss(score_0, v2) 0.12435375\n",
            "self.loss(score_2, v3) 0.067801826\n",
            "loss tensor(0.5794, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08567266\n",
            "self.loss(score_0, v1) 0.32691288\n",
            "self.loss(score_0, v2) 0.2422879\n",
            "self.loss(score_2, v3) 0.06572554\n",
            "loss tensor(0.7535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0864825\n",
            "self.loss(score_0, v1) 0.15014583\n",
            "self.loss(score_0, v2) 0.10473565\n",
            "self.loss(score_2, v3) 0.043475434\n",
            "loss tensor(0.4066, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.080217026\n",
            "self.loss(score_0, v1) 0.11493081\n",
            "self.loss(score_0, v2) 0.07671836\n",
            "self.loss(score_2, v3) 0.053821757\n",
            "loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055262238\n",
            "self.loss(score_0, v1) 0.26856992\n",
            "self.loss(score_0, v2) 0.17752942\n",
            "self.loss(score_2, v3) 0.031871833\n",
            "loss tensor(0.5492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10635917\n",
            "self.loss(score_0, v1) 0.27826872\n",
            "self.loss(score_0, v2) 0.16124807\n",
            "self.loss(score_2, v3) 0.069112666\n",
            "loss tensor(0.6495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.079220146\n",
            "self.loss(score_0, v1) 0.124095865\n",
            "self.loss(score_0, v2) 0.094100945\n",
            "self.loss(score_2, v3) 0.062677614\n",
            "loss tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23785278\n",
            "self.loss(score_0, v1) 0.2253579\n",
            "self.loss(score_0, v2) 0.1527436\n",
            "self.loss(score_2, v3) 0.09869439\n",
            "loss tensor(0.7640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13980924\n",
            "self.loss(score_0, v1) 0.43157005\n",
            "self.loss(score_0, v2) 0.34372202\n",
            "self.loss(score_2, v3) 0.058817487\n",
            "loss tensor(1.0033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15272991\n",
            "self.loss(score_0, v1) 0.27960876\n",
            "self.loss(score_0, v2) 0.2519169\n",
            "self.loss(score_2, v3) 0.072737426\n",
            "loss tensor(0.7934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08959272\n",
            "self.loss(score_0, v1) 0.19014153\n",
            "self.loss(score_0, v2) 0.17874324\n",
            "self.loss(score_2, v3) 0.06763779\n",
            "loss tensor(0.5599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07827341\n",
            "self.loss(score_0, v1) 0.11098675\n",
            "self.loss(score_0, v2) 0.13163604\n",
            "self.loss(score_2, v3) 0.064130545\n",
            "loss tensor(0.4171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10422991\n",
            "self.loss(score_0, v1) 0.16546664\n",
            "self.loss(score_0, v2) 0.09479203\n",
            "self.loss(score_2, v3) 0.051765554\n",
            "loss tensor(0.4421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08641242\n",
            "self.loss(score_0, v1) 0.17268808\n",
            "self.loss(score_0, v2) 0.15658785\n",
            "self.loss(score_2, v3) 0.054536916\n",
            "loss tensor(0.4975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07250948\n",
            "self.loss(score_0, v1) 0.17976813\n",
            "self.loss(score_0, v2) 0.13280156\n",
            "self.loss(score_2, v3) 0.053978276\n",
            "loss tensor(0.4660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.36773366\n",
            "self.loss(score_0, v1) 0.89436847\n",
            "self.loss(score_0, v2) 0.5404098\n",
            "self.loss(score_2, v3) 0.048069656\n",
            "loss tensor(1.8746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.101266384\n",
            "self.loss(score_0, v1) 0.19068228\n",
            "self.loss(score_0, v2) 0.13920383\n",
            "self.loss(score_2, v3) 0.06288567\n",
            "loss tensor(0.5255, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08532989\n",
            "self.loss(score_0, v1) 0.4922088\n",
            "self.loss(score_0, v2) 0.49361584\n",
            "self.loss(score_2, v3) 0.09379696\n",
            "loss tensor(1.2119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06980969\n",
            "self.loss(score_0, v1) 0.10723965\n",
            "self.loss(score_0, v2) 0.10682719\n",
            "self.loss(score_2, v3) 0.051730264\n",
            "loss tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.065658376\n",
            "self.loss(score_0, v1) 0.092317\n",
            "self.loss(score_0, v2) 0.090231776\n",
            "self.loss(score_2, v3) 0.05157305\n",
            "loss tensor(0.3256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10049972\n",
            "self.loss(score_0, v1) 0.28397802\n",
            "self.loss(score_0, v2) 0.22725956\n",
            "self.loss(score_2, v3) 0.06097042\n",
            "loss tensor(0.7032, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08785959\n",
            "self.loss(score_0, v1) 0.13637035\n",
            "self.loss(score_0, v2) 0.08481482\n",
            "self.loss(score_2, v3) 0.058118362\n",
            "loss tensor(0.3962, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.084691815\n",
            "self.loss(score_0, v1) 0.22542237\n",
            "self.loss(score_0, v2) 0.18035415\n",
            "self.loss(score_2, v3) 0.0547157\n",
            "loss tensor(0.5725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06432251\n",
            "self.loss(score_0, v1) 0.11047137\n",
            "self.loss(score_0, v2) 0.07027698\n",
            "self.loss(score_2, v3) 0.042800907\n",
            "loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11338125\n",
            "self.loss(score_0, v1) 0.31860057\n",
            "self.loss(score_0, v2) 0.27392715\n",
            "self.loss(score_2, v3) 0.047906023\n",
            "loss tensor(0.7778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07306812\n",
            "self.loss(score_0, v1) 0.13086297\n",
            "self.loss(score_0, v2) 0.0892588\n",
            "self.loss(score_2, v3) 0.059052892\n",
            "loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07313792\n",
            "self.loss(score_0, v1) 0.11955312\n",
            "self.loss(score_0, v2) 0.06447038\n",
            "self.loss(score_2, v3) 0.05398309\n",
            "loss tensor(0.3381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09098098\n",
            "self.loss(score_0, v1) 0.14818683\n",
            "self.loss(score_0, v2) 0.098380566\n",
            "self.loss(score_2, v3) 0.05476081\n",
            "loss tensor(0.4197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07919382\n",
            "self.loss(score_0, v1) 0.39511594\n",
            "self.loss(score_0, v2) 0.31327015\n",
            "self.loss(score_2, v3) 0.046765156\n",
            "loss tensor(0.8577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09375035\n",
            "self.loss(score_0, v1) 0.13414812\n",
            "self.loss(score_0, v2) 0.1231486\n",
            "self.loss(score_2, v3) 0.06656113\n",
            "loss tensor(0.4509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.083058745\n",
            "self.loss(score_0, v1) 0.4406931\n",
            "self.loss(score_0, v2) 0.43539426\n",
            "self.loss(score_2, v3) 0.17418067\n",
            "loss tensor(1.2204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09886972\n",
            "self.loss(score_0, v1) 0.14316036\n",
            "self.loss(score_0, v2) 0.12287972\n",
            "self.loss(score_2, v3) 0.047984928\n",
            "loss tensor(0.4369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0659467\n",
            "self.loss(score_0, v1) 0.11349288\n",
            "self.loss(score_0, v2) 0.10662566\n",
            "self.loss(score_2, v3) 0.059050113\n",
            "loss tensor(0.3746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06582895\n",
            "self.loss(score_0, v1) 0.23197198\n",
            "self.loss(score_0, v2) 0.20603865\n",
            "self.loss(score_2, v3) 0.055502724\n",
            "loss tensor(0.5871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13884544\n",
            "self.loss(score_0, v1) 0.24693698\n",
            "self.loss(score_0, v2) 0.18531391\n",
            "self.loss(score_2, v3) 0.05152087\n",
            "loss tensor(0.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11279068\n",
            "self.loss(score_0, v1) 0.15980585\n",
            "self.loss(score_0, v2) 0.12195672\n",
            "self.loss(score_2, v3) 0.061686277\n",
            "loss tensor(0.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10084553\n",
            "self.loss(score_0, v1) 0.18975559\n",
            "self.loss(score_0, v2) 0.13488446\n",
            "self.loss(score_2, v3) 0.06161523\n",
            "loss tensor(0.5179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08533796\n",
            "self.loss(score_0, v1) 0.20129457\n",
            "self.loss(score_0, v2) 0.32973295\n",
            "self.loss(score_2, v3) 0.07782179\n",
            "loss tensor(0.7331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09218228\n",
            "self.loss(score_0, v1) 0.1443259\n",
            "self.loss(score_0, v2) 0.100726046\n",
            "self.loss(score_2, v3) 0.049269386\n",
            "loss tensor(0.4111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.33566788\n",
            "self.loss(score_0, v1) 0.35027626\n",
            "self.loss(score_0, v2) 0.093196444\n",
            "self.loss(score_2, v3) 0.056609154\n",
            "loss tensor(0.8641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10516242\n",
            "self.loss(score_0, v1) 0.28532824\n",
            "self.loss(score_0, v2) 0.20443042\n",
            "self.loss(score_2, v3) 0.06410331\n",
            "loss tensor(0.6911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.076583\n",
            "self.loss(score_0, v1) 0.112789534\n",
            "self.loss(score_0, v2) 0.07228939\n",
            "self.loss(score_2, v3) 0.05465787\n",
            "loss tensor(0.3436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07190609\n",
            "self.loss(score_0, v1) 0.12219066\n",
            "self.loss(score_0, v2) 0.145068\n",
            "self.loss(score_2, v3) 0.055056397\n",
            "loss tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10224791\n",
            "self.loss(score_0, v1) 0.32465875\n",
            "self.loss(score_0, v2) 0.35222623\n",
            "self.loss(score_2, v3) 0.074748255\n",
            "loss tensor(0.8913, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.080753535\n",
            "self.loss(score_0, v1) 0.36285934\n",
            "self.loss(score_0, v2) 0.41728044\n",
            "self.loss(score_2, v3) 0.1283682\n",
            "loss tensor(1.0534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19721417\n",
            "self.loss(score_0, v1) 0.37127516\n",
            "self.loss(score_0, v2) 0.20693478\n",
            "self.loss(score_2, v3) 0.07338217\n",
            "loss tensor(0.8855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12320283\n",
            "self.loss(score_0, v1) 0.16512331\n",
            "self.loss(score_0, v2) 0.11708118\n",
            "self.loss(score_2, v3) 0.050994545\n",
            "loss tensor(0.4819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08710032\n",
            "self.loss(score_0, v1) 0.14542533\n",
            "self.loss(score_0, v2) 0.13018022\n",
            "self.loss(score_2, v3) 0.06824543\n",
            "loss tensor(0.4651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06295278\n",
            "self.loss(score_0, v1) 0.08979747\n",
            "self.loss(score_0, v2) 0.071930744\n",
            "self.loss(score_2, v3) 0.04847779\n",
            "loss tensor(0.2974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.082977585\n",
            "self.loss(score_0, v1) 0.21527979\n",
            "self.loss(score_0, v2) 0.23198164\n",
            "self.loss(score_2, v3) 0.056362525\n",
            "loss tensor(0.6148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17966045\n",
            "self.loss(score_0, v1) 0.5889799\n",
            "self.loss(score_0, v2) 0.3486078\n",
            "self.loss(score_2, v3) 0.06424125\n",
            "loss tensor(1.2136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08455353\n",
            "self.loss(score_0, v1) 0.1388939\n",
            "self.loss(score_0, v2) 0.09596276\n",
            "self.loss(score_2, v3) 0.059186596\n",
            "loss tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.083025254\n",
            "self.loss(score_0, v1) 0.15215953\n",
            "self.loss(score_0, v2) 0.13395984\n",
            "self.loss(score_2, v3) 0.058737878\n",
            "loss tensor(0.4573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06693894\n",
            "self.loss(score_0, v1) 0.45776734\n",
            "self.loss(score_0, v2) 1.0818957\n",
            "self.loss(score_2, v3) 0.7552356\n",
            "loss tensor(2.7395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07198304\n",
            "self.loss(score_0, v1) 0.1180866\n",
            "self.loss(score_0, v2) 0.10435557\n",
            "self.loss(score_2, v3) 0.05767899\n",
            "loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.090335965\n",
            "self.loss(score_0, v1) 0.12082676\n",
            "self.loss(score_0, v2) 0.14562924\n",
            "self.loss(score_2, v3) 0.19499321\n",
            "loss tensor(0.6493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07798604\n",
            "self.loss(score_0, v1) 0.2628522\n",
            "self.loss(score_0, v2) 0.20222844\n",
            "self.loss(score_2, v3) 0.0536359\n",
            "loss tensor(0.6235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09267361\n",
            "self.loss(score_0, v1) 0.1651232\n",
            "self.loss(score_0, v2) 0.10899097\n",
            "self.loss(score_2, v3) 0.05921496\n",
            "loss tensor(0.4556, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10807268\n",
            "self.loss(score_0, v1) 0.1964992\n",
            "self.loss(score_0, v2) 0.16221315\n",
            "self.loss(score_2, v3) 0.07078791\n",
            "loss tensor(0.5730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06450722\n",
            "self.loss(score_0, v1) 0.091862746\n",
            "self.loss(score_0, v2) 0.09525817\n",
            "self.loss(score_2, v3) 0.051256552\n",
            "loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09694679\n",
            "self.loss(score_0, v1) 0.26853552\n",
            "self.loss(score_0, v2) 0.21966147\n",
            "self.loss(score_2, v3) 0.06162284\n",
            "loss tensor(0.6776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.085124835\n",
            "self.loss(score_0, v1) 0.14606921\n",
            "self.loss(score_0, v2) 0.09315081\n",
            "self.loss(score_2, v3) 0.05605294\n",
            "loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056283813\n",
            "self.loss(score_0, v1) 0.096624024\n",
            "self.loss(score_0, v2) 0.10018523\n",
            "self.loss(score_2, v3) 0.03847276\n",
            "loss tensor(0.3108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.044702157\n",
            "self.loss(score_0, v1) 0.10924432\n",
            "self.loss(score_0, v2) 0.058913924\n",
            "self.loss(score_2, v3) 0.034312356\n",
            "loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.4117533\n",
            "self.loss(score_0, v1) 0.41055945\n",
            "self.loss(score_0, v2) 0.19282262\n",
            "self.loss(score_2, v3) 0.124308504\n",
            "loss tensor(1.2016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05865322\n",
            "self.loss(score_0, v1) 0.0958369\n",
            "self.loss(score_0, v2) 0.07008004\n",
            "self.loss(score_2, v3) 0.040181663\n",
            "loss tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.116382115\n",
            "self.loss(score_0, v1) 0.23604874\n",
            "self.loss(score_0, v2) 0.13161238\n",
            "self.loss(score_2, v3) 0.050624933\n",
            "loss tensor(0.5600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051258158\n",
            "self.loss(score_0, v1) 0.09352487\n",
            "self.loss(score_0, v2) 0.06655248\n",
            "self.loss(score_2, v3) 0.04094538\n",
            "loss tensor(0.2728, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06476511\n",
            "self.loss(score_0, v1) 0.11172388\n",
            "self.loss(score_0, v2) 0.14365427\n",
            "self.loss(score_2, v3) 0.06004965\n",
            "loss tensor(0.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.102378525\n",
            "self.loss(score_0, v1) 0.18297873\n",
            "self.loss(score_0, v2) 0.16842766\n",
            "self.loss(score_2, v3) 0.07091515\n",
            "loss tensor(0.5602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.097955205\n",
            "self.loss(score_0, v1) 0.18101488\n",
            "self.loss(score_0, v2) 0.17730612\n",
            "self.loss(score_2, v3) 0.061839595\n",
            "loss tensor(0.5490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09371562\n",
            "self.loss(score_0, v1) 0.17252034\n",
            "self.loss(score_0, v2) 0.1579595\n",
            "self.loss(score_2, v3) 0.07353357\n",
            "loss tensor(0.5345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.110153444\n",
            "self.loss(score_0, v1) 0.107988715\n",
            "self.loss(score_0, v2) 0.09051991\n",
            "self.loss(score_2, v3) 0.052608702\n",
            "loss tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08403941\n",
            "self.loss(score_0, v1) 0.12530981\n",
            "self.loss(score_0, v2) 0.08970615\n",
            "self.loss(score_2, v3) 0.069502294\n",
            "loss tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07452511\n",
            "self.loss(score_0, v1) 0.115870915\n",
            "self.loss(score_0, v2) 0.21939233\n",
            "self.loss(score_2, v3) 0.19422005\n",
            "loss tensor(0.7011, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055944413\n",
            "self.loss(score_0, v1) 0.11608373\n",
            "self.loss(score_0, v2) 0.113176405\n",
            "self.loss(score_2, v3) 0.04190099\n",
            "loss tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08353127\n",
            "self.loss(score_0, v1) 0.15771456\n",
            "self.loss(score_0, v2) 0.10417256\n",
            "self.loss(score_2, v3) 0.07574666\n",
            "loss tensor(0.4590, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07576015\n",
            "self.loss(score_0, v1) 0.19305949\n",
            "self.loss(score_0, v2) 0.20944619\n",
            "self.loss(score_2, v3) 0.10015224\n",
            "loss tensor(0.6285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06985145\n",
            "self.loss(score_0, v1) 0.40236992\n",
            "self.loss(score_0, v2) 0.59663296\n",
            "self.loss(score_2, v3) 0.17616312\n",
            "loss tensor(1.3331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1038398\n",
            "self.loss(score_0, v1) 0.18529403\n",
            "self.loss(score_0, v2) 0.13253352\n",
            "self.loss(score_2, v3) 0.091716975\n",
            "loss tensor(0.5592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09015032\n",
            "self.loss(score_0, v1) 0.3256567\n",
            "self.loss(score_0, v2) 0.30263838\n",
            "self.loss(score_2, v3) 0.06764593\n",
            "loss tensor(0.8199, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07584826\n",
            "self.loss(score_0, v1) 0.104373775\n",
            "self.loss(score_0, v2) 0.08383656\n",
            "self.loss(score_2, v3) 0.047499757\n",
            "loss tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07968101\n",
            "self.loss(score_0, v1) 0.2333741\n",
            "self.loss(score_0, v2) 0.23149253\n",
            "self.loss(score_2, v3) 0.073112816\n",
            "loss tensor(0.6542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.071904086\n",
            "self.loss(score_0, v1) 0.13514975\n",
            "self.loss(score_0, v2) 0.10630958\n",
            "self.loss(score_2, v3) 0.051466152\n",
            "loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09821854\n",
            "self.loss(score_0, v1) 0.1676026\n",
            "self.loss(score_0, v2) 0.118671924\n",
            "self.loss(score_2, v3) 0.0765251\n",
            "loss tensor(0.4993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07372468\n",
            "self.loss(score_0, v1) 0.1681128\n",
            "self.loss(score_0, v2) 0.14937301\n",
            "self.loss(score_2, v3) 0.06313362\n",
            "loss tensor(0.4859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.098413706\n",
            "self.loss(score_0, v1) 0.13472627\n",
            "self.loss(score_0, v2) 0.09455891\n",
            "self.loss(score_2, v3) 0.057098895\n",
            "loss tensor(0.4133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08000865\n",
            "self.loss(score_0, v1) 0.14650841\n",
            "self.loss(score_0, v2) 0.12934138\n",
            "self.loss(score_2, v3) 0.060961243\n",
            "loss tensor(0.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09100605\n",
            "self.loss(score_0, v1) 0.55578834\n",
            "self.loss(score_0, v2) 0.5213463\n",
            "self.loss(score_2, v3) 0.07340626\n",
            "loss tensor(1.2782, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0800162\n",
            "self.loss(score_0, v1) 0.14272854\n",
            "self.loss(score_0, v2) 0.13224676\n",
            "self.loss(score_2, v3) 0.05690004\n",
            "loss tensor(0.4403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073727645\n",
            "self.loss(score_0, v1) 0.11274884\n",
            "self.loss(score_0, v2) 0.09328283\n",
            "self.loss(score_2, v3) 0.048512135\n",
            "loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.100422494\n",
            "self.loss(score_0, v1) 0.31847593\n",
            "self.loss(score_0, v2) 0.24383742\n",
            "self.loss(score_2, v3) 0.07274538\n",
            "loss tensor(0.7719, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12189421\n",
            "self.loss(score_0, v1) 0.18563531\n",
            "self.loss(score_0, v2) 0.08970757\n",
            "self.loss(score_2, v3) 0.064408645\n",
            "loss tensor(0.4939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12332658\n",
            "self.loss(score_0, v1) 0.1433172\n",
            "self.loss(score_0, v2) 0.11872537\n",
            "self.loss(score_2, v3) 0.055304658\n",
            "loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19901042\n",
            "self.loss(score_0, v1) 0.20856862\n",
            "self.loss(score_0, v2) 0.14772232\n",
            "self.loss(score_2, v3) 0.08425561\n",
            "loss tensor(0.6817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09030828\n",
            "self.loss(score_0, v1) 0.16894916\n",
            "self.loss(score_0, v2) 0.12294729\n",
            "self.loss(score_2, v3) 0.06288556\n",
            "loss tensor(0.4765, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12953314\n",
            "self.loss(score_0, v1) 0.25252882\n",
            "self.loss(score_0, v2) 0.09682619\n",
            "self.loss(score_2, v3) 0.056044027\n",
            "loss tensor(0.5630, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0883711\n",
            "self.loss(score_0, v1) 0.33479947\n",
            "self.loss(score_0, v2) 0.25905555\n",
            "self.loss(score_2, v3) 0.07091783\n",
            "loss tensor(0.7886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10679565\n",
            "self.loss(score_0, v1) 0.13635536\n",
            "self.loss(score_0, v2) 0.08161769\n",
            "self.loss(score_2, v3) 0.0536266\n",
            "loss tensor(0.4052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12049006\n",
            "self.loss(score_0, v1) 0.19099613\n",
            "self.loss(score_0, v2) 0.099555396\n",
            "self.loss(score_2, v3) 0.050869722\n",
            "loss tensor(0.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07446819\n",
            "self.loss(score_0, v1) 0.12131272\n",
            "self.loss(score_0, v2) 0.12654985\n",
            "self.loss(score_2, v3) 0.07110151\n",
            "loss tensor(0.4290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09767563\n",
            "self.loss(score_0, v1) 0.3646865\n",
            "self.loss(score_0, v2) 0.33208317\n",
            "self.loss(score_2, v3) 0.048009403\n",
            "loss tensor(0.8665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052785255\n",
            "self.loss(score_0, v1) 0.11101494\n",
            "self.loss(score_0, v2) 0.09856603\n",
            "self.loss(score_2, v3) 0.046143606\n",
            "loss tensor(0.3316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08581478\n",
            "self.loss(score_0, v1) 0.42469722\n",
            "self.loss(score_0, v2) 0.3650533\n",
            "self.loss(score_2, v3) 0.07116064\n",
            "loss tensor(0.9823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06271957\n",
            "self.loss(score_0, v1) 0.099038415\n",
            "self.loss(score_0, v2) 0.085678495\n",
            "self.loss(score_2, v3) 0.04628387\n",
            "loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.071575\n",
            "self.loss(score_0, v1) 0.14114137\n",
            "self.loss(score_0, v2) 0.12832382\n",
            "self.loss(score_2, v3) 0.06353959\n",
            "loss tensor(0.4363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2060772\n",
            "self.loss(score_0, v1) 0.23225658\n",
            "self.loss(score_0, v2) 0.17497908\n",
            "self.loss(score_2, v3) 0.13999277\n",
            "loss tensor(0.8233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060849637\n",
            "self.loss(score_0, v1) 0.14711802\n",
            "self.loss(score_0, v2) 0.16319233\n",
            "self.loss(score_2, v3) 0.050716396\n",
            "loss tensor(0.4472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05896554\n",
            "self.loss(score_0, v1) 0.1341672\n",
            "self.loss(score_0, v2) 0.08511455\n",
            "self.loss(score_2, v3) 0.047274016\n",
            "loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.092546165\n",
            "self.loss(score_0, v1) 0.19480534\n",
            "self.loss(score_0, v2) 0.16465434\n",
            "self.loss(score_2, v3) 0.067453444\n",
            "loss tensor(0.5532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11924341\n",
            "self.loss(score_0, v1) 0.66178375\n",
            "self.loss(score_0, v2) 0.61471885\n",
            "self.loss(score_2, v3) 0.054614678\n",
            "loss tensor(1.4777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09955183\n",
            "self.loss(score_0, v1) 0.14783561\n",
            "self.loss(score_0, v2) 0.10397637\n",
            "self.loss(score_2, v3) 0.07112151\n",
            "loss tensor(0.4580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11029618\n",
            "self.loss(score_0, v1) 0.20991755\n",
            "self.loss(score_0, v2) 0.13452639\n",
            "self.loss(score_2, v3) 0.056162886\n",
            "loss tensor(0.5390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.107397944\n",
            "self.loss(score_0, v1) 0.27591097\n",
            "self.loss(score_0, v2) 0.30845055\n",
            "self.loss(score_2, v3) 0.11829304\n",
            "loss tensor(0.8692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06785157\n",
            "self.loss(score_0, v1) 0.45575288\n",
            "self.loss(score_0, v2) 0.43097758\n",
            "self.loss(score_2, v3) 0.117575735\n",
            "loss tensor(1.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.079367206\n",
            "self.loss(score_0, v1) 0.12862277\n",
            "self.loss(score_0, v2) 0.121710144\n",
            "self.loss(score_2, v3) 0.053039268\n",
            "loss tensor(0.4093, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03933051\n",
            "self.loss(score_0, v1) 0.085510574\n",
            "self.loss(score_0, v2) 0.11702616\n",
            "self.loss(score_2, v3) 0.030980662\n",
            "loss tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.088112764\n",
            "self.loss(score_0, v1) 0.13534626\n",
            "self.loss(score_0, v2) 0.096284114\n",
            "self.loss(score_2, v3) 0.062316835\n",
            "loss tensor(0.4132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06518397\n",
            "self.loss(score_0, v1) 0.124510214\n",
            "self.loss(score_0, v2) 0.12547627\n",
            "self.loss(score_2, v3) 0.06928\n",
            "loss tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06766908\n",
            "self.loss(score_0, v1) 0.09006282\n",
            "self.loss(score_0, v2) 0.06649175\n",
            "self.loss(score_2, v3) 0.057331614\n",
            "loss tensor(0.3102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.065982714\n",
            "self.loss(score_0, v1) 0.13010663\n",
            "self.loss(score_0, v2) 0.06144657\n",
            "self.loss(score_2, v3) 0.03958\n",
            "loss tensor(0.3169, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08799845\n",
            "self.loss(score_0, v1) 0.12928948\n",
            "self.loss(score_0, v2) 0.096001804\n",
            "self.loss(score_2, v3) 0.059002426\n",
            "loss tensor(0.4018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13547026\n",
            "self.loss(score_0, v1) 0.16681021\n",
            "self.loss(score_0, v2) 0.092301704\n",
            "self.loss(score_2, v3) 0.06551204\n",
            "loss tensor(0.4929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04936075\n",
            "self.loss(score_0, v1) 0.082578786\n",
            "self.loss(score_0, v2) 0.060708985\n",
            "self.loss(score_2, v3) 0.033978388\n",
            "loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.085117936\n",
            "self.loss(score_0, v1) 0.19288716\n",
            "self.loss(score_0, v2) 0.2236251\n",
            "self.loss(score_2, v3) 0.0732707\n",
            "loss tensor(0.6115, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23080365\n",
            "self.loss(score_0, v1) 0.31582698\n",
            "self.loss(score_0, v2) 0.07231992\n",
            "self.loss(score_2, v3) 0.045222953\n",
            "loss tensor(0.6868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06796666\n",
            "self.loss(score_0, v1) 0.10779793\n",
            "self.loss(score_0, v2) 0.092948735\n",
            "self.loss(score_2, v3) 0.050347224\n",
            "loss tensor(0.3442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0768711\n",
            "self.loss(score_0, v1) 0.11844977\n",
            "self.loss(score_0, v2) 0.08727499\n",
            "self.loss(score_2, v3) 0.07262934\n",
            "loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09601084\n",
            "self.loss(score_0, v1) 0.28345913\n",
            "self.loss(score_0, v2) 0.24737164\n",
            "self.loss(score_2, v3) 0.06533688\n",
            "loss tensor(0.7248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08181916\n",
            "self.loss(score_0, v1) 0.20660363\n",
            "self.loss(score_0, v2) 0.13084172\n",
            "self.loss(score_2, v3) 0.04991923\n",
            "loss tensor(0.4941, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.114212275\n",
            "self.loss(score_0, v1) 0.23508017\n",
            "self.loss(score_0, v2) 0.12949626\n",
            "self.loss(score_2, v3) 0.048535347\n",
            "loss tensor(0.5516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1322044\n",
            "self.loss(score_0, v1) 0.18642578\n",
            "self.loss(score_0, v2) 0.09859643\n",
            "self.loss(score_2, v3) 0.07148165\n",
            "loss tensor(0.5244, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04701698\n",
            "self.loss(score_0, v1) 0.14293714\n",
            "self.loss(score_0, v2) 0.19701783\n",
            "self.loss(score_2, v3) 0.03323627\n",
            "loss tensor(0.4368, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09761827\n",
            "self.loss(score_0, v1) 0.11688155\n",
            "self.loss(score_0, v2) 0.07908876\n",
            "self.loss(score_2, v3) 0.049289983\n",
            "loss tensor(0.3675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07117843\n",
            "self.loss(score_0, v1) 0.12395625\n",
            "self.loss(score_0, v2) 0.14097756\n",
            "self.loss(score_2, v3) 0.053617913\n",
            "loss tensor(0.4165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05801152\n",
            "self.loss(score_0, v1) 0.09350972\n",
            "self.loss(score_0, v2) 0.06934029\n",
            "self.loss(score_2, v3) 0.04814537\n",
            "loss tensor(0.2931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21993013\n",
            "self.loss(score_0, v1) 0.29802954\n",
            "self.loss(score_0, v2) 0.10591795\n",
            "self.loss(score_2, v3) 0.060053416\n",
            "loss tensor(0.7140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07698549\n",
            "self.loss(score_0, v1) 0.08805994\n",
            "self.loss(score_0, v2) 0.068095125\n",
            "self.loss(score_2, v3) 0.049244385\n",
            "loss tensor(0.3070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07865282\n",
            "self.loss(score_0, v1) 0.22519867\n",
            "self.loss(score_0, v2) 0.19182315\n",
            "self.loss(score_2, v3) 0.07075881\n",
            "loss tensor(0.6018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09882335\n",
            "self.loss(score_0, v1) 0.25454032\n",
            "self.loss(score_0, v2) 0.62355465\n",
            "self.loss(score_2, v3) 0.6233947\n",
            "loss tensor(1.9120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.070827514\n",
            "self.loss(score_0, v1) 0.10229691\n",
            "self.loss(score_0, v2) 0.072239876\n",
            "self.loss(score_2, v3) 0.050651915\n",
            "loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22361135\n",
            "self.loss(score_0, v1) 0.3248101\n",
            "self.loss(score_0, v2) 0.21740742\n",
            "self.loss(score_2, v3) 0.057068944\n",
            "loss tensor(0.8514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08977014\n",
            "self.loss(score_0, v1) 0.2762168\n",
            "self.loss(score_0, v2) 0.23768476\n",
            "self.loss(score_2, v3) 0.050102066\n",
            "loss tensor(0.6788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07869941\n",
            "self.loss(score_0, v1) 0.16272287\n",
            "self.loss(score_0, v2) 0.15135507\n",
            "self.loss(score_2, v3) 0.06557685\n",
            "loss tensor(0.4911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0924671\n",
            "self.loss(score_0, v1) 0.12046144\n",
            "self.loss(score_0, v2) 0.060316503\n",
            "self.loss(score_2, v3) 0.041822407\n",
            "loss tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0866231\n",
            "self.loss(score_0, v1) 0.20568399\n",
            "self.loss(score_0, v2) 0.17974126\n",
            "self.loss(score_2, v3) 0.050685696\n",
            "loss tensor(0.5481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18762237\n",
            "self.loss(score_0, v1) 0.25911137\n",
            "self.loss(score_0, v2) 0.09864198\n",
            "self.loss(score_2, v3) 0.05383101\n",
            "loss tensor(0.6261, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06698359\n",
            "self.loss(score_0, v1) 0.27536014\n",
            "self.loss(score_0, v2) 0.21482402\n",
            "self.loss(score_2, v3) 0.05518624\n",
            "loss tensor(0.6399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16528024\n",
            "self.loss(score_0, v1) 0.20857726\n",
            "self.loss(score_0, v2) 0.16207574\n",
            "self.loss(score_2, v3) 0.05583908\n",
            "loss tensor(0.6197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08327784\n",
            "self.loss(score_0, v1) 0.14541693\n",
            "self.loss(score_0, v2) 0.12567778\n",
            "self.loss(score_2, v3) 0.051435612\n",
            "loss tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09615989\n",
            "self.loss(score_0, v1) 0.13039474\n",
            "self.loss(score_0, v2) 0.08743704\n",
            "self.loss(score_2, v3) 0.056011647\n",
            "loss tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08851639\n",
            "self.loss(score_0, v1) 0.16597813\n",
            "self.loss(score_0, v2) 0.16506511\n",
            "self.loss(score_2, v3) 0.05420128\n",
            "loss tensor(0.5009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.25393215\n",
            "self.loss(score_0, v1) 0.53683084\n",
            "self.loss(score_0, v2) 0.5349741\n",
            "self.loss(score_2, v3) 0.1796322\n",
            "loss tensor(1.5952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06598274\n",
            "self.loss(score_0, v1) 0.115781866\n",
            "self.loss(score_0, v2) 0.09721256\n",
            "self.loss(score_2, v3) 0.055279274\n",
            "loss tensor(0.3619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16529022\n",
            "self.loss(score_0, v1) 0.2791506\n",
            "self.loss(score_0, v2) 0.18545103\n",
            "self.loss(score_2, v3) 0.050291784\n",
            "loss tensor(0.7053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08834067\n",
            "self.loss(score_0, v1) 0.11476436\n",
            "self.loss(score_0, v2) 0.081935525\n",
            "self.loss(score_2, v3) 0.06867538\n",
            "loss tensor(0.3881, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.065861985\n",
            "self.loss(score_0, v1) 0.124324165\n",
            "self.loss(score_0, v2) 0.096741006\n",
            "self.loss(score_2, v3) 0.045169152\n",
            "loss tensor(0.3547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07530775\n",
            "self.loss(score_0, v1) 0.12776168\n",
            "self.loss(score_0, v2) 0.09091266\n",
            "self.loss(score_2, v3) 0.06288779\n",
            "loss tensor(0.3883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09022155\n",
            "self.loss(score_0, v1) 0.121901855\n",
            "self.loss(score_0, v2) 0.15440921\n",
            "self.loss(score_2, v3) 0.095242195\n",
            "loss tensor(0.5094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06404773\n",
            "self.loss(score_0, v1) 0.09045686\n",
            "self.loss(score_0, v2) 0.08471241\n",
            "self.loss(score_2, v3) 0.049923006\n",
            "loss tensor(0.3141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07290699\n",
            "self.loss(score_0, v1) 0.11195815\n",
            "self.loss(score_0, v2) 0.08743388\n",
            "self.loss(score_2, v3) 0.047042783\n",
            "loss tensor(0.3429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073224135\n",
            "self.loss(score_0, v1) 0.7830869\n",
            "self.loss(score_0, v2) 0.7985192\n",
            "self.loss(score_2, v3) 0.06404041\n",
            "loss tensor(1.7509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08277419\n",
            "self.loss(score_0, v1) 0.17477028\n",
            "self.loss(score_0, v2) 0.12554513\n",
            "self.loss(score_2, v3) 0.051312137\n",
            "loss tensor(0.4601, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.067399524\n",
            "self.loss(score_0, v1) 0.112364694\n",
            "self.loss(score_0, v2) 0.08486233\n",
            "self.loss(score_2, v3) 0.051255535\n",
            "loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08168583\n",
            "self.loss(score_0, v1) 0.14258996\n",
            "self.loss(score_0, v2) 0.12384545\n",
            "self.loss(score_2, v3) 0.059337135\n",
            "loss tensor(0.4371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08016688\n",
            "self.loss(score_0, v1) 0.15974978\n",
            "self.loss(score_0, v2) 0.0844223\n",
            "self.loss(score_2, v3) 0.05983317\n",
            "loss tensor(0.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06652918\n",
            "self.loss(score_0, v1) 0.20923938\n",
            "self.loss(score_0, v2) 0.19535302\n",
            "self.loss(score_2, v3) 0.04907063\n",
            "loss tensor(0.5447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.084133446\n",
            "self.loss(score_0, v1) 0.19549827\n",
            "self.loss(score_0, v2) 0.16540788\n",
            "self.loss(score_2, v3) 0.046151515\n",
            "loss tensor(0.5143, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08485189\n",
            "self.loss(score_0, v1) 0.31912398\n",
            "self.loss(score_0, v2) 0.29123852\n",
            "self.loss(score_2, v3) 0.061779987\n",
            "loss tensor(0.7879, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0981708\n",
            "self.loss(score_0, v1) 0.37454948\n",
            "self.loss(score_0, v2) 0.28196114\n",
            "self.loss(score_2, v3) 0.080742046\n",
            "loss tensor(0.8758, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15445578\n",
            "self.loss(score_0, v1) 0.33769852\n",
            "self.loss(score_0, v2) 0.34576207\n",
            "self.loss(score_2, v3) 0.17408502\n",
            "loss tensor(1.0990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16960609\n",
            "self.loss(score_0, v1) 0.39403236\n",
            "self.loss(score_0, v2) 0.46287057\n",
            "self.loss(score_2, v3) 0.053769637\n",
            "loss tensor(1.1072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08451213\n",
            "self.loss(score_0, v1) 0.4310856\n",
            "self.loss(score_0, v2) 0.3568355\n",
            "self.loss(score_2, v3) 0.06832808\n",
            "loss tensor(0.9749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.085761294\n",
            "self.loss(score_0, v1) 0.1538602\n",
            "self.loss(score_0, v2) 0.082673535\n",
            "self.loss(score_2, v3) 0.050053418\n",
            "loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10397772\n",
            "self.loss(score_0, v1) 0.13282008\n",
            "self.loss(score_0, v2) 0.08728286\n",
            "self.loss(score_2, v3) 0.049328633\n",
            "loss tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.043986343\n",
            "self.loss(score_0, v1) 0.07444699\n",
            "self.loss(score_0, v2) 0.061241046\n",
            "self.loss(score_2, v3) 0.035652727\n",
            "loss tensor(0.2332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06648101\n",
            "self.loss(score_0, v1) 0.18648207\n",
            "self.loss(score_0, v2) 0.25355455\n",
            "self.loss(score_2, v3) 0.04607195\n",
            "loss tensor(0.5756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.24167642\n",
            "self.loss(score_0, v1) 0.30442637\n",
            "self.loss(score_0, v2) 0.105208784\n",
            "self.loss(score_2, v3) 0.058613382\n",
            "loss tensor(0.7392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.072115466\n",
            "self.loss(score_0, v1) 0.23084518\n",
            "self.loss(score_0, v2) 0.1942148\n",
            "self.loss(score_2, v3) 0.065501064\n",
            "loss tensor(0.5954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.093373775\n",
            "self.loss(score_0, v1) 0.19840167\n",
            "self.loss(score_0, v2) 0.14828731\n",
            "self.loss(score_2, v3) 0.04933925\n",
            "loss tensor(0.5141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.030595452\n",
            "self.loss(score_0, v1) 0.108060956\n",
            "self.loss(score_0, v2) 0.12088776\n",
            "self.loss(score_2, v3) 0.05708915\n",
            "loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.103709765\n",
            "self.loss(score_0, v1) 0.26386452\n",
            "self.loss(score_0, v2) 0.18325177\n",
            "self.loss(score_2, v3) 0.05115556\n",
            "loss tensor(0.6276, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0917709\n",
            "self.loss(score_0, v1) 0.11878167\n",
            "self.loss(score_0, v2) 0.086618714\n",
            "self.loss(score_2, v3) 0.0544072\n",
            "loss tensor(0.3788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07137207\n",
            "self.loss(score_0, v1) 0.20199212\n",
            "self.loss(score_0, v2) 0.16359662\n",
            "self.loss(score_2, v3) 0.067415655\n",
            "loss tensor(0.5381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.080411375\n",
            "self.loss(score_0, v1) 0.11969271\n",
            "self.loss(score_0, v2) 0.11993084\n",
            "self.loss(score_2, v3) 0.07242669\n",
            "loss tensor(0.4287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05753077\n",
            "self.loss(score_0, v1) 0.17611945\n",
            "self.loss(score_0, v2) 0.09147305\n",
            "self.loss(score_2, v3) 0.044000417\n",
            "loss tensor(0.3911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.087202996\n",
            "self.loss(score_0, v1) 0.42897287\n",
            "self.loss(score_0, v2) 0.35374776\n",
            "self.loss(score_2, v3) 0.05257167\n",
            "loss tensor(0.9488, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06543023\n",
            "self.loss(score_0, v1) 0.13111831\n",
            "self.loss(score_0, v2) 0.066731915\n",
            "self.loss(score_2, v3) 0.04526323\n",
            "loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057992354\n",
            "self.loss(score_0, v1) 0.09726409\n",
            "self.loss(score_0, v2) 0.08058541\n",
            "self.loss(score_2, v3) 0.037602086\n",
            "loss tensor(0.2922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10949495\n",
            "self.loss(score_0, v1) 0.11600858\n",
            "self.loss(score_0, v2) 0.092553265\n",
            "self.loss(score_2, v3) 0.056667317\n",
            "loss tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2038086\n",
            "self.loss(score_0, v1) 0.22258745\n",
            "self.loss(score_0, v2) 0.092600755\n",
            "self.loss(score_2, v3) 0.06961376\n",
            "loss tensor(0.6234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1170392\n",
            "self.loss(score_0, v1) 0.17600082\n",
            "self.loss(score_0, v2) 0.12715273\n",
            "self.loss(score_2, v3) 0.05423539\n",
            "loss tensor(0.5015, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.092434056\n",
            "self.loss(score_0, v1) 0.12536824\n",
            "self.loss(score_0, v2) 0.116423085\n",
            "self.loss(score_2, v3) 0.07065382\n",
            "loss tensor(0.4402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07816209\n",
            "self.loss(score_0, v1) 0.16316882\n",
            "self.loss(score_0, v2) 0.14085773\n",
            "self.loss(score_2, v3) 0.05199208\n",
            "loss tensor(0.4602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05483021\n",
            "self.loss(score_0, v1) 0.09033992\n",
            "self.loss(score_0, v2) 0.06465159\n",
            "self.loss(score_2, v3) 0.037031364\n",
            "loss tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09389789\n",
            "self.loss(score_0, v1) 0.52342343\n",
            "self.loss(score_0, v2) 0.5126379\n",
            "self.loss(score_2, v3) 0.07046214\n",
            "loss tensor(1.2357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13189141\n",
            "self.loss(score_0, v1) 0.16285525\n",
            "self.loss(score_0, v2) 0.10159037\n",
            "self.loss(score_2, v3) 0.05496407\n",
            "loss tensor(0.4788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.079753965\n",
            "self.loss(score_0, v1) 0.12726964\n",
            "self.loss(score_0, v2) 0.09133271\n",
            "self.loss(score_2, v3) 0.069023386\n",
            "loss tensor(0.4019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16112988\n",
            "self.loss(score_0, v1) 0.56112593\n",
            "self.loss(score_0, v2) 0.42359877\n",
            "self.loss(score_2, v3) 0.064442575\n",
            "loss tensor(1.2425, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07065617\n",
            "self.loss(score_0, v1) 0.19036843\n",
            "self.loss(score_0, v2) 0.19344604\n",
            "self.loss(score_2, v3) 0.060550515\n",
            "loss tensor(0.5453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14256583\n",
            "self.loss(score_0, v1) 0.22608909\n",
            "self.loss(score_0, v2) 0.21635191\n",
            "self.loss(score_2, v3) 0.06352685\n",
            "loss tensor(0.6803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09330036\n",
            "self.loss(score_0, v1) 0.1439477\n",
            "self.loss(score_0, v2) 0.120746955\n",
            "self.loss(score_2, v3) 0.052011512\n",
            "loss tensor(0.4360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13806412\n",
            "self.loss(score_0, v1) 0.24776767\n",
            "self.loss(score_0, v2) 0.17413656\n",
            "self.loss(score_2, v3) 0.061242033\n",
            "loss tensor(0.6518, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.098605454\n",
            "self.loss(score_0, v1) 0.16148055\n",
            "self.loss(score_0, v2) 0.13134636\n",
            "self.loss(score_2, v3) 0.04777021\n",
            "loss tensor(0.4631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.069045916\n",
            "self.loss(score_0, v1) 0.12036874\n",
            "self.loss(score_0, v2) 0.103976846\n",
            "self.loss(score_2, v3) 0.051603224\n",
            "loss tensor(0.3708, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21074751\n",
            "self.loss(score_0, v1) 0.18640701\n",
            "self.loss(score_0, v2) 0.13686629\n",
            "self.loss(score_2, v3) 0.051197182\n",
            "loss tensor(0.6108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06935987\n",
            "self.loss(score_0, v1) 0.28086486\n",
            "self.loss(score_0, v2) 0.24272043\n",
            "self.loss(score_2, v3) 0.052882753\n",
            "loss tensor(0.6723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10018154\n",
            "self.loss(score_0, v1) 0.132839\n",
            "self.loss(score_0, v2) 0.0754337\n",
            "self.loss(score_2, v3) 0.057629064\n",
            "loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08952227\n",
            "self.loss(score_0, v1) 0.16764218\n",
            "self.loss(score_0, v2) 0.10770753\n",
            "self.loss(score_2, v3) 0.06143201\n",
            "loss tensor(0.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11774747\n",
            "self.loss(score_0, v1) 0.23258618\n",
            "self.loss(score_0, v2) 0.22516179\n",
            "self.loss(score_2, v3) 0.06837329\n",
            "loss tensor(0.6781, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12884001\n",
            "self.loss(score_0, v1) 0.21795654\n",
            "self.loss(score_0, v2) 0.14923206\n",
            "self.loss(score_2, v3) 0.060840547\n",
            "loss tensor(0.5873, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13608615\n",
            "self.loss(score_0, v1) 0.13723262\n",
            "self.loss(score_0, v2) 0.077007785\n",
            "self.loss(score_2, v3) 0.045370426\n",
            "loss tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.086463846\n",
            "self.loss(score_0, v1) 0.124945946\n",
            "self.loss(score_0, v2) 0.12111142\n",
            "self.loss(score_2, v3) 0.05556049\n",
            "loss tensor(0.4159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07156303\n",
            "self.loss(score_0, v1) 0.1008052\n",
            "self.loss(score_0, v2) 0.08355209\n",
            "self.loss(score_2, v3) 0.05084423\n",
            "loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056802757\n",
            "self.loss(score_0, v1) 0.09674999\n",
            "self.loss(score_0, v2) 0.103385836\n",
            "self.loss(score_2, v3) 0.049389515\n",
            "loss tensor(0.3310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11345705\n",
            "self.loss(score_0, v1) 0.2986934\n",
            "self.loss(score_0, v2) 0.30061\n",
            "self.loss(score_2, v3) 0.059081025\n",
            "loss tensor(0.8014, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.081760824\n",
            "self.loss(score_0, v1) 0.40039775\n",
            "self.loss(score_0, v2) 0.37757125\n",
            "self.loss(score_2, v3) 0.06753448\n",
            "loss tensor(0.9610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.082936324\n",
            "self.loss(score_0, v1) 0.09945391\n",
            "self.loss(score_0, v2) 0.072355576\n",
            "self.loss(score_2, v3) 0.050057556\n",
            "loss tensor(0.3298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07824174\n",
            "self.loss(score_0, v1) 0.27339396\n",
            "self.loss(score_0, v2) 0.27699158\n",
            "self.loss(score_2, v3) 0.044239517\n",
            "loss tensor(0.6950, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15455447\n",
            "self.loss(score_0, v1) 0.18148929\n",
            "self.loss(score_0, v2) 0.14408234\n",
            "self.loss(score_2, v3) 0.15940234\n",
            "loss tensor(0.7192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06090441\n",
            "self.loss(score_0, v1) 0.12815635\n",
            "self.loss(score_0, v2) 0.16401194\n",
            "self.loss(score_2, v3) 0.056842722\n",
            "loss tensor(0.4383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18503116\n",
            "self.loss(score_0, v1) 0.14308055\n",
            "self.loss(score_0, v2) 0.10266514\n",
            "self.loss(score_2, v3) 0.060610518\n",
            "loss tensor(0.5217, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11531997\n",
            "self.loss(score_0, v1) 0.14804618\n",
            "self.loss(score_0, v2) 0.0835517\n",
            "self.loss(score_2, v3) 0.056538135\n",
            "loss tensor(0.4317, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13485439\n",
            "self.loss(score_0, v1) 0.18618576\n",
            "self.loss(score_0, v2) 0.10671483\n",
            "self.loss(score_2, v3) 0.055345923\n",
            "loss tensor(0.5108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06870191\n",
            "self.loss(score_0, v1) 0.08237964\n",
            "self.loss(score_0, v2) 0.05216219\n",
            "self.loss(score_2, v3) 0.034816083\n",
            "loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07195885\n",
            "self.loss(score_0, v1) 0.11873221\n",
            "self.loss(score_0, v2) 0.11243248\n",
            "self.loss(score_2, v3) 0.052570917\n",
            "loss tensor(0.3820, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06464298\n",
            "self.loss(score_0, v1) 0.10562428\n",
            "self.loss(score_0, v2) 0.07502683\n",
            "self.loss(score_2, v3) 0.048711028\n",
            "loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06100069\n",
            "self.loss(score_0, v1) 0.39626697\n",
            "self.loss(score_0, v2) 0.39268118\n",
            "self.loss(score_2, v3) 0.05058152\n",
            "loss tensor(0.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06734694\n",
            "self.loss(score_0, v1) 0.10780028\n",
            "self.loss(score_0, v2) 0.11816394\n",
            "self.loss(score_2, v3) 0.05890331\n",
            "loss tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16301422\n",
            "self.loss(score_0, v1) 0.2038877\n",
            "self.loss(score_0, v2) 0.089696415\n",
            "self.loss(score_2, v3) 0.050858304\n",
            "loss tensor(0.5329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11002372\n",
            "self.loss(score_0, v1) 0.13130341\n",
            "self.loss(score_0, v2) 0.08451544\n",
            "self.loss(score_2, v3) 0.06355865\n",
            "loss tensor(0.4212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07818173\n",
            "self.loss(score_0, v1) 0.12626061\n",
            "self.loss(score_0, v2) 0.23751462\n",
            "self.loss(score_2, v3) 0.22044884\n",
            "loss tensor(0.7726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08091563\n",
            "self.loss(score_0, v1) 0.15018144\n",
            "self.loss(score_0, v2) 0.10396173\n",
            "self.loss(score_2, v3) 0.06295566\n",
            "loss tensor(0.4295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06510099\n",
            "self.loss(score_0, v1) 0.10596812\n",
            "self.loss(score_0, v2) 0.07538017\n",
            "self.loss(score_2, v3) 0.053536974\n",
            "loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11797119\n",
            "self.loss(score_0, v1) 0.13665313\n",
            "self.loss(score_0, v2) 0.08211923\n",
            "self.loss(score_2, v3) 0.050696958\n",
            "loss tensor(0.4128, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08030216\n",
            "self.loss(score_0, v1) 0.10711834\n",
            "self.loss(score_0, v2) 0.097131\n",
            "self.loss(score_2, v3) 0.04923563\n",
            "loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06792303\n",
            "self.loss(score_0, v1) 0.19511825\n",
            "self.loss(score_0, v2) 0.1987367\n",
            "self.loss(score_2, v3) 0.06286317\n",
            "loss tensor(0.5561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.069208235\n",
            "self.loss(score_0, v1) 0.14151563\n",
            "self.loss(score_0, v2) 0.13632426\n",
            "self.loss(score_2, v3) 0.04453114\n",
            "loss tensor(0.4138, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05819581\n",
            "self.loss(score_0, v1) 0.14900273\n",
            "self.loss(score_0, v2) 0.09823977\n",
            "self.loss(score_2, v3) 0.04220631\n",
            "loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08857306\n",
            "self.loss(score_0, v1) 0.34502843\n",
            "self.loss(score_0, v2) 0.275642\n",
            "self.loss(score_2, v3) 0.05855607\n",
            "loss tensor(0.7971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13083246\n",
            "self.loss(score_0, v1) 0.19938724\n",
            "self.loss(score_0, v2) 0.13025424\n",
            "self.loss(score_2, v3) 0.068116345\n",
            "loss tensor(0.5626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077026166\n",
            "self.loss(score_0, v1) 0.15058513\n",
            "self.loss(score_0, v2) 0.18656631\n",
            "self.loss(score_2, v3) 0.11002636\n",
            "loss tensor(0.5792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08591606\n",
            "self.loss(score_0, v1) 0.10877741\n",
            "self.loss(score_0, v2) 0.116992936\n",
            "self.loss(score_2, v3) 0.05570267\n",
            "loss tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10328186\n",
            "self.loss(score_0, v1) 0.13142818\n",
            "self.loss(score_0, v2) 0.076161325\n",
            "self.loss(score_2, v3) 0.047293667\n",
            "loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09252968\n",
            "self.loss(score_0, v1) 0.18719167\n",
            "self.loss(score_0, v2) 0.16470774\n",
            "self.loss(score_2, v3) 0.052545536\n",
            "loss tensor(0.5232, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.256487\n",
            "self.loss(score_0, v1) 0.54932505\n",
            "self.loss(score_0, v2) 0.43386683\n",
            "self.loss(score_2, v3) 0.03454168\n",
            "loss tensor(1.2915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13172685\n",
            "self.loss(score_0, v1) 0.1653226\n",
            "self.loss(score_0, v2) 0.07318047\n",
            "self.loss(score_2, v3) 0.04168747\n",
            "loss tensor(0.4328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12755893\n",
            "self.loss(score_0, v1) 0.22627744\n",
            "self.loss(score_0, v2) 0.21985456\n",
            "self.loss(score_2, v3) 0.04967259\n",
            "loss tensor(0.6482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.042567804\n",
            "self.loss(score_0, v1) 0.21625447\n",
            "self.loss(score_0, v2) 0.23032205\n",
            "self.loss(score_2, v3) 0.036253408\n",
            "loss tensor(0.5435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.091594554\n",
            "self.loss(score_0, v1) 0.18807021\n",
            "self.loss(score_0, v2) 0.14948638\n",
            "self.loss(score_2, v3) 0.054828066\n",
            "loss tensor(0.5114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.085905276\n",
            "self.loss(score_0, v1) 0.14065474\n",
            "self.loss(score_0, v2) 0.11594322\n",
            "self.loss(score_2, v3) 0.05937543\n",
            "loss tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0640941\n",
            "self.loss(score_0, v1) 0.121365175\n",
            "self.loss(score_0, v2) 0.0902089\n",
            "self.loss(score_2, v3) 0.044315055\n",
            "loss tensor(0.3421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.082031146\n",
            "self.loss(score_0, v1) 0.14226109\n",
            "self.loss(score_0, v2) 0.09837972\n",
            "self.loss(score_2, v3) 0.055198576\n",
            "loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.091161184\n",
            "self.loss(score_0, v1) 0.17395028\n",
            "self.loss(score_0, v2) 0.17112343\n",
            "self.loss(score_2, v3) 0.048896898\n",
            "loss tensor(0.5096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06970857\n",
            "self.loss(score_0, v1) 0.10799533\n",
            "self.loss(score_0, v2) 0.105988026\n",
            "self.loss(score_2, v3) 0.07057258\n",
            "loss tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08161052\n",
            "self.loss(score_0, v1) 0.12740238\n",
            "self.loss(score_0, v2) 0.10289589\n",
            "self.loss(score_2, v3) 0.05298504\n",
            "loss tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06806826\n",
            "self.loss(score_0, v1) 0.10815353\n",
            "self.loss(score_0, v2) 0.12174367\n",
            "self.loss(score_2, v3) 0.064127535\n",
            "loss tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09089088\n",
            "self.loss(score_0, v1) 0.25669238\n",
            "self.loss(score_0, v2) 0.24131355\n",
            "self.loss(score_2, v3) 0.059228875\n",
            "loss tensor(0.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 0.5809177450218778, Train Accuracy : 0.9988638723098364\n",
            " Validation Accuracy : 6.599797197993021\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.057625845\n",
            "self.loss(score_0, v1) 0.1798319\n",
            "self.loss(score_0, v2) 0.27416292\n",
            "self.loss(score_2, v3) 0.07777127\n",
            "loss tensor(0.6283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052459605\n",
            "self.loss(score_0, v1) 0.09839226\n",
            "self.loss(score_0, v2) 0.15694702\n",
            "self.loss(score_2, v3) 0.08644617\n",
            "loss tensor(0.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22755308\n",
            "self.loss(score_0, v1) 0.35981858\n",
            "self.loss(score_0, v2) 0.17704518\n",
            "self.loss(score_2, v3) 0.04519128\n",
            "loss tensor(0.8322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16451982\n",
            "self.loss(score_0, v1) 0.26886848\n",
            "self.loss(score_0, v2) 0.15618177\n",
            "self.loss(score_2, v3) 0.05606942\n",
            "loss tensor(0.6737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07349874\n",
            "self.loss(score_0, v1) 0.2265469\n",
            "self.loss(score_0, v2) 0.22556472\n",
            "self.loss(score_2, v3) 0.042765368\n",
            "loss tensor(0.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.065197885\n",
            "self.loss(score_0, v1) 0.10186701\n",
            "self.loss(score_0, v2) 0.07234489\n",
            "self.loss(score_2, v3) 0.0459578\n",
            "loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06094997\n",
            "self.loss(score_0, v1) 0.102253\n",
            "self.loss(score_0, v2) 0.06665311\n",
            "self.loss(score_2, v3) 0.04950303\n",
            "loss tensor(0.3041, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07975164\n",
            "self.loss(score_0, v1) 0.10817157\n",
            "self.loss(score_0, v2) 0.066722885\n",
            "self.loss(score_2, v3) 0.03940716\n",
            "loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.074094154\n",
            "self.loss(score_0, v1) 0.116569415\n",
            "self.loss(score_0, v2) 0.108055145\n",
            "self.loss(score_2, v3) 0.054630347\n",
            "loss tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06678024\n",
            "self.loss(score_0, v1) 0.10647812\n",
            "self.loss(score_0, v2) 0.121241055\n",
            "self.loss(score_2, v3) 0.064053826\n",
            "loss tensor(0.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09973075\n",
            "self.loss(score_0, v1) 0.42465347\n",
            "self.loss(score_0, v2) 0.33265686\n",
            "self.loss(score_2, v3) 0.053873874\n",
            "loss tensor(0.9379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08412797\n",
            "self.loss(score_0, v1) 0.13562961\n",
            "self.loss(score_0, v2) 0.118175104\n",
            "self.loss(score_2, v3) 0.04621163\n",
            "loss tensor(0.4073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08524163\n",
            "self.loss(score_0, v1) 0.20894243\n",
            "self.loss(score_0, v2) 0.16971956\n",
            "self.loss(score_2, v3) 0.04559104\n",
            "loss tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13395171\n",
            "self.loss(score_0, v1) 0.18674386\n",
            "self.loss(score_0, v2) 0.17591566\n",
            "self.loss(score_2, v3) 0.0497192\n",
            "loss tensor(0.5712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.063643396\n",
            "self.loss(score_0, v1) 0.11236395\n",
            "self.loss(score_0, v2) 0.10356775\n",
            "self.loss(score_2, v3) 0.0469729\n",
            "loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19932583\n",
            "self.loss(score_0, v1) 0.21206069\n",
            "self.loss(score_0, v2) 0.086706996\n",
            "self.loss(score_2, v3) 0.06707609\n",
            "loss tensor(0.5987, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08939599\n",
            "self.loss(score_0, v1) 0.143508\n",
            "self.loss(score_0, v2) 0.095922984\n",
            "self.loss(score_2, v3) 0.055808168\n",
            "loss tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077235684\n",
            "self.loss(score_0, v1) 0.13185476\n",
            "self.loss(score_0, v2) 0.10506077\n",
            "self.loss(score_2, v3) 0.0483566\n",
            "loss tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.33463964\n",
            "self.loss(score_0, v1) 0.39599165\n",
            "self.loss(score_0, v2) 0.24962598\n",
            "self.loss(score_2, v3) 0.06735945\n",
            "loss tensor(1.0813, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08988796\n",
            "self.loss(score_0, v1) 0.1712128\n",
            "self.loss(score_0, v2) 0.1880265\n",
            "self.loss(score_2, v3) 0.05942223\n",
            "loss tensor(0.5383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09501873\n",
            "self.loss(score_0, v1) 0.13476808\n",
            "self.loss(score_0, v2) 0.10928452\n",
            "self.loss(score_2, v3) 0.05205971\n",
            "loss tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12825692\n",
            "self.loss(score_0, v1) 0.15962093\n",
            "self.loss(score_0, v2) 0.08010658\n",
            "self.loss(score_2, v3) 0.061366547\n",
            "loss tensor(0.4600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058450997\n",
            "self.loss(score_0, v1) 0.108997256\n",
            "self.loss(score_0, v2) 0.17012207\n",
            "self.loss(score_2, v3) 0.06015271\n",
            "loss tensor(0.4278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057720993\n",
            "self.loss(score_0, v1) 0.086989485\n",
            "self.loss(score_0, v2) 0.08538607\n",
            "self.loss(score_2, v3) 0.04175386\n",
            "loss tensor(0.2927, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06680052\n",
            "self.loss(score_0, v1) 0.105213255\n",
            "self.loss(score_0, v2) 0.07584688\n",
            "self.loss(score_2, v3) 0.043911852\n",
            "loss tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07176414\n",
            "self.loss(score_0, v1) 0.13593116\n",
            "self.loss(score_0, v2) 0.104938984\n",
            "self.loss(score_2, v3) 0.061398145\n",
            "loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.083161205\n",
            "self.loss(score_0, v1) 0.1686596\n",
            "self.loss(score_0, v2) 0.110058464\n",
            "self.loss(score_2, v3) 0.05479495\n",
            "loss tensor(0.4441, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06445753\n",
            "self.loss(score_0, v1) 0.115982085\n",
            "self.loss(score_0, v2) 0.08984183\n",
            "self.loss(score_2, v3) 0.059023585\n",
            "loss tensor(0.3588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09442029\n",
            "self.loss(score_0, v1) 0.25861594\n",
            "self.loss(score_0, v2) 0.23617755\n",
            "self.loss(score_2, v3) 0.065389745\n",
            "loss tensor(0.6873, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.064387515\n",
            "self.loss(score_0, v1) 0.11199159\n",
            "self.loss(score_0, v2) 0.11826952\n",
            "self.loss(score_2, v3) 0.05589339\n",
            "loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.086789496\n",
            "self.loss(score_0, v1) 0.36881393\n",
            "self.loss(score_0, v2) 0.25927198\n",
            "self.loss(score_2, v3) 0.05100316\n",
            "loss tensor(0.7914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0740499\n",
            "self.loss(score_0, v1) 0.10862492\n",
            "self.loss(score_0, v2) 0.068158224\n",
            "self.loss(score_2, v3) 0.048063457\n",
            "loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.44271448\n",
            "self.loss(score_0, v1) 0.48941386\n",
            "self.loss(score_0, v2) 0.63993305\n",
            "self.loss(score_2, v3) 0.7329191\n",
            "loss tensor(2.6714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08517448\n",
            "self.loss(score_0, v1) 0.10457281\n",
            "self.loss(score_0, v2) 0.08049813\n",
            "self.loss(score_2, v3) 0.056715764\n",
            "loss tensor(0.3553, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07200296\n",
            "self.loss(score_0, v1) 0.12437242\n",
            "self.loss(score_0, v2) 0.12737845\n",
            "self.loss(score_2, v3) 0.056760028\n",
            "loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07085949\n",
            "self.loss(score_0, v1) 0.14297226\n",
            "self.loss(score_0, v2) 0.098985694\n",
            "self.loss(score_2, v3) 0.06513037\n",
            "loss tensor(0.4105, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.067601345\n",
            "self.loss(score_0, v1) 0.116143405\n",
            "self.loss(score_0, v2) 0.0861855\n",
            "self.loss(score_2, v3) 0.06574311\n",
            "loss tensor(0.3685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07301028\n",
            "self.loss(score_0, v1) 0.19600922\n",
            "self.loss(score_0, v2) 0.18402949\n",
            "self.loss(score_2, v3) 0.059695706\n",
            "loss tensor(0.5426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14404412\n",
            "self.loss(score_0, v1) 0.19786997\n",
            "self.loss(score_0, v2) 0.08992932\n",
            "self.loss(score_2, v3) 0.063610755\n",
            "loss tensor(0.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07285742\n",
            "self.loss(score_0, v1) 0.13861394\n",
            "self.loss(score_0, v2) 0.21574521\n",
            "self.loss(score_2, v3) 0.16092919\n",
            "loss tensor(0.6686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13246809\n",
            "self.loss(score_0, v1) 0.16817178\n",
            "self.loss(score_0, v2) 0.057341054\n",
            "self.loss(score_2, v3) 0.037470475\n",
            "loss tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.24685305\n",
            "self.loss(score_0, v1) 0.54612535\n",
            "self.loss(score_0, v2) 0.34892377\n",
            "self.loss(score_2, v3) 0.046348237\n",
            "loss tensor(1.2114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.082894236\n",
            "self.loss(score_0, v1) 0.11753836\n",
            "self.loss(score_0, v2) 0.10131602\n",
            "self.loss(score_2, v3) 0.0654795\n",
            "loss tensor(0.4000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053922288\n",
            "self.loss(score_0, v1) 0.09979647\n",
            "self.loss(score_0, v2) 0.09312817\n",
            "self.loss(score_2, v3) 0.049684174\n",
            "loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07539816\n",
            "self.loss(score_0, v1) 0.112134606\n",
            "self.loss(score_0, v2) 0.1031193\n",
            "self.loss(score_2, v3) 0.05529885\n",
            "loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.067513734\n",
            "self.loss(score_0, v1) 0.1261682\n",
            "self.loss(score_0, v2) 0.09467331\n",
            "self.loss(score_2, v3) 0.047325935\n",
            "loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.066368155\n",
            "self.loss(score_0, v1) 0.11825954\n",
            "self.loss(score_0, v2) 0.084931545\n",
            "self.loss(score_2, v3) 0.06170116\n",
            "loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08474658\n",
            "self.loss(score_0, v1) 0.2450022\n",
            "self.loss(score_0, v2) 0.22751468\n",
            "self.loss(score_2, v3) 0.05008012\n",
            "loss tensor(0.6324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058262005\n",
            "self.loss(score_0, v1) 0.07831832\n",
            "self.loss(score_0, v2) 0.087605104\n",
            "self.loss(score_2, v3) 0.04868261\n",
            "loss tensor(0.2972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07501659\n",
            "self.loss(score_0, v1) 0.1551633\n",
            "self.loss(score_0, v2) 0.14352538\n",
            "self.loss(score_2, v3) 0.062983215\n",
            "loss tensor(0.4682, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15475023\n",
            "self.loss(score_0, v1) 0.53184783\n",
            "self.loss(score_0, v2) 0.40806758\n",
            "self.loss(score_2, v3) 0.06451431\n",
            "loss tensor(1.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06495323\n",
            "self.loss(score_0, v1) 0.106877424\n",
            "self.loss(score_0, v2) 0.075442426\n",
            "self.loss(score_2, v3) 0.05324315\n",
            "loss tensor(0.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11847054\n",
            "self.loss(score_0, v1) 0.24584784\n",
            "self.loss(score_0, v2) 0.3644487\n",
            "self.loss(score_2, v3) 0.17125076\n",
            "loss tensor(0.9856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.087506175\n",
            "self.loss(score_0, v1) 0.11438328\n",
            "self.loss(score_0, v2) 0.08458136\n",
            "self.loss(score_2, v3) 0.062405344\n",
            "loss tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.32952508\n",
            "self.loss(score_0, v1) 0.42008743\n",
            "self.loss(score_0, v2) 0.14266574\n",
            "self.loss(score_2, v3) 0.07040735\n",
            "loss tensor(0.9979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.092963174\n",
            "self.loss(score_0, v1) 0.15366223\n",
            "self.loss(score_0, v2) 0.13957602\n",
            "self.loss(score_2, v3) 0.058681566\n",
            "loss tensor(0.4742, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12763318\n",
            "self.loss(score_0, v1) 0.19216071\n",
            "self.loss(score_0, v2) 0.1123138\n",
            "self.loss(score_2, v3) 0.06055954\n",
            "loss tensor(0.5229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075710766\n",
            "self.loss(score_0, v1) 0.2864653\n",
            "self.loss(score_0, v2) 0.2206346\n",
            "self.loss(score_2, v3) 0.060110833\n",
            "loss tensor(0.6730, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07702761\n",
            "self.loss(score_0, v1) 0.13982469\n",
            "self.loss(score_0, v2) 0.09803336\n",
            "self.loss(score_2, v3) 0.03841841\n",
            "loss tensor(0.3725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.069455914\n",
            "self.loss(score_0, v1) 0.10377837\n",
            "self.loss(score_0, v2) 0.07027888\n",
            "self.loss(score_2, v3) 0.048547067\n",
            "loss tensor(0.3163, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04801375\n",
            "self.loss(score_0, v1) 0.2520856\n",
            "self.loss(score_0, v2) 0.16948232\n",
            "self.loss(score_2, v3) 0.02818233\n",
            "loss tensor(0.5119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09587821\n",
            "self.loss(score_0, v1) 0.25596634\n",
            "self.loss(score_0, v2) 0.14709128\n",
            "self.loss(score_2, v3) 0.06143771\n",
            "loss tensor(0.5911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.069705285\n",
            "self.loss(score_0, v1) 0.1099111\n",
            "self.loss(score_0, v2) 0.08312227\n",
            "self.loss(score_2, v3) 0.057635136\n",
            "loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22401269\n",
            "self.loss(score_0, v1) 0.20640235\n",
            "self.loss(score_0, v2) 0.14586477\n",
            "self.loss(score_2, v3) 0.09398246\n",
            "loss tensor(0.7173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12973195\n",
            "self.loss(score_0, v1) 0.4055602\n",
            "self.loss(score_0, v2) 0.32580075\n",
            "self.loss(score_2, v3) 0.052840054\n",
            "loss tensor(0.9404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14241254\n",
            "self.loss(score_0, v1) 0.25356027\n",
            "self.loss(score_0, v2) 0.2294349\n",
            "self.loss(score_2, v3) 0.06554232\n",
            "loss tensor(0.7237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08152105\n",
            "self.loss(score_0, v1) 0.16535771\n",
            "self.loss(score_0, v2) 0.15991032\n",
            "self.loss(score_2, v3) 0.061690502\n",
            "loss tensor(0.4993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07003418\n",
            "self.loss(score_0, v1) 0.10115642\n",
            "self.loss(score_0, v2) 0.1153625\n",
            "self.loss(score_2, v3) 0.05991288\n",
            "loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09389106\n",
            "self.loss(score_0, v1) 0.15158255\n",
            "self.loss(score_0, v2) 0.09003552\n",
            "self.loss(score_2, v3) 0.046550907\n",
            "loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.076316655\n",
            "self.loss(score_0, v1) 0.15898073\n",
            "self.loss(score_0, v2) 0.15062776\n",
            "self.loss(score_2, v3) 0.04891667\n",
            "loss tensor(0.4593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06564601\n",
            "self.loss(score_0, v1) 0.13649043\n",
            "self.loss(score_0, v2) 0.11839036\n",
            "self.loss(score_2, v3) 0.048529886\n",
            "loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.34021124\n",
            "self.loss(score_0, v1) 0.78015304\n",
            "self.loss(score_0, v2) 0.49629158\n",
            "self.loss(score_2, v3) 0.042536482\n",
            "loss tensor(1.6805, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09271673\n",
            "self.loss(score_0, v1) 0.16824552\n",
            "self.loss(score_0, v2) 0.12817599\n",
            "self.loss(score_2, v3) 0.0572245\n",
            "loss tensor(0.4750, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.076514825\n",
            "self.loss(score_0, v1) 0.45001328\n",
            "self.loss(score_0, v2) 0.45998833\n",
            "self.loss(score_2, v3) 0.08472787\n",
            "loss tensor(1.1136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0617859\n",
            "self.loss(score_0, v1) 0.09516623\n",
            "self.loss(score_0, v2) 0.09704987\n",
            "self.loss(score_2, v3) 0.04634784\n",
            "loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058110636\n",
            "self.loss(score_0, v1) 0.08114216\n",
            "self.loss(score_0, v2) 0.078677624\n",
            "self.loss(score_2, v3) 0.046525598\n",
            "loss tensor(0.2877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09016594\n",
            "self.loss(score_0, v1) 0.26230425\n",
            "self.loss(score_0, v2) 0.21341735\n",
            "self.loss(score_2, v3) 0.053996753\n",
            "loss tensor(0.6469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07705706\n",
            "self.loss(score_0, v1) 0.123600915\n",
            "self.loss(score_0, v2) 0.078697234\n",
            "self.loss(score_2, v3) 0.052421093\n",
            "loss tensor(0.3580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07540948\n",
            "self.loss(score_0, v1) 0.20085058\n",
            "self.loss(score_0, v2) 0.16124932\n",
            "self.loss(score_2, v3) 0.048534706\n",
            "loss tensor(0.5103, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056674585\n",
            "self.loss(score_0, v1) 0.098865554\n",
            "self.loss(score_0, v2) 0.06547511\n",
            "self.loss(score_2, v3) 0.037761576\n",
            "loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10491838\n",
            "self.loss(score_0, v1) 0.28745162\n",
            "self.loss(score_0, v2) 0.25470734\n",
            "self.loss(score_2, v3) 0.043155443\n",
            "loss tensor(0.7118, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06382437\n",
            "self.loss(score_0, v1) 0.11940043\n",
            "self.loss(score_0, v2) 0.08051869\n",
            "self.loss(score_2, v3) 0.052308057\n",
            "loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.064265504\n",
            "self.loss(score_0, v1) 0.104817934\n",
            "self.loss(score_0, v2) 0.05839993\n",
            "self.loss(score_2, v3) 0.048064075\n",
            "loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08055043\n",
            "self.loss(score_0, v1) 0.13508824\n",
            "self.loss(score_0, v2) 0.08904106\n",
            "self.loss(score_2, v3) 0.04855279\n",
            "loss tensor(0.3775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06940941\n",
            "self.loss(score_0, v1) 0.37696946\n",
            "self.loss(score_0, v2) 0.29545376\n",
            "self.loss(score_2, v3) 0.04155354\n",
            "loss tensor(0.8042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.085011356\n",
            "self.loss(score_0, v1) 0.1198371\n",
            "self.loss(score_0, v2) 0.11249974\n",
            "self.loss(score_2, v3) 0.059340134\n",
            "loss tensor(0.4064, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07268817\n",
            "self.loss(score_0, v1) 0.41288528\n",
            "self.loss(score_0, v2) 0.41780218\n",
            "self.loss(score_2, v3) 0.16303842\n",
            "loss tensor(1.1479, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08924202\n",
            "self.loss(score_0, v1) 0.12887724\n",
            "self.loss(score_0, v2) 0.11605933\n",
            "self.loss(score_2, v3) 0.043350596\n",
            "loss tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057748884\n",
            "self.loss(score_0, v1) 0.09977634\n",
            "self.loss(score_0, v2) 0.09664159\n",
            "self.loss(score_2, v3) 0.053573575\n",
            "loss tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0578776\n",
            "self.loss(score_0, v1) 0.21802473\n",
            "self.loss(score_0, v2) 0.19773497\n",
            "self.loss(score_2, v3) 0.049679723\n",
            "loss tensor(0.5482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12947525\n",
            "self.loss(score_0, v1) 0.20975713\n",
            "self.loss(score_0, v2) 0.16694008\n",
            "self.loss(score_2, v3) 0.045977224\n",
            "loss tensor(0.5751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.100511365\n",
            "self.loss(score_0, v1) 0.14356974\n",
            "self.loss(score_0, v2) 0.11188611\n",
            "self.loss(score_2, v3) 0.056248784\n",
            "loss tensor(0.4403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0927464\n",
            "self.loss(score_0, v1) 0.16888799\n",
            "self.loss(score_0, v2) 0.12329912\n",
            "self.loss(score_2, v3) 0.05595131\n",
            "loss tensor(0.4689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075556085\n",
            "self.loss(score_0, v1) 0.16805509\n",
            "self.loss(score_0, v2) 0.30331135\n",
            "self.loss(score_2, v3) 0.068617865\n",
            "loss tensor(0.6498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.081671976\n",
            "self.loss(score_0, v1) 0.12771508\n",
            "self.loss(score_0, v2) 0.09339067\n",
            "self.loss(score_2, v3) 0.044244234\n",
            "loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.31230414\n",
            "self.loss(score_0, v1) 0.3034063\n",
            "self.loss(score_0, v2) 0.085641526\n",
            "self.loss(score_2, v3) 0.050165653\n",
            "loss tensor(0.7766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09739209\n",
            "self.loss(score_0, v1) 0.25818825\n",
            "self.loss(score_0, v2) 0.19062881\n",
            "self.loss(score_2, v3) 0.057332814\n",
            "loss tensor(0.6322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0671226\n",
            "self.loss(score_0, v1) 0.10096891\n",
            "self.loss(score_0, v2) 0.065041825\n",
            "self.loss(score_2, v3) 0.048509225\n",
            "loss tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06338922\n",
            "self.loss(score_0, v1) 0.10913095\n",
            "self.loss(score_0, v2) 0.13363461\n",
            "self.loss(score_2, v3) 0.050037663\n",
            "loss tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09381564\n",
            "self.loss(score_0, v1) 0.30553225\n",
            "self.loss(score_0, v2) 0.33454818\n",
            "self.loss(score_2, v3) 0.06986295\n",
            "loss tensor(0.8387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07304488\n",
            "self.loss(score_0, v1) 0.33536196\n",
            "self.loss(score_0, v2) 0.39091897\n",
            "self.loss(score_2, v3) 0.122846596\n",
            "loss tensor(0.9836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17971098\n",
            "self.loss(score_0, v1) 0.33214465\n",
            "self.loss(score_0, v2) 0.1947593\n",
            "self.loss(score_2, v3) 0.06813177\n",
            "loss tensor(0.8088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11409055\n",
            "self.loss(score_0, v1) 0.14664002\n",
            "self.loss(score_0, v2) 0.10702536\n",
            "self.loss(score_2, v3) 0.04531496\n",
            "loss tensor(0.4357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07804603\n",
            "self.loss(score_0, v1) 0.13124298\n",
            "self.loss(score_0, v2) 0.11735251\n",
            "self.loss(score_2, v3) 0.06169143\n",
            "loss tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05537557\n",
            "self.loss(score_0, v1) 0.079103515\n",
            "self.loss(score_0, v2) 0.06450893\n",
            "self.loss(score_2, v3) 0.04383816\n",
            "loss tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07337839\n",
            "self.loss(score_0, v1) 0.19873653\n",
            "self.loss(score_0, v2) 0.22361219\n",
            "self.loss(score_2, v3) 0.05099366\n",
            "loss tensor(0.5722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17141294\n",
            "self.loss(score_0, v1) 0.5491672\n",
            "self.loss(score_0, v2) 0.32748136\n",
            "self.loss(score_2, v3) 0.057554252\n",
            "loss tensor(1.1344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07585308\n",
            "self.loss(score_0, v1) 0.12610239\n",
            "self.loss(score_0, v2) 0.08609001\n",
            "self.loss(score_2, v3) 0.05319253\n",
            "loss tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07619999\n",
            "self.loss(score_0, v1) 0.13569252\n",
            "self.loss(score_0, v2) 0.12239798\n",
            "self.loss(score_2, v3) 0.053171694\n",
            "loss tensor(0.4140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05942024\n",
            "self.loss(score_0, v1) 0.44209477\n",
            "self.loss(score_0, v2) 1.0286685\n",
            "self.loss(score_2, v3) 0.6982178\n",
            "loss tensor(2.5775, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06753724\n",
            "self.loss(score_0, v1) 0.10036582\n",
            "self.loss(score_0, v2) 0.09408223\n",
            "self.loss(score_2, v3) 0.051311806\n",
            "loss tensor(0.3390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08204247\n",
            "self.loss(score_0, v1) 0.110105045\n",
            "self.loss(score_0, v2) 0.13795348\n",
            "self.loss(score_2, v3) 0.18438251\n",
            "loss tensor(0.6067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06963331\n",
            "self.loss(score_0, v1) 0.24170083\n",
            "self.loss(score_0, v2) 0.1939522\n",
            "self.loss(score_2, v3) 0.049540237\n",
            "loss tensor(0.5796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08185365\n",
            "self.loss(score_0, v1) 0.14939104\n",
            "self.loss(score_0, v2) 0.10111591\n",
            "self.loss(score_2, v3) 0.05331379\n",
            "loss tensor(0.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0980634\n",
            "self.loss(score_0, v1) 0.1693036\n",
            "self.loss(score_0, v2) 0.14285779\n",
            "self.loss(score_2, v3) 0.063414715\n",
            "loss tensor(0.5053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056501336\n",
            "self.loss(score_0, v1) 0.080881156\n",
            "self.loss(score_0, v2) 0.086407796\n",
            "self.loss(score_2, v3) 0.046653986\n",
            "loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08789992\n",
            "self.loss(score_0, v1) 0.24113905\n",
            "self.loss(score_0, v2) 0.20268531\n",
            "self.loss(score_2, v3) 0.05466483\n",
            "loss tensor(0.6137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07750544\n",
            "self.loss(score_0, v1) 0.12352512\n",
            "self.loss(score_0, v2) 0.08331787\n",
            "self.loss(score_2, v3) 0.049976207\n",
            "loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050350968\n",
            "self.loss(score_0, v1) 0.08460288\n",
            "self.loss(score_0, v2) 0.08401263\n",
            "self.loss(score_2, v3) 0.03519838\n",
            "loss tensor(0.2718, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.038655944\n",
            "self.loss(score_0, v1) 0.09605751\n",
            "self.loss(score_0, v2) 0.05038634\n",
            "self.loss(score_2, v3) 0.029657133\n",
            "loss tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.39031637\n",
            "self.loss(score_0, v1) 0.35844782\n",
            "self.loss(score_0, v2) 0.18051724\n",
            "self.loss(score_2, v3) 0.11550384\n",
            "loss tensor(1.1025, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053193484\n",
            "self.loss(score_0, v1) 0.08573394\n",
            "self.loss(score_0, v2) 0.06358089\n",
            "self.loss(score_2, v3) 0.035985716\n",
            "loss tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10652261\n",
            "self.loss(score_0, v1) 0.21436568\n",
            "self.loss(score_0, v2) 0.12383419\n",
            "self.loss(score_2, v3) 0.046071257\n",
            "loss tensor(0.5138, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.045790046\n",
            "self.loss(score_0, v1) 0.08186366\n",
            "self.loss(score_0, v2) 0.061773807\n",
            "self.loss(score_2, v3) 0.03693363\n",
            "loss tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056619372\n",
            "self.loss(score_0, v1) 0.09963125\n",
            "self.loss(score_0, v2) 0.13340312\n",
            "self.loss(score_2, v3) 0.055780876\n",
            "loss tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09366813\n",
            "self.loss(score_0, v1) 0.16699143\n",
            "self.loss(score_0, v2) 0.15299836\n",
            "self.loss(score_2, v3) 0.06633833\n",
            "loss tensor(0.5132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08920125\n",
            "self.loss(score_0, v1) 0.16529849\n",
            "self.loss(score_0, v2) 0.1670822\n",
            "self.loss(score_2, v3) 0.05561877\n",
            "loss tensor(0.5050, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08536817\n",
            "self.loss(score_0, v1) 0.15956858\n",
            "self.loss(score_0, v2) 0.14860052\n",
            "self.loss(score_2, v3) 0.06548478\n",
            "loss tensor(0.4918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09835376\n",
            "self.loss(score_0, v1) 0.09734403\n",
            "self.loss(score_0, v2) 0.08124075\n",
            "self.loss(score_2, v3) 0.04662645\n",
            "loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0737316\n",
            "self.loss(score_0, v1) 0.11099055\n",
            "self.loss(score_0, v2) 0.08019743\n",
            "self.loss(score_2, v3) 0.061803386\n",
            "loss tensor(0.3576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06672018\n",
            "self.loss(score_0, v1) 0.10105853\n",
            "self.loss(score_0, v2) 0.20622846\n",
            "self.loss(score_2, v3) 0.18744692\n",
            "loss tensor(0.6552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049466923\n",
            "self.loss(score_0, v1) 0.10290893\n",
            "self.loss(score_0, v2) 0.09961369\n",
            "self.loss(score_2, v3) 0.03787726\n",
            "loss tensor(0.3088, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07353615\n",
            "self.loss(score_0, v1) 0.14080672\n",
            "self.loss(score_0, v2) 0.09476718\n",
            "self.loss(score_2, v3) 0.069377735\n",
            "loss tensor(0.4132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06664164\n",
            "self.loss(score_0, v1) 0.17839563\n",
            "self.loss(score_0, v2) 0.19785485\n",
            "self.loss(score_2, v3) 0.093253896\n",
            "loss tensor(0.5828, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060974546\n",
            "self.loss(score_0, v1) 0.3786911\n",
            "self.loss(score_0, v2) 0.56913656\n",
            "self.loss(score_2, v3) 0.1661488\n",
            "loss tensor(1.2580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.094131224\n",
            "self.loss(score_0, v1) 0.17151177\n",
            "self.loss(score_0, v2) 0.12027921\n",
            "self.loss(score_2, v3) 0.08477472\n",
            "loss tensor(0.5131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08007686\n",
            "self.loss(score_0, v1) 0.30540356\n",
            "self.loss(score_0, v2) 0.2812592\n",
            "self.loss(score_2, v3) 0.06190562\n",
            "loss tensor(0.7596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06630526\n",
            "self.loss(score_0, v1) 0.09190473\n",
            "self.loss(score_0, v2) 0.074528836\n",
            "self.loss(score_2, v3) 0.04243844\n",
            "loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07019999\n",
            "self.loss(score_0, v1) 0.2168236\n",
            "self.loss(score_0, v2) 0.21805373\n",
            "self.loss(score_2, v3) 0.068147846\n",
            "loss tensor(0.6073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06322789\n",
            "self.loss(score_0, v1) 0.11892454\n",
            "self.loss(score_0, v2) 0.09817723\n",
            "self.loss(score_2, v3) 0.046446897\n",
            "loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08951306\n",
            "self.loss(score_0, v1) 0.1522681\n",
            "self.loss(score_0, v2) 0.10805598\n",
            "self.loss(score_2, v3) 0.069313526\n",
            "loss tensor(0.4538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06498007\n",
            "self.loss(score_0, v1) 0.1558465\n",
            "self.loss(score_0, v2) 0.14149517\n",
            "self.loss(score_2, v3) 0.05684955\n",
            "loss tensor(0.4476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08806558\n",
            "self.loss(score_0, v1) 0.118900016\n",
            "self.loss(score_0, v2) 0.085499465\n",
            "self.loss(score_2, v3) 0.050814275\n",
            "loss tensor(0.3687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.072426274\n",
            "self.loss(score_0, v1) 0.12811008\n",
            "self.loss(score_0, v2) 0.116363585\n",
            "self.loss(score_2, v3) 0.055939764\n",
            "loss tensor(0.4008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08123085\n",
            "self.loss(score_0, v1) 0.5257151\n",
            "self.loss(score_0, v2) 0.4957686\n",
            "self.loss(score_2, v3) 0.06657932\n",
            "loss tensor(1.2026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07054497\n",
            "self.loss(score_0, v1) 0.12800473\n",
            "self.loss(score_0, v2) 0.11841254\n",
            "self.loss(score_2, v3) 0.051921856\n",
            "loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06472927\n",
            "self.loss(score_0, v1) 0.10012397\n",
            "self.loss(score_0, v2) 0.08426283\n",
            "self.loss(score_2, v3) 0.043392602\n",
            "loss tensor(0.3142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08990688\n",
            "self.loss(score_0, v1) 0.28707945\n",
            "self.loss(score_0, v2) 0.22447212\n",
            "self.loss(score_2, v3) 0.06565411\n",
            "loss tensor(0.6999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.110519625\n",
            "self.loss(score_0, v1) 0.16924608\n",
            "self.loss(score_0, v2) 0.08056072\n",
            "self.loss(score_2, v3) 0.05850228\n",
            "loss tensor(0.4481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11460262\n",
            "self.loss(score_0, v1) 0.13285306\n",
            "self.loss(score_0, v2) 0.10880559\n",
            "self.loss(score_2, v3) 0.049620386\n",
            "loss tensor(0.4307, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19149812\n",
            "self.loss(score_0, v1) 0.18261813\n",
            "self.loss(score_0, v2) 0.13725418\n",
            "self.loss(score_2, v3) 0.07941845\n",
            "loss tensor(0.6305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08083604\n",
            "self.loss(score_0, v1) 0.15004784\n",
            "self.loss(score_0, v2) 0.11366251\n",
            "self.loss(score_2, v3) 0.056242734\n",
            "loss tensor(0.4289, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11850233\n",
            "self.loss(score_0, v1) 0.23034571\n",
            "self.loss(score_0, v2) 0.08707948\n",
            "self.loss(score_2, v3) 0.050175745\n",
            "loss tensor(0.5112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07856545\n",
            "self.loss(score_0, v1) 0.30618447\n",
            "self.loss(score_0, v2) 0.23351018\n",
            "self.loss(score_2, v3) 0.063656144\n",
            "loss tensor(0.7137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.098031096\n",
            "self.loss(score_0, v1) 0.12223728\n",
            "self.loss(score_0, v2) 0.07351731\n",
            "self.loss(score_2, v3) 0.048042323\n",
            "loss tensor(0.3658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10952941\n",
            "self.loss(score_0, v1) 0.17180379\n",
            "self.loss(score_0, v2) 0.0882349\n",
            "self.loss(score_2, v3) 0.044784002\n",
            "loss tensor(0.4367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.065486684\n",
            "self.loss(score_0, v1) 0.108488254\n",
            "self.loss(score_0, v2) 0.11545024\n",
            "self.loss(score_2, v3) 0.0640193\n",
            "loss tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08837488\n",
            "self.loss(score_0, v1) 0.33937213\n",
            "self.loss(score_0, v2) 0.317366\n",
            "self.loss(score_2, v3) 0.043120854\n",
            "loss tensor(0.8098, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04697648\n",
            "self.loss(score_0, v1) 0.09752868\n",
            "self.loss(score_0, v2) 0.090206064\n",
            "self.loss(score_2, v3) 0.0410597\n",
            "loss tensor(0.2963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07595929\n",
            "self.loss(score_0, v1) 0.39925927\n",
            "self.loss(score_0, v2) 0.34460014\n",
            "self.loss(score_2, v3) 0.063632235\n",
            "loss tensor(0.9153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055482913\n",
            "self.loss(score_0, v1) 0.08650618\n",
            "self.loss(score_0, v2) 0.07745392\n",
            "self.loss(score_2, v3) 0.041497532\n",
            "loss tensor(0.2817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06324544\n",
            "self.loss(score_0, v1) 0.12553824\n",
            "self.loss(score_0, v2) 0.117970854\n",
            "self.loss(score_2, v3) 0.05734162\n",
            "loss tensor(0.3928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19698766\n",
            "self.loss(score_0, v1) 0.21200916\n",
            "self.loss(score_0, v2) 0.16150618\n",
            "self.loss(score_2, v3) 0.13144787\n",
            "loss tensor(0.7677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053686786\n",
            "self.loss(score_0, v1) 0.13349262\n",
            "self.loss(score_0, v2) 0.15206134\n",
            "self.loss(score_2, v3) 0.045881107\n",
            "loss tensor(0.4081, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05202494\n",
            "self.loss(score_0, v1) 0.11772491\n",
            "self.loss(score_0, v2) 0.07839693\n",
            "self.loss(score_2, v3) 0.0425127\n",
            "loss tensor(0.3119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.084115155\n",
            "self.loss(score_0, v1) 0.16662331\n",
            "self.loss(score_0, v2) 0.1479463\n",
            "self.loss(score_2, v3) 0.061977886\n",
            "loss tensor(0.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11266429\n",
            "self.loss(score_0, v1) 0.62551415\n",
            "self.loss(score_0, v2) 0.5902402\n",
            "self.loss(score_2, v3) 0.048955884\n",
            "loss tensor(1.4019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09063454\n",
            "self.loss(score_0, v1) 0.13172233\n",
            "self.loss(score_0, v2) 0.094762035\n",
            "self.loss(score_2, v3) 0.063404255\n",
            "loss tensor(0.4122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10312519\n",
            "self.loss(score_0, v1) 0.18958473\n",
            "self.loss(score_0, v2) 0.12522344\n",
            "self.loss(score_2, v3) 0.050476212\n",
            "loss tensor(0.4936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09711122\n",
            "self.loss(score_0, v1) 0.2400838\n",
            "self.loss(score_0, v2) 0.28381938\n",
            "self.loss(score_2, v3) 0.111325145\n",
            "loss tensor(0.7880, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060221557\n",
            "self.loss(score_0, v1) 0.43010128\n",
            "self.loss(score_0, v2) 0.40986666\n",
            "self.loss(score_2, v3) 0.11035979\n",
            "loss tensor(1.0657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.070823304\n",
            "self.loss(score_0, v1) 0.11449315\n",
            "self.loss(score_0, v2) 0.11063034\n",
            "self.loss(score_2, v3) 0.047347438\n",
            "loss tensor(0.3670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03523317\n",
            "self.loss(score_0, v1) 0.07248036\n",
            "self.loss(score_0, v2) 0.10530907\n",
            "self.loss(score_2, v3) 0.028108045\n",
            "loss tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077859074\n",
            "self.loss(score_0, v1) 0.11978875\n",
            "self.loss(score_0, v2) 0.08603811\n",
            "self.loss(score_2, v3) 0.056596473\n",
            "loss tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05771818\n",
            "self.loss(score_0, v1) 0.11344068\n",
            "self.loss(score_0, v2) 0.11159363\n",
            "self.loss(score_2, v3) 0.061177045\n",
            "loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060080677\n",
            "self.loss(score_0, v1) 0.078924924\n",
            "self.loss(score_0, v2) 0.059588775\n",
            "self.loss(score_2, v3) 0.05114042\n",
            "loss tensor(0.2753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058199197\n",
            "self.loss(score_0, v1) 0.11572441\n",
            "self.loss(score_0, v2) 0.054433793\n",
            "self.loss(score_2, v3) 0.03484541\n",
            "loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077790424\n",
            "self.loss(score_0, v1) 0.11431618\n",
            "self.loss(score_0, v2) 0.08623223\n",
            "self.loss(score_2, v3) 0.052188277\n",
            "loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12658416\n",
            "self.loss(score_0, v1) 0.15073368\n",
            "self.loss(score_0, v2) 0.08324347\n",
            "self.loss(score_2, v3) 0.05837189\n",
            "loss tensor(0.4481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.043105517\n",
            "self.loss(score_0, v1) 0.07276114\n",
            "self.loss(score_0, v2) 0.05472478\n",
            "self.loss(score_2, v3) 0.030591669\n",
            "loss tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075624056\n",
            "self.loss(score_0, v1) 0.16961217\n",
            "self.loss(score_0, v2) 0.20113376\n",
            "self.loss(score_2, v3) 0.068543054\n",
            "loss tensor(0.5492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21914932\n",
            "self.loss(score_0, v1) 0.30236244\n",
            "self.loss(score_0, v2) 0.06517671\n",
            "self.loss(score_2, v3) 0.039236296\n",
            "loss tensor(0.6455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060116686\n",
            "self.loss(score_0, v1) 0.09707485\n",
            "self.loss(score_0, v2) 0.08423658\n",
            "self.loss(score_2, v3) 0.04447245\n",
            "loss tensor(0.3081, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06778023\n",
            "self.loss(score_0, v1) 0.10550973\n",
            "self.loss(score_0, v2) 0.07970821\n",
            "self.loss(score_2, v3) 0.06447735\n",
            "loss tensor(0.3497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.085246384\n",
            "self.loss(score_0, v1) 0.25991184\n",
            "self.loss(score_0, v2) 0.23375584\n",
            "self.loss(score_2, v3) 0.05873768\n",
            "loss tensor(0.6670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073499575\n",
            "self.loss(score_0, v1) 0.18737563\n",
            "self.loss(score_0, v2) 0.12354432\n",
            "self.loss(score_2, v3) 0.04459187\n",
            "loss tensor(0.4513, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1052306\n",
            "self.loss(score_0, v1) 0.2151644\n",
            "self.loss(score_0, v2) 0.121568665\n",
            "self.loss(score_2, v3) 0.043871187\n",
            "loss tensor(0.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12077811\n",
            "self.loss(score_0, v1) 0.17120072\n",
            "self.loss(score_0, v2) 0.090412356\n",
            "self.loss(score_2, v3) 0.06369379\n",
            "loss tensor(0.4779, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.041208737\n",
            "self.loss(score_0, v1) 0.124973334\n",
            "self.loss(score_0, v2) 0.17833172\n",
            "self.loss(score_2, v3) 0.029967222\n",
            "loss tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08773224\n",
            "self.loss(score_0, v1) 0.10355561\n",
            "self.loss(score_0, v2) 0.070645794\n",
            "self.loss(score_2, v3) 0.043551326\n",
            "loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06410663\n",
            "self.loss(score_0, v1) 0.10785605\n",
            "self.loss(score_0, v2) 0.12439709\n",
            "self.loss(score_2, v3) 0.048512932\n",
            "loss tensor(0.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050956704\n",
            "self.loss(score_0, v1) 0.081822224\n",
            "self.loss(score_0, v2) 0.0616662\n",
            "self.loss(score_2, v3) 0.04372412\n",
            "loss tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21027659\n",
            "self.loss(score_0, v1) 0.27597252\n",
            "self.loss(score_0, v2) 0.09293125\n",
            "self.loss(score_2, v3) 0.05311204\n",
            "loss tensor(0.6588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06813063\n",
            "self.loss(score_0, v1) 0.07764059\n",
            "self.loss(score_0, v2) 0.0607892\n",
            "self.loss(score_2, v3) 0.04384735\n",
            "loss tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07010941\n",
            "self.loss(score_0, v1) 0.20949508\n",
            "self.loss(score_0, v2) 0.18044533\n",
            "self.loss(score_2, v3) 0.06338959\n",
            "loss tensor(0.5551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0910861\n",
            "self.loss(score_0, v1) 0.23192398\n",
            "self.loss(score_0, v2) 0.5583961\n",
            "self.loss(score_2, v3) 0.5748538\n",
            "loss tensor(1.7437, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.062685\n",
            "self.loss(score_0, v1) 0.08977938\n",
            "self.loss(score_0, v2) 0.06458982\n",
            "self.loss(score_2, v3) 0.04497389\n",
            "loss tensor(0.2845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21175191\n",
            "self.loss(score_0, v1) 0.30211273\n",
            "self.loss(score_0, v2) 0.20638864\n",
            "self.loss(score_2, v3) 0.050238915\n",
            "loss tensor(0.7956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.081294805\n",
            "self.loss(score_0, v1) 0.24888508\n",
            "self.loss(score_0, v2) 0.2212049\n",
            "self.loss(score_2, v3) 0.044324785\n",
            "loss tensor(0.6179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.070320085\n",
            "self.loss(score_0, v1) 0.14742282\n",
            "self.loss(score_0, v2) 0.1399079\n",
            "self.loss(score_2, v3) 0.059808396\n",
            "loss tensor(0.4474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08498247\n",
            "self.loss(score_0, v1) 0.10593992\n",
            "self.loss(score_0, v2) 0.052143335\n",
            "self.loss(score_2, v3) 0.03671242\n",
            "loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.078391\n",
            "self.loss(score_0, v1) 0.19082299\n",
            "self.loss(score_0, v2) 0.16848376\n",
            "self.loss(score_2, v3) 0.04508373\n",
            "loss tensor(0.5053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17416503\n",
            "self.loss(score_0, v1) 0.23262581\n",
            "self.loss(score_0, v2) 0.08960096\n",
            "self.loss(score_2, v3) 0.048690178\n",
            "loss tensor(0.5694, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0590603\n",
            "self.loss(score_0, v1) 0.2543051\n",
            "self.loss(score_0, v2) 0.1997922\n",
            "self.loss(score_2, v3) 0.049574975\n",
            "loss tensor(0.5875, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15817489\n",
            "self.loss(score_0, v1) 0.19198139\n",
            "self.loss(score_0, v2) 0.15392695\n",
            "self.loss(score_2, v3) 0.05101532\n",
            "loss tensor(0.5806, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07530967\n",
            "self.loss(score_0, v1) 0.13095112\n",
            "self.loss(score_0, v2) 0.11498921\n",
            "self.loss(score_2, v3) 0.04566358\n",
            "loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.088433\n",
            "self.loss(score_0, v1) 0.11248064\n",
            "self.loss(score_0, v2) 0.080047816\n",
            "self.loss(score_2, v3) 0.049630262\n",
            "loss tensor(0.3554, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.079231724\n",
            "self.loss(score_0, v1) 0.1487135\n",
            "self.loss(score_0, v2) 0.1515538\n",
            "self.loss(score_2, v3) 0.04882773\n",
            "loss tensor(0.4527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23451822\n",
            "self.loss(score_0, v1) 0.49075583\n",
            "self.loss(score_0, v2) 0.5091339\n",
            "self.loss(score_2, v3) 0.17122374\n",
            "loss tensor(1.4912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058454104\n",
            "self.loss(score_0, v1) 0.10176253\n",
            "self.loss(score_0, v2) 0.087810874\n",
            "self.loss(score_2, v3) 0.05101504\n",
            "loss tensor(0.3246, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15497546\n",
            "self.loss(score_0, v1) 0.26350045\n",
            "self.loss(score_0, v2) 0.17569235\n",
            "self.loss(score_2, v3) 0.045460638\n",
            "loss tensor(0.6624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07852998\n",
            "self.loss(score_0, v1) 0.10067626\n",
            "self.loss(score_0, v2) 0.07312743\n",
            "self.loss(score_2, v3) 0.06143135\n",
            "loss tensor(0.3445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05870968\n",
            "self.loss(score_0, v1) 0.112158164\n",
            "self.loss(score_0, v2) 0.09003296\n",
            "self.loss(score_2, v3) 0.04023607\n",
            "loss tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06691333\n",
            "self.loss(score_0, v1) 0.11396486\n",
            "self.loss(score_0, v2) 0.08172035\n",
            "self.loss(score_2, v3) 0.05590696\n",
            "loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08147698\n",
            "self.loss(score_0, v1) 0.10946799\n",
            "self.loss(score_0, v2) 0.14566988\n",
            "self.loss(score_2, v3) 0.08941034\n",
            "loss tensor(0.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0573078\n",
            "self.loss(score_0, v1) 0.080568075\n",
            "self.loss(score_0, v2) 0.07606962\n",
            "self.loss(score_2, v3) 0.04448321\n",
            "loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.064351484\n",
            "self.loss(score_0, v1) 0.09964582\n",
            "self.loss(score_0, v2) 0.079006955\n",
            "self.loss(score_2, v3) 0.0418272\n",
            "loss tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06492743\n",
            "self.loss(score_0, v1) 0.7057755\n",
            "self.loss(score_0, v2) 0.7473287\n",
            "self.loss(score_2, v3) 0.059529137\n",
            "loss tensor(1.6073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07453333\n",
            "self.loss(score_0, v1) 0.15241104\n",
            "self.loss(score_0, v2) 0.11231388\n",
            "self.loss(score_2, v3) 0.045563\n",
            "loss tensor(0.4076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05921602\n",
            "self.loss(score_0, v1) 0.10047675\n",
            "self.loss(score_0, v2) 0.07784324\n",
            "self.loss(score_2, v3) 0.044989318\n",
            "loss tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07351431\n",
            "self.loss(score_0, v1) 0.1287568\n",
            "self.loss(score_0, v2) 0.114030585\n",
            "self.loss(score_2, v3) 0.053345527\n",
            "loss tensor(0.3963, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.071025155\n",
            "self.loss(score_0, v1) 0.14584225\n",
            "self.loss(score_0, v2) 0.07579646\n",
            "self.loss(score_2, v3) 0.053309314\n",
            "loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058700446\n",
            "self.loss(score_0, v1) 0.19213119\n",
            "self.loss(score_0, v2) 0.18844709\n",
            "self.loss(score_2, v3) 0.043632094\n",
            "loss tensor(0.5047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07682177\n",
            "self.loss(score_0, v1) 0.1877259\n",
            "self.loss(score_0, v2) 0.15992111\n",
            "self.loss(score_2, v3) 0.040571786\n",
            "loss tensor(0.4853, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075471744\n",
            "self.loss(score_0, v1) 0.29825664\n",
            "self.loss(score_0, v2) 0.27738026\n",
            "self.loss(score_2, v3) 0.055820774\n",
            "loss tensor(0.7348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08870089\n",
            "self.loss(score_0, v1) 0.35106358\n",
            "self.loss(score_0, v2) 0.26778856\n",
            "self.loss(score_2, v3) 0.07551633\n",
            "loss tensor(0.8208, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14042605\n",
            "self.loss(score_0, v1) 0.30679858\n",
            "self.loss(score_0, v2) 0.32526425\n",
            "self.loss(score_2, v3) 0.16699427\n",
            "loss tensor(1.0230, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15520313\n",
            "self.loss(score_0, v1) 0.3400869\n",
            "self.loss(score_0, v2) 0.43856812\n",
            "self.loss(score_2, v3) 0.049746286\n",
            "loss tensor(1.0085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075049184\n",
            "self.loss(score_0, v1) 0.40897214\n",
            "self.loss(score_0, v2) 0.34088695\n",
            "self.loss(score_2, v3) 0.061588433\n",
            "loss tensor(0.9173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07610564\n",
            "self.loss(score_0, v1) 0.13699515\n",
            "self.loss(score_0, v2) 0.07635412\n",
            "self.loss(score_2, v3) 0.044579796\n",
            "loss tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09630612\n",
            "self.loss(score_0, v1) 0.1236207\n",
            "self.loss(score_0, v2) 0.08191488\n",
            "self.loss(score_2, v3) 0.044169832\n",
            "loss tensor(0.3681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.038607508\n",
            "self.loss(score_0, v1) 0.066952944\n",
            "self.loss(score_0, v2) 0.05752015\n",
            "self.loss(score_2, v3) 0.03153622\n",
            "loss tensor(0.2104, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0585439\n",
            "self.loss(score_0, v1) 0.1589039\n",
            "self.loss(score_0, v2) 0.23168044\n",
            "self.loss(score_2, v3) 0.04322337\n",
            "loss tensor(0.5140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22359405\n",
            "self.loss(score_0, v1) 0.2725565\n",
            "self.loss(score_0, v2) 0.097785704\n",
            "self.loss(score_2, v3) 0.05248712\n",
            "loss tensor(0.6727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06328592\n",
            "self.loss(score_0, v1) 0.21138066\n",
            "self.loss(score_0, v2) 0.18434688\n",
            "self.loss(score_2, v3) 0.05886799\n",
            "loss tensor(0.5473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08515848\n",
            "self.loss(score_0, v1) 0.18227273\n",
            "self.loss(score_0, v2) 0.13249657\n",
            "self.loss(score_2, v3) 0.04495753\n",
            "loss tensor(0.4674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.026533138\n",
            "self.loss(score_0, v1) 0.104445495\n",
            "self.loss(score_0, v2) 0.116061\n",
            "self.loss(score_2, v3) 0.049997285\n",
            "loss tensor(0.3220, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09693175\n",
            "self.loss(score_0, v1) 0.25035766\n",
            "self.loss(score_0, v2) 0.17872849\n",
            "self.loss(score_2, v3) 0.045860905\n",
            "loss tensor(0.5948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08380444\n",
            "self.loss(score_0, v1) 0.10480511\n",
            "self.loss(score_0, v2) 0.079750635\n",
            "self.loss(score_2, v3) 0.048755858\n",
            "loss tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06423035\n",
            "self.loss(score_0, v1) 0.18292066\n",
            "self.loss(score_0, v2) 0.15215582\n",
            "self.loss(score_2, v3) 0.059709296\n",
            "loss tensor(0.4889, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.071346335\n",
            "self.loss(score_0, v1) 0.10644376\n",
            "self.loss(score_0, v2) 0.10879314\n",
            "self.loss(score_2, v3) 0.0650159\n",
            "loss tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05099749\n",
            "self.loss(score_0, v1) 0.15901965\n",
            "self.loss(score_0, v2) 0.08509475\n",
            "self.loss(score_2, v3) 0.038786177\n",
            "loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.079416074\n",
            "self.loss(score_0, v1) 0.39669117\n",
            "self.loss(score_0, v2) 0.3295346\n",
            "self.loss(score_2, v3) 0.047144897\n",
            "loss tensor(0.8764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057869043\n",
            "self.loss(score_0, v1) 0.11730713\n",
            "self.loss(score_0, v2) 0.06343139\n",
            "self.loss(score_2, v3) 0.04033402\n",
            "loss tensor(0.2991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05151883\n",
            "self.loss(score_0, v1) 0.09200941\n",
            "self.loss(score_0, v2) 0.07591898\n",
            "self.loss(score_2, v3) 0.033385463\n",
            "loss tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09884685\n",
            "self.loss(score_0, v1) 0.10575879\n",
            "self.loss(score_0, v2) 0.0835991\n",
            "self.loss(score_2, v3) 0.05178685\n",
            "loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18745928\n",
            "self.loss(score_0, v1) 0.19436634\n",
            "self.loss(score_0, v2) 0.08576664\n",
            "self.loss(score_2, v3) 0.06197586\n",
            "loss tensor(0.5606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10858559\n",
            "self.loss(score_0, v1) 0.15817268\n",
            "self.loss(score_0, v2) 0.11983204\n",
            "self.loss(score_2, v3) 0.04921114\n",
            "loss tensor(0.4604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.083239496\n",
            "self.loss(score_0, v1) 0.11185141\n",
            "self.loss(score_0, v2) 0.105318144\n",
            "self.loss(score_2, v3) 0.063456275\n",
            "loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07077092\n",
            "self.loss(score_0, v1) 0.14947054\n",
            "self.loss(score_0, v2) 0.13228306\n",
            "self.loss(score_2, v3) 0.04696159\n",
            "loss tensor(0.4230, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049492087\n",
            "self.loss(score_0, v1) 0.08010591\n",
            "self.loss(score_0, v2) 0.058285836\n",
            "self.loss(score_2, v3) 0.032722216\n",
            "loss tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0852513\n",
            "self.loss(score_0, v1) 0.49923337\n",
            "self.loss(score_0, v2) 0.48876074\n",
            "self.loss(score_2, v3) 0.06299738\n",
            "loss tensor(1.1677, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.120858885\n",
            "self.loss(score_0, v1) 0.14293072\n",
            "self.loss(score_0, v2) 0.09331409\n",
            "self.loss(score_2, v3) 0.04860423\n",
            "loss tensor(0.4300, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07217432\n",
            "self.loss(score_0, v1) 0.11243887\n",
            "self.loss(score_0, v2) 0.08157739\n",
            "self.loss(score_2, v3) 0.062063795\n",
            "loss tensor(0.3593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14720243\n",
            "self.loss(score_0, v1) 0.49584317\n",
            "self.loss(score_0, v2) 0.3827196\n",
            "self.loss(score_2, v3) 0.05766384\n",
            "loss tensor(1.1123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06297749\n",
            "self.loss(score_0, v1) 0.17157134\n",
            "self.loss(score_0, v2) 0.17889374\n",
            "self.loss(score_2, v3) 0.055025402\n",
            "loss tensor(0.4960, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13282216\n",
            "self.loss(score_0, v1) 0.20119937\n",
            "self.loss(score_0, v2) 0.19809942\n",
            "self.loss(score_2, v3) 0.05694583\n",
            "loss tensor(0.6175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.085086405\n",
            "self.loss(score_0, v1) 0.12981938\n",
            "self.loss(score_0, v2) 0.11193832\n",
            "self.loss(score_2, v3) 0.04650944\n",
            "loss tensor(0.3966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12750493\n",
            "self.loss(score_0, v1) 0.23166001\n",
            "self.loss(score_0, v2) 0.16338848\n",
            "self.loss(score_2, v3) 0.054412585\n",
            "loss tensor(0.6042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08980872\n",
            "self.loss(score_0, v1) 0.14948747\n",
            "self.loss(score_0, v2) 0.12292883\n",
            "self.loss(score_2, v3) 0.04221984\n",
            "loss tensor(0.4256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061401032\n",
            "self.loss(score_0, v1) 0.109985396\n",
            "self.loss(score_0, v2) 0.096651495\n",
            "self.loss(score_2, v3) 0.046101928\n",
            "loss tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.20250055\n",
            "self.loss(score_0, v1) 0.16805527\n",
            "self.loss(score_0, v2) 0.12894692\n",
            "self.loss(score_2, v3) 0.04630695\n",
            "loss tensor(0.5690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061481778\n",
            "self.loss(score_0, v1) 0.26170164\n",
            "self.loss(score_0, v2) 0.22895865\n",
            "self.loss(score_2, v3) 0.04765998\n",
            "loss tensor(0.6236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08830431\n",
            "self.loss(score_0, v1) 0.1200863\n",
            "self.loss(score_0, v2) 0.06810955\n",
            "self.loss(score_2, v3) 0.051161803\n",
            "loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08084064\n",
            "self.loss(score_0, v1) 0.15505515\n",
            "self.loss(score_0, v2) 0.10023517\n",
            "self.loss(score_2, v3) 0.05480656\n",
            "loss tensor(0.4183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10890374\n",
            "self.loss(score_0, v1) 0.20801091\n",
            "self.loss(score_0, v2) 0.2125763\n",
            "self.loss(score_2, v3) 0.06137855\n",
            "loss tensor(0.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.119047605\n",
            "self.loss(score_0, v1) 0.19752343\n",
            "self.loss(score_0, v2) 0.1383855\n",
            "self.loss(score_2, v3) 0.053898547\n",
            "loss tensor(0.5358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12580939\n",
            "self.loss(score_0, v1) 0.12289459\n",
            "self.loss(score_0, v2) 0.06934672\n",
            "self.loss(score_2, v3) 0.039731476\n",
            "loss tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07694228\n",
            "self.loss(score_0, v1) 0.11155966\n",
            "self.loss(score_0, v2) 0.10813532\n",
            "self.loss(score_2, v3) 0.049492195\n",
            "loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06308446\n",
            "self.loss(score_0, v1) 0.089710265\n",
            "self.loss(score_0, v2) 0.076380804\n",
            "self.loss(score_2, v3) 0.045946624\n",
            "loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05003988\n",
            "self.loss(score_0, v1) 0.086576164\n",
            "self.loss(score_0, v2) 0.09361462\n",
            "self.loss(score_2, v3) 0.045264088\n",
            "loss tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10463882\n",
            "self.loss(score_0, v1) 0.27545175\n",
            "self.loss(score_0, v2) 0.28368196\n",
            "self.loss(score_2, v3) 0.052785806\n",
            "loss tensor(0.7430, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07334347\n",
            "self.loss(score_0, v1) 0.37534225\n",
            "self.loss(score_0, v2) 0.3558537\n",
            "self.loss(score_2, v3) 0.0607431\n",
            "loss tensor(0.8957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.074111156\n",
            "self.loss(score_0, v1) 0.08848152\n",
            "self.loss(score_0, v2) 0.06361411\n",
            "self.loss(score_2, v3) 0.044372626\n",
            "loss tensor(0.2928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06929012\n",
            "self.loss(score_0, v1) 0.25722256\n",
            "self.loss(score_0, v2) 0.26577276\n",
            "self.loss(score_2, v3) 0.03917945\n",
            "loss tensor(0.6511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14503706\n",
            "self.loss(score_0, v1) 0.1684173\n",
            "self.loss(score_0, v2) 0.13113308\n",
            "self.loss(score_2, v3) 0.15015098\n",
            "loss tensor(0.6698, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053284824\n",
            "self.loss(score_0, v1) 0.11408071\n",
            "self.loss(score_0, v2) 0.15114616\n",
            "self.loss(score_2, v3) 0.05194437\n",
            "loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17631294\n",
            "self.loss(score_0, v1) 0.1285737\n",
            "self.loss(score_0, v2) 0.09318657\n",
            "self.loss(score_2, v3) 0.053753212\n",
            "loss tensor(0.4787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1064196\n",
            "self.loss(score_0, v1) 0.1323439\n",
            "self.loss(score_0, v2) 0.07567828\n",
            "self.loss(score_2, v3) 0.05032911\n",
            "loss tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12810867\n",
            "self.loss(score_0, v1) 0.17724372\n",
            "self.loss(score_0, v2) 0.103369914\n",
            "self.loss(score_2, v3) 0.048916746\n",
            "loss tensor(0.4821, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060597017\n",
            "self.loss(score_0, v1) 0.07349323\n",
            "self.loss(score_0, v2) 0.04699232\n",
            "self.loss(score_2, v3) 0.030614909\n",
            "loss tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.064113565\n",
            "self.loss(score_0, v1) 0.107694425\n",
            "self.loss(score_0, v2) 0.103375345\n",
            "self.loss(score_2, v3) 0.04765242\n",
            "loss tensor(0.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05705078\n",
            "self.loss(score_0, v1) 0.09396477\n",
            "self.loss(score_0, v2) 0.067109555\n",
            "self.loss(score_2, v3) 0.043204736\n",
            "loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056276057\n",
            "self.loss(score_0, v1) 0.34856385\n",
            "self.loss(score_0, v2) 0.35423857\n",
            "self.loss(score_2, v3) 0.045006346\n",
            "loss tensor(0.8266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059725996\n",
            "self.loss(score_0, v1) 0.096771084\n",
            "self.loss(score_0, v2) 0.10909708\n",
            "self.loss(score_2, v3) 0.05392213\n",
            "loss tensor(0.3465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15135826\n",
            "self.loss(score_0, v1) 0.18388365\n",
            "self.loss(score_0, v2) 0.08081014\n",
            "self.loss(score_2, v3) 0.044902537\n",
            "loss tensor(0.4834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09951004\n",
            "self.loss(score_0, v1) 0.11698111\n",
            "self.loss(score_0, v2) 0.07597268\n",
            "self.loss(score_2, v3) 0.0563081\n",
            "loss tensor(0.3769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.070760824\n",
            "self.loss(score_0, v1) 0.1125079\n",
            "self.loss(score_0, v2) 0.22799823\n",
            "self.loss(score_2, v3) 0.21395265\n",
            "loss tensor(0.7322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07136735\n",
            "self.loss(score_0, v1) 0.13476291\n",
            "self.loss(score_0, v2) 0.09502637\n",
            "self.loss(score_2, v3) 0.056676965\n",
            "loss tensor(0.3862, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057408784\n",
            "self.loss(score_0, v1) 0.09376395\n",
            "self.loss(score_0, v2) 0.068737455\n",
            "self.loss(score_2, v3) 0.047613204\n",
            "loss tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10827429\n",
            "self.loss(score_0, v1) 0.1238985\n",
            "self.loss(score_0, v2) 0.0743703\n",
            "self.loss(score_2, v3) 0.044671148\n",
            "loss tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0715116\n",
            "self.loss(score_0, v1) 0.094266586\n",
            "self.loss(score_0, v2) 0.08808546\n",
            "self.loss(score_2, v3) 0.04348539\n",
            "loss tensor(0.3191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060348693\n",
            "self.loss(score_0, v1) 0.17756313\n",
            "self.loss(score_0, v2) 0.18425663\n",
            "self.loss(score_2, v3) 0.0559867\n",
            "loss tensor(0.5061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06196257\n",
            "self.loss(score_0, v1) 0.128445\n",
            "self.loss(score_0, v2) 0.12706052\n",
            "self.loss(score_2, v3) 0.03951311\n",
            "loss tensor(0.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051506326\n",
            "self.loss(score_0, v1) 0.13426732\n",
            "self.loss(score_0, v2) 0.08983246\n",
            "self.loss(score_2, v3) 0.037995663\n",
            "loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07939112\n",
            "self.loss(score_0, v1) 0.33323973\n",
            "self.loss(score_0, v2) 0.2672118\n",
            "self.loss(score_2, v3) 0.05233442\n",
            "loss tensor(0.7583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.121347375\n",
            "self.loss(score_0, v1) 0.17961451\n",
            "self.loss(score_0, v2) 0.119379506\n",
            "self.loss(score_2, v3) 0.06129996\n",
            "loss tensor(0.5123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.068829544\n",
            "self.loss(score_0, v1) 0.13612284\n",
            "self.loss(score_0, v2) 0.17654525\n",
            "self.loss(score_2, v3) 0.10394756\n",
            "loss tensor(0.5374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077591196\n",
            "self.loss(score_0, v1) 0.0954444\n",
            "self.loss(score_0, v2) 0.10581312\n",
            "self.loss(score_2, v3) 0.04997954\n",
            "loss tensor(0.3538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09437382\n",
            "self.loss(score_0, v1) 0.119174644\n",
            "self.loss(score_0, v2) 0.068808794\n",
            "self.loss(score_2, v3) 0.041615345\n",
            "loss tensor(0.3448, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08310462\n",
            "self.loss(score_0, v1) 0.1708696\n",
            "self.loss(score_0, v2) 0.15405989\n",
            "self.loss(score_2, v3) 0.047994614\n",
            "loss tensor(0.4800, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.24585083\n",
            "self.loss(score_0, v1) 0.5230405\n",
            "self.loss(score_0, v2) 0.42476326\n",
            "self.loss(score_2, v3) 0.030814385\n",
            "loss tensor(1.2399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12127919\n",
            "self.loss(score_0, v1) 0.14762102\n",
            "self.loss(score_0, v2) 0.0662316\n",
            "self.loss(score_2, v3) 0.036632657\n",
            "loss tensor(0.3901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.118735336\n",
            "self.loss(score_0, v1) 0.20064136\n",
            "self.loss(score_0, v2) 0.20457979\n",
            "self.loss(score_2, v3) 0.044299286\n",
            "loss tensor(0.5904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03729634\n",
            "self.loss(score_0, v1) 0.20948589\n",
            "self.loss(score_0, v2) 0.2252845\n",
            "self.loss(score_2, v3) 0.03182836\n",
            "loss tensor(0.5198, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08403068\n",
            "self.loss(score_0, v1) 0.17081232\n",
            "self.loss(score_0, v2) 0.14014508\n",
            "self.loss(score_2, v3) 0.048663087\n",
            "loss tensor(0.4680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077098586\n",
            "self.loss(score_0, v1) 0.12378021\n",
            "self.loss(score_0, v2) 0.10443565\n",
            "self.loss(score_2, v3) 0.05355738\n",
            "loss tensor(0.3857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05870668\n",
            "self.loss(score_0, v1) 0.10708767\n",
            "self.loss(score_0, v2) 0.08190564\n",
            "self.loss(score_2, v3) 0.03920056\n",
            "loss tensor(0.3065, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07396986\n",
            "self.loss(score_0, v1) 0.12739113\n",
            "self.loss(score_0, v2) 0.08907908\n",
            "self.loss(score_2, v3) 0.04927823\n",
            "loss tensor(0.3644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.082934745\n",
            "self.loss(score_0, v1) 0.15838128\n",
            "self.loss(score_0, v2) 0.1602253\n",
            "self.loss(score_2, v3) 0.043681394\n",
            "loss tensor(0.4671, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06285497\n",
            "self.loss(score_0, v1) 0.095475115\n",
            "self.loss(score_0, v2) 0.09577069\n",
            "self.loss(score_2, v3) 0.0642614\n",
            "loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073448665\n",
            "self.loss(score_0, v1) 0.113988504\n",
            "self.loss(score_0, v2) 0.0920433\n",
            "self.loss(score_2, v3) 0.047153775\n",
            "loss tensor(0.3502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060335968\n",
            "self.loss(score_0, v1) 0.09696152\n",
            "self.loss(score_0, v2) 0.11099241\n",
            "self.loss(score_2, v3) 0.05688054\n",
            "loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08164952\n",
            "self.loss(score_0, v1) 0.23457803\n",
            "self.loss(score_0, v2) 0.22793937\n",
            "self.loss(score_2, v3) 0.053144936\n",
            "loss tensor(0.6239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 0.5305147467145495, Train Accuracy : 0.9988800486481781\n",
            " Validation Accuracy : 6.599874719071029\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.051120162\n",
            "self.loss(score_0, v1) 0.16300434\n",
            "self.loss(score_0, v2) 0.25440314\n",
            "self.loss(score_2, v3) 0.07395617\n",
            "loss tensor(0.5795, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.046485964\n",
            "self.loss(score_0, v1) 0.08317525\n",
            "self.loss(score_0, v2) 0.14515689\n",
            "self.loss(score_2, v3) 0.0804792\n",
            "loss tensor(0.3955, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21689644\n",
            "self.loss(score_0, v1) 0.34032658\n",
            "self.loss(score_0, v2) 0.16736574\n",
            "self.loss(score_2, v3) 0.040026624\n",
            "loss tensor(0.7846, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15531404\n",
            "self.loss(score_0, v1) 0.24402301\n",
            "self.loss(score_0, v2) 0.14209421\n",
            "self.loss(score_2, v3) 0.0495386\n",
            "loss tensor(0.6157, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.067813486\n",
            "self.loss(score_0, v1) 0.21077049\n",
            "self.loss(score_0, v2) 0.21048301\n",
            "self.loss(score_2, v3) 0.03858902\n",
            "loss tensor(0.5470, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05794969\n",
            "self.loss(score_0, v1) 0.08878823\n",
            "self.loss(score_0, v2) 0.06380524\n",
            "self.loss(score_2, v3) 0.04058325\n",
            "loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05409615\n",
            "self.loss(score_0, v1) 0.09058575\n",
            "self.loss(score_0, v2) 0.060579527\n",
            "self.loss(score_2, v3) 0.043577887\n",
            "loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07229983\n",
            "self.loss(score_0, v1) 0.09618329\n",
            "self.loss(score_0, v2) 0.06010375\n",
            "self.loss(score_2, v3) 0.034626234\n",
            "loss tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0661391\n",
            "self.loss(score_0, v1) 0.10359066\n",
            "self.loss(score_0, v2) 0.09697063\n",
            "self.loss(score_2, v3) 0.04844898\n",
            "loss tensor(0.3394, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058975197\n",
            "self.loss(score_0, v1) 0.09431756\n",
            "self.loss(score_0, v2) 0.11049553\n",
            "self.loss(score_2, v3) 0.05701557\n",
            "loss tensor(0.3493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09145088\n",
            "self.loss(score_0, v1) 0.40256745\n",
            "self.loss(score_0, v2) 0.3207134\n",
            "self.loss(score_2, v3) 0.047444265\n",
            "loss tensor(0.8859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07560421\n",
            "self.loss(score_0, v1) 0.12068848\n",
            "self.loss(score_0, v2) 0.10621722\n",
            "self.loss(score_2, v3) 0.041020364\n",
            "loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0760643\n",
            "self.loss(score_0, v1) 0.1906423\n",
            "self.loss(score_0, v2) 0.15894255\n",
            "self.loss(score_2, v3) 0.0406856\n",
            "loss tensor(0.4867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.122994184\n",
            "self.loss(score_0, v1) 0.1684082\n",
            "self.loss(score_0, v2) 0.162317\n",
            "self.loss(score_2, v3) 0.044967942\n",
            "loss tensor(0.5212, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056753766\n",
            "self.loss(score_0, v1) 0.09996772\n",
            "self.loss(score_0, v2) 0.09345756\n",
            "self.loss(score_2, v3) 0.041476738\n",
            "loss tensor(0.3124, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1832006\n",
            "self.loss(score_0, v1) 0.1858697\n",
            "self.loss(score_0, v2) 0.07870565\n",
            "self.loss(score_2, v3) 0.059353493\n",
            "loss tensor(0.5368, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08113275\n",
            "self.loss(score_0, v1) 0.12949657\n",
            "self.loss(score_0, v2) 0.090301454\n",
            "self.loss(score_2, v3) 0.050194796\n",
            "loss tensor(0.3762, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06899927\n",
            "self.loss(score_0, v1) 0.1171991\n",
            "self.loss(score_0, v2) 0.09456354\n",
            "self.loss(score_2, v3) 0.042889528\n",
            "loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.31963694\n",
            "self.loss(score_0, v1) 0.36901718\n",
            "self.loss(score_0, v2) 0.23726916\n",
            "self.loss(score_2, v3) 0.059814315\n",
            "loss tensor(1.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08204988\n",
            "self.loss(score_0, v1) 0.15234001\n",
            "self.loss(score_0, v2) 0.17433429\n",
            "self.loss(score_2, v3) 0.053620953\n",
            "loss tensor(0.4892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08611012\n",
            "self.loss(score_0, v1) 0.12106505\n",
            "self.loss(score_0, v2) 0.10057302\n",
            "self.loss(score_2, v3) 0.045771968\n",
            "loss tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11726738\n",
            "self.loss(score_0, v1) 0.14408782\n",
            "self.loss(score_0, v2) 0.0714429\n",
            "self.loss(score_2, v3) 0.05451391\n",
            "loss tensor(0.4146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051249027\n",
            "self.loss(score_0, v1) 0.09520992\n",
            "self.loss(score_0, v2) 0.15690129\n",
            "self.loss(score_2, v3) 0.05492884\n",
            "loss tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051868312\n",
            "self.loss(score_0, v1) 0.07728975\n",
            "self.loss(score_0, v2) 0.07832009\n",
            "self.loss(score_2, v3) 0.036788847\n",
            "loss tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059175555\n",
            "self.loss(score_0, v1) 0.09249652\n",
            "self.loss(score_0, v2) 0.066842206\n",
            "self.loss(score_2, v3) 0.038606215\n",
            "loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06365018\n",
            "self.loss(score_0, v1) 0.12073514\n",
            "self.loss(score_0, v2) 0.095240794\n",
            "self.loss(score_2, v3) 0.054449853\n",
            "loss tensor(0.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0760783\n",
            "self.loss(score_0, v1) 0.15151207\n",
            "self.loss(score_0, v2) 0.09983172\n",
            "self.loss(score_2, v3) 0.048884198\n",
            "loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056703277\n",
            "self.loss(score_0, v1) 0.10259701\n",
            "self.loss(score_0, v2) 0.07985741\n",
            "self.loss(score_2, v3) 0.052421883\n",
            "loss tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08738028\n",
            "self.loss(score_0, v1) 0.22947288\n",
            "self.loss(score_0, v2) 0.21726204\n",
            "self.loss(score_2, v3) 0.059330154\n",
            "loss tensor(0.6231, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057197757\n",
            "self.loss(score_0, v1) 0.10029879\n",
            "self.loss(score_0, v2) 0.10936737\n",
            "self.loss(score_2, v3) 0.04982561\n",
            "loss tensor(0.3416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07880427\n",
            "self.loss(score_0, v1) 0.34828207\n",
            "self.loss(score_0, v2) 0.24691871\n",
            "self.loss(score_2, v3) 0.045066267\n",
            "loss tensor(0.7416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06560164\n",
            "self.loss(score_0, v1) 0.09647051\n",
            "self.loss(score_0, v2) 0.062067598\n",
            "self.loss(score_2, v3) 0.042620853\n",
            "loss tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.42702502\n",
            "self.loss(score_0, v1) 0.4642793\n",
            "self.loss(score_0, v2) 0.60966337\n",
            "self.loss(score_2, v3) 0.7086204\n",
            "loss tensor(2.5639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07591094\n",
            "self.loss(score_0, v1) 0.0926393\n",
            "self.loss(score_0, v2) 0.072975576\n",
            "self.loss(score_2, v3) 0.050051097\n",
            "loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06356912\n",
            "self.loss(score_0, v1) 0.11073972\n",
            "self.loss(score_0, v2) 0.1170341\n",
            "self.loss(score_2, v3) 0.05018214\n",
            "loss tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06339589\n",
            "self.loss(score_0, v1) 0.1269555\n",
            "self.loss(score_0, v2) 0.08865018\n",
            "self.loss(score_2, v3) 0.058219858\n",
            "loss tensor(0.3663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060417823\n",
            "self.loss(score_0, v1) 0.10257693\n",
            "self.loss(score_0, v2) 0.07793227\n",
            "self.loss(score_2, v3) 0.058524378\n",
            "loss tensor(0.3287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06482212\n",
            "self.loss(score_0, v1) 0.17966746\n",
            "self.loss(score_0, v2) 0.17264134\n",
            "self.loss(score_2, v3) 0.053465027\n",
            "loss tensor(0.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13533561\n",
            "self.loss(score_0, v1) 0.18296033\n",
            "self.loss(score_0, v2) 0.08061898\n",
            "self.loss(score_2, v3) 0.0562826\n",
            "loss tensor(0.4833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.066021614\n",
            "self.loss(score_0, v1) 0.12353442\n",
            "self.loss(score_0, v2) 0.19793595\n",
            "self.loss(score_2, v3) 0.15281315\n",
            "loss tensor(0.6167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12201035\n",
            "self.loss(score_0, v1) 0.14940678\n",
            "self.loss(score_0, v2) 0.05071313\n",
            "self.loss(score_2, v3) 0.032919325\n",
            "loss tensor(0.3715, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2330249\n",
            "self.loss(score_0, v1) 0.48493636\n",
            "self.loss(score_0, v2) 0.32235682\n",
            "self.loss(score_2, v3) 0.04094058\n",
            "loss tensor(1.1017, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.074145496\n",
            "self.loss(score_0, v1) 0.10235371\n",
            "self.loss(score_0, v2) 0.092448205\n",
            "self.loss(score_2, v3) 0.059198633\n",
            "loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04762415\n",
            "self.loss(score_0, v1) 0.08892879\n",
            "self.loss(score_0, v2) 0.08629727\n",
            "self.loss(score_2, v3) 0.04420224\n",
            "loss tensor(0.2892, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0667981\n",
            "self.loss(score_0, v1) 0.09927276\n",
            "self.loss(score_0, v2) 0.09544779\n",
            "self.loss(score_2, v3) 0.04945115\n",
            "loss tensor(0.3357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060006835\n",
            "self.loss(score_0, v1) 0.11152824\n",
            "self.loss(score_0, v2) 0.086958416\n",
            "self.loss(score_2, v3) 0.04190614\n",
            "loss tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058995493\n",
            "self.loss(score_0, v1) 0.10274713\n",
            "self.loss(score_0, v2) 0.0756848\n",
            "self.loss(score_2, v3) 0.055152874\n",
            "loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077345006\n",
            "self.loss(score_0, v1) 0.21948761\n",
            "self.loss(score_0, v2) 0.21061042\n",
            "self.loss(score_2, v3) 0.044331864\n",
            "loss tensor(0.5739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050947677\n",
            "self.loss(score_0, v1) 0.06888833\n",
            "self.loss(score_0, v2) 0.07518189\n",
            "self.loss(score_2, v3) 0.04395584\n",
            "loss tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06720032\n",
            "self.loss(score_0, v1) 0.14045675\n",
            "self.loss(score_0, v2) 0.13164993\n",
            "self.loss(score_2, v3) 0.05718385\n",
            "loss tensor(0.4251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14026338\n",
            "self.loss(score_0, v1) 0.46259958\n",
            "self.loss(score_0, v2) 0.36566815\n",
            "self.loss(score_2, v3) 0.058097772\n",
            "loss tensor(1.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057825617\n",
            "self.loss(score_0, v1) 0.09381392\n",
            "self.loss(score_0, v2) 0.06791552\n",
            "self.loss(score_2, v3) 0.04771103\n",
            "loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10725492\n",
            "self.loss(score_0, v1) 0.21757187\n",
            "self.loss(score_0, v2) 0.34480342\n",
            "self.loss(score_2, v3) 0.16188186\n",
            "loss tensor(0.9125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07844567\n",
            "self.loss(score_0, v1) 0.10159303\n",
            "self.loss(score_0, v2) 0.07505303\n",
            "self.loss(score_2, v3) 0.055418458\n",
            "loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.31223303\n",
            "self.loss(score_0, v1) 0.3917615\n",
            "self.loss(score_0, v2) 0.12848598\n",
            "self.loss(score_2, v3) 0.06308977\n",
            "loss tensor(0.9271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08367\n",
            "self.loss(score_0, v1) 0.13865559\n",
            "self.loss(score_0, v2) 0.12560089\n",
            "self.loss(score_2, v3) 0.052363228\n",
            "loss tensor(0.4265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11801396\n",
            "self.loss(score_0, v1) 0.17456691\n",
            "self.loss(score_0, v2) 0.10193434\n",
            "self.loss(score_2, v3) 0.053793665\n",
            "loss tensor(0.4752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06758923\n",
            "self.loss(score_0, v1) 0.25961027\n",
            "self.loss(score_0, v2) 0.20396818\n",
            "self.loss(score_2, v3) 0.054021135\n",
            "loss tensor(0.6122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.069527164\n",
            "self.loss(score_0, v1) 0.12853545\n",
            "self.loss(score_0, v2) 0.090822235\n",
            "self.loss(score_2, v3) 0.033857096\n",
            "loss tensor(0.3397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061379742\n",
            "self.loss(score_0, v1) 0.09187018\n",
            "self.loss(score_0, v2) 0.06404024\n",
            "self.loss(score_2, v3) 0.043739256\n",
            "loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04308174\n",
            "self.loss(score_0, v1) 0.23744585\n",
            "self.loss(score_0, v2) 0.16364309\n",
            "self.loss(score_2, v3) 0.024739336\n",
            "loss tensor(0.4813, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08733681\n",
            "self.loss(score_0, v1) 0.23675853\n",
            "self.loss(score_0, v2) 0.13372675\n",
            "self.loss(score_2, v3) 0.05431694\n",
            "loss tensor(0.5393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061647184\n",
            "self.loss(score_0, v1) 0.0969727\n",
            "self.loss(score_0, v2) 0.073733024\n",
            "self.loss(score_2, v3) 0.051755115\n",
            "loss tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21241921\n",
            "self.loss(score_0, v1) 0.18816578\n",
            "self.loss(score_0, v2) 0.13821176\n",
            "self.loss(score_2, v3) 0.08830612\n",
            "loss tensor(0.6713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12116078\n",
            "self.loss(score_0, v1) 0.3779347\n",
            "self.loss(score_0, v2) 0.30842078\n",
            "self.loss(score_2, v3) 0.0471937\n",
            "loss tensor(0.8783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13343258\n",
            "self.loss(score_0, v1) 0.23004952\n",
            "self.loss(score_0, v2) 0.20999716\n",
            "self.loss(score_2, v3) 0.05849511\n",
            "loss tensor(0.6612, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07489865\n",
            "self.loss(score_0, v1) 0.14704432\n",
            "self.loss(score_0, v2) 0.14664817\n",
            "self.loss(score_2, v3) 0.055411458\n",
            "loss tensor(0.4517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.063566156\n",
            "self.loss(score_0, v1) 0.09120962\n",
            "self.loss(score_0, v2) 0.100394525\n",
            "self.loss(score_2, v3) 0.055634752\n",
            "loss tensor(0.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08557513\n",
            "self.loss(score_0, v1) 0.13907382\n",
            "self.loss(score_0, v2) 0.08460797\n",
            "self.loss(score_2, v3) 0.041348305\n",
            "loss tensor(0.3713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06825685\n",
            "self.loss(score_0, v1) 0.14613286\n",
            "self.loss(score_0, v2) 0.1432046\n",
            "self.loss(score_2, v3) 0.043224417\n",
            "loss tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05944292\n",
            "self.loss(score_0, v1) 0.11556146\n",
            "self.loss(score_0, v2) 0.10756452\n",
            "self.loss(score_2, v3) 0.043319277\n",
            "loss tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3155681\n",
            "self.loss(score_0, v1) 0.6429239\n",
            "self.loss(score_0, v2) 0.44182378\n",
            "self.loss(score_2, v3) 0.037682306\n",
            "loss tensor(1.4568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08491036\n",
            "self.loss(score_0, v1) 0.15077895\n",
            "self.loss(score_0, v2) 0.11949155\n",
            "self.loss(score_2, v3) 0.051604148\n",
            "loss tensor(0.4326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06932947\n",
            "self.loss(score_0, v1) 0.41344538\n",
            "self.loss(score_0, v2) 0.43251118\n",
            "self.loss(score_2, v3) 0.07715196\n",
            "loss tensor(1.0310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055001963\n",
            "self.loss(score_0, v1) 0.08452626\n",
            "self.loss(score_0, v2) 0.0897225\n",
            "self.loss(score_2, v3) 0.041273884\n",
            "loss tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05132267\n",
            "self.loss(score_0, v1) 0.07142853\n",
            "self.loss(score_0, v2) 0.06959619\n",
            "self.loss(score_2, v3) 0.04128323\n",
            "loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08202461\n",
            "self.loss(score_0, v1) 0.23089164\n",
            "self.loss(score_0, v2) 0.19467705\n",
            "self.loss(score_2, v3) 0.047690857\n",
            "loss tensor(0.5791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.068319954\n",
            "self.loss(score_0, v1) 0.11107768\n",
            "self.loss(score_0, v2) 0.0734465\n",
            "self.loss(score_2, v3) 0.047047555\n",
            "loss tensor(0.3234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06799078\n",
            "self.loss(score_0, v1) 0.17840788\n",
            "self.loss(score_0, v2) 0.14677581\n",
            "self.loss(score_2, v3) 0.042696476\n",
            "loss tensor(0.4572, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050787523\n",
            "self.loss(score_0, v1) 0.088854015\n",
            "self.loss(score_0, v2) 0.06048202\n",
            "self.loss(score_2, v3) 0.033163957\n",
            "loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09781682\n",
            "self.loss(score_0, v1) 0.26070213\n",
            "self.loss(score_0, v2) 0.23883185\n",
            "self.loss(score_2, v3) 0.038530763\n",
            "loss tensor(0.6551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05654867\n",
            "self.loss(score_0, v1) 0.10696204\n",
            "self.loss(score_0, v2) 0.07239101\n",
            "self.loss(score_2, v3) 0.04603353\n",
            "loss tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056826692\n",
            "self.loss(score_0, v1) 0.09253827\n",
            "self.loss(score_0, v2) 0.05241129\n",
            "self.loss(score_2, v3) 0.042595554\n",
            "loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07220092\n",
            "self.loss(score_0, v1) 0.12262646\n",
            "self.loss(score_0, v2) 0.080677226\n",
            "self.loss(score_2, v3) 0.042697176\n",
            "loss tensor(0.3396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061040323\n",
            "self.loss(score_0, v1) 0.36172262\n",
            "self.loss(score_0, v2) 0.2799305\n",
            "self.loss(score_2, v3) 0.036558338\n",
            "loss tensor(0.7575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.076769166\n",
            "self.loss(score_0, v1) 0.10713122\n",
            "self.loss(score_0, v2) 0.10277515\n",
            "self.loss(score_2, v3) 0.052456167\n",
            "loss tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06451227\n",
            "self.loss(score_0, v1) 0.3831038\n",
            "self.loss(score_0, v2) 0.3961946\n",
            "self.loss(score_2, v3) 0.15381055\n",
            "loss tensor(1.0745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.081559286\n",
            "self.loss(score_0, v1) 0.11602914\n",
            "self.loss(score_0, v2) 0.10837216\n",
            "self.loss(score_2, v3) 0.038655717\n",
            "loss tensor(0.3639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050909936\n",
            "self.loss(score_0, v1) 0.088009246\n",
            "self.loss(score_0, v2) 0.08797966\n",
            "self.loss(score_2, v3) 0.04807122\n",
            "loss tensor(0.2990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05098308\n",
            "self.loss(score_0, v1) 0.20338093\n",
            "self.loss(score_0, v2) 0.18733653\n",
            "self.loss(score_2, v3) 0.04386017\n",
            "loss tensor(0.5075, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12063074\n",
            "self.loss(score_0, v1) 0.18027304\n",
            "self.loss(score_0, v2) 0.15430358\n",
            "self.loss(score_2, v3) 0.040854186\n",
            "loss tensor(0.5165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.089433074\n",
            "self.loss(score_0, v1) 0.13153052\n",
            "self.loss(score_0, v2) 0.10224496\n",
            "self.loss(score_2, v3) 0.05103038\n",
            "loss tensor(0.3998, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0847158\n",
            "self.loss(score_0, v1) 0.15204784\n",
            "self.loss(score_0, v2) 0.114515975\n",
            "self.loss(score_2, v3) 0.05042604\n",
            "loss tensor(0.4269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06720599\n",
            "self.loss(score_0, v1) 0.1376904\n",
            "self.loss(score_0, v2) 0.278412\n",
            "self.loss(score_2, v3) 0.060559344\n",
            "loss tensor(0.5741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0726917\n",
            "self.loss(score_0, v1) 0.11330221\n",
            "self.loss(score_0, v2) 0.0864676\n",
            "self.loss(score_2, v3) 0.039253023\n",
            "loss tensor(0.3313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.29100004\n",
            "self.loss(score_0, v1) 0.26546755\n",
            "self.loss(score_0, v2) 0.07833822\n",
            "self.loss(score_2, v3) 0.04443871\n",
            "loss tensor(0.7015, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08909904\n",
            "self.loss(score_0, v1) 0.23634937\n",
            "self.loss(score_0, v2) 0.17794201\n",
            "self.loss(score_2, v3) 0.05083996\n",
            "loss tensor(0.5797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05919978\n",
            "self.loss(score_0, v1) 0.08978363\n",
            "self.loss(score_0, v2) 0.058112793\n",
            "self.loss(score_2, v3) 0.042855725\n",
            "loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05576616\n",
            "self.loss(score_0, v1) 0.097229086\n",
            "self.loss(score_0, v2) 0.12209183\n",
            "self.loss(score_2, v3) 0.04511077\n",
            "loss tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08676457\n",
            "self.loss(score_0, v1) 0.28764904\n",
            "self.loss(score_0, v2) 0.31809196\n",
            "self.loss(score_2, v3) 0.06471249\n",
            "loss tensor(0.7896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.065114334\n",
            "self.loss(score_0, v1) 0.31211078\n",
            "self.loss(score_0, v2) 0.3712122\n",
            "self.loss(score_2, v3) 0.11863218\n",
            "loss tensor(0.9264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16528122\n",
            "self.loss(score_0, v1) 0.3026256\n",
            "self.loss(score_0, v2) 0.18226168\n",
            "self.loss(score_2, v3) 0.06271548\n",
            "loss tensor(0.7442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.106566034\n",
            "self.loss(score_0, v1) 0.13205738\n",
            "self.loss(score_0, v2) 0.09854252\n",
            "self.loss(score_2, v3) 0.040124778\n",
            "loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.070018545\n",
            "self.loss(score_0, v1) 0.11715117\n",
            "self.loss(score_0, v2) 0.10614756\n",
            "self.loss(score_2, v3) 0.05491741\n",
            "loss tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.048607748\n",
            "self.loss(score_0, v1) 0.0697218\n",
            "self.loss(score_0, v2) 0.057747662\n",
            "self.loss(score_2, v3) 0.038900424\n",
            "loss tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06483048\n",
            "self.loss(score_0, v1) 0.1824854\n",
            "self.loss(score_0, v2) 0.21390438\n",
            "self.loss(score_2, v3) 0.045507107\n",
            "loss tensor(0.5295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16285545\n",
            "self.loss(score_0, v1) 0.51041114\n",
            "self.loss(score_0, v2) 0.3061664\n",
            "self.loss(score_2, v3) 0.051207885\n",
            "loss tensor(1.0562, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.068344966\n",
            "self.loss(score_0, v1) 0.11232839\n",
            "self.loss(score_0, v2) 0.07618316\n",
            "self.loss(score_2, v3) 0.047596417\n",
            "loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06943082\n",
            "self.loss(score_0, v1) 0.120441645\n",
            "self.loss(score_0, v2) 0.11104092\n",
            "self.loss(score_2, v3) 0.047605395\n",
            "loss tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052709028\n",
            "self.loss(score_0, v1) 0.419275\n",
            "self.loss(score_0, v2) 0.9636663\n",
            "self.loss(score_2, v3) 0.63942456\n",
            "loss tensor(2.3948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061899077\n",
            "self.loss(score_0, v1) 0.09004208\n",
            "self.loss(score_0, v2) 0.08709596\n",
            "self.loss(score_2, v3) 0.04618051\n",
            "loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07476863\n",
            "self.loss(score_0, v1) 0.0999039\n",
            "self.loss(score_0, v2) 0.12860505\n",
            "self.loss(score_2, v3) 0.17405334\n",
            "loss tensor(0.5644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06304821\n",
            "self.loss(score_0, v1) 0.22398889\n",
            "self.loss(score_0, v2) 0.18603295\n",
            "self.loss(score_2, v3) 0.04514207\n",
            "loss tensor(0.5408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07283623\n",
            "self.loss(score_0, v1) 0.13472132\n",
            "self.loss(score_0, v2) 0.09323093\n",
            "self.loss(score_2, v3) 0.047554757\n",
            "loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.088919595\n",
            "self.loss(score_0, v1) 0.14776807\n",
            "self.loss(score_0, v2) 0.12837169\n",
            "self.loss(score_2, v3) 0.0567351\n",
            "loss tensor(0.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049451064\n",
            "self.loss(score_0, v1) 0.07111177\n",
            "self.loss(score_0, v2) 0.07826001\n",
            "self.loss(score_2, v3) 0.042033095\n",
            "loss tensor(0.2619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08021496\n",
            "self.loss(score_0, v1) 0.20669594\n",
            "self.loss(score_0, v2) 0.18311825\n",
            "self.loss(score_2, v3) 0.04853876\n",
            "loss tensor(0.5428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0702581\n",
            "self.loss(score_0, v1) 0.10620794\n",
            "self.loss(score_0, v2) 0.07413296\n",
            "self.loss(score_2, v3) 0.044310663\n",
            "loss tensor(0.3171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04539959\n",
            "self.loss(score_0, v1) 0.07375858\n",
            "self.loss(score_0, v2) 0.07193131\n",
            "self.loss(score_2, v3) 0.031789884\n",
            "loss tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.033932675\n",
            "self.loss(score_0, v1) 0.0856041\n",
            "self.loss(score_0, v2) 0.04361262\n",
            "self.loss(score_2, v3) 0.025767114\n",
            "loss tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.37001052\n",
            "self.loss(score_0, v1) 0.31580326\n",
            "self.loss(score_0, v2) 0.1682872\n",
            "self.loss(score_2, v3) 0.10650873\n",
            "loss tensor(1.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.048156336\n",
            "self.loss(score_0, v1) 0.07723444\n",
            "self.loss(score_0, v2) 0.057928085\n",
            "self.loss(score_2, v3) 0.03175244\n",
            "loss tensor(0.2309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09799843\n",
            "self.loss(score_0, v1) 0.19408247\n",
            "self.loss(score_0, v2) 0.11560325\n",
            "self.loss(score_2, v3) 0.041460454\n",
            "loss tensor(0.4699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04058583\n",
            "self.loss(score_0, v1) 0.07184282\n",
            "self.loss(score_0, v2) 0.057199758\n",
            "self.loss(score_2, v3) 0.032779664\n",
            "loss tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049828097\n",
            "self.loss(score_0, v1) 0.08823984\n",
            "self.loss(score_0, v2) 0.12317691\n",
            "self.loss(score_2, v3) 0.050749935\n",
            "loss tensor(0.3374, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08635119\n",
            "self.loss(score_0, v1) 0.15193492\n",
            "self.loss(score_0, v2) 0.14043146\n",
            "self.loss(score_2, v3) 0.061089423\n",
            "loss tensor(0.4704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08117509\n",
            "self.loss(score_0, v1) 0.15036675\n",
            "self.loss(score_0, v2) 0.15720506\n",
            "self.loss(score_2, v3) 0.049636893\n",
            "loss tensor(0.4632, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07707069\n",
            "self.loss(score_0, v1) 0.14480904\n",
            "self.loss(score_0, v2) 0.13776001\n",
            "self.loss(score_2, v3) 0.058442\n",
            "loss tensor(0.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08854181\n",
            "self.loss(score_0, v1) 0.08687836\n",
            "self.loss(score_0, v2) 0.07225149\n",
            "self.loss(score_2, v3) 0.04130343\n",
            "loss tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0653248\n",
            "self.loss(score_0, v1) 0.098176435\n",
            "self.loss(score_0, v2) 0.07104437\n",
            "self.loss(score_2, v3) 0.054962818\n",
            "loss tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059721615\n",
            "self.loss(score_0, v1) 0.08898522\n",
            "self.loss(score_0, v2) 0.19219472\n",
            "self.loss(score_2, v3) 0.17960526\n",
            "loss tensor(0.6103, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.044270307\n",
            "self.loss(score_0, v1) 0.09123853\n",
            "self.loss(score_0, v2) 0.08761689\n",
            "self.loss(score_2, v3) 0.033883482\n",
            "loss tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06489722\n",
            "self.loss(score_0, v1) 0.12672736\n",
            "self.loss(score_0, v2) 0.08624836\n",
            "self.loss(score_2, v3) 0.06282063\n",
            "loss tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058959864\n",
            "self.loss(score_0, v1) 0.16366065\n",
            "self.loss(score_0, v2) 0.18614899\n",
            "self.loss(score_2, v3) 0.0864058\n",
            "loss tensor(0.5384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05364961\n",
            "self.loss(score_0, v1) 0.35427424\n",
            "self.loss(score_0, v2) 0.54247975\n",
            "self.loss(score_2, v3) 0.15653367\n",
            "loss tensor(1.1852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0853953\n",
            "self.loss(score_0, v1) 0.1571286\n",
            "self.loss(score_0, v2) 0.108363554\n",
            "self.loss(score_2, v3) 0.077692926\n",
            "loss tensor(0.4674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07198813\n",
            "self.loss(score_0, v1) 0.28553495\n",
            "self.loss(score_0, v2) 0.2610189\n",
            "self.loss(score_2, v3) 0.056159835\n",
            "loss tensor(0.7028, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058472414\n",
            "self.loss(score_0, v1) 0.08013935\n",
            "self.loss(score_0, v2) 0.06562516\n",
            "self.loss(score_2, v3) 0.037553433\n",
            "loss tensor(0.2606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.062045578\n",
            "self.loss(score_0, v1) 0.19788854\n",
            "self.loss(score_0, v2) 0.20417592\n",
            "self.loss(score_2, v3) 0.062493473\n",
            "loss tensor(0.5579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055934865\n",
            "self.loss(score_0, v1) 0.10512329\n",
            "self.loss(score_0, v2) 0.09069049\n",
            "self.loss(score_2, v3) 0.04134114\n",
            "loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08189807\n",
            "self.loss(score_0, v1) 0.13617937\n",
            "self.loss(score_0, v2) 0.09680227\n",
            "self.loss(score_2, v3) 0.062372155\n",
            "loss tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05741331\n",
            "self.loss(score_0, v1) 0.1432556\n",
            "self.loss(score_0, v2) 0.13363037\n",
            "self.loss(score_2, v3) 0.05079107\n",
            "loss tensor(0.4105, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.079078965\n",
            "self.loss(score_0, v1) 0.10442782\n",
            "self.loss(score_0, v2) 0.07682751\n",
            "self.loss(score_2, v3) 0.045134295\n",
            "loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06513354\n",
            "self.loss(score_0, v1) 0.112068534\n",
            "self.loss(score_0, v2) 0.10455327\n",
            "self.loss(score_2, v3) 0.050752185\n",
            "loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07309\n",
            "self.loss(score_0, v1) 0.4869947\n",
            "self.loss(score_0, v2) 0.465911\n",
            "self.loss(score_2, v3) 0.060065076\n",
            "loss tensor(1.1161, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.062163092\n",
            "self.loss(score_0, v1) 0.11433357\n",
            "self.loss(score_0, v2) 0.10669294\n",
            "self.loss(score_2, v3) 0.04666085\n",
            "loss tensor(0.3532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056948226\n",
            "self.loss(score_0, v1) 0.088319175\n",
            "self.loss(score_0, v2) 0.075690284\n",
            "self.loss(score_2, v3) 0.038606275\n",
            "loss tensor(0.2789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.080843985\n",
            "self.loss(score_0, v1) 0.25774786\n",
            "self.loss(score_0, v2) 0.2058595\n",
            "self.loss(score_2, v3) 0.05890746\n",
            "loss tensor(0.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09963774\n",
            "self.loss(score_0, v1) 0.15421735\n",
            "self.loss(score_0, v2) 0.07264079\n",
            "self.loss(score_2, v3) 0.052298788\n",
            "loss tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10660678\n",
            "self.loss(score_0, v1) 0.12324839\n",
            "self.loss(score_0, v2) 0.099292904\n",
            "self.loss(score_2, v3) 0.044320498\n",
            "loss tensor(0.3956, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1844791\n",
            "self.loss(score_0, v1) 0.15900025\n",
            "self.loss(score_0, v2) 0.12684186\n",
            "self.loss(score_2, v3) 0.07457504\n",
            "loss tensor(0.5822, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07286104\n",
            "self.loss(score_0, v1) 0.13194284\n",
            "self.loss(score_0, v2) 0.104682446\n",
            "self.loss(score_2, v3) 0.050225083\n",
            "loss tensor(0.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.109693035\n",
            "self.loss(score_0, v1) 0.20998639\n",
            "self.loss(score_0, v2) 0.07772017\n",
            "self.loss(score_2, v3) 0.044748288\n",
            "loss tensor(0.4645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.070132956\n",
            "self.loss(score_0, v1) 0.28031492\n",
            "self.loss(score_0, v2) 0.21070796\n",
            "self.loss(score_2, v3) 0.056871697\n",
            "loss tensor(0.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.089716166\n",
            "self.loss(score_0, v1) 0.10977325\n",
            "self.loss(score_0, v2) 0.06593959\n",
            "self.loss(score_2, v3) 0.042626876\n",
            "loss tensor(0.3294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09970134\n",
            "self.loss(score_0, v1) 0.1549089\n",
            "self.loss(score_0, v2) 0.07804932\n",
            "self.loss(score_2, v3) 0.039510485\n",
            "loss tensor(0.3919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05760152\n",
            "self.loss(score_0, v1) 0.09600033\n",
            "self.loss(score_0, v2) 0.105522156\n",
            "self.loss(score_2, v3) 0.057308596\n",
            "loss tensor(0.3451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07956205\n",
            "self.loss(score_0, v1) 0.313127\n",
            "self.loss(score_0, v2) 0.30323648\n",
            "self.loss(score_2, v3) 0.03835665\n",
            "loss tensor(0.7535, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.041657805\n",
            "self.loss(score_0, v1) 0.08555942\n",
            "self.loss(score_0, v2) 0.082801044\n",
            "self.loss(score_2, v3) 0.036339857\n",
            "loss tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06728862\n",
            "self.loss(score_0, v1) 0.37356213\n",
            "self.loss(score_0, v2) 0.32475248\n",
            "self.loss(score_2, v3) 0.05665085\n",
            "loss tensor(0.8506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04895449\n",
            "self.loss(score_0, v1) 0.07563516\n",
            "self.loss(score_0, v2) 0.069282815\n",
            "self.loss(score_2, v3) 0.03693463\n",
            "loss tensor(0.2493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05564801\n",
            "self.loss(score_0, v1) 0.11161365\n",
            "self.loss(score_0, v2) 0.10836774\n",
            "self.loss(score_2, v3) 0.05136504\n",
            "loss tensor(0.3527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18760413\n",
            "self.loss(score_0, v1) 0.19218697\n",
            "self.loss(score_0, v2) 0.14930446\n",
            "self.loss(score_2, v3) 0.12322536\n",
            "loss tensor(0.7139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.047270607\n",
            "self.loss(score_0, v1) 0.12100418\n",
            "self.loss(score_0, v2) 0.1407978\n",
            "self.loss(score_2, v3) 0.04098054\n",
            "loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0459563\n",
            "self.loss(score_0, v1) 0.10318511\n",
            "self.loss(score_0, v2) 0.071956135\n",
            "self.loss(score_2, v3) 0.03795703\n",
            "loss tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.076104105\n",
            "self.loss(score_0, v1) 0.14721183\n",
            "self.loss(score_0, v2) 0.13406514\n",
            "self.loss(score_2, v3) 0.056393668\n",
            "loss tensor(0.4420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.105163425\n",
            "self.loss(score_0, v1) 0.59095174\n",
            "self.loss(score_0, v2) 0.5666631\n",
            "self.loss(score_2, v3) 0.043746077\n",
            "loss tensor(1.3284, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08289892\n",
            "self.loss(score_0, v1) 0.11613777\n",
            "self.loss(score_0, v2) 0.08531258\n",
            "self.loss(score_2, v3) 0.05635041\n",
            "loss tensor(0.3689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09545483\n",
            "self.loss(score_0, v1) 0.16999346\n",
            "self.loss(score_0, v2) 0.11706144\n",
            "self.loss(score_2, v3) 0.045011327\n",
            "loss tensor(0.4500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08774485\n",
            "self.loss(score_0, v1) 0.210609\n",
            "self.loss(score_0, v2) 0.26226234\n",
            "self.loss(score_2, v3) 0.10509756\n",
            "loss tensor(0.7183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053477164\n",
            "self.loss(score_0, v1) 0.397262\n",
            "self.loss(score_0, v2) 0.38326743\n",
            "self.loss(score_2, v3) 0.103025034\n",
            "loss tensor(0.9885, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.063065305\n",
            "self.loss(score_0, v1) 0.10080256\n",
            "self.loss(score_0, v2) 0.099421255\n",
            "self.loss(score_2, v3) 0.042138096\n",
            "loss tensor(0.3265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.031497065\n",
            "self.loss(score_0, v1) 0.061880898\n",
            "self.loss(score_0, v2) 0.09573946\n",
            "self.loss(score_2, v3) 0.025139492\n",
            "loss tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06889685\n",
            "self.loss(score_0, v1) 0.106088206\n",
            "self.loss(score_0, v2) 0.07685713\n",
            "self.loss(score_2, v3) 0.05080306\n",
            "loss tensor(0.3280, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05082252\n",
            "self.loss(score_0, v1) 0.100850895\n",
            "self.loss(score_0, v2) 0.10052901\n",
            "self.loss(score_2, v3) 0.05412896\n",
            "loss tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052942626\n",
            "self.loss(score_0, v1) 0.068874106\n",
            "self.loss(score_0, v2) 0.053022828\n",
            "self.loss(score_2, v3) 0.04543084\n",
            "loss tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051620334\n",
            "self.loss(score_0, v1) 0.10066737\n",
            "self.loss(score_0, v2) 0.047703333\n",
            "self.loss(score_2, v3) 0.030510934\n",
            "loss tensor(0.2458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06893768\n",
            "self.loss(score_0, v1) 0.10059544\n",
            "self.loss(score_0, v2) 0.07703078\n",
            "self.loss(score_2, v3) 0.046075653\n",
            "loss tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.116857186\n",
            "self.loss(score_0, v1) 0.13264264\n",
            "self.loss(score_0, v2) 0.07482841\n",
            "self.loss(score_2, v3) 0.051787376\n",
            "loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03776267\n",
            "self.loss(score_0, v1) 0.06426192\n",
            "self.loss(score_0, v2) 0.049054705\n",
            "self.loss(score_2, v3) 0.027206572\n",
            "loss tensor(0.1919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06700524\n",
            "self.loss(score_0, v1) 0.1490622\n",
            "self.loss(score_0, v2) 0.182776\n",
            "self.loss(score_2, v3) 0.06330936\n",
            "loss tensor(0.4938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2090612\n",
            "self.loss(score_0, v1) 0.28908867\n",
            "self.loss(score_0, v2) 0.05778395\n",
            "self.loss(score_2, v3) 0.0342199\n",
            "loss tensor(0.6073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053108126\n",
            "self.loss(score_0, v1) 0.08655763\n",
            "self.loss(score_0, v2) 0.0750772\n",
            "self.loss(score_2, v3) 0.03923787\n",
            "loss tensor(0.2736, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05959736\n",
            "self.loss(score_0, v1) 0.09338433\n",
            "self.loss(score_0, v2) 0.07191186\n",
            "self.loss(score_2, v3) 0.057126094\n",
            "loss tensor(0.3106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07647152\n",
            "self.loss(score_0, v1) 0.23346344\n",
            "self.loss(score_0, v2) 0.21916004\n",
            "self.loss(score_2, v3) 0.05288933\n",
            "loss tensor(0.6084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.066235326\n",
            "self.loss(score_0, v1) 0.1714245\n",
            "self.loss(score_0, v2) 0.11464587\n",
            "self.loss(score_2, v3) 0.03939864\n",
            "loss tensor(0.4114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09713004\n",
            "self.loss(score_0, v1) 0.19586973\n",
            "self.loss(score_0, v2) 0.11320927\n",
            "self.loss(score_2, v3) 0.039328154\n",
            "loss tensor(0.4652, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10992845\n",
            "self.loss(score_0, v1) 0.15573917\n",
            "self.loss(score_0, v2) 0.08187088\n",
            "self.loss(score_2, v3) 0.056563932\n",
            "loss tensor(0.4324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03623419\n",
            "self.loss(score_0, v1) 0.10990324\n",
            "self.loss(score_0, v2) 0.16334064\n",
            "self.loss(score_2, v3) 0.026728272\n",
            "loss tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.079023644\n",
            "self.loss(score_0, v1) 0.09152497\n",
            "self.loss(score_0, v2) 0.062424473\n",
            "self.loss(score_2, v3) 0.038472313\n",
            "loss tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05794108\n",
            "self.loss(score_0, v1) 0.09350817\n",
            "self.loss(score_0, v2) 0.1096443\n",
            "self.loss(score_2, v3) 0.043675542\n",
            "loss tensor(0.3266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04479951\n",
            "self.loss(score_0, v1) 0.07139641\n",
            "self.loss(score_0, v2) 0.054495703\n",
            "self.loss(score_2, v3) 0.03964434\n",
            "loss tensor(0.2302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19832008\n",
            "self.loss(score_0, v1) 0.2495987\n",
            "self.loss(score_0, v2) 0.08030078\n",
            "self.loss(score_2, v3) 0.04709365\n",
            "loss tensor(0.5989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060107443\n",
            "self.loss(score_0, v1) 0.068018705\n",
            "self.loss(score_0, v2) 0.05399083\n",
            "self.loss(score_2, v3) 0.038874403\n",
            "loss tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.062318414\n",
            "self.loss(score_0, v1) 0.19355643\n",
            "self.loss(score_0, v2) 0.16769326\n",
            "self.loss(score_2, v3) 0.05667152\n",
            "loss tensor(0.5086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08387454\n",
            "self.loss(score_0, v1) 0.21437028\n",
            "self.loss(score_0, v2) 0.49392945\n",
            "self.loss(score_2, v3) 0.52683944\n",
            "loss tensor(1.5824, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055550225\n",
            "self.loss(score_0, v1) 0.078831345\n",
            "self.loss(score_0, v2) 0.05721322\n",
            "self.loss(score_2, v3) 0.039616168\n",
            "loss tensor(0.2510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2003873\n",
            "self.loss(score_0, v1) 0.28006023\n",
            "self.loss(score_0, v2) 0.19594076\n",
            "self.loss(score_2, v3) 0.04422657\n",
            "loss tensor(0.7427, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07327888\n",
            "self.loss(score_0, v1) 0.22653368\n",
            "self.loss(score_0, v2) 0.20733845\n",
            "self.loss(score_2, v3) 0.039004713\n",
            "loss tensor(0.5657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.062783085\n",
            "self.loss(score_0, v1) 0.13311937\n",
            "self.loss(score_0, v2) 0.12791821\n",
            "self.loss(score_2, v3) 0.05432611\n",
            "loss tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07847287\n",
            "self.loss(score_0, v1) 0.092715085\n",
            "self.loss(score_0, v2) 0.04475742\n",
            "self.loss(score_2, v3) 0.03221902\n",
            "loss tensor(0.2643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.071060404\n",
            "self.loss(score_0, v1) 0.1778062\n",
            "self.loss(score_0, v2) 0.15825872\n",
            "self.loss(score_2, v3) 0.039852783\n",
            "loss tensor(0.4669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16150555\n",
            "self.loss(score_0, v1) 0.20912713\n",
            "self.loss(score_0, v2) 0.081330396\n",
            "self.loss(score_2, v3) 0.04376225\n",
            "loss tensor(0.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05180566\n",
            "self.loss(score_0, v1) 0.23418817\n",
            "self.loss(score_0, v2) 0.18494411\n",
            "self.loss(score_2, v3) 0.044112682\n",
            "loss tensor(0.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15051629\n",
            "self.loss(score_0, v1) 0.17637338\n",
            "self.loss(score_0, v2) 0.14732626\n",
            "self.loss(score_2, v3) 0.04608253\n",
            "loss tensor(0.5433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.068183646\n",
            "self.loss(score_0, v1) 0.11639893\n",
            "self.loss(score_0, v2) 0.10410426\n",
            "self.loss(score_2, v3) 0.04034462\n",
            "loss tensor(0.3492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08026385\n",
            "self.loss(score_0, v1) 0.09828695\n",
            "self.loss(score_0, v2) 0.07232226\n",
            "self.loss(score_2, v3) 0.043814033\n",
            "loss tensor(0.3166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.070754044\n",
            "self.loss(score_0, v1) 0.131806\n",
            "self.loss(score_0, v2) 0.13912635\n",
            "self.loss(score_2, v3) 0.04397803\n",
            "loss tensor(0.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21719651\n",
            "self.loss(score_0, v1) 0.44284895\n",
            "self.loss(score_0, v2) 0.47904104\n",
            "self.loss(score_2, v3) 0.16396149\n",
            "loss tensor(1.3850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051806558\n",
            "self.loss(score_0, v1) 0.08933943\n",
            "self.loss(score_0, v2) 0.08002979\n",
            "self.loss(score_2, v3) 0.04647508\n",
            "loss tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14552891\n",
            "self.loss(score_0, v1) 0.24947935\n",
            "self.loss(score_0, v2) 0.16540332\n",
            "self.loss(score_2, v3) 0.04069719\n",
            "loss tensor(0.6215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.069831505\n",
            "self.loss(score_0, v1) 0.08728125\n",
            "self.loss(score_0, v2) 0.06463578\n",
            "self.loss(score_2, v3) 0.054834068\n",
            "loss tensor(0.3040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052130662\n",
            "self.loss(score_0, v1) 0.10207896\n",
            "self.loss(score_0, v2) 0.083442494\n",
            "self.loss(score_2, v3) 0.035617486\n",
            "loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059344023\n",
            "self.loss(score_0, v1) 0.10064649\n",
            "self.loss(score_0, v2) 0.073040344\n",
            "self.loss(score_2, v3) 0.049472246\n",
            "loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07330521\n",
            "self.loss(score_0, v1) 0.09773694\n",
            "self.loss(score_0, v2) 0.13702004\n",
            "self.loss(score_2, v3) 0.083599105\n",
            "loss tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05082784\n",
            "self.loss(score_0, v1) 0.07170447\n",
            "self.loss(score_0, v2) 0.06838864\n",
            "self.loss(score_2, v3) 0.039389707\n",
            "loss tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0566581\n",
            "self.loss(score_0, v1) 0.08819353\n",
            "self.loss(score_0, v2) 0.07104429\n",
            "self.loss(score_2, v3) 0.03700644\n",
            "loss tensor(0.2714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057760336\n",
            "self.loss(score_0, v1) 0.6224139\n",
            "self.loss(score_0, v2) 0.6937888\n",
            "self.loss(score_2, v3) 0.05513051\n",
            "loss tensor(1.4567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06708007\n",
            "self.loss(score_0, v1) 0.13311718\n",
            "self.loss(score_0, v2) 0.10034302\n",
            "self.loss(score_2, v3) 0.040366877\n",
            "loss tensor(0.3611, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052150577\n",
            "self.loss(score_0, v1) 0.089733586\n",
            "self.loss(score_0, v2) 0.06953553\n",
            "self.loss(score_2, v3) 0.039442685\n",
            "loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06652115\n",
            "self.loss(score_0, v1) 0.11515522\n",
            "self.loss(score_0, v2) 0.10424815\n",
            "self.loss(score_2, v3) 0.047630057\n",
            "loss tensor(0.3574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06283744\n",
            "self.loss(score_0, v1) 0.132213\n",
            "self.loss(score_0, v2) 0.068009734\n",
            "self.loss(score_2, v3) 0.04722747\n",
            "loss tensor(0.3339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05176008\n",
            "self.loss(score_0, v1) 0.1764452\n",
            "self.loss(score_0, v2) 0.18081021\n",
            "self.loss(score_2, v3) 0.038513552\n",
            "loss tensor(0.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07005251\n",
            "self.loss(score_0, v1) 0.17815782\n",
            "self.loss(score_0, v2) 0.15295134\n",
            "self.loss(score_2, v3) 0.035604995\n",
            "loss tensor(0.4546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06702522\n",
            "self.loss(score_0, v1) 0.2773247\n",
            "self.loss(score_0, v2) 0.26388398\n",
            "self.loss(score_2, v3) 0.050144207\n",
            "loss tensor(0.6835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08026563\n",
            "self.loss(score_0, v1) 0.3242995\n",
            "self.loss(score_0, v2) 0.24928407\n",
            "self.loss(score_2, v3) 0.06926021\n",
            "loss tensor(0.7577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12677734\n",
            "self.loss(score_0, v1) 0.27518997\n",
            "self.loss(score_0, v2) 0.30373034\n",
            "self.loss(score_2, v3) 0.16026208\n",
            "loss tensor(0.9461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14178494\n",
            "self.loss(score_0, v1) 0.28635946\n",
            "self.loss(score_0, v2) 0.41371423\n",
            "self.loss(score_2, v3) 0.045551155\n",
            "loss tensor(0.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06655964\n",
            "self.loss(score_0, v1) 0.38291112\n",
            "self.loss(score_0, v2) 0.31942788\n",
            "self.loss(score_2, v3) 0.05514515\n",
            "loss tensor(0.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.067620635\n",
            "self.loss(score_0, v1) 0.122640304\n",
            "self.loss(score_0, v2) 0.070233166\n",
            "self.loss(score_2, v3) 0.03953137\n",
            "loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08935032\n",
            "self.loss(score_0, v1) 0.120437674\n",
            "self.loss(score_0, v2) 0.07955243\n",
            "self.loss(score_2, v3) 0.039317824\n",
            "loss tensor(0.3483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.033756666\n",
            "self.loss(score_0, v1) 0.06096163\n",
            "self.loss(score_0, v2) 0.053916942\n",
            "self.loss(score_2, v3) 0.02772486\n",
            "loss tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051456288\n",
            "self.loss(score_0, v1) 0.13293369\n",
            "self.loss(score_0, v2) 0.2108421\n",
            "self.loss(score_2, v3) 0.040607497\n",
            "loss tensor(0.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2049902\n",
            "self.loss(score_0, v1) 0.24247925\n",
            "self.loss(score_0, v2) 0.091306016\n",
            "self.loss(score_2, v3) 0.046903502\n",
            "loss tensor(0.6091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055609465\n",
            "self.loss(score_0, v1) 0.19166765\n",
            "self.loss(score_0, v2) 0.1739268\n",
            "self.loss(score_2, v3) 0.0528522\n",
            "loss tensor(0.5005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07730013\n",
            "self.loss(score_0, v1) 0.16802967\n",
            "self.loss(score_0, v2) 0.119847186\n",
            "self.loss(score_2, v3) 0.04071916\n",
            "loss tensor(0.4263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.023114681\n",
            "self.loss(score_0, v1) 0.10074707\n",
            "self.loss(score_0, v2) 0.1107694\n",
            "self.loss(score_2, v3) 0.044032957\n",
            "loss tensor(0.3007, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09062558\n",
            "self.loss(score_0, v1) 0.2362921\n",
            "self.loss(score_0, v2) 0.17206569\n",
            "self.loss(score_2, v3) 0.041064538\n",
            "loss tensor(0.5606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075726844\n",
            "self.loss(score_0, v1) 0.09314442\n",
            "self.loss(score_0, v2) 0.073656\n",
            "self.loss(score_2, v3) 0.043623473\n",
            "loss tensor(0.3080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05775965\n",
            "self.loss(score_0, v1) 0.16382845\n",
            "self.loss(score_0, v2) 0.14033541\n",
            "self.loss(score_2, v3) 0.052691348\n",
            "loss tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06299165\n",
            "self.loss(score_0, v1) 0.09358505\n",
            "self.loss(score_0, v2) 0.09822097\n",
            "self.loss(score_2, v3) 0.058279812\n",
            "loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.045153983\n",
            "self.loss(score_0, v1) 0.14406492\n",
            "self.loss(score_0, v2) 0.07849102\n",
            "self.loss(score_2, v3) 0.03416794\n",
            "loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07228417\n",
            "self.loss(score_0, v1) 0.36536136\n",
            "self.loss(score_0, v2) 0.30692193\n",
            "self.loss(score_2, v3) 0.04222787\n",
            "loss tensor(0.8079, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051150773\n",
            "self.loss(score_0, v1) 0.10505776\n",
            "self.loss(score_0, v2) 0.060547374\n",
            "self.loss(score_2, v3) 0.03590029\n",
            "loss tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.045646384\n",
            "self.loss(score_0, v1) 0.08722772\n",
            "self.loss(score_0, v2) 0.07131252\n",
            "self.loss(score_2, v3) 0.029472152\n",
            "loss tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08924087\n",
            "self.loss(score_0, v1) 0.09615907\n",
            "self.loss(score_0, v2) 0.075358614\n",
            "self.loss(score_2, v3) 0.046861045\n",
            "loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17219663\n",
            "self.loss(score_0, v1) 0.17014627\n",
            "self.loss(score_0, v2) 0.07898638\n",
            "self.loss(score_2, v3) 0.055079103\n",
            "loss tensor(0.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10092\n",
            "self.loss(score_0, v1) 0.14284065\n",
            "self.loss(score_0, v2) 0.113096625\n",
            "self.loss(score_2, v3) 0.04464998\n",
            "loss tensor(0.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.074632905\n",
            "self.loss(score_0, v1) 0.09869142\n",
            "self.loss(score_0, v2) 0.094765335\n",
            "self.loss(score_2, v3) 0.05701527\n",
            "loss tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06423484\n",
            "self.loss(score_0, v1) 0.13673696\n",
            "self.loss(score_0, v2) 0.12276718\n",
            "self.loss(score_2, v3) 0.042067822\n",
            "loss tensor(0.3868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.044496223\n",
            "self.loss(score_0, v1) 0.070797\n",
            "self.loss(score_0, v2) 0.052119635\n",
            "self.loss(score_2, v3) 0.02876445\n",
            "loss tensor(0.2106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07727194\n",
            "self.loss(score_0, v1) 0.47286245\n",
            "self.loss(score_0, v2) 0.46398026\n",
            "self.loss(score_2, v3) 0.056104805\n",
            "loss tensor(1.0983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11065862\n",
            "self.loss(score_0, v1) 0.12452311\n",
            "self.loss(score_0, v2) 0.08516554\n",
            "self.loss(score_2, v3) 0.04282121\n",
            "loss tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06503756\n",
            "self.loss(score_0, v1) 0.098829925\n",
            "self.loss(score_0, v2) 0.07280526\n",
            "self.loss(score_2, v3) 0.05560566\n",
            "loss tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13429046\n",
            "self.loss(score_0, v1) 0.42296237\n",
            "self.loss(score_0, v2) 0.33596778\n",
            "self.loss(score_2, v3) 0.05203046\n",
            "loss tensor(0.9713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05597632\n",
            "self.loss(score_0, v1) 0.152839\n",
            "self.loss(score_0, v2) 0.16325746\n",
            "self.loss(score_2, v3) 0.050100446\n",
            "loss tensor(0.4472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12401381\n",
            "self.loss(score_0, v1) 0.17809424\n",
            "self.loss(score_0, v2) 0.18033417\n",
            "self.loss(score_2, v3) 0.050939918\n",
            "loss tensor(0.5589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07762687\n",
            "self.loss(score_0, v1) 0.11533598\n",
            "self.loss(score_0, v2) 0.10159628\n",
            "self.loss(score_2, v3) 0.04151838\n",
            "loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1180204\n",
            "self.loss(score_0, v1) 0.21649346\n",
            "self.loss(score_0, v2) 0.1523205\n",
            "self.loss(score_2, v3) 0.048288316\n",
            "loss tensor(0.5593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08176009\n",
            "self.loss(score_0, v1) 0.13808277\n",
            "self.loss(score_0, v2) 0.114041425\n",
            "self.loss(score_2, v3) 0.037285026\n",
            "loss tensor(0.3898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.054697335\n",
            "self.loss(score_0, v1) 0.099784\n",
            "self.loss(score_0, v2) 0.089510605\n",
            "self.loss(score_2, v3) 0.041197218\n",
            "loss tensor(0.3058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19300674\n",
            "self.loss(score_0, v1) 0.1503426\n",
            "self.loss(score_0, v2) 0.120923996\n",
            "self.loss(score_2, v3) 0.04168281\n",
            "loss tensor(0.5268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05445029\n",
            "self.loss(score_0, v1) 0.24419054\n",
            "self.loss(score_0, v2) 0.2159462\n",
            "self.loss(score_2, v3) 0.042718913\n",
            "loss tensor(0.5787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07798721\n",
            "self.loss(score_0, v1) 0.10807165\n",
            "self.loss(score_0, v2) 0.060661417\n",
            "self.loss(score_2, v3) 0.04525151\n",
            "loss tensor(0.3146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07329483\n",
            "self.loss(score_0, v1) 0.14117333\n",
            "self.loss(score_0, v2) 0.09171213\n",
            "self.loss(score_2, v3) 0.048847534\n",
            "loss tensor(0.3795, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.101056285\n",
            "self.loss(score_0, v1) 0.1813661\n",
            "self.loss(score_0, v2) 0.19921196\n",
            "self.loss(score_2, v3) 0.055137884\n",
            "loss tensor(0.5643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11012109\n",
            "self.loss(score_0, v1) 0.17720792\n",
            "self.loss(score_0, v2) 0.12679149\n",
            "self.loss(score_2, v3) 0.047889993\n",
            "loss tensor(0.4860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1157942\n",
            "self.loss(score_0, v1) 0.10829449\n",
            "self.loss(score_0, v2) 0.061958585\n",
            "self.loss(score_2, v3) 0.034776162\n",
            "loss tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.068431854\n",
            "self.loss(score_0, v1) 0.098982126\n",
            "self.loss(score_0, v2) 0.09549725\n",
            "self.loss(score_2, v3) 0.04390836\n",
            "loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055543493\n",
            "self.loss(score_0, v1) 0.0792345\n",
            "self.loss(score_0, v2) 0.06915095\n",
            "self.loss(score_2, v3) 0.041309558\n",
            "loss tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.043959893\n",
            "self.loss(score_0, v1) 0.07688086\n",
            "self.loss(score_0, v2) 0.084608674\n",
            "self.loss(score_2, v3) 0.04131804\n",
            "loss tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.096291795\n",
            "self.loss(score_0, v1) 0.24987097\n",
            "self.loss(score_0, v2) 0.26625925\n",
            "self.loss(score_2, v3) 0.046977\n",
            "loss tensor(0.6829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06556232\n",
            "self.loss(score_0, v1) 0.34414083\n",
            "self.loss(score_0, v2) 0.33169472\n",
            "self.loss(score_2, v3) 0.05445346\n",
            "loss tensor(0.8231, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.066108376\n",
            "self.loss(score_0, v1) 0.07766341\n",
            "self.loss(score_0, v2) 0.05515553\n",
            "self.loss(score_2, v3) 0.039212525\n",
            "loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061352964\n",
            "self.loss(score_0, v1) 0.23873359\n",
            "self.loss(score_0, v2) 0.2528441\n",
            "self.loss(score_2, v3) 0.03459598\n",
            "loss tensor(0.6048, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13467246\n",
            "self.loss(score_0, v1) 0.15419039\n",
            "self.loss(score_0, v2) 0.11817895\n",
            "self.loss(score_2, v3) 0.14083408\n",
            "loss tensor(0.6183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.046506617\n",
            "self.loss(score_0, v1) 0.10072763\n",
            "self.loss(score_0, v2) 0.13864774\n",
            "self.loss(score_2, v3) 0.047452718\n",
            "loss tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16742767\n",
            "self.loss(score_0, v1) 0.11512227\n",
            "self.loss(score_0, v2) 0.0846166\n",
            "self.loss(score_2, v3) 0.04758213\n",
            "loss tensor(0.4385, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09804975\n",
            "self.loss(score_0, v1) 0.11738291\n",
            "self.loss(score_0, v2) 0.06754715\n",
            "self.loss(score_2, v3) 0.04469337\n",
            "loss tensor(0.3500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.121485576\n",
            "self.loss(score_0, v1) 0.1719097\n",
            "self.loss(score_0, v2) 0.099945836\n",
            "self.loss(score_2, v3) 0.043096807\n",
            "loss tensor(0.4580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053343426\n",
            "self.loss(score_0, v1) 0.06503381\n",
            "self.loss(score_0, v2) 0.04181763\n",
            "self.loss(score_2, v3) 0.026878182\n",
            "loss tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056962084\n",
            "self.loss(score_0, v1) 0.096931\n",
            "self.loss(score_0, v2) 0.09386057\n",
            "self.loss(score_2, v3) 0.04326471\n",
            "loss tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05023267\n",
            "self.loss(score_0, v1) 0.08278539\n",
            "self.loss(score_0, v2) 0.0595243\n",
            "self.loss(score_2, v3) 0.03810022\n",
            "loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051466364\n",
            "self.loss(score_0, v1) 0.29683468\n",
            "self.loss(score_0, v2) 0.31365645\n",
            "self.loss(score_2, v3) 0.04015309\n",
            "loss tensor(0.7222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052789327\n",
            "self.loss(score_0, v1) 0.086716324\n",
            "self.loss(score_0, v2) 0.100625694\n",
            "self.loss(score_2, v3) 0.04892564\n",
            "loss tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14003497\n",
            "self.loss(score_0, v1) 0.16527516\n",
            "self.loss(score_0, v2) 0.072554365\n",
            "self.loss(score_2, v3) 0.039489053\n",
            "loss tensor(0.4371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08964962\n",
            "self.loss(score_0, v1) 0.10378578\n",
            "self.loss(score_0, v2) 0.06768849\n",
            "self.loss(score_2, v3) 0.04977715\n",
            "loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06388992\n",
            "self.loss(score_0, v1) 0.09985455\n",
            "self.loss(score_0, v2) 0.21361831\n",
            "self.loss(score_2, v3) 0.20519528\n",
            "loss tensor(0.6852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.062544025\n",
            "self.loss(score_0, v1) 0.12098424\n",
            "self.loss(score_0, v2) 0.08602607\n",
            "self.loss(score_2, v3) 0.05082364\n",
            "loss tensor(0.3458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050510157\n",
            "self.loss(score_0, v1) 0.0824825\n",
            "self.loss(score_0, v2) 0.062078796\n",
            "self.loss(score_2, v3) 0.042154238\n",
            "loss tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09950764\n",
            "self.loss(score_0, v1) 0.111396834\n",
            "self.loss(score_0, v2) 0.06661473\n",
            "self.loss(score_2, v3) 0.03929967\n",
            "loss tensor(0.3365, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06356695\n",
            "self.loss(score_0, v1) 0.08234043\n",
            "self.loss(score_0, v2) 0.07991602\n",
            "self.loss(score_2, v3) 0.038303453\n",
            "loss tensor(0.2833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053254515\n",
            "self.loss(score_0, v1) 0.15949845\n",
            "self.loss(score_0, v2) 0.16873534\n",
            "self.loss(score_2, v3) 0.049647897\n",
            "loss tensor(0.4560, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05540614\n",
            "self.loss(score_0, v1) 0.11611264\n",
            "self.loss(score_0, v2) 0.11774537\n",
            "self.loss(score_2, v3) 0.034950636\n",
            "loss tensor(0.3417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.045351025\n",
            "self.loss(score_0, v1) 0.12062296\n",
            "self.loss(score_0, v2) 0.08146004\n",
            "self.loss(score_2, v3) 0.03404837\n",
            "loss tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07082911\n",
            "self.loss(score_0, v1) 0.31842548\n",
            "self.loss(score_0, v2) 0.2558506\n",
            "self.loss(score_2, v3) 0.046503264\n",
            "loss tensor(0.7149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11115556\n",
            "self.loss(score_0, v1) 0.15878439\n",
            "self.loss(score_0, v2) 0.10885206\n",
            "self.loss(score_2, v3) 0.05521284\n",
            "loss tensor(0.4616, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061365698\n",
            "self.loss(score_0, v1) 0.122022815\n",
            "self.loss(score_0, v2) 0.16596338\n",
            "self.loss(score_2, v3) 0.09764186\n",
            "loss tensor(0.4958, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06999866\n",
            "self.loss(score_0, v1) 0.08285205\n",
            "self.loss(score_0, v2) 0.094977796\n",
            "self.loss(score_2, v3) 0.044642445\n",
            "loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08644341\n",
            "self.loss(score_0, v1) 0.10718203\n",
            "self.loss(score_0, v2) 0.06119471\n",
            "self.loss(score_2, v3) 0.03659243\n",
            "loss tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07422442\n",
            "self.loss(score_0, v1) 0.15623945\n",
            "self.loss(score_0, v2) 0.14364105\n",
            "self.loss(score_2, v3) 0.043473992\n",
            "loss tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23325124\n",
            "self.loss(score_0, v1) 0.483156\n",
            "self.loss(score_0, v2) 0.4088084\n",
            "self.loss(score_2, v3) 0.027447741\n",
            "loss tensor(1.1664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11089501\n",
            "self.loss(score_0, v1) 0.12873456\n",
            "self.loss(score_0, v2) 0.059284665\n",
            "self.loss(score_2, v3) 0.032060497\n",
            "loss tensor(0.3470, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11005943\n",
            "self.loss(score_0, v1) 0.17525877\n",
            "self.loss(score_0, v2) 0.18828787\n",
            "self.loss(score_2, v3) 0.039517816\n",
            "loss tensor(0.5329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.032490443\n",
            "self.loss(score_0, v1) 0.19899361\n",
            "self.loss(score_0, v2) 0.21761273\n",
            "self.loss(score_2, v3) 0.027858607\n",
            "loss tensor(0.4909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07706249\n",
            "self.loss(score_0, v1) 0.15151961\n",
            "self.loss(score_0, v2) 0.13001452\n",
            "self.loss(score_2, v3) 0.04318975\n",
            "loss tensor(0.4234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06902679\n",
            "self.loss(score_0, v1) 0.10866699\n",
            "self.loss(score_0, v2) 0.09275246\n",
            "self.loss(score_2, v3) 0.04841694\n",
            "loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05335197\n",
            "self.loss(score_0, v1) 0.094473146\n",
            "self.loss(score_0, v2) 0.07390561\n",
            "self.loss(score_2, v3) 0.03453957\n",
            "loss tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06680027\n",
            "self.loss(score_0, v1) 0.11372177\n",
            "self.loss(score_0, v2) 0.08024119\n",
            "self.loss(score_2, v3) 0.043938838\n",
            "loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07539406\n",
            "self.loss(score_0, v1) 0.14414768\n",
            "self.loss(score_0, v2) 0.14916489\n",
            "self.loss(score_2, v3) 0.038830698\n",
            "loss tensor(0.4270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056448817\n",
            "self.loss(score_0, v1) 0.08406341\n",
            "self.loss(score_0, v2) 0.08608371\n",
            "self.loss(score_2, v3) 0.058217082\n",
            "loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06594147\n",
            "self.loss(score_0, v1) 0.10177887\n",
            "self.loss(score_0, v2) 0.08191954\n",
            "self.loss(score_2, v3) 0.041923657\n",
            "loss tensor(0.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053325195\n",
            "self.loss(score_0, v1) 0.08638065\n",
            "self.loss(score_0, v2) 0.10063119\n",
            "self.loss(score_2, v3) 0.05030514\n",
            "loss tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073298186\n",
            "self.loss(score_0, v1) 0.21363686\n",
            "self.loss(score_0, v2) 0.21428275\n",
            "self.loss(score_2, v3) 0.047554072\n",
            "loss tensor(0.5725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 0.4833497461050179, Train Accuracy : 0.9988927385463046\n",
            " Validation Accuracy : 6.599938208529815\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_0,'-o')\n",
        "plt.plot(loss_1,'-o')\n",
        "plt.plot(loss_2,'-o')\n",
        "plt.plot(loss_3,'-o')\n",
        "plt.xlabel('sample')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['loss 0','loss 1','loss 2','loss 3'])\n",
        "plt.title('loss vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UPfmfthBjSZw",
        "outputId": "12b10056-b0d6-4033-fccd-0203b853ee06"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy evalutaion F-scores"
      ],
      "metadata": {
        "id": "sJbWsH72N2Mb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. create folder with part object of all pieces \n",
        "2. load a piece from dataloader with true labels, the mixed piece and the part object \n",
        "3. create notearray from part object\n",
        "4. take 1 note from notearrray - input -> find corresponding frame by looking at time and pitch\n",
        "\n",
        "\n",
        "Output: pianoroll\n",
        "\n",
        "1 note in notearray could be mulitple bins\n",
        "\n",
        "take 1 note from notearrray - input -> find corresponding frame by looking at time and pitch\n",
        "\n",
        "note start at same time with different pitch -> different notes\n",
        "\n",
        "for each note array find corresponding matrix -> \n",
        "\n",
        "\n",
        "if note is only composed by 1 bin: save indx of vocie -> save it to note array\n",
        "\n",
        "if more than 1: look what are idx that compose this note -> majority note -> save it for the note array (if its 50/50 take it random -> count how often this happens) \n",
        "\n",
        "\n",
        "with idx : in note_array find which note corresponds to what voice"
      ],
      "metadata": {
        "id": "CFClch37N6nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MusicDataset_new(PATH_TO_DATA) #MusicDataset(PATH_TO_DATA)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "\n",
        "val_dataloader "
      ],
      "metadata": {
        "id": "afYHFVNMlMnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e53786-139b-4db9-9949-032588b47650"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f95b238fbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## makes cell output nothing\n",
        "%%capture  \n",
        "output_dim = 88\n",
        "model = MusicNetwork(network_type, output_dim, hidden_dim, rnn_depth, cell_type)  \n",
        "checkpoint = torch.load(\"./AI-MA_project/model_temp_epoch5.pkl\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "4TAhTQcpmx8m"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create dic with key:filename, val: part_obj  for fugues"
      ],
      "metadata": {
        "id": "5RVmMv6Q9CJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if PATH_TO_DATA == \"AI-MA_project/bach_pr_fugues\":\n",
        "    path_parts = \"AI-MA_project/bach_fugues\"\n",
        "    part_dic = {}\n",
        "\n",
        "    #### create a list with all filenames in the right order ####\n",
        "    file_names_part = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.mid'): continue\n",
        "        file_names_part.append(filename[3:7])\n",
        "    #print(file_names_part)\n",
        "\n",
        "    #### create a list with all part objects in the right order ####\n",
        "    part_list = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.mid'): continue\n",
        "        fullname = os.path.join(path_parts, filename)\n",
        "        part = partitura.load_score_midi(fullname)\n",
        "        part_list.append(part)\n",
        "    #print(part_list)\n",
        "\n",
        "    #### create a dict with keys:filenames , values: part object ####\n",
        "    for i in range(len(file_names_part)):\n",
        "        part_dic[file_names_part[i]] = part_list[i]\n",
        "    \n",
        "    print(part_dic.keys(),part_dic.values())"
      ],
      "metadata": {
        "id": "_XYM_KWu2qkX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create dic with key:filename, val: part_obj  for chorales"
      ],
      "metadata": {
        "id": "6D9oTp_lNQbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if PATH_TO_DATA == \"AI-MA_project/pianoroll_88\":\n",
        "    path_parts = \"AI-MA_project/chorales_converted\"\n",
        "    part_dic = {}\n",
        "\n",
        "    #### create a list with all filenames in the right order ####\n",
        "    file_names_part = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.xml'): continue\n",
        "        file_names_part.append(filename[4:7])\n",
        "    #print(file_names_part)\n",
        "\n",
        "    #### create a list with all part objects in the right order ####\n",
        "    part_list = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.xml'): continue\n",
        "        fullname = os.path.join(path_parts, filename)\n",
        "        part = partitura.load_musicxml(fullname)\n",
        "        part_list.append(part)\n",
        "    #print(part_list)\n",
        "\n",
        "    #### create a dict with keys:filenames , values: part object ####\n",
        "    for i in range(len(file_names_part)):\n",
        "        part_dic[file_names_part[i]] = part_list[i]\n",
        "    \n",
        "    print(\"part_dic.keys()\",part_dic.keys())\n",
        "    print(\"part_dic.values()\",part_dic.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4q58c16NjbE",
        "outputId": "dad3f3ba-1b2f-452f-a299-c3fd1eaf47f8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part_dic.keys() dict_keys(['001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '042', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', '054', '055', '056', '057', '058', '059', '060', '061', '062', '063', '064', '065', '066', '067', '068', '069', '070', '071', '072', '073', '074', '075', '076', '077', '078', '079', '080', '081', '082', '083', '084', '085', '086', '087', '088', '089', '090', '091', '092', '093', '094', '095', '096', '097', '098', '099', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371'])\n",
            "part_dic.values() dict_values([[<partitura.score.Part object at 0x7f95ab1b89d0>, <partitura.score.Part object at 0x7f95ab1b71d0>, <partitura.score.Part object at 0x7f95ab1b76d0>, <partitura.score.Part object at 0x7f95ab1b7110>], [<partitura.score.Part object at 0x7f95ab08b510>, <partitura.score.Part object at 0x7f95ab04ad50>, <partitura.score.Part object at 0x7f95ab04add0>, <partitura.score.Part object at 0x7f95ab04ae50>], [<partitura.score.Part object at 0x7f95aafadbd0>, <partitura.score.Part object at 0x7f95aaf73950>, <partitura.score.Part object at 0x7f95aaf739d0>, <partitura.score.Part object at 0x7f95aaf73a50>], [<partitura.score.Part object at 0x7f95aaeb97d0>, <partitura.score.Part object at 0x7f95aae72e10>, <partitura.score.Part object at 0x7f95aae72e90>, <partitura.score.Part object at 0x7f95aae72f10>], [<partitura.score.Part object at 0x7f95aadb0690>, <partitura.score.Part object at 0x7f95aad698d0>, <partitura.score.Part object at 0x7f95aad69950>, <partitura.score.Part object at 0x7f95aad699d0>], [<partitura.score.Part object at 0x7f95aab81090>, <partitura.score.Part object at 0x7f95aab81350>, <partitura.score.Part object at 0x7f95aab813d0>, <partitura.score.Part object at 0x7f95aab81450>], [<partitura.score.Part object at 0x7f95aab1bbd0>, <partitura.score.Part object at 0x7f95aaac1bd0>, <partitura.score.Part object at 0x7f95aaac1c50>, <partitura.score.Part object at 0x7f95aaac1cd0>], [<partitura.score.Part object at 0x7f95ab196cd0>, <partitura.score.Part object at 0x7f9684737490>, <partitura.score.Part object at 0x7f95aa9c3050>, <partitura.score.Part object at 0x7f95b230e550>], [<partitura.score.Part object at 0x7f95b2476b90>, <partitura.score.Part object at 0x7f95b24bbb90>, <partitura.score.Part object at 0x7f95b24fa410>, <partitura.score.Part object at 0x7f95b24fa4d0>], [<partitura.score.Part object at 0x7f9682bbe590>, <partitura.score.Part object at 0x7f95aa74c4d0>, <partitura.score.Part object at 0x7f95aa74c790>, <partitura.score.Part object at 0x7f95aa74c810>], [<partitura.score.Part object at 0x7f95aa67fc10>, <partitura.score.Part object at 0x7f95aa6b6e90>, <partitura.score.Part object at 0x7f95aa6b6f10>, <partitura.score.Part object at 0x7f95aa6b6f90>], [<partitura.score.Part object at 0x7f95aa4d0890>, <partitura.score.Part object at 0x7f95aa444d10>, <partitura.score.Part object at 0x7f95aa444d90>, <partitura.score.Part object at 0x7f95aa444e10>], [<partitura.score.Part object at 0x7f95aa3f89d0>, <partitura.score.Part object at 0x7f95aa3ac250>, <partitura.score.Part object at 0x7f95aa3ac2d0>, <partitura.score.Part object at 0x7f95aa3ac350>], [<partitura.score.Part object at 0x7f95aa23ce50>, <partitura.score.Part object at 0x7f95aa218fd0>, <partitura.score.Part object at 0x7f95aa1c7090>, <partitura.score.Part object at 0x7f95aa1c7110>], [<partitura.score.Part object at 0x7f95aa113690>, <partitura.score.Part object at 0x7f95aa0da590>, <partitura.score.Part object at 0x7f95aa0da610>, <partitura.score.Part object at 0x7f95aa0da690>], [<partitura.score.Part object at 0x7f95a1f87d10>, <partitura.score.Part object at 0x7f95a1f52810>, <partitura.score.Part object at 0x7f95a1f52890>, <partitura.score.Part object at 0x7f95a1f52910>], [<partitura.score.Part object at 0x7f95a1e72110>, <partitura.score.Part object at 0x7f95a1dd00d0>, <partitura.score.Part object at 0x7f95a1dd0110>, <partitura.score.Part object at 0x7f95a1dd0190>], [<partitura.score.Part object at 0x7f95b1e5a450>, <partitura.score.Part object at 0x7f95a1d57110>, <partitura.score.Part object at 0x7f95a1d89850>, <partitura.score.Part object at 0x7f95a1d89750>], [<partitura.score.Part object at 0x7f95a1c0b850>, <partitura.score.Part object at 0x7f95a1bc8d90>, <partitura.score.Part object at 0x7f95a1bc8e10>, <partitura.score.Part object at 0x7f95a1bc8e90>], [<partitura.score.Part object at 0x7f95a1b09650>, <partitura.score.Part object at 0x7f95a1ad5050>, <partitura.score.Part object at 0x7f95a1ad50d0>, <partitura.score.Part object at 0x7f95a1ad5150>], [<partitura.score.Part object at 0x7f95a1a1e550>, <partitura.score.Part object at 0x7f95a19e91d0>, <partitura.score.Part object at 0x7f95a19e9250>, <partitura.score.Part object at 0x7f95a19e92d0>], [<partitura.score.Part object at 0x7f95a1920d50>, <partitura.score.Part object at 0x7f95a18d8d50>, <partitura.score.Part object at 0x7f95a18d8dd0>, <partitura.score.Part object at 0x7f95a18d8e50>], [<partitura.score.Part object at 0x7f95a17c6f90>, <partitura.score.Part object at 0x7f95a179d550>, <partitura.score.Part object at 0x7f95a179d5d0>, <partitura.score.Part object at 0x7f95a179d650>], [<partitura.score.Part object at 0x7f95a16eab90>, <partitura.score.Part object at 0x7f95a16a4f50>, <partitura.score.Part object at 0x7f95a16a4fd0>, <partitura.score.Part object at 0x7f95a1646090>], [<partitura.score.Part object at 0x7f95a1584590>, <partitura.score.Part object at 0x7f95a15bca90>, <partitura.score.Part object at 0x7f95a15bcb10>, <partitura.score.Part object at 0x7f95a15bcb90>], [<partitura.score.Part object at 0x7f95a1490910>, <partitura.score.Part object at 0x7f95a144dd90>, <partitura.score.Part object at 0x7f95a144de10>, <partitura.score.Part object at 0x7f95a144de90>], [<partitura.score.Part object at 0x7f95a138d510>, <partitura.score.Part object at 0x7f95a1343550>, <partitura.score.Part object at 0x7f95a13435d0>, <partitura.score.Part object at 0x7f95a1343650>], [<partitura.score.Part object at 0x7f95a12f8e90>, <partitura.score.Part object at 0x7f95a12b8310>, <partitura.score.Part object at 0x7f95a12b8390>, <partitura.score.Part object at 0x7f95a12b8410>], [<partitura.score.Part object at 0x7f95a11cead0>, <partitura.score.Part object at 0x7f95a11f7c90>, <partitura.score.Part object at 0x7f95a1182190>, <partitura.score.Part object at 0x7f95a1182210>], [<partitura.score.Part object at 0x7f95a1089b90>, <partitura.score.Part object at 0x7f95a1089c10>, <partitura.score.Part object at 0x7f95a1089c90>, <partitura.score.Part object at 0x7f95a1089d10>], [<partitura.score.Part object at 0x7f95a0fdfed0>, <partitura.score.Part object at 0x7f95a0fa83d0>, <partitura.score.Part object at 0x7f95a0fa8450>, <partitura.score.Part object at 0x7f95a0fa84d0>], [<partitura.score.Part object at 0x7f95a0eeda50>, <partitura.score.Part object at 0x7f95a0eb13d0>, <partitura.score.Part object at 0x7f95a0eb1450>, <partitura.score.Part object at 0x7f95a0eb14d0>], [<partitura.score.Part object at 0x7f95a0dfce90>, <partitura.score.Part object at 0x7f95a0d411d0>, <partitura.score.Part object at 0x7f95a0d41250>, <partitura.score.Part object at 0x7f95a0d412d0>], [<partitura.score.Part object at 0x7f95a0cf6b50>, <partitura.score.Part object at 0x7f95a0cad650>, <partitura.score.Part object at 0x7f95a0cad6d0>, <partitura.score.Part object at 0x7f95a0cad750>], [<partitura.score.Part object at 0x7f95a0b71050>, <partitura.score.Part object at 0x7f95a0b11d90>, <partitura.score.Part object at 0x7f95a0b11e10>, <partitura.score.Part object at 0x7f95a0b11e90>], [<partitura.score.Part object at 0x7f95a0a46910>, <partitura.score.Part object at 0x7f95a0a71d90>, <partitura.score.Part object at 0x7f95a0a7c490>, <partitura.score.Part object at 0x7f95a0a7c510>], [<partitura.score.Part object at 0x7f95a095d910>, <partitura.score.Part object at 0x7f95a0927590>, <partitura.score.Part object at 0x7f95a0927610>, <partitura.score.Part object at 0x7f95a0927690>], [<partitura.score.Part object at 0x7f95a080ee50>, <partitura.score.Part object at 0x7f95a07da910>, <partitura.score.Part object at 0x7f95a07da990>, <partitura.score.Part object at 0x7f95a07daa10>], [<partitura.score.Part object at 0x7f95a071f0d0>, <partitura.score.Part object at 0x7f95a06ca890>, <partitura.score.Part object at 0x7f95a06ca910>, <partitura.score.Part object at 0x7f95a06ca990>], [<partitura.score.Part object at 0x7f95a062be10>, <partitura.score.Part object at 0x7f95a05f1110>, <partitura.score.Part object at 0x7f95a05f1190>, <partitura.score.Part object at 0x7f95a05f1210>], [<partitura.score.Part object at 0x7f95a0503210>, <partitura.score.Part object at 0x7f95a05299d0>, <partitura.score.Part object at 0x7f95a0529a50>, <partitura.score.Part object at 0x7f95a0529ad0>], [<partitura.score.Part object at 0x7f95a0406f90>, <partitura.score.Part object at 0x7f95a0406b10>, <partitura.score.Part object at 0x7f95a03e8c50>, <partitura.score.Part object at 0x7f95a03e8f50>], [<partitura.score.Part object at 0x7f95a037a8d0>, <partitura.score.Part object at 0x7f95a031ff50>, <partitura.score.Part object at 0x7f95a031ffd0>, <partitura.score.Part object at 0x7f95a033b090>], [<partitura.score.Part object at 0x7f95a0208350>, <partitura.score.Part object at 0x7f95a01d4c50>, <partitura.score.Part object at 0x7f95a01d4cd0>, <partitura.score.Part object at 0x7f95a01d4d50>], [<partitura.score.Part object at 0x7f95a0103d10>, <partitura.score.Part object at 0x7f95a0137490>, <partitura.score.Part object at 0x7f95a0137510>, <partitura.score.Part object at 0x7f95a0137590>], [<partitura.score.Part object at 0x7f949dfc9450>, <partitura.score.Part object at 0x7f949df948d0>, <partitura.score.Part object at 0x7f949df94950>, <partitura.score.Part object at 0x7f949df949d0>], [<partitura.score.Part object at 0x7f949ded39d0>, <partitura.score.Part object at 0x7f949de8a450>, <partitura.score.Part object at 0x7f949de8a4d0>, <partitura.score.Part object at 0x7f949de8a550>], [<partitura.score.Part object at 0x7f949ddd8450>, <partitura.score.Part object at 0x7f949dd93e50>, <partitura.score.Part object at 0x7f949dd93ed0>, <partitura.score.Part object at 0x7f949dd93f50>], [<partitura.score.Part object at 0x7f949dcd88d0>, <partitura.score.Part object at 0x7f949dc8f710>, <partitura.score.Part object at 0x7f949dc8f790>, <partitura.score.Part object at 0x7f949dc8f810>], [<partitura.score.Part object at 0x7f949dbf3d50>, <partitura.score.Part object at 0x7f949dbbc390>, <partitura.score.Part object at 0x7f949dbbc410>, <partitura.score.Part object at 0x7f949dbbc490>], [<partitura.score.Part object at 0x7f949da92190>, <partitura.score.Part object at 0x7f949da4cd90>, <partitura.score.Part object at 0x7f949da4ce10>, <partitura.score.Part object at 0x7f949da4ce90>], [<partitura.score.Part object at 0x7f949d99f250>, <partitura.score.Part object at 0x7f949d958390>, <partitura.score.Part object at 0x7f949d958410>, <partitura.score.Part object at 0x7f949d958490>], [<partitura.score.Part object at 0x7f949d869190>, <partitura.score.Part object at 0x7f949d83aad0>, <partitura.score.Part object at 0x7f949d83ab50>, <partitura.score.Part object at 0x7f949d83abd0>], [<partitura.score.Part object at 0x7f949d765ad0>, <partitura.score.Part object at 0x7f949d71b810>, <partitura.score.Part object at 0x7f949d71b890>, <partitura.score.Part object at 0x7f949d71b910>], [<partitura.score.Part object at 0x7f949d6a6b90>, <partitura.score.Part object at 0x7f95a0391f50>, <partitura.score.Part object at 0x7f949d6bbf90>, <partitura.score.Part object at 0x7f949d67d250>], [<partitura.score.Part object at 0x7f949d5b3e90>, <partitura.score.Part object at 0x7f949d56cd10>, <partitura.score.Part object at 0x7f949d56cd90>, <partitura.score.Part object at 0x7f949d56ce10>], [<partitura.score.Part object at 0x7f949d47a490>, <partitura.score.Part object at 0x7f949d3c8850>, <partitura.score.Part object at 0x7f949d3c8890>, <partitura.score.Part object at 0x7f949d3c8910>], [<partitura.score.Part object at 0x7f949d362850>, <partitura.score.Part object at 0x7f949d309cd0>, <partitura.score.Part object at 0x7f949d309d50>, <partitura.score.Part object at 0x7f949d309dd0>], [<partitura.score.Part object at 0x7f949d18e050>, <partitura.score.Part object at 0x7f949d14e1d0>, <partitura.score.Part object at 0x7f949d14e250>, <partitura.score.Part object at 0x7f949d14e2d0>], [<partitura.score.Part object at 0x7f949d095b10>, <partitura.score.Part object at 0x7f949d050c50>, <partitura.score.Part object at 0x7f949d050cd0>, <partitura.score.Part object at 0x7f949d050d50>], [<partitura.score.Part object at 0x7f949cf80f50>, <partitura.score.Part object at 0x7f949cf43510>, <partitura.score.Part object at 0x7f949cf43590>, <partitura.score.Part object at 0x7f949cf43610>], [<partitura.score.Part object at 0x7f949ce52310>, <partitura.score.Part object at 0x7f949ce204d0>, <partitura.score.Part object at 0x7f949ce20550>, <partitura.score.Part object at 0x7f949ce205d0>], [<partitura.score.Part object at 0x7f949cd47290>, <partitura.score.Part object at 0x7f949cd71cd0>, <partitura.score.Part object at 0x7f949cd71d50>, <partitura.score.Part object at 0x7f949cd71dd0>], [<partitura.score.Part object at 0x7f949ccb90d0>, <partitura.score.Part object at 0x7f949cc75ad0>, <partitura.score.Part object at 0x7f949cc75b50>, <partitura.score.Part object at 0x7f949cc75bd0>], [<partitura.score.Part object at 0x7f949cb5bb10>, <partitura.score.Part object at 0x7f949cb22110>, <partitura.score.Part object at 0x7f949cb22190>, <partitura.score.Part object at 0x7f949cb22210>], [<partitura.score.Part object at 0x7f949ca65450>, <partitura.score.Part object at 0x7f949ca1f3d0>, <partitura.score.Part object at 0x7f949ca1f450>, <partitura.score.Part object at 0x7f949ca1f4d0>], [<partitura.score.Part object at 0x7f949c9219d0>, <partitura.score.Part object at 0x7f949c8f8310>, <partitura.score.Part object at 0x7f949c8f8390>, <partitura.score.Part object at 0x7f949c8f8410>], [<partitura.score.Part object at 0x7f949c7d6850>, <partitura.score.Part object at 0x7f949c7b7050>, <partitura.score.Part object at 0x7f949c7b70d0>, <partitura.score.Part object at 0x7f949c7b7150>], [<partitura.score.Part object at 0x7f949c6d4950>, <partitura.score.Part object at 0x7f949c68f3d0>, <partitura.score.Part object at 0x7f949c68f450>, <partitura.score.Part object at 0x7f949c68f4d0>], [<partitura.score.Part object at 0x7f949c68f490>, <partitura.score.Part object at 0x7f949c521890>, <partitura.score.Part object at 0x7f949c4abbd0>, <partitura.score.Part object at 0x7f949c4abc50>], [<partitura.score.Part object at 0x7f949c313d10>, <partitura.score.Part object at 0x7f949c2820d0>, <partitura.score.Part object at 0x7f949c282150>, <partitura.score.Part object at 0x7f949c2821d0>], [<partitura.score.Part object at 0x7f949c1828d0>, <partitura.score.Part object at 0x7f949c1592d0>, <partitura.score.Part object at 0x7f949c159350>, <partitura.score.Part object at 0x7f949c1593d0>], [<partitura.score.Part object at 0x7f949c088490>, <partitura.score.Part object at 0x7f949c0b3fd0>, <partitura.score.Part object at 0x7f949c052090>, <partitura.score.Part object at 0x7f949c052110>], [<partitura.score.Part object at 0x7f949bffff50>, <partitura.score.Part object at 0x7f949bf46310>, <partitura.score.Part object at 0x7f949bf46390>, <partitura.score.Part object at 0x7f949bf46410>], [<partitura.score.Part object at 0x7f949be863d0>, <partitura.score.Part object at 0x7f949bebf6d0>, <partitura.score.Part object at 0x7f949bebf750>, <partitura.score.Part object at 0x7f949bebf7d0>], [<partitura.score.Part object at 0x7f949bd83550>, <partitura.score.Part object at 0x7f949bdba390>, <partitura.score.Part object at 0x7f949bdba410>, <partitura.score.Part object at 0x7f949bdba490>], [<partitura.score.Part object at 0x7f949bc9bcd0>, <partitura.score.Part object at 0x7f949bc67610>, <partitura.score.Part object at 0x7f949bc67690>, <partitura.score.Part object at 0x7f949bc67710>], [<partitura.score.Part object at 0x7f949bb4dc90>, <partitura.score.Part object at 0x7f949bb1a690>, <partitura.score.Part object at 0x7f949bb1a710>, <partitura.score.Part object at 0x7f949bb1a790>], [<partitura.score.Part object at 0x7f949ba5e310>, <partitura.score.Part object at 0x7f949ba17450>, <partitura.score.Part object at 0x7f949ba174d0>, <partitura.score.Part object at 0x7f949ba17550>], [<partitura.score.Part object at 0x7f949b9766d0>, <partitura.score.Part object at 0x7f949b8c05d0>, <partitura.score.Part object at 0x7f949b8c0650>, <partitura.score.Part object at 0x7f949b8c06d0>], [<partitura.score.Part object at 0x7f949b804a90>, <partitura.score.Part object at 0x7f949b83fc90>, <partitura.score.Part object at 0x7f949b83fd10>, <partitura.score.Part object at 0x7f949b83fd90>], [<partitura.score.Part object at 0x7f949b735a50>, <partitura.score.Part object at 0x7f949b6fed90>, <partitura.score.Part object at 0x7f949b6fedd0>, <partitura.score.Part object at 0x7f949b6fee50>], [<partitura.score.Part object at 0x7f949b5870d0>, <partitura.score.Part object at 0x7f949b555950>, <partitura.score.Part object at 0x7f949b5559d0>, <partitura.score.Part object at 0x7f949b555a50>], [<partitura.score.Part object at 0x7f949b44f790>, <partitura.score.Part object at 0x7f949b41cf10>, <partitura.score.Part object at 0x7f949b41cf90>, <partitura.score.Part object at 0x7f949b3c9050>], [<partitura.score.Part object at 0x7f949b336990>, <partitura.score.Part object at 0x7f949b285c50>, <partitura.score.Part object at 0x7f949b285cd0>, <partitura.score.Part object at 0x7f949b285d50>], [<partitura.score.Part object at 0x7f949b183e90>, <partitura.score.Part object at 0x7f949b155190>, <partitura.score.Part object at 0x7f949b155210>, <partitura.score.Part object at 0x7f949b155290>], [<partitura.score.Part object at 0x7f949b040c50>, <partitura.score.Part object at 0x7f949b00ba10>, <partitura.score.Part object at 0x7f949b00ba90>, <partitura.score.Part object at 0x7f949b00bb10>], [<partitura.score.Part object at 0x7f949af6d350>, <partitura.score.Part object at 0x7f949af2ce50>, <partitura.score.Part object at 0x7f949af2ced0>, <partitura.score.Part object at 0x7f949af2cf50>], [<partitura.score.Part object at 0x7f949ae7e550>, <partitura.score.Part object at 0x7f949ae38910>, <partitura.score.Part object at 0x7f949ae38990>, <partitura.score.Part object at 0x7f949ae38a10>], [<partitura.score.Part object at 0x7f949ad78ed0>, <partitura.score.Part object at 0x7f949ad3e610>, <partitura.score.Part object at 0x7f949ad3e650>, <partitura.score.Part object at 0x7f949ad3e6d0>], [<partitura.score.Part object at 0x7f949ac75050>, <partitura.score.Part object at 0x7f949ac14210>, <partitura.score.Part object at 0x7f949ac14290>, <partitura.score.Part object at 0x7f949ac14310>], [<partitura.score.Part object at 0x7f949aab8810>, <partitura.score.Part object at 0x7f949a9c8290>, <partitura.score.Part object at 0x7f949a9c8310>, <partitura.score.Part object at 0x7f949a9c8390>], [<partitura.score.Part object at 0x7f949a938110>, <partitura.score.Part object at 0x7f949a8f5390>, <partitura.score.Part object at 0x7f949a8f5410>, <partitura.score.Part object at 0x7f949a8f5490>], [<partitura.score.Part object at 0x7f949a813150>, <partitura.score.Part object at 0x7f949a83db90>, <partitura.score.Part object at 0x7f949a83dc10>, <partitura.score.Part object at 0x7f949a83dc90>], [<partitura.score.Part object at 0x7f949c357050>, <partitura.score.Part object at 0x7f949a70d550>, <partitura.score.Part object at 0x7f949a70d450>, <partitura.score.Part object at 0x7f949a724c10>], [<partitura.score.Part object at 0x7f949a677a10>, <partitura.score.Part object at 0x7f949a63e0d0>, <partitura.score.Part object at 0x7f949a63e150>, <partitura.score.Part object at 0x7f949a63e1d0>], [<partitura.score.Part object at 0x7f949a516b10>, <partitura.score.Part object at 0x7f949a4d1dd0>, <partitura.score.Part object at 0x7f949a4d1e50>, <partitura.score.Part object at 0x7f949a4d1ed0>], [<partitura.score.Part object at 0x7f949a43fa90>, <partitura.score.Part object at 0x7f949a38cd90>, <partitura.score.Part object at 0x7f949a38ce10>, <partitura.score.Part object at 0x7f949a38ce90>], [<partitura.score.Part object at 0x7f949a2e1190>, <partitura.score.Part object at 0x7f949a29a390>, <partitura.score.Part object at 0x7f949a29a410>, <partitura.score.Part object at 0x7f949a29a490>], [<partitura.score.Part object at 0x7f949a1da750>, <partitura.score.Part object at 0x7f949a194a50>, <partitura.score.Part object at 0x7f949a194ad0>, <partitura.score.Part object at 0x7f949a194b50>], [<partitura.score.Part object at 0x7f949a0f3f50>, <partitura.score.Part object at 0x7f949a0beed0>, <partitura.score.Part object at 0x7f949a0bef50>, <partitura.score.Part object at 0x7f949a0befd0>], [<partitura.score.Part object at 0x7f949a712190>, <partitura.score.Part object at 0x7f9499fa8dd0>, <partitura.score.Part object at 0x7f9499fa8e50>, <partitura.score.Part object at 0x7f9499fa8ed0>], [<partitura.score.Part object at 0x7f9499eef0d0>, <partitura.score.Part object at 0x7f9499ea7cd0>, <partitura.score.Part object at 0x7f9499ea7d50>, <partitura.score.Part object at 0x7f9499ea7dd0>], [<partitura.score.Part object at 0x7f9499df84d0>, <partitura.score.Part object at 0x7f9499db3ad0>, <partitura.score.Part object at 0x7f9499db3b50>, <partitura.score.Part object at 0x7f9499db3bd0>], [<partitura.score.Part object at 0x7f9499ce3290>, <partitura.score.Part object at 0x7f9499c90e10>, <partitura.score.Part object at 0x7f9499c90e90>, <partitura.score.Part object at 0x7f9499c90f10>], [<partitura.score.Part object at 0x7f9499bca490>, <partitura.score.Part object at 0x7f9499b835d0>, <partitura.score.Part object at 0x7f9499b83650>, <partitura.score.Part object at 0x7f9499b836d0>], [<partitura.score.Part object at 0x7f9499ae12d0>, <partitura.score.Part object at 0x7f9499aaa650>, <partitura.score.Part object at 0x7f9499aaa6d0>, <partitura.score.Part object at 0x7f9499aaa750>], [<partitura.score.Part object at 0x7f9499901c10>, <partitura.score.Part object at 0x7f94998f1e10>, <partitura.score.Part object at 0x7f94998f1e90>, <partitura.score.Part object at 0x7f94998f1f10>], [<partitura.score.Part object at 0x7f9499835a90>, <partitura.score.Part object at 0x7f94997ebe90>, <partitura.score.Part object at 0x7f94997ebf10>, <partitura.score.Part object at 0x7f94997ebf90>], [<partitura.score.Part object at 0x7f94996faa90>, <partitura.score.Part object at 0x7f9499652a10>, <partitura.score.Part object at 0x7f9499652a90>, <partitura.score.Part object at 0x7f9499652b10>], [<partitura.score.Part object at 0x7f94995bb150>, <partitura.score.Part object at 0x7f949957be50>, <partitura.score.Part object at 0x7f949957bed0>, <partitura.score.Part object at 0x7f949957bf50>], [<partitura.score.Part object at 0x7f94994116d0>, <partitura.score.Part object at 0x7f9499411190>, <partitura.score.Part object at 0x7f9499ff7d50>, <partitura.score.Part object at 0x7f949941d710>], [<partitura.score.Part object at 0x7f94993b6dd0>, <partitura.score.Part object at 0x7f949936a750>, <partitura.score.Part object at 0x7f949936a7d0>, <partitura.score.Part object at 0x7f949936a850>], [<partitura.score.Part object at 0x7f9499256110>, <partitura.score.Part object at 0x7f949921f7d0>, <partitura.score.Part object at 0x7f949921f810>, <partitura.score.Part object at 0x7f949921f890>], [<partitura.score.Part object at 0x7f9499175890>, <partitura.score.Part object at 0x7f9499135a90>, <partitura.score.Part object at 0x7f9499135b10>, <partitura.score.Part object at 0x7f9499135b90>], [<partitura.score.Part object at 0x7f9499014dd0>, <partitura.score.Part object at 0x7f9498fde810>, <partitura.score.Part object at 0x7f9498fde890>, <partitura.score.Part object at 0x7f9498fde910>], [<partitura.score.Part object at 0x7f9498e00750>, <partitura.score.Part object at 0x7f9498df8e10>, <partitura.score.Part object at 0x7f9498df8e90>, <partitura.score.Part object at 0x7f9498df8f10>], [<partitura.score.Part object at 0x7f9498ceb650>, <partitura.score.Part object at 0x7f9498cacb50>, <partitura.score.Part object at 0x7f9498cacbd0>, <partitura.score.Part object at 0x7f9498cacc50>], [<partitura.score.Part object at 0x7f9498bb5b90>, <partitura.score.Part object at 0x7f9498bb5c50>, <partitura.score.Part object at 0x7f9498bb5bd0>, <partitura.score.Part object at 0x7f9498bb5cd0>], [<partitura.score.Part object at 0x7f9498a03390>, <partitura.score.Part object at 0x7f94989e5f50>, <partitura.score.Part object at 0x7f94989e5fd0>, <partitura.score.Part object at 0x7f949899a090>], [<partitura.score.Part object at 0x7f94988e8e90>, <partitura.score.Part object at 0x7f94988b4ad0>, <partitura.score.Part object at 0x7f94988b4b50>, <partitura.score.Part object at 0x7f94988b4bd0>], [<partitura.score.Part object at 0x7f9498756750>, <partitura.score.Part object at 0x7f9498736710>, <partitura.score.Part object at 0x7f9498736790>, <partitura.score.Part object at 0x7f9498736810>], [<partitura.score.Part object at 0x7f94985d1250>, <partitura.score.Part object at 0x7f94985a3e50>, <partitura.score.Part object at 0x7f94985a3ed0>, <partitura.score.Part object at 0x7f94985a3f50>], [<partitura.score.Part object at 0x7f949849c4d0>, <partitura.score.Part object at 0x7f9498465410>, <partitura.score.Part object at 0x7f9498465490>, <partitura.score.Part object at 0x7f9498465510>], [<partitura.score.Part object at 0x7f949835fad0>, <partitura.score.Part object at 0x7f9498322e90>, <partitura.score.Part object at 0x7f9498322f10>, <partitura.score.Part object at 0x7f9498322f90>], [<partitura.score.Part object at 0x7f9498229710>, <partitura.score.Part object at 0x7f9498229790>, <partitura.score.Part object at 0x7f9498229810>, <partitura.score.Part object at 0x7f9498229890>], [<partitura.score.Part object at 0x7f949810ea10>, <partitura.score.Part object at 0x7f94980da990>, <partitura.score.Part object at 0x7f94980daa10>, <partitura.score.Part object at 0x7f94980daa90>], [<partitura.score.Part object at 0x7f9498020110>, <partitura.score.Part object at 0x7f9497fcbe10>, <partitura.score.Part object at 0x7f9497fcbe90>, <partitura.score.Part object at 0x7f9497fcbf10>], [<partitura.score.Part object at 0x7f9497f360d0>, <partitura.score.Part object at 0x7f9497ef7a90>, <partitura.score.Part object at 0x7f9497ef7b10>, <partitura.score.Part object at 0x7f9497ef7b90>], [<partitura.score.Part object at 0x7f9497e3cb50>, <partitura.score.Part object at 0x7f9497df2e50>, <partitura.score.Part object at 0x7f9497df2ed0>, <partitura.score.Part object at 0x7f9497df2f50>], [<partitura.score.Part object at 0x7f9497d57d50>, <partitura.score.Part object at 0x7f9497d76550>, <partitura.score.Part object at 0x7f9497d765d0>, <partitura.score.Part object at 0x7f9497d76650>], [<partitura.score.Part object at 0x7f9497c8db10>, <partitura.score.Part object at 0x7f9497c41190>, <partitura.score.Part object at 0x7f9497c41210>, <partitura.score.Part object at 0x7f9497c41290>], [<partitura.score.Part object at 0x7f94979b6c50>, <partitura.score.Part object at 0x7f9497898490>, <partitura.score.Part object at 0x7f9497898510>, <partitura.score.Part object at 0x7f9497898590>], [<partitura.score.Part object at 0x7f9497619b10>, <partitura.score.Part object at 0x7f949754a250>, <partitura.score.Part object at 0x7f949754a2d0>, <partitura.score.Part object at 0x7f949754a350>], [<partitura.score.Part object at 0x7f9497449890>, <partitura.score.Part object at 0x7f949740ae90>, <partitura.score.Part object at 0x7f949740af10>, <partitura.score.Part object at 0x7f949740af90>], [<partitura.score.Part object at 0x7f9497324b10>, <partitura.score.Part object at 0x7f9497284350>, <partitura.score.Part object at 0x7f94972843d0>, <partitura.score.Part object at 0x7f9497284450>], [<partitura.score.Part object at 0x7f949722f110>, <partitura.score.Part object at 0x7f94971d9850>, <partitura.score.Part object at 0x7f94971d98d0>, <partitura.score.Part object at 0x7f94971d9950>], [<partitura.score.Part object at 0x7f949709ad50>, <partitura.score.Part object at 0x7f9497000a90>, <partitura.score.Part object at 0x7f9497000b10>, <partitura.score.Part object at 0x7f9497000b90>], [<partitura.score.Part object at 0x7f9496f4bb90>, <partitura.score.Part object at 0x7f9496f04950>, <partitura.score.Part object at 0x7f9496f049d0>, <partitura.score.Part object at 0x7f9496f04a50>], [<partitura.score.Part object at 0x7f9496e555d0>, <partitura.score.Part object at 0x7f9496e0ed50>, <partitura.score.Part object at 0x7f9496e0edd0>, <partitura.score.Part object at 0x7f9496e0ee50>], [<partitura.score.Part object at 0x7f9498001090>, <partitura.score.Part object at 0x7f9496dc7750>, <partitura.score.Part object at 0x7f9496dc7450>, <partitura.score.Part object at 0x7f9496d68c50>], [<partitura.score.Part object at 0x7f9496c5f110>, <partitura.score.Part object at 0x7f9496c0fd50>, <partitura.score.Part object at 0x7f9496c0fdd0>, <partitura.score.Part object at 0x7f9496c0fe50>], [<partitura.score.Part object at 0x7f9496b7bc90>, <partitura.score.Part object at 0x7f9496ac7d10>, <partitura.score.Part object at 0x7f9496ac7d90>, <partitura.score.Part object at 0x7f9496ac7e10>], [<partitura.score.Part object at 0x7f949698c710>, <partitura.score.Part object at 0x7f949696a610>, <partitura.score.Part object at 0x7f949696a650>, <partitura.score.Part object at 0x7f949696a6d0>], [<partitura.score.Part object at 0x7f949684cf90>, <partitura.score.Part object at 0x7f9496816810>, <partitura.score.Part object at 0x7f9496816890>, <partitura.score.Part object at 0x7f9496816910>], [<partitura.score.Part object at 0x7f949675d990>, <partitura.score.Part object at 0x7f9496715cd0>, <partitura.score.Part object at 0x7f9496715d50>, <partitura.score.Part object at 0x7f9496715dd0>], [<partitura.score.Part object at 0x7f9496648a90>, <partitura.score.Part object at 0x7f949667f850>, <partitura.score.Part object at 0x7f949667f8d0>, <partitura.score.Part object at 0x7f949667f950>], [<partitura.score.Part object at 0x7f9496559590>, <partitura.score.Part object at 0x7f949651ae10>, <partitura.score.Part object at 0x7f949651ae90>, <partitura.score.Part object at 0x7f949651af10>], [<partitura.score.Part object at 0x7f9496449290>, <partitura.score.Part object at 0x7f949647f090>, <partitura.score.Part object at 0x7f949647f110>, <partitura.score.Part object at 0x7f949647f190>], [<partitura.score.Part object at 0x7f94963fe5d0>, <partitura.score.Part object at 0x7f94963a3f10>, <partitura.score.Part object at 0x7f94963a3f90>, <partitura.score.Part object at 0x7f9496341050>], [<partitura.score.Part object at 0x7f94962ce450>, <partitura.score.Part object at 0x7f94962f9750>, <partitura.score.Part object at 0x7f94962f97d0>, <partitura.score.Part object at 0x7f94962f9850>], [<partitura.score.Part object at 0x7f94961e45d0>, <partitura.score.Part object at 0x7f94961a4cd0>, <partitura.score.Part object at 0x7f94961a4d50>, <partitura.score.Part object at 0x7f94961a4dd0>], [<partitura.score.Part object at 0x7f94960e4c10>, <partitura.score.Part object at 0x7f94960a91d0>, <partitura.score.Part object at 0x7f94960a9250>, <partitura.score.Part object at 0x7f94960a92d0>], [<partitura.score.Part object at 0x7f949603dd50>, <partitura.score.Part object at 0x7f9495ff62d0>, <partitura.score.Part object at 0x7f9495ff6350>, <partitura.score.Part object at 0x7f9495ff63d0>], [<partitura.score.Part object at 0x7f9495ee3a90>, <partitura.score.Part object at 0x7f9495eb0290>, <partitura.score.Part object at 0x7f9495eb0310>, <partitura.score.Part object at 0x7f9495eb0390>], [<partitura.score.Part object at 0x7f9495dd6850>, <partitura.score.Part object at 0x7f9495d8a2d0>, <partitura.score.Part object at 0x7f9495d8a350>, <partitura.score.Part object at 0x7f9495d8a3d0>], [<partitura.score.Part object at 0x7f9495d2ab90>, <partitura.score.Part object at 0x7f9495ce2310>, <partitura.score.Part object at 0x7f9495ce2390>, <partitura.score.Part object at 0x7f9495ce2410>], [<partitura.score.Part object at 0x7f9495bf2c90>, <partitura.score.Part object at 0x7f9495b4c790>, <partitura.score.Part object at 0x7f9495b4c810>, <partitura.score.Part object at 0x7f9495b4c890>], [<partitura.score.Part object at 0x7f9495af9a50>, <partitura.score.Part object at 0x7f9495ab11d0>, <partitura.score.Part object at 0x7f9495ab1250>, <partitura.score.Part object at 0x7f9495ab12d0>], [<partitura.score.Part object at 0x7f95b1e8a1d0>, <partitura.score.Part object at 0x7f9495a27210>, <partitura.score.Part object at 0x7f9495a06990>, <partitura.score.Part object at 0x7f949ceae5d0>], [<partitura.score.Part object at 0x7f94958cfa90>, <partitura.score.Part object at 0x7f9495887290>, <partitura.score.Part object at 0x7f9495887310>, <partitura.score.Part object at 0x7f9495887390>], [<partitura.score.Part object at 0x7f94957f2210>, <partitura.score.Part object at 0x7f94957b5e10>, <partitura.score.Part object at 0x7f94957b5e90>, <partitura.score.Part object at 0x7f94957b5f10>], [<partitura.score.Part object at 0x7f949568ef50>, <partitura.score.Part object at 0x7f9495648910>, <partitura.score.Part object at 0x7f9495648990>, <partitura.score.Part object at 0x7f9495648a10>], [<partitura.score.Part object at 0x7f94955ad090>, <partitura.score.Part object at 0x7f94955427d0>, <partitura.score.Part object at 0x7f9495542850>, <partitura.score.Part object at 0x7f94955428d0>], [<partitura.score.Part object at 0x7f9495494310>, <partitura.score.Part object at 0x7f9495454690>, <partitura.score.Part object at 0x7f9495454710>, <partitura.score.Part object at 0x7f9495454790>], [<partitura.score.Part object at 0x7f9495343690>, <partitura.score.Part object at 0x7f9495303e10>, <partitura.score.Part object at 0x7f9495303e90>, <partitura.score.Part object at 0x7f9495303f10>], [<partitura.score.Part object at 0x7f949527af50>, <partitura.score.Part object at 0x7f94951c7ed0>, <partitura.score.Part object at 0x7f94951c7f50>, <partitura.score.Part object at 0x7f94951c7fd0>], [<partitura.score.Part object at 0x7f949517a250>, <partitura.score.Part object at 0x7f9495128890>, <partitura.score.Part object at 0x7f9495128910>, <partitura.score.Part object at 0x7f9495128990>], [<partitura.score.Part object at 0x7f9495038f50>, <partitura.score.Part object at 0x7f9494f88bd0>, <partitura.score.Part object at 0x7f9494f88c50>, <partitura.score.Part object at 0x7f9494f88cd0>], [<partitura.score.Part object at 0x7f9494f292d0>, <partitura.score.Part object at 0x7f9494ed3490>, <partitura.score.Part object at 0x7f9494ed3950>, <partitura.score.Part object at 0x7f9494ed39d0>], [<partitura.score.Part object at 0x7f9494e0d450>, <partitura.score.Part object at 0x7f9494dca790>, <partitura.score.Part object at 0x7f9494dca810>, <partitura.score.Part object at 0x7f9494dca890>], [<partitura.score.Part object at 0x7f9494d2c790>, <partitura.score.Part object at 0x7f9494cf6210>, <partitura.score.Part object at 0x7f9494cf6290>, <partitura.score.Part object at 0x7f9494cf6310>], [<partitura.score.Part object at 0x7f9494c2cc10>, <partitura.score.Part object at 0x7f9494be5c90>, <partitura.score.Part object at 0x7f9494be5d10>, <partitura.score.Part object at 0x7f9494be5d90>], [<partitura.score.Part object at 0x7f9494b230d0>, <partitura.score.Part object at 0x7f9494ad1d10>, <partitura.score.Part object at 0x7f9494ad1d90>, <partitura.score.Part object at 0x7f9494ad1e10>], [<partitura.score.Part object at 0x7f9494a6ff10>, <partitura.score.Part object at 0x7f9494a26350>, <partitura.score.Part object at 0x7f9494a263d0>, <partitura.score.Part object at 0x7f9494a26450>], [<partitura.score.Part object at 0x7f9494965f50>, <partitura.score.Part object at 0x7f9494921dd0>, <partitura.score.Part object at 0x7f9494921e50>, <partitura.score.Part object at 0x7f9494921ed0>], [<partitura.score.Part object at 0x7f9494861050>, <partitura.score.Part object at 0x7f9494877d10>, <partitura.score.Part object at 0x7f9494877d90>, <partitura.score.Part object at 0x7f9494877e10>], [<partitura.score.Part object at 0x7f9494795d10>, <partitura.score.Part object at 0x7f949474aa50>, <partitura.score.Part object at 0x7f949474aad0>, <partitura.score.Part object at 0x7f949474ab50>], [<partitura.score.Part object at 0x7f94965fcf50>, <partitura.score.Part object at 0x7f9494647bd0>, <partitura.score.Part object at 0x7f94946479d0>, <partitura.score.Part object at 0x7f949463aad0>], [<partitura.score.Part object at 0x7f9494568610>, <partitura.score.Part object at 0x7f9494513950>, <partitura.score.Part object at 0x7f94945139d0>, <partitura.score.Part object at 0x7f9494513a50>], [<partitura.score.Part object at 0x7f949444ff90>, <partitura.score.Part object at 0x7f9494415950>, <partitura.score.Part object at 0x7f94944159d0>, <partitura.score.Part object at 0x7f9494415a50>], [<partitura.score.Part object at 0x7f949436dd10>, <partitura.score.Part object at 0x7f9494334790>, <partitura.score.Part object at 0x7f9494334810>, <partitura.score.Part object at 0x7f9494334890>], [<partitura.score.Part object at 0x7f9494208c50>, <partitura.score.Part object at 0x7f94941c6c90>, <partitura.score.Part object at 0x7f94941c6d10>, <partitura.score.Part object at 0x7f94941c6d90>], [<partitura.score.Part object at 0x7f9494113cd0>, <partitura.score.Part object at 0x7f94940dc7d0>, <partitura.score.Part object at 0x7f94940dc850>, <partitura.score.Part object at 0x7f94940dc8d0>], [<partitura.score.Part object at 0x7f9494000e10>, <partitura.score.Part object at 0x7f9494034590>, <partitura.score.Part object at 0x7f9494034610>, <partitura.score.Part object at 0x7f9494034690>], [<partitura.score.Part object at 0x7f9493f02b10>, <partitura.score.Part object at 0x7f9493f3fa90>, <partitura.score.Part object at 0x7f9493f3fb10>, <partitura.score.Part object at 0x7f9493f3fb90>], [<partitura.score.Part object at 0x7f9493e5e950>, <partitura.score.Part object at 0x7f9493e0be90>, <partitura.score.Part object at 0x7f9493e0bf10>, <partitura.score.Part object at 0x7f9493e0bf90>], [<partitura.score.Part object at 0x7f9493db6bd0>, <partitura.score.Part object at 0x7f9493d6b410>, <partitura.score.Part object at 0x7f9493d6b490>, <partitura.score.Part object at 0x7f9493d6b510>], [<partitura.score.Part object at 0x7f9493c89bd0>, <partitura.score.Part object at 0x7f9493c42150>, <partitura.score.Part object at 0x7f9493c421d0>, <partitura.score.Part object at 0x7f9493c42250>], [<partitura.score.Part object at 0x7f9493b94490>, <partitura.score.Part object at 0x7f9493b41f10>, <partitura.score.Part object at 0x7f9493b41f90>, <partitura.score.Part object at 0x7f9493b5e050>], [<partitura.score.Part object at 0x7f9493af86d0>, <partitura.score.Part object at 0x7f9493ab16d0>, <partitura.score.Part object at 0x7f9493ab1750>, <partitura.score.Part object at 0x7f9493ab17d0>], [<partitura.score.Part object at 0x7f94939d0d10>, <partitura.score.Part object at 0x7f9493987610>, <partitura.score.Part object at 0x7f9493987690>, <partitura.score.Part object at 0x7f9493987710>], [<partitura.score.Part object at 0x7f94939252d0>, <partitura.score.Part object at 0x7f94938cfe10>, <partitura.score.Part object at 0x7f94938cfe90>, <partitura.score.Part object at 0x7f94938cff10>], [<partitura.score.Part object at 0x7f9493808190>, <partitura.score.Part object at 0x7f94937c05d0>, <partitura.score.Part object at 0x7f94937c0650>, <partitura.score.Part object at 0x7f94937c06d0>], [<partitura.score.Part object at 0x7f9493724c90>, <partitura.score.Part object at 0x7f94936ed950>, <partitura.score.Part object at 0x7f94936ed9d0>, <partitura.score.Part object at 0x7f94936eda50>], [<partitura.score.Part object at 0x7f94935e27d0>, <partitura.score.Part object at 0x7f94935b0110>, <partitura.score.Part object at 0x7f94935b0190>, <partitura.score.Part object at 0x7f94935b0210>], [<partitura.score.Part object at 0x7f949334f110>, <partitura.score.Part object at 0x7f94932f9590>, <partitura.score.Part object at 0x7f94932f9690>, <partitura.score.Part object at 0x7f94932f9710>], [<partitura.score.Part object at 0x7f949314d410>, <partitura.score.Part object at 0x7f9493123fd0>, <partitura.score.Part object at 0x7f94930d0090>, <partitura.score.Part object at 0x7f94930d0110>], [<partitura.score.Part object at 0x7f949302ca90>, <partitura.score.Part object at 0x7f9492feed90>, <partitura.score.Part object at 0x7f9492feee10>, <partitura.score.Part object at 0x7f9492feee90>], [<partitura.score.Part object at 0x7f9492efa190>, <partitura.score.Part object at 0x7f9492ebcc90>, <partitura.score.Part object at 0x7f9492ebcd10>, <partitura.score.Part object at 0x7f9492ebcd90>], [<partitura.score.Part object at 0x7f9492ccb090>, <partitura.score.Part object at 0x7f9492c82350>, <partitura.score.Part object at 0x7f9492c823d0>, <partitura.score.Part object at 0x7f9492c82450>], [<partitura.score.Part object at 0x7f9492b08550>, <partitura.score.Part object at 0x7f9492af7290>, <partitura.score.Part object at 0x7f9492af7310>, <partitura.score.Part object at 0x7f9492af7390>], [<partitura.score.Part object at 0x7f94929f9b10>, <partitura.score.Part object at 0x7f94929b7e10>, <partitura.score.Part object at 0x7f94929b7e90>, <partitura.score.Part object at 0x7f94929b7f10>], [<partitura.score.Part object at 0x7f94928d4390>, <partitura.score.Part object at 0x7f94928fbc10>, <partitura.score.Part object at 0x7f94928fbc90>, <partitura.score.Part object at 0x7f94928fbd10>], [<partitura.score.Part object at 0x7f949250edd0>, <partitura.score.Part object at 0x7f94923c2550>, <partitura.score.Part object at 0x7f94923c2590>, <partitura.score.Part object at 0x7f94923c2610>], [<partitura.score.Part object at 0x7f94922ffdd0>, <partitura.score.Part object at 0x7f9492257610>, <partitura.score.Part object at 0x7f9492257690>, <partitura.score.Part object at 0x7f9492257710>], [<partitura.score.Part object at 0x7f94921a5c90>, <partitura.score.Part object at 0x7f94921603d0>, <partitura.score.Part object at 0x7f9492160450>, <partitura.score.Part object at 0x7f94921604d0>], [<partitura.score.Part object at 0x7f9492048310>, <partitura.score.Part object at 0x7f9492009f50>, <partitura.score.Part object at 0x7f9492009fd0>, <partitura.score.Part object at 0x7f9492030090>], [<partitura.score.Part object at 0x7f9492030050>, <partitura.score.Part object at 0x7f9491f5eb50>, <partitura.score.Part object at 0x7f9491f26d50>, <partitura.score.Part object at 0x7f9491f26dd0>], [<partitura.score.Part object at 0x7f9491e22a10>, <partitura.score.Part object at 0x7f9491ded290>, <partitura.score.Part object at 0x7f9491ded310>, <partitura.score.Part object at 0x7f9491ded390>], [<partitura.score.Part object at 0x7f9491c83610>, <partitura.score.Part object at 0x7f9491c53a50>, <partitura.score.Part object at 0x7f9491c53ad0>, <partitura.score.Part object at 0x7f9491c53b50>], [<partitura.score.Part object at 0x7f9491b47350>, <partitura.score.Part object at 0x7f9491b097d0>, <partitura.score.Part object at 0x7f9491b09850>, <partitura.score.Part object at 0x7f9491b098d0>], [<partitura.score.Part object at 0x7f9491abfd90>, <partitura.score.Part object at 0x7f9491a76d50>, <partitura.score.Part object at 0x7f9491a76dd0>, <partitura.score.Part object at 0x7f9491a76e50>], [<partitura.score.Part object at 0x7f94918441d0>, <partitura.score.Part object at 0x7f94917c8a10>, <partitura.score.Part object at 0x7f94917c8a90>, <partitura.score.Part object at 0x7f94917c8b10>], [<partitura.score.Part object at 0x7f9491615f90>, <partitura.score.Part object at 0x7f94915aa6d0>, <partitura.score.Part object at 0x7f94915aa750>, <partitura.score.Part object at 0x7f94915aa7d0>], [<partitura.score.Part object at 0x7f9491468610>, <partitura.score.Part object at 0x7f94913cb190>, <partitura.score.Part object at 0x7f94913cb210>, <partitura.score.Part object at 0x7f94913cb290>], [<partitura.score.Part object at 0x7f949136b650>, <partitura.score.Part object at 0x7f949131e090>, <partitura.score.Part object at 0x7f949131e110>, <partitura.score.Part object at 0x7f949131e190>], [<partitura.score.Part object at 0x7f949121c950>, <partitura.score.Part object at 0x7f94911eb690>, <partitura.score.Part object at 0x7f94911eb710>, <partitura.score.Part object at 0x7f94911eb790>], [<partitura.score.Part object at 0x7f94910c1690>, <partitura.score.Part object at 0x7f94910fe190>, <partitura.score.Part object at 0x7f94910fe210>, <partitura.score.Part object at 0x7f94910fe290>], [<partitura.score.Part object at 0x7f9490f7d150>, <partitura.score.Part object at 0x7f9490ee44d0>, <partitura.score.Part object at 0x7f9490ee4550>, <partitura.score.Part object at 0x7f9490ee45d0>], [<partitura.score.Part object at 0x7f9490dc3a90>, <partitura.score.Part object at 0x7f9490d807d0>, <partitura.score.Part object at 0x7f9490d80850>, <partitura.score.Part object at 0x7f9490d808d0>], [<partitura.score.Part object at 0x7f9490ee4590>, <partitura.score.Part object at 0x7f9490ccc2d0>, <partitura.score.Part object at 0x7f9490c87650>, <partitura.score.Part object at 0x7f9490c876d0>], [<partitura.score.Part object at 0x7f9490c0a310>, <partitura.score.Part object at 0x7f9490c0a1d0>, <partitura.score.Part object at 0x7f9491c42810>, <partitura.score.Part object at 0x7f9491c42650>], [<partitura.score.Part object at 0x7f9490af7fd0>, <partitura.score.Part object at 0x7f9490aac850>, <partitura.score.Part object at 0x7f9490aac8d0>, <partitura.score.Part object at 0x7f9490aac950>], [<partitura.score.Part object at 0x7f94909fcb10>, <partitura.score.Part object at 0x7f94909b8b50>, <partitura.score.Part object at 0x7f94909b8bd0>, <partitura.score.Part object at 0x7f94909b8c50>], [<partitura.score.Part object at 0x7f9490894950>, <partitura.score.Part object at 0x7f9490853890>, <partitura.score.Part object at 0x7f9490853910>, <partitura.score.Part object at 0x7f9490853990>], [<partitura.score.Part object at 0x7f9490721a10>, <partitura.score.Part object at 0x7f94906fdf50>, <partitura.score.Part object at 0x7f94906fdfd0>, <partitura.score.Part object at 0x7f94906a8090>], [<partitura.score.Part object at 0x7f9490606490>, <partitura.score.Part object at 0x7f949061ec50>, <partitura.score.Part object at 0x7f9490635050>, <partitura.score.Part object at 0x7f94906350d0>], [<partitura.score.Part object at 0x7f94904f0950>, <partitura.score.Part object at 0x7f949045a950>, <partitura.score.Part object at 0x7f949045a9d0>, <partitura.score.Part object at 0x7f949045aa50>], [<partitura.score.Part object at 0x7f94903ba610>, <partitura.score.Part object at 0x7f9490375850>, <partitura.score.Part object at 0x7f94903758d0>, <partitura.score.Part object at 0x7f9490375950>], [<partitura.score.Part object at 0x7f94902499d0>, <partitura.score.Part object at 0x7f9490209d50>, <partitura.score.Part object at 0x7f9490209dd0>, <partitura.score.Part object at 0x7f9490209e50>], [<partitura.score.Part object at 0x7f9490159c10>, <partitura.score.Part object at 0x7f9490121190>, <partitura.score.Part object at 0x7f9490121210>, <partitura.score.Part object at 0x7f9490121290>], [<partitura.score.Part object at 0x7f94900669d0>, <partitura.score.Part object at 0x7f949001ee50>, <partitura.score.Part object at 0x7f949001eed0>, <partitura.score.Part object at 0x7f949001ef50>], [<partitura.score.Part object at 0x7f948fe8a0d0>, <partitura.score.Part object at 0x7f948fe78890>, <partitura.score.Part object at 0x7f948fe78910>, <partitura.score.Part object at 0x7f948fe78990>], [<partitura.score.Part object at 0x7f948fd33b50>, <partitura.score.Part object at 0x7f948fc86f10>, <partitura.score.Part object at 0x7f948fc86f90>, <partitura.score.Part object at 0x7f948fcb0050>], [<partitura.score.Part object at 0x7f948fc2d6d0>, <partitura.score.Part object at 0x7f948fbe2250>, <partitura.score.Part object at 0x7f948fbe22d0>, <partitura.score.Part object at 0x7f948fbe2350>], [<partitura.score.Part object at 0x7f948faa8050>, <partitura.score.Part object at 0x7f948fa538d0>, <partitura.score.Part object at 0x7f948fa53950>, <partitura.score.Part object at 0x7f948fa539d0>], [<partitura.score.Part object at 0x7f948f98c590>, <partitura.score.Part object at 0x7f948f959050>, <partitura.score.Part object at 0x7f948f9590d0>, <partitura.score.Part object at 0x7f948f959150>], [<partitura.score.Part object at 0x7f948f841290>, <partitura.score.Part object at 0x7f948f807710>, <partitura.score.Part object at 0x7f948f807790>, <partitura.score.Part object at 0x7f948f807810>], [<partitura.score.Part object at 0x7f949001ef10>, <partitura.score.Part object at 0x7f948f786050>, <partitura.score.Part object at 0x7f948f747950>, <partitura.score.Part object at 0x7f948f747b50>], [<partitura.score.Part object at 0x7f948f543690>, <partitura.score.Part object at 0x7f948f4dec10>, <partitura.score.Part object at 0x7f948f4dec90>, <partitura.score.Part object at 0x7f948f4ded10>], [<partitura.score.Part object at 0x7f948f3df990>, <partitura.score.Part object at 0x7f948f39f950>, <partitura.score.Part object at 0x7f948f39f9d0>, <partitura.score.Part object at 0x7f948f39fa50>], [<partitura.score.Part object at 0x7f948f283250>, <partitura.score.Part object at 0x7f948f245690>, <partitura.score.Part object at 0x7f948f245710>, <partitura.score.Part object at 0x7f948f245790>], [<partitura.score.Part object at 0x7f948f155150>, <partitura.score.Part object at 0x7f948f124ed0>, <partitura.score.Part object at 0x7f948f124f50>, <partitura.score.Part object at 0x7f948f124fd0>], [<partitura.score.Part object at 0x7f948f073510>, <partitura.score.Part object at 0x7f948f01ff50>, <partitura.score.Part object at 0x7f948f01ffd0>, <partitura.score.Part object at 0x7f948f03d090>], [<partitura.score.Part object at 0x7f948ef29190>, <partitura.score.Part object at 0x7f948eeeb750>, <partitura.score.Part object at 0x7f948eeeb7d0>, <partitura.score.Part object at 0x7f948eeeb850>], [<partitura.score.Part object at 0x7f948ee1d550>, <partitura.score.Part object at 0x7f948edd53d0>, <partitura.score.Part object at 0x7f948edd5450>, <partitura.score.Part object at 0x7f948edd54d0>], [<partitura.score.Part object at 0x7f948ed17b50>, <partitura.score.Part object at 0x7f948ecdc0d0>, <partitura.score.Part object at 0x7f948ecdc150>, <partitura.score.Part object at 0x7f948ecdc1d0>], [<partitura.score.Part object at 0x7f948ec30390>, <partitura.score.Part object at 0x7f948ebeb9d0>, <partitura.score.Part object at 0x7f948ebeba50>, <partitura.score.Part object at 0x7f948ebebad0>], [<partitura.score.Part object at 0x7f948eaf8050>, <partitura.score.Part object at 0x7f948ea99e50>, <partitura.score.Part object at 0x7f948ea99ed0>, <partitura.score.Part object at 0x7f948ea99f50>], [<partitura.score.Part object at 0x7f948e9dd6d0>, <partitura.score.Part object at 0x7f948e99fd50>, <partitura.score.Part object at 0x7f948e99fdd0>, <partitura.score.Part object at 0x7f948e99fe50>], [<partitura.score.Part object at 0x7f948e7d1850>, <partitura.score.Part object at 0x7f948e75c950>, <partitura.score.Part object at 0x7f948e75c9d0>, <partitura.score.Part object at 0x7f948e75ca50>], [<partitura.score.Part object at 0x7f948e668f10>, <partitura.score.Part object at 0x7f948e5c3950>, <partitura.score.Part object at 0x7f948e5c39d0>, <partitura.score.Part object at 0x7f948e5c3a50>], [<partitura.score.Part object at 0x7f948e51ec90>, <partitura.score.Part object at 0x7f948e4e7590>, <partitura.score.Part object at 0x7f948e4e7610>, <partitura.score.Part object at 0x7f948e4e7690>], [<partitura.score.Part object at 0x7f948e3e3c50>, <partitura.score.Part object at 0x7f948e3b06d0>, <partitura.score.Part object at 0x7f948e3b0750>, <partitura.score.Part object at 0x7f948e3b07d0>], [<partitura.score.Part object at 0x7f948e295550>, <partitura.score.Part object at 0x7f948e251b10>, <partitura.score.Part object at 0x7f948e251b90>, <partitura.score.Part object at 0x7f948e251c10>], [<partitura.score.Part object at 0x7f948e1f28d0>, <partitura.score.Part object at 0x7f948e1a7350>, <partitura.score.Part object at 0x7f948e1a73d0>, <partitura.score.Part object at 0x7f948e1a7450>], [<partitura.score.Part object at 0x7f948e0a8c10>, <partitura.score.Part object at 0x7f948e07cc50>, <partitura.score.Part object at 0x7f948e07ccd0>, <partitura.score.Part object at 0x7f948e07cd50>], [<partitura.score.Part object at 0x7f948deb3590>, <partitura.score.Part object at 0x7f948ddc1090>, <partitura.score.Part object at 0x7f948ddc1110>, <partitura.score.Part object at 0x7f948ddc1190>], [<partitura.score.Part object at 0x7f948dd16fd0>, <partitura.score.Part object at 0x7f948dcd9350>, <partitura.score.Part object at 0x7f948dcd93d0>, <partitura.score.Part object at 0x7f948dcd9450>], [<partitura.score.Part object at 0x7f948dc1cb50>, <partitura.score.Part object at 0x7f948dbe1250>, <partitura.score.Part object at 0x7f948dbe12d0>, <partitura.score.Part object at 0x7f948dbe1350>], [<partitura.score.Part object at 0x7f948db18e50>, <partitura.score.Part object at 0x7f948dada210>, <partitura.score.Part object at 0x7f948dada290>, <partitura.score.Part object at 0x7f948dada310>], [<partitura.score.Part object at 0x7f948da1b210>, <partitura.score.Part object at 0x7f948d9d42d0>, <partitura.score.Part object at 0x7f948d9d4350>, <partitura.score.Part object at 0x7f948d9d43d0>], [<partitura.score.Part object at 0x7f948d93e090>, <partitura.score.Part object at 0x7f948d8e9110>, <partitura.score.Part object at 0x7f948d8e9190>, <partitura.score.Part object at 0x7f948d8e9210>], [<partitura.score.Part object at 0x7f948d7e7cd0>, <partitura.score.Part object at 0x7f948d7b09d0>, <partitura.score.Part object at 0x7f948d7b0a50>, <partitura.score.Part object at 0x7f948d7b0ad0>], [<partitura.score.Part object at 0x7f948d689190>, <partitura.score.Part object at 0x7f948d642510>, <partitura.score.Part object at 0x7f948d642590>, <partitura.score.Part object at 0x7f948d642610>], [<partitura.score.Part object at 0x7f948d5a6750>, <partitura.score.Part object at 0x7f948d563f50>, <partitura.score.Part object at 0x7f948d563fd0>, <partitura.score.Part object at 0x7f948d508090>], [<partitura.score.Part object at 0x7f948d3c30d0>, <partitura.score.Part object at 0x7f948d3b0350>, <partitura.score.Part object at 0x7f948d3b03d0>, <partitura.score.Part object at 0x7f948d3b0450>], [<partitura.score.Part object at 0x7f948d2aaa90>, <partitura.score.Part object at 0x7f948d2722d0>, <partitura.score.Part object at 0x7f948d272350>, <partitura.score.Part object at 0x7f948d2723d0>], [<partitura.score.Part object at 0x7f948d146e10>, <partitura.score.Part object at 0x7f948d111110>, <partitura.score.Part object at 0x7f948d111190>, <partitura.score.Part object at 0x7f948d111210>], [<partitura.score.Part object at 0x7f948d06fed0>, <partitura.score.Part object at 0x7f948cfc8990>, <partitura.score.Part object at 0x7f948cfc8a10>, <partitura.score.Part object at 0x7f948cfc8a90>], [<partitura.score.Part object at 0x7f948ced4ed0>, <partitura.score.Part object at 0x7f948ceb1ad0>, <partitura.score.Part object at 0x7f948ceb1b50>, <partitura.score.Part object at 0x7f948ceb1bd0>], [<partitura.score.Part object at 0x7f948cdaca10>, <partitura.score.Part object at 0x7f948cd77790>, <partitura.score.Part object at 0x7f948cd77810>, <partitura.score.Part object at 0x7f948cd77890>], [<partitura.score.Part object at 0x7f948cc4da10>, <partitura.score.Part object at 0x7f948cc0aa90>, <partitura.score.Part object at 0x7f948cc0ab10>, <partitura.score.Part object at 0x7f948cc0ab90>], [<partitura.score.Part object at 0x7f948cb49b50>, <partitura.score.Part object at 0x7f948cb10390>, <partitura.score.Part object at 0x7f948cb10410>, <partitura.score.Part object at 0x7f948cb10490>], [<partitura.score.Part object at 0x7f948ca49ad0>, <partitura.score.Part object at 0x7f948ca01c10>, <partitura.score.Part object at 0x7f948ca01c90>, <partitura.score.Part object at 0x7f948ca01d10>], [<partitura.score.Part object at 0x7f948c8f0ed0>, <partitura.score.Part object at 0x7f948c86f390>, <partitura.score.Part object at 0x7f948c86f410>, <partitura.score.Part object at 0x7f948c86f490>], [<partitura.score.Part object at 0x7f948c759e10>, <partitura.score.Part object at 0x7f948c7215d0>, <partitura.score.Part object at 0x7f948c721650>, <partitura.score.Part object at 0x7f948c7216d0>], [<partitura.score.Part object at 0x7f948c646990>, <partitura.score.Part object at 0x7f948c67b410>, <partitura.score.Part object at 0x7f948c67b450>, <partitura.score.Part object at 0x7f948c67b4d0>], [<partitura.score.Part object at 0x7f948c4cdd50>, <partitura.score.Part object at 0x7f948c4480d0>, <partitura.score.Part object at 0x7f948c448150>, <partitura.score.Part object at 0x7f948c4481d0>], [<partitura.score.Part object at 0x7f948c3ddb10>, <partitura.score.Part object at 0x7f948d09f510>, <partitura.score.Part object at 0x7f948c35a3d0>, <partitura.score.Part object at 0x7f948c35a410>], [<partitura.score.Part object at 0x7f948c2ac450>, <partitura.score.Part object at 0x7f948c26ad10>, <partitura.score.Part object at 0x7f948c26ad90>, <partitura.score.Part object at 0x7f948c26ae10>], [<partitura.score.Part object at 0x7f948c12f250>, <partitura.score.Part object at 0x7f948c0fb110>, <partitura.score.Part object at 0x7f948c0fb190>, <partitura.score.Part object at 0x7f948c0fb210>], [<partitura.score.Part object at 0x7f948bfddb50>, <partitura.score.Part object at 0x7f948bfa9390>, <partitura.score.Part object at 0x7f948bfa9410>, <partitura.score.Part object at 0x7f948bfa9490>], [<partitura.score.Part object at 0x7f948beefa10>, <partitura.score.Part object at 0x7f948bea8f50>, <partitura.score.Part object at 0x7f948bea8fd0>, <partitura.score.Part object at 0x7f948be4b090>], [<partitura.score.Part object at 0x7f948bdfbf50>, <partitura.score.Part object at 0x7f948bdbf290>, <partitura.score.Part object at 0x7f948bdbf310>, <partitura.score.Part object at 0x7f948bdbf390>], [<partitura.score.Part object at 0x7f948bcd7f10>, <partitura.score.Part object at 0x7f948bc8a490>, <partitura.score.Part object at 0x7f948bc8a510>, <partitura.score.Part object at 0x7f948bc8a590>], [<partitura.score.Part object at 0x7f948bc36cd0>, <partitura.score.Part object at 0x7f948bbf0e10>, <partitura.score.Part object at 0x7f948bbf0e90>, <partitura.score.Part object at 0x7f948bbf0f10>], [<partitura.score.Part object at 0x7f948bb3edd0>, <partitura.score.Part object at 0x7f948ba849d0>, <partitura.score.Part object at 0x7f948ba84a50>, <partitura.score.Part object at 0x7f948ba84ad0>], [<partitura.score.Part object at 0x7f948b9d7a90>, <partitura.score.Part object at 0x7f948b9a0110>, <partitura.score.Part object at 0x7f948b9a0190>, <partitura.score.Part object at 0x7f948b9a0210>], [<partitura.score.Part object at 0x7f948b8822d0>, <partitura.score.Part object at 0x7f948b84e690>, <partitura.score.Part object at 0x7f948b84e710>, <partitura.score.Part object at 0x7f948b84e790>], [<partitura.score.Part object at 0x7f948b798d50>, <partitura.score.Part object at 0x7f948b75e690>, <partitura.score.Part object at 0x7f948b75e710>, <partitura.score.Part object at 0x7f948b75e790>], [<partitura.score.Part object at 0x7f948b692590>, <partitura.score.Part object at 0x7f948b647210>, <partitura.score.Part object at 0x7f948b647290>, <partitura.score.Part object at 0x7f948b647310>], [<partitura.score.Part object at 0x7f948b596190>, <partitura.score.Part object at 0x7f948b552510>, <partitura.score.Part object at 0x7f948b552590>, <partitura.score.Part object at 0x7f948b552610>], [<partitura.score.Part object at 0x7f948b4e6e90>, <partitura.score.Part object at 0x7f948b49aa10>, <partitura.score.Part object at 0x7f948b49aa90>, <partitura.score.Part object at 0x7f948b49ab10>], [<partitura.score.Part object at 0x7f948b361310>, <partitura.score.Part object at 0x7f948b2cdad0>, <partitura.score.Part object at 0x7f948b2cdb50>, <partitura.score.Part object at 0x7f948b2cdbd0>], [<partitura.score.Part object at 0x7f948b1f3290>, <partitura.score.Part object at 0x7f948b141b10>, <partitura.score.Part object at 0x7f948b141b90>, <partitura.score.Part object at 0x7f948b141c10>], [<partitura.score.Part object at 0x7f948b0a9610>, <partitura.score.Part object at 0x7f948b064e50>, <partitura.score.Part object at 0x7f948b064ed0>, <partitura.score.Part object at 0x7f948b064f50>], [<partitura.score.Part object at 0x7f948d09f6d0>, <partitura.score.Part object at 0x7f948b031dd0>, <partitura.score.Part object at 0x7f948b031ed0>, <partitura.score.Part object at 0x7f948b031e10>], [<partitura.score.Part object at 0x7f948ae6c110>, <partitura.score.Part object at 0x7f948ae24250>, <partitura.score.Part object at 0x7f948ae242d0>, <partitura.score.Part object at 0x7f948ae24350>], [<partitura.score.Part object at 0x7f948ad6aed0>, <partitura.score.Part object at 0x7f948ad30450>, <partitura.score.Part object at 0x7f948ad304d0>, <partitura.score.Part object at 0x7f948ad30550>], [<partitura.score.Part object at 0x7f948ac22ed0>, <partitura.score.Part object at 0x7f948abef210>, <partitura.score.Part object at 0x7f948abef290>, <partitura.score.Part object at 0x7f948abef310>], [<partitura.score.Part object at 0x7f948ab0f410>, <partitura.score.Part object at 0x7f948ab38e10>, <partitura.score.Part object at 0x7f948ab38e90>, <partitura.score.Part object at 0x7f948ab38f10>], [<partitura.score.Part object at 0x7f948aa02510>, <partitura.score.Part object at 0x7f948aa3e410>, <partitura.score.Part object at 0x7f948aa3e490>, <partitura.score.Part object at 0x7f948aa3e510>], [<partitura.score.Part object at 0x7f948a91ead0>, <partitura.score.Part object at 0x7f948a8e7790>, <partitura.score.Part object at 0x7f948a8e7810>, <partitura.score.Part object at 0x7f948a8e7890>], [<partitura.score.Part object at 0x7f948a7b8b50>, <partitura.score.Part object at 0x7f948a722e10>, <partitura.score.Part object at 0x7f948a722e90>, <partitura.score.Part object at 0x7f948a722f10>], [<partitura.score.Part object at 0x7f948a5dbc90>, <partitura.score.Part object at 0x7f948a5bd890>, <partitura.score.Part object at 0x7f948a5bd910>, <partitura.score.Part object at 0x7f948a5bd990>], [<partitura.score.Part object at 0x7f948a4efe50>, <partitura.score.Part object at 0x7f948a4a38d0>, <partitura.score.Part object at 0x7f948a4a3950>, <partitura.score.Part object at 0x7f948a4a39d0>], [<partitura.score.Part object at 0x7f948a34fa90>, <partitura.score.Part object at 0x7f948a33a310>, <partitura.score.Part object at 0x7f948a33a390>, <partitura.score.Part object at 0x7f948a33a410>], [<partitura.score.Part object at 0x7f948a26c2d0>, <partitura.score.Part object at 0x7f948a216c10>, <partitura.score.Part object at 0x7f948a216c90>, <partitura.score.Part object at 0x7f948a216d10>], [<partitura.score.Part object at 0x7f948a162810>, <partitura.score.Part object at 0x7f948a11ca10>, <partitura.score.Part object at 0x7f948a11ca90>, <partitura.score.Part object at 0x7f948a11cb10>], [<partitura.score.Part object at 0x7f948a023c90>, <partitura.score.Part object at 0x7f9489ffa350>, <partitura.score.Part object at 0x7f9489ffa3d0>, <partitura.score.Part object at 0x7f9489ffa450>], [<partitura.score.Part object at 0x7f9489ec7fd0>, <partitura.score.Part object at 0x7f9489e8e650>, <partitura.score.Part object at 0x7f9489e8e6d0>, <partitura.score.Part object at 0x7f9489e8e750>], [<partitura.score.Part object at 0x7f9489de3750>, <partitura.score.Part object at 0x7f9489da9590>, <partitura.score.Part object at 0x7f9489da9610>, <partitura.score.Part object at 0x7f9489da9690>], [<partitura.score.Part object at 0x7f9489cf1850>, <partitura.score.Part object at 0x7f9489cb5190>, <partitura.score.Part object at 0x7f9489cb5210>, <partitura.score.Part object at 0x7f9489cb5290>], [<partitura.score.Part object at 0x7f9489bea450>, <partitura.score.Part object at 0x7f9489b98f10>, <partitura.score.Part object at 0x7f9489b98f90>, <partitura.score.Part object at 0x7f9489bb6050>], [<partitura.score.Part object at 0x7f9489ae4490>, <partitura.score.Part object at 0x7f9489aa0a90>, <partitura.score.Part object at 0x7f9489aa0b10>, <partitura.score.Part object at 0x7f9489aa0b90>], [<partitura.score.Part object at 0x7f9489984490>, <partitura.score.Part object at 0x7f9489943cd0>, <partitura.score.Part object at 0x7f9489943d50>, <partitura.score.Part object at 0x7f9489943dd0>], [<partitura.score.Part object at 0x7f9489867d90>, <partitura.score.Part object at 0x7f94897c6190>, <partitura.score.Part object at 0x7f94897c6210>, <partitura.score.Part object at 0x7f94897c6290>], [<partitura.score.Part object at 0x7f9489741390>, <partitura.score.Part object at 0x7f9489757f90>, <partitura.score.Part object at 0x7f9489757fd0>, <partitura.score.Part object at 0x7f9489770090>], [<partitura.score.Part object at 0x7f948969f950>, <partitura.score.Part object at 0x7f948965ab50>, <partitura.score.Part object at 0x7f948965abd0>, <partitura.score.Part object at 0x7f948965ac50>], [<partitura.score.Part object at 0x7f9489568250>, <partitura.score.Part object at 0x7f9489538990>, <partitura.score.Part object at 0x7f9489538a10>, <partitura.score.Part object at 0x7f9489538a90>], [<partitura.score.Part object at 0x7f94893c53d0>, <partitura.score.Part object at 0x7f9489382e50>, <partitura.score.Part object at 0x7f9489382ed0>, <partitura.score.Part object at 0x7f9489382f50>], [<partitura.score.Part object at 0x7f94892d3590>, <partitura.score.Part object at 0x7f948928c450>, <partitura.score.Part object at 0x7f948928c4d0>, <partitura.score.Part object at 0x7f948928c550>], [<partitura.score.Part object at 0x7f94891cb710>, <partitura.score.Part object at 0x7f9489186f10>, <partitura.score.Part object at 0x7f9489186f90>, <partitura.score.Part object at 0x7f94891ac050>], [<partitura.score.Part object at 0x7f94890d0550>, <partitura.score.Part object at 0x7f948908a990>, <partitura.score.Part object at 0x7f948908aa10>, <partitura.score.Part object at 0x7f948908aa90>], [<partitura.score.Part object at 0x7f9488f83110>, <partitura.score.Part object at 0x7f9488f4d890>, <partitura.score.Part object at 0x7f9488f4d910>, <partitura.score.Part object at 0x7f9488f4d990>], [<partitura.score.Part object at 0x7f9488ef9e50>, <partitura.score.Part object at 0x7f9488ead4d0>, <partitura.score.Part object at 0x7f9488ead550>, <partitura.score.Part object at 0x7f9488ead5d0>], [<partitura.score.Part object at 0x7f9488d870d0>, <partitura.score.Part object at 0x7f9488d45910>, <partitura.score.Part object at 0x7f9488d45990>, <partitura.score.Part object at 0x7f9488d45a10>], [<partitura.score.Part object at 0x7f9488c9bb10>, <partitura.score.Part object at 0x7f9488c55b10>, <partitura.score.Part object at 0x7f9488c55b90>, <partitura.score.Part object at 0x7f9488c55c10>], [<partitura.score.Part object at 0x7f9488b9add0>, <partitura.score.Part object at 0x7f9488b4fdd0>, <partitura.score.Part object at 0x7f9488b4fe50>, <partitura.score.Part object at 0x7f9488b4fed0>], [<partitura.score.Part object at 0x7f9488a5b550>, <partitura.score.Part object at 0x7f9488a2a910>, <partitura.score.Part object at 0x7f9488a2a990>, <partitura.score.Part object at 0x7f9488a2aa10>], [<partitura.score.Part object at 0x7f94888cf650>, <partitura.score.Part object at 0x7f94888ad7d0>, <partitura.score.Part object at 0x7f94888ad850>, <partitura.score.Part object at 0x7f94888ad8d0>], [<partitura.score.Part object at 0x7f94887dc690>, <partitura.score.Part object at 0x7f9488785dd0>, <partitura.score.Part object at 0x7f9488785e50>, <partitura.score.Part object at 0x7f9488785ed0>], [<partitura.score.Part object at 0x7f94886cfd90>, <partitura.score.Part object at 0x7f9488696510>, <partitura.score.Part object at 0x7f9488696590>, <partitura.score.Part object at 0x7f9488696610>], [<partitura.score.Part object at 0x7f94885ccf50>, <partitura.score.Part object at 0x7f94885904d0>, <partitura.score.Part object at 0x7f9488590550>, <partitura.score.Part object at 0x7f94885905d0>], [<partitura.score.Part object at 0x7f94884964d0>, <partitura.score.Part object at 0x7f9488461ed0>, <partitura.score.Part object at 0x7f9488461f50>, <partitura.score.Part object at 0x7f9488461fd0>], [<partitura.score.Part object at 0x7f94883fddd0>, <partitura.score.Part object at 0x7f94883ae190>, <partitura.score.Part object at 0x7f94883ae550>, <partitura.score.Part object at 0x7f94883ae5d0>], [<partitura.score.Part object at 0x7f94882dcc90>, <partitura.score.Part object at 0x7f9488297650>, <partitura.score.Part object at 0x7f94882976d0>, <partitura.score.Part object at 0x7f9488297750>], [<partitura.score.Part object at 0x7f94881d4b10>, <partitura.score.Part object at 0x7f948818cd10>, <partitura.score.Part object at 0x7f948818cd90>, <partitura.score.Part object at 0x7f948818ce10>], [<partitura.score.Part object at 0x7f94880afc10>, <partitura.score.Part object at 0x7f948800e950>, <partitura.score.Part object at 0x7f948800e9d0>, <partitura.score.Part object at 0x7f948800ea50>], [<partitura.score.Part object at 0x7f9487f4fa90>, <partitura.score.Part object at 0x7f9487f07cd0>, <partitura.score.Part object at 0x7f9487f07d50>, <partitura.score.Part object at 0x7f9487f07dd0>], [<partitura.score.Part object at 0x7f9487e167d0>, <partitura.score.Part object at 0x7f9487de6410>, <partitura.score.Part object at 0x7f9487de6490>, <partitura.score.Part object at 0x7f9487de6510>], [<partitura.score.Part object at 0x7f9487d1b810>, <partitura.score.Part object at 0x7f9487cd3390>, <partitura.score.Part object at 0x7f9487cd3410>, <partitura.score.Part object at 0x7f9487cd3490>], [<partitura.score.Part object at 0x7f9487c1ffd0>, <partitura.score.Part object at 0x7f9487be8510>, <partitura.score.Part object at 0x7f9487be8590>, <partitura.score.Part object at 0x7f9487be8610>], [<partitura.score.Part object at 0x7f9487aebe10>, <partitura.score.Part object at 0x7f9487a46250>, <partitura.score.Part object at 0x7f9487a462d0>, <partitura.score.Part object at 0x7f9487a46350>], [<partitura.score.Part object at 0x7f9487990690>, <partitura.score.Part object at 0x7f948794bc10>, <partitura.score.Part object at 0x7f948794bc90>, <partitura.score.Part object at 0x7f948794bd10>], [<partitura.score.Part object at 0x7f94878ac950>, <partitura.score.Part object at 0x7f9487876090>, <partitura.score.Part object at 0x7f9487876110>, <partitura.score.Part object at 0x7f9487876190>], [<partitura.score.Part object at 0x7f948775cfd0>, <partitura.score.Part object at 0x7f9487728c10>, <partitura.score.Part object at 0x7f9487728c90>, <partitura.score.Part object at 0x7f9487728d10>], [<partitura.score.Part object at 0x7f948766ef50>, <partitura.score.Part object at 0x7f9487633510>, <partitura.score.Part object at 0x7f9487633590>, <partitura.score.Part object at 0x7f9487633610>], [<partitura.score.Part object at 0x7f94874da110>, <partitura.score.Part object at 0x7f94874ac850>, <partitura.score.Part object at 0x7f94874ac8d0>, <partitura.score.Part object at 0x7f94874ac950>], [<partitura.score.Part object at 0x7f9487371510>, <partitura.score.Part object at 0x7f94872d7590>, <partitura.score.Part object at 0x7f94872d75d0>, <partitura.score.Part object at 0x7f94872d7650>], [<partitura.score.Part object at 0x7f9487233510>, <partitura.score.Part object at 0x7f94871f1b50>, <partitura.score.Part object at 0x7f94871f1bd0>, <partitura.score.Part object at 0x7f94871f1c50>], [<partitura.score.Part object at 0x7f94872d7610>, <partitura.score.Part object at 0x7f94870fb5d0>, <partitura.score.Part object at 0x7f94870fba90>, <partitura.score.Part object at 0x7f94870fbc10>], [<partitura.score.Part object at 0x7f9486fc83d0>, <partitura.score.Part object at 0x7f9486f829d0>, <partitura.score.Part object at 0x7f9486f82a50>, <partitura.score.Part object at 0x7f9486f82ad0>], [<partitura.score.Part object at 0x7f9486ed2610>, <partitura.score.Part object at 0x7f9486e8e6d0>, <partitura.score.Part object at 0x7f9486e8e750>, <partitura.score.Part object at 0x7f9486e8e7d0>], [<partitura.score.Part object at 0x7f9486de1c50>, <partitura.score.Part object at 0x7f9486da7610>, <partitura.score.Part object at 0x7f9486da7690>, <partitura.score.Part object at 0x7f9486da7710>], [<partitura.score.Part object at 0x7f9486c80bd0>, <partitura.score.Part object at 0x7f9486c452d0>, <partitura.score.Part object at 0x7f9486c45310>, <partitura.score.Part object at 0x7f9486c45390>], [<partitura.score.Part object at 0x7f9486b6cd10>, <partitura.score.Part object at 0x7f9486acde50>, <partitura.score.Part object at 0x7f9486acded0>, <partitura.score.Part object at 0x7f9486acdf50>], [<partitura.score.Part object at 0x7f94869cb7d0>, <partitura.score.Part object at 0x7f9486989cd0>, <partitura.score.Part object at 0x7f9486989d50>, <partitura.score.Part object at 0x7f9486989dd0>], [<partitura.score.Part object at 0x7f94868fba50>, <partitura.score.Part object at 0x7f9486846390>, <partitura.score.Part object at 0x7f9486846410>, <partitura.score.Part object at 0x7f9486846490>], [<partitura.score.Part object at 0x7f948678dd10>, <partitura.score.Part object at 0x7f9486752490>, <partitura.score.Part object at 0x7f9486752510>, <partitura.score.Part object at 0x7f9486752590>], [<partitura.score.Part object at 0x7f9486697d50>, <partitura.score.Part object at 0x7f948665e890>, <partitura.score.Part object at 0x7f948665e910>, <partitura.score.Part object at 0x7f948665e990>], [<partitura.score.Part object at 0x7f9486552110>, <partitura.score.Part object at 0x7f9486510b10>, <partitura.score.Part object at 0x7f9486510b90>, <partitura.score.Part object at 0x7f9486510c10>], [<partitura.score.Part object at 0x7f9486463590>, <partitura.score.Part object at 0x7f948641eb10>, <partitura.score.Part object at 0x7f948641eb90>, <partitura.score.Part object at 0x7f948641ec10>], [<partitura.score.Part object at 0x7f948630b3d0>, <partitura.score.Part object at 0x7f94862d81d0>, <partitura.score.Part object at 0x7f94862d8250>, <partitura.score.Part object at 0x7f94862d82d0>], [<partitura.score.Part object at 0x7f9486224e90>, <partitura.score.Part object at 0x7f94861e91d0>, <partitura.score.Part object at 0x7f94861e9250>, <partitura.score.Part object at 0x7f94861e92d0>], [<partitura.score.Part object at 0x7f94862d8290>, <partitura.score.Part object at 0x7f94860eca10>, <partitura.score.Part object at 0x7f94860ecb90>, <partitura.score.Part object at 0x7f94860ecc50>], [<partitura.score.Part object at 0x7f9485fcced0>, <partitura.score.Part object at 0x7f9485f96890>, <partitura.score.Part object at 0x7f9485f96910>, <partitura.score.Part object at 0x7f9485f96990>], [<partitura.score.Part object at 0x7f9485e8c6d0>, <partitura.score.Part object at 0x7f9485e56a50>, <partitura.score.Part object at 0x7f9485e56ad0>, <partitura.score.Part object at 0x7f9485e56b50>]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate chorales"
      ],
      "metadata": {
        "id": "yphGmsr-NSV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluate chorals"
      ],
      "metadata": {
        "id": "v4TJGKiUs086"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_one_choral(model, train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match\n",
        "                                      \n",
        "            \n",
        "            #if idx > 40: # or idx==2:\n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "                part_3 = part[3]\n",
        "                note_array_3 = part_3.note_array\n",
        "\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "                note_counter_3 += len(note_array_3)\n",
        "\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "                \n",
        "                #print(\"note_array_0\",note_array_0)\n",
        "                   \n",
        "                \n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):\n",
        "                    #print(\"note_array[onset_beat]:\",note_array[\"onset_beat\"])\n",
        "                    \n",
        "                    #### get only indices that are positive\n",
        "\n",
        "                    onset_beat = note_array[\"onset_beat\"][note_array[\"onset_beat\"]>=0]\n",
        "\n",
        "                    #print(\"new onset\", onset_beat)\n",
        "                    duration_beat = note_array[\"duration_beat\"][note_array[\"onset_beat\"]>=0]\n",
        "                    pitch_list = note_array[\"pitch\"][note_array[\"onset_beat\"]>=0]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "                    #print(\"note_idx_end:\",note_idx_end)\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "                    \n",
        "                    #print(\"note_idx_start\",note_idx_start)\n",
        "                    #print(\"note_idx_end\",note_idx_end)\n",
        "                    #print(\"pitch_list\",pitch_list)\n",
        "                    \n",
        "\n",
        "                    # do model prediction\n",
        "                    model.eval()\n",
        "                    voices = voices.to(device).float()\n",
        "                    monophonic=True\n",
        "                    with torch.no_grad():\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        #print(\"prediction:\",prediction)\n",
        "                        label = ground_truth_label_list[el_note_arr]\n",
        "\n",
        "                \n",
        "                    for i in range(len(note_idx_start)):\n",
        "\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "\n",
        "                        #print(\"prediction:\",pred_list_first)\n",
        "                        #if pred_list_first.shape == torch.Size([0]):\n",
        "                        #    print(\"empty:\",i)\n",
        "                        \n",
        "\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "                        accordance_dict[str(label)].append(0)\n",
        "\n",
        "\n",
        "                count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "                for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                    counting = 0\n",
        "                    ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                    for j in range(len(total_predictions_dict[i])):\n",
        "                        #print(\"total_predictions_dict[i][j]:\",total_predictions_dict[i][j] )\n",
        "                        #print(i,j)\n",
        "                        #if total_predictions_dict[i][j].shape == torch.Size([0]):\n",
        "                            #print(\"fail indices:\",i,j)\n",
        "\n",
        "                        if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                    count_dict_2[i].append(counting)\n",
        "\n",
        "                acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "                acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "\n",
        "                print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "                print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "\n",
        "                \n",
        "                acc_score_dict[\"0\"].append(acc_0)\n",
        "                acc_score_dict[\"1\"].append(acc_1)\n",
        "                acc_score_dict[\"2\"].append(acc_2)\n",
        "                acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "    print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "    return total_predictions_dict, total_truth_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])\n"
      ],
      "metadata": {
        "id": "UXr2DeiLSyLm"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([-1,-2,1,2,3])\n",
        "c = np.array([5,6,7,8,9])\n",
        "\n",
        "a[a>0], c[a>0]"
      ],
      "metadata": {
        "id": "_pX25-OmlSkN",
        "outputId": "9ee228b1-3245-4a04-d255-f46ba0b5f93a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 2, 3]), array([7, 8, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pred , dict_gt, acc_0 , acc_1, acc_2, acc_3 = evaluate_one_choral(model,val_dataloader,part_dic,F1=False)\n",
        "acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghAmXcXTTtD1",
        "outputId": "6af74997-fba6-4fed-bd18-cc6de490f605"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc 0, sample 0: 0.9758064516129032\n",
            "acc 1, sample 0: 0.9512195121951219\n",
            "acc 2, sample 0: 0.963302752293578\n",
            "acc 3, sample 0: 1.0\n",
            "acc 0, sample 1: 0.09859154929577464\n",
            "acc 1, sample 1: 0.20967741935483872\n",
            "acc 2, sample 1: 0.2413793103448276\n",
            "acc 3, sample 1: 0.23728813559322035\n",
            "acc 0, sample 2: 0.09803921568627451\n",
            "acc 1, sample 2: 0.23404255319148937\n",
            "acc 2, sample 2: 0.3\n",
            "acc 3, sample 2: 0.23809523809523808\n",
            "acc 0, sample 3: 0.0851063829787234\n",
            "acc 1, sample 3: 0.22916666666666666\n",
            "acc 2, sample 3: 0.2222222222222222\n",
            "acc 3, sample 3: 0.05084745762711865\n",
            "acc 0, sample 4: 0.04878048780487805\n",
            "acc 1, sample 4: 0.2631578947368421\n",
            "acc 2, sample 4: 0.225\n",
            "acc 3, sample 4: 0.3548387096774194\n",
            "acc 0, sample 5: 0.056179775280898875\n",
            "acc 1, sample 5: 0.18604651162790697\n",
            "acc 2, sample 5: 0.18604651162790697\n",
            "acc 3, sample 5: 0.2222222222222222\n",
            "acc 0, sample 6: 0.0660377358490566\n",
            "acc 1, sample 6: 0.14018691588785046\n",
            "acc 2, sample 6: 0.23\n",
            "acc 3, sample 6: 0.20454545454545456\n",
            "acc 0, sample 7: 0.07142857142857142\n",
            "acc 1, sample 7: 0.16279069767441862\n",
            "acc 2, sample 7: 0.26\n",
            "acc 3, sample 7: 0.22727272727272727\n",
            "acc 0, sample 8: 0.1111111111111111\n",
            "acc 1, sample 8: 0.19230769230769232\n",
            "acc 2, sample 8: 0.34782608695652173\n",
            "acc 3, sample 8: 0.22727272727272727\n",
            "acc 0, sample 9: 0.04878048780487805\n",
            "acc 1, sample 9: 0.21052631578947367\n",
            "acc 2, sample 9: 0.13513513513513514\n",
            "acc 3, sample 9: 0.0967741935483871\n",
            "acc 0, sample 10: 1.0\n",
            "acc 1, sample 10: 0.9811320754716981\n",
            "acc 2, sample 10: 1.0\n",
            "acc 3, sample 10: 1.0\n",
            "acc 0, sample 11: 0.9873417721518988\n",
            "acc 1, sample 11: 0.9878048780487805\n",
            "acc 2, sample 11: 0.9692307692307692\n",
            "acc 3, sample 11: 1.0\n",
            "acc 0, sample 12: 0.9259259259259259\n",
            "acc 1, sample 12: 0.9583333333333334\n",
            "acc 2, sample 12: 1.0\n",
            "acc 3, sample 12: 1.0\n",
            "acc 0, sample 13: 0.14285714285714285\n",
            "acc 1, sample 13: 0.22580645161290322\n",
            "acc 2, sample 13: 0.3728813559322034\n",
            "acc 3, sample 13: 0.22448979591836735\n",
            "acc 0, sample 14: 0.9726027397260274\n",
            "acc 1, sample 14: 0.9571428571428572\n",
            "acc 2, sample 14: 0.9193548387096774\n",
            "acc 3, sample 14: 1.0\n",
            "acc 0, sample 15: 0.08\n",
            "acc 1, sample 15: 0.23529411764705882\n",
            "acc 2, sample 15: 0.3191489361702128\n",
            "acc 3, sample 15: 0.10256410256410256\n",
            "acc 0, sample 16: 0.08\n",
            "acc 1, sample 16: 0.2692307692307692\n",
            "acc 2, sample 16: 0.2413793103448276\n",
            "acc 3, sample 16: 0.24390243902439024\n",
            "acc 0, sample 17: 0.08333333333333333\n",
            "acc 1, sample 17: 0.12121212121212122\n",
            "acc 2, sample 17: 0.16216216216216217\n",
            "acc 3, sample 17: 0.1\n",
            "acc 0, sample 18: 0.08108108108108109\n",
            "acc 1, sample 18: 0.1875\n",
            "acc 2, sample 18: 0.04878048780487805\n",
            "acc 3, sample 18: 0.12903225806451613\n",
            "acc 0, sample 19: 0.07142857142857142\n",
            "acc 1, sample 19: 0.2037037037037037\n",
            "acc 2, sample 19: 0.34\n",
            "acc 3, sample 19: 0.3023255813953488\n",
            "acc 0, sample 20: 0.1864406779661017\n",
            "acc 1, sample 20: 0.2222222222222222\n",
            "acc 2, sample 20: 0.22\n",
            "acc 3, sample 20: 0.358974358974359\n",
            "acc 0, sample 21: 1.0\n",
            "acc 1, sample 21: 0.9230769230769231\n",
            "acc 2, sample 21: 1.0\n",
            "acc 3, sample 21: 1.0\n",
            "acc 0, sample 22: 0.14666666666666667\n",
            "acc 1, sample 22: 0.38095238095238093\n",
            "acc 2, sample 22: 0.3541666666666667\n",
            "acc 3, sample 22: 0.2553191489361702\n",
            "acc 0, sample 23: 0.9824561403508771\n",
            "acc 1, sample 23: 0.9574468085106383\n",
            "acc 2, sample 23: 0.9803921568627451\n",
            "acc 3, sample 23: 0.9736842105263158\n",
            "acc 0, sample 24: 0.06896551724137931\n",
            "acc 1, sample 24: 0.18032786885245902\n",
            "acc 2, sample 24: 0.11320754716981132\n",
            "acc 3, sample 24: 0.1346153846153846\n",
            "acc 0, sample 25: 0.9622641509433962\n",
            "acc 1, sample 25: 0.98\n",
            "acc 2, sample 25: 1.0\n",
            "acc 3, sample 25: 1.0\n",
            "acc 0, sample 26: 1.0\n",
            "acc 1, sample 26: 1.0\n",
            "acc 2, sample 26: 0.9210526315789473\n",
            "acc 3, sample 26: 0.9473684210526315\n",
            "acc 0, sample 27: 1.0\n",
            "acc 1, sample 27: 0.972972972972973\n",
            "acc 2, sample 27: 1.0\n",
            "acc 3, sample 27: 1.0\n",
            "acc 0, sample 28: 0.9777777777777777\n",
            "acc 1, sample 28: 0.926829268292683\n",
            "acc 2, sample 28: 0.9285714285714286\n",
            "acc 3, sample 28: 1.0\n",
            "acc 0, sample 29: 0.975609756097561\n",
            "acc 1, sample 29: 0.9534883720930233\n",
            "acc 2, sample 29: 0.8888888888888888\n",
            "acc 3, sample 29: 0.972972972972973\n",
            "acc 0, sample 30: 0.0625\n",
            "acc 1, sample 30: 0.358974358974359\n",
            "acc 2, sample 30: 0.32432432432432434\n",
            "acc 3, sample 30: 0.16666666666666666\n",
            "acc 0, sample 31: 0.9857142857142858\n",
            "acc 1, sample 31: 1.0\n",
            "acc 2, sample 31: 1.0\n",
            "acc 3, sample 31: 1.0\n",
            "acc 0, sample 32: 0.08633093525179857\n",
            "acc 1, sample 32: 0.17197452229299362\n",
            "acc 2, sample 32: 0.15217391304347827\n",
            "acc 3, sample 32: 0.22608695652173913\n",
            "acc 0, sample 33: 0.09090909090909091\n",
            "acc 1, sample 33: 0.358974358974359\n",
            "acc 2, sample 33: 0.21951219512195122\n",
            "acc 3, sample 33: 0.36363636363636365\n",
            "acc 0, sample 34: 0.08860759493670886\n",
            "acc 1, sample 34: 0.2054794520547945\n",
            "acc 2, sample 34: 0.1780821917808219\n",
            "acc 3, sample 34: 0.0625\n",
            "acc 0, sample 35: 0.07272727272727272\n",
            "acc 1, sample 35: 0.1702127659574468\n",
            "acc 2, sample 35: 0.3\n",
            "acc 3, sample 35: 0.16279069767441862\n",
            "acc 0, sample 36: 0.9692307692307692\n",
            "acc 1, sample 36: 0.9827586206896551\n",
            "acc 2, sample 36: 0.9464285714285714\n",
            "acc 3, sample 36: 1.0\n",
            "acc 0, sample 37: 0.1\n",
            "acc 1, sample 37: 0.14285714285714285\n",
            "acc 2, sample 37: 0.34782608695652173\n",
            "acc 3, sample 37: 0.28205128205128205\n",
            "acc 0, sample 38: 0.1\n",
            "acc 1, sample 38: 0.28846153846153844\n",
            "acc 2, sample 38: 0.3541666666666667\n",
            "acc 3, sample 38: 0.14285714285714285\n",
            "acc 0, sample 39: 0.04838709677419355\n",
            "acc 1, sample 39: 0.18461538461538463\n",
            "acc 2, sample 39: 0.27692307692307694\n",
            "acc 3, sample 39: 0.22\n",
            "acc 0, sample 40: 0.1111111111111111\n",
            "acc 1, sample 40: 0.2\n",
            "acc 2, sample 40: 0.2653061224489796\n",
            "acc 3, sample 40: 0.13043478260869565\n",
            "acc 0, sample 41: 0.06493506493506493\n",
            "acc 1, sample 41: 0.2125\n",
            "acc 2, sample 41: 0.2318840579710145\n",
            "acc 3, sample 41: 0.07142857142857142\n",
            "acc 0, sample 42: 0.05357142857142857\n",
            "acc 1, sample 42: 0.16\n",
            "acc 2, sample 42: 0.3148148148148148\n",
            "acc 3, sample 42: 0.26666666666666666\n",
            "acc 0, sample 43: 0.18181818181818182\n",
            "acc 1, sample 43: 0.3684210526315789\n",
            "acc 2, sample 43: 0.21621621621621623\n",
            "acc 3, sample 43: 0.21052631578947367\n",
            "acc 0, sample 44: 1.0\n",
            "acc 1, sample 44: 0.9253731343283582\n",
            "acc 2, sample 44: 0.95\n",
            "acc 3, sample 44: 1.0\n",
            "acc 0, sample 45: 0.1111111111111111\n",
            "acc 1, sample 45: 0.3220338983050847\n",
            "acc 2, sample 45: 0.29411764705882354\n",
            "acc 3, sample 45: 0.2\n",
            "acc 0, sample 46: 1.0\n",
            "acc 1, sample 46: 0.95\n",
            "acc 2, sample 46: 0.9459459459459459\n",
            "acc 3, sample 46: 1.0\n",
            "acc 0, sample 47: 0.9464285714285714\n",
            "acc 1, sample 47: 0.9636363636363636\n",
            "acc 2, sample 47: 1.0\n",
            "acc 3, sample 47: 1.0\n",
            "acc 0, sample 48: 0.9491525423728814\n",
            "acc 1, sample 48: 0.9333333333333333\n",
            "acc 2, sample 48: 0.9655172413793104\n",
            "acc 3, sample 48: 1.0\n",
            "acc 0, sample 49: 0.022727272727272728\n",
            "acc 1, sample 49: 0.16666666666666666\n",
            "acc 2, sample 49: 0.2647058823529412\n",
            "acc 3, sample 49: 0.09090909090909091\n",
            "acc 0, sample 50: 0.03636363636363636\n",
            "acc 1, sample 50: 0.1509433962264151\n",
            "acc 2, sample 50: 0.15384615384615385\n",
            "acc 3, sample 50: 0.325\n",
            "acc 0, sample 51: 0.16279069767441862\n",
            "acc 1, sample 51: 0.19230769230769232\n",
            "acc 2, sample 51: 0.3157894736842105\n",
            "acc 3, sample 51: 0.11363636363636363\n",
            "acc 0, sample 52: 0.03125\n",
            "acc 1, sample 52: 0.10526315789473684\n",
            "acc 2, sample 52: 0.14285714285714285\n",
            "acc 3, sample 52: 0.13333333333333333\n",
            "acc 0, sample 53: 0.125\n",
            "acc 1, sample 53: 0.2692307692307692\n",
            "acc 2, sample 53: 0.3469387755102041\n",
            "acc 3, sample 53: 0.1951219512195122\n",
            "acc 0, sample 54: 0.09210526315789473\n",
            "acc 1, sample 54: 0.18292682926829268\n",
            "acc 2, sample 54: 0.2714285714285714\n",
            "acc 3, sample 54: 0.20967741935483872\n",
            "acc 0, sample 55: 1.0\n",
            "acc 1, sample 55: 0.9736842105263158\n",
            "acc 2, sample 55: 1.0\n",
            "acc 3, sample 55: 1.0\n",
            "note counters: v0: 3241 v1: 3156 v2: 3000 v3: 2626\n",
            "total_predictions_dict dict_keys(['0', '1', '2', '3'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3906675883788661,\n",
              " 0.4704326420186091,\n",
              " 0.49408811197202057,\n",
              " 0.467459449004522)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy_for_chorals(model, train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match\n",
        "                                      \n",
        "            \n",
        "            if idx != 1: # or idx==2:\n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "                part_3 = part[3]\n",
        "                note_array_3 = part_3.note_array\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "                note_counter_3 += len(note_array_3)\n",
        "\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "\n",
        "                   \n",
        "                \n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):\n",
        "                    onset_beat = note_array[\"onset_beat\"]\n",
        "                    duration_beat = note_array[\"duration_beat\"]\n",
        "                    pitch_list = note_array[\"pitch\"]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "\n",
        "                               \n",
        "                    # do model prediction\n",
        "                    model.eval()\n",
        "                    voices = voices.to(device).float()\n",
        "                    monophonic=True\n",
        "                    with torch.no_grad():\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        label = ground_truth_label_list[el_note_arr]\n",
        "\n",
        "                \n",
        "                    for i in range(len(note_idx_start)):\n",
        "\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "\n",
        "                        #print(\"prediction:\",pred_list_first)\n",
        "                        \n",
        "\n",
        "\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "                        accordance_dict[str(label)].append(0)\n",
        "\n",
        "\n",
        "                count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "                for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                    counting = 0\n",
        "                    ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                    for j in range(len(total_predictions_dict[i])):\n",
        "                        #print(\"total_predictions_dict[i][j]:\",total_predictions_dict[i][j] )\n",
        "                        if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                    count_dict_2[i].append(counting)\n",
        "\n",
        "                acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "                acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "\n",
        "                print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "                print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "\n",
        "                \n",
        "                acc_score_dict[\"0\"].append(acc_0)\n",
        "                acc_score_dict[\"1\"].append(acc_1)\n",
        "                acc_score_dict[\"2\"].append(acc_2)\n",
        "                acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "    print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "    print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "    return total_predictions_dict, total_truth_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])\n",
        "    #return total_predictions_dict, total_truth_dict"
      ],
      "metadata": {
        "id": "F394uNmtMfLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pred , dict_gt, acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_chorals(model,val_dataloader,part_dic,F1=False)\n",
        "acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "id": "RWxVG3XAYTcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluate fugues"
      ],
      "metadata": {
        "id": "TzTpXHznL02j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import statistics\n",
        "\n",
        "\n",
        "def evaluate_accuracy_for_all(model, train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match\n",
        "                                      \n",
        "            \n",
        "            #if idx == 0 or idx==2:\n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2]\n",
        "\n",
        "                if len(part)== 4:\n",
        "                    part_3 = part[3]\n",
        "                    note_array_3 = part_3.note_array\n",
        "                    note_counter_3 += len(note_array_3)\n",
        "                    list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "\n",
        "                   \n",
        "                \n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):\n",
        "                    onset_beat = note_array[\"onset_beat\"]\n",
        "                    duration_beat = note_array[\"duration_beat\"]\n",
        "                    pitch_list = note_array[\"pitch\"]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "\n",
        "                               \n",
        "                    # do model prediction\n",
        "                    model.eval()\n",
        "                    voices = voices.to(device).float()\n",
        "                    monophonic=True\n",
        "                    with torch.no_grad():\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        label = ground_truth_label_list[el_note_arr]\n",
        "\n",
        "                \n",
        "                    for i in range(len(note_idx_start)):\n",
        "\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "                        \n",
        "                        if i < len(note_idx_start)-1:\n",
        "                            start_second = note_idx_start[i+1]\n",
        "                            end_second =  note_idx_end[i+1]\n",
        "                            pitch_second = pitch_list[i+1]\n",
        "                            pred_list_second = prediction[start_second:end_second,pitch_second]\n",
        "\n",
        "\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "\n",
        "                        result_second = all(elem == pred_list_second[0] for elem in pred_list_second)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result_second == False:\n",
        "                            major_, major_idx = torch.mode(pred_list_second,0)\n",
        "                            major_ = major_.numpy().tolist()\n",
        "                            pred_list_second = [major_ for i in pred_list_second]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "\n",
        "                            \n",
        "                        if F1 == True:\n",
        "                            if pred_list_first[0] == pred_list_second[0]:   #the list might have diff lenghts as diff notes have diff lengths, so is ito oke to just take first elemet\n",
        "                                accordance_dict[str(label)].append(1)\n",
        "                            else:\n",
        "                                accordance_dict[str(label)].append(0)\n",
        "\n",
        "                if F1 == False:\n",
        "                    count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                    print(\"total_predictions_dict.keys())\",total_predictions_dict.keys())\n",
        "\n",
        "                    for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                      counting = 0\n",
        "                      ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                      for j in range(len(total_predictions_dict[i])):\n",
        "                          if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                      count_dict_2[i].append(counting)\n",
        "\n",
        "                    acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                    acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                    acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "\n",
        "                    print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                    print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                    print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "\n",
        "                    if len(list_of_note_arrays)==4:\n",
        "                        acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "                        print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "                        acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "                    acc_score_dict[\"0\"].append(acc_0)\n",
        "                    acc_score_dict[\"1\"].append(acc_1)\n",
        "                    acc_score_dict[\"2\"].append(acc_2)\n",
        "\n",
        "                if F1 == True:\n",
        "                    pred_0 = accordance_dict[\"0\"]\n",
        "                    pred_1 = accordance_dict[\"1\"]\n",
        "                    pred_2 = accordance_dict[\"2\"]                   \n",
        "                    truth_0 = [1 for i in range(len(accordance_dict[\"0\"]))]\n",
        "                    truth_1 = [1 for i in range(len(accordance_dict[\"1\"]))]\n",
        "                    truth_2 = [1 for i in range(len(accordance_dict[\"2\"]))]                  \n",
        "                    f1_v0 = sklearn.metrics.f1_score(truth_0, pred_0)\n",
        "                    f1_v1 = sklearn.metrics.f1_score(truth_1, pred_1)\n",
        "                    f1_v2 = sklearn.metrics.f1_score(truth_2, pred_2)                \n",
        "                    f_score_dict[\"0\"].append(f1_v0)\n",
        "                    f_score_dict[\"1\"].append(f1_v1)\n",
        "                    f_score_dict[\"2\"].append(f1_v2)\n",
        "                    if len(part)==4:\n",
        "                      pred_3 = accordance_dict[\"3\"]\n",
        "                      truth_3 = [1 for i in range(len(accordance_dict[\"3\"]))]\n",
        "                      f1_v3 = sklearn.metrics.f1_score(truth_3, pred_3)\n",
        "                      f_score_dict[\"3\"].append(f1_v3)\n",
        "    \n",
        "    if F1 == True:\n",
        "        return statistics.mean(f_score_dict[\"0\"]), statistics.mean(f_score_dict[\"1\"]), statistics.mean(f_score_dict[\"2\"]),statistics.mean(f_score_dict[\"3\"])\n",
        "    \n",
        "    if F1 == False:\n",
        "        print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "        print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "        return total_predictions_dict, total_truth_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])\n",
        "        #return total_predictions_dict, total_truth_dict"
      ],
      "metadata": {
        "id": "0xbN5YU8nGT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pred , dict_gt, acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_all(model,val_dataloader,part_dic,F1=False)\n",
        "acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "id": "20MP5Gk5kc2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 30 epoch, no loss modifier:\n",
        "#ACC:(0.9165209182020722,\n",
        "# 0.7864434689151618,\n",
        "# 0.8130949796045199,\n",
        "# 0.003652274754166715)\n",
        "\n",
        "# 20 epoch, no loss modifier:\n",
        "#(0.7962210840410273, 0.8669639629052727, 0.751302181991106, 0.0)\n",
        "\n",
        "# 20 ep, loss3 *1,5\n",
        "#(0.8721136343927623,\n",
        " 0.8319586824413445,\n",
        " 0.7563218924966578,\n",
        " 0.09029535181592076)"
      ],
      "metadata": {
        "id": "6mCYnJLnHfYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_all(model,train_dataloader,part_dic,F1=False)\n",
        "dict_pred , dict_gt, acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_all(model,val_dataloader,part_dic,F1=False)\n",
        "acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "id": "ygMV28FhKVAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluate fugues F1 score"
      ],
      "metadata": {
        "id": "52P6em3ANb1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_v0, f1_v1, f1_v2, f1_v3 = evaluate_accuracy_for_all(model,val_dataloader,part_dic,F1=True)\n",
        "print(f1_v0, f1_v1, f1_v2, f1_v3)"
      ],
      "metadata": {
        "id": "FLLmyO6o5vW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pred.keys()"
      ],
      "metadata": {
        "id": "79s64i5_lDN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "for gt, i in enumerate(dict_pred.keys()):\n",
        "  counting = 0\n",
        "  for j in range(len(dict_pred[i])):\n",
        "      if dict_pred[i][j][0] == gt:\n",
        "        print(dict_pred[i][j],dict_gt[i][j])\n",
        "        counting +=1\n",
        "\n",
        "      \n",
        "  count_dict_2[i].append(counting)\n",
        "\n",
        "print(count_dict_2[\"0\"],count_dict_2[\"1\"],count_dict_2[\"2\"],count_dict_2[\"3\"])\n",
        "\n",
        "if len(dict_pred.keys())==4:\n",
        "    print(\"accuracy:\",count_dict_2[\"0\"][0]/len(dict_pred[\"0\"]),count_dict_2[\"1\"][0]/len(dict_pred[\"1\"]),count_dict_2[\"2\"][0]/len(dict_pred[\"2\"]),count_dict_2[\"3\"][0]/len(dict_pred[\"3\"]))\n",
        "\n",
        "if len(dict_pred.keys())==3:\n",
        "    print(\"accuracy:\",count_dict_2[\"0\"][0]/len(dict_pred[\"0\"]),count_dict_2[\"1\"][0]/len(dict_pred[\"1\"]),count_dict_2[\"2\"][0]/len(dict_pred[\"2\"]))"
      ],
      "metadata": {
        "id": "VYBpV_hMfGGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### take 0 -> compare to truth of 0,1,2,3 -> overall voice\n",
        "\n",
        "count_list = []\n",
        "\n",
        "count_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "truth_dic = {'0': 0, '1': 1, '2': 2, '3': 3 }\n",
        "\n",
        "voice_entry_list = [\"0\", \"1\", \"2\", \"3\"]\n",
        "for voice_entry_one in voice_entry_list:\n",
        "    for voice_entry_two in voice_entry_list:\n",
        "        count_list = []\n",
        "        #print(\"voices:\",voice_entry_one,voice_entry_two)\n",
        "        for i in range(len(dict_pred[voice_entry_one])):\n",
        "            if dict_pred[voice_entry_one][i][0] == truth_dic[voice_entry_two]:      #dict_truth[voice_entry_two][i][0]:\n",
        "                count_list.append(1)\n",
        "            else:\n",
        "                count_list.append(0)\n",
        "        count_dict[voice_entry_one].append(count_list)\n",
        "\n",
        "dictionary_sum={}\n",
        "for i in voice_entry_list:\n",
        "    v0_match,v1_match,v2_match,v3_match = count_dict[i]\n",
        "    sum_v0 = np.sum(v0_match)\n",
        "    sum_v1 = np.sum(v1_match)\n",
        "    sum_v2 = np.sum(v2_match)\n",
        "    sum_v3 = np.sum(v3_match)\n",
        "    dictionary_sum[\"v0\"] = sum_v0\n",
        "    dictionary_sum[\"v1\"] = sum_v1\n",
        "    dictionary_sum[\"v2\"] = sum_v2\n",
        "    dictionary_sum[\"v3\"] = sum_v3\n",
        "\n",
        "    val_list = list(dictionary_sum.values())\n",
        "    \n",
        "    print(\"voice{} matches with\".format(i))\n",
        "    print(\"dict\",dictionary_sum)\n",
        "\n",
        "    max_sum = max(sum_v0,sum_v1,sum_v2,sum_v3)\n",
        "\n",
        "\n",
        "    print(\"max_sum\", val_list.index(max_sum) )\n",
        "\n",
        "    print(\"accuracy voice{}:\".format(i), max_sum/(sum_v0+sum_v1+sum_v2+sum_v3) )\n",
        "    print(\"________________\")\n",
        "    print(\" \")"
      ],
      "metadata": {
        "id": "BoQcV_i038DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR MONOPHONIC F1\n",
        "\n",
        "# start with GT\n",
        "# look at first note in pred-> save note label\n",
        "# look at second note in pred-> if same note as before : SUCESS if it is not: FAIL\n",
        " # DO This for all 4 voices\n",
        " ## in GT there is always the same voice following -> would always be an array of 1\n",
        "\n",
        "## POLYPHONIC \n",
        "\n",
        "# prbl after 1 note there can be multiple diff voices .. chords\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-bR7gcej90qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "you have the ground truth on the different parts that you get when you import your score. Each part correspond to a voice. So if your note array contains all notes of all voices, you have for each note in your note array a number that is the ground truth voice (that you take from the part) and a number that is the predicted voice (that you take from the maximum vote)."
      ],
      "metadata": {
        "id": "Z5q305YzvjMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "start time, duration , pitch to separate \n",
        "\n",
        "use the onset_beat and duration_beat\n",
        "\n",
        "multiply them according to the values set when producing the pianorolls \n",
        "\n",
        "-> get the position in the pianoroll\n",
        "\n",
        "time_div = 12\n",
        "\n"
      ],
      "metadata": {
        "id": "EmvxtyaVKG27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "A94mchm4LV6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"val_accuracy_v0\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v1\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v2\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v3\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Accuracy0','Accuracy1','Accuracy2','Accuracy3'])\n",
        "plt.title('Accuracy vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1TgJDHaxAgYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"val_accuracy\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend('Accuracy')\n",
        "plt.title('Accuracy vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OxMs8GEfMvPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"train_loss\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Loss'])\n",
        "plt.title('Loss vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqMcJT5aFL01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old training loop - matrix and non matrix format"
      ],
      "metadata": {
        "id": "4olpdwzyG8dQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def training_loop(model,optimizer, train_dataloader, monophonic, epochs=50, val_dataloader=None, device=None, scheduler=None):\n",
        "    if device is None:\n",
        "        device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "        print(f\"Training on device: {device}\")\n",
        "\n",
        "    print(\"monophonic set to:\",monophonic)\n",
        "    model = model.to(device)\n",
        "    history = defaultdict(list)\n",
        "\n",
        "    for i_epoch in range(1, epochs + 1):\n",
        "        loss_sum = 0\n",
        "        #accuracy_v0_sum = 0\n",
        "        #accuracy_v1_sum = 0\n",
        "        #accuracy_v2_sum = 0\n",
        "        #accuracy_v3_sum = 0\n",
        "\n",
        "        accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "        val_accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "\n",
        "        accuracy_v_all_sum = 0\n",
        "        model.train()\n",
        "        accuracy_sum = 0\n",
        "        \n",
        "\n",
        "        for idx, (voices, lens, nbr_voices) in enumerate(train_dataloader):  \n",
        "            \n",
        "            voices = voices.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            loss = model.forward(voices, lens, nbr_voices)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()    \n",
        "\n",
        "            if monophonic == False:\n",
        "                with torch.no_grad():\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                    mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "\n",
        "                    \n",
        "                    single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "                    \"\"\"\n",
        "                    if nbr_voices == 4: \n",
        "                        v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2), torch.tensor(pred_v3)], dim=2)\n",
        "                    if nbr_voices ==3:\n",
        "                        v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2)], dim=2)\n",
        "                    v_pred_argm = v_pred_comb.argmax(dim=2)\n",
        "                    mask_pred = (v_pred_comb.sum(axis=2) == 0).numpy()\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                    print(\"v_pred_flat:\", v_pred_flat.shape)\n",
        "                    \"\"\"\n",
        "                    \"\"\"\n",
        "                    if nbr_voices == 4:                   \n",
        "                        v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu(), np.squeeze(voices[:,:,:,3]).cpu()], dim=2)\n",
        "                    if nbr_voices ==3:\n",
        "                        v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu()], dim=2)\n",
        "                    v_ori_argm = v_ori_comb.argmax(dim=2)\n",
        "                    mask_ori = (v_ori_comb.sum(axis=2) == 0).numpy()\n",
        "                    print(\"old mask\", mask_ori.shape)\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    print(\"v_ori_flat\", v_ori_flat.shape)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)   \n",
        "                    print(\"acc\",acc)                    \n",
        "                    accuracy_sum += acc \n",
        "                    \"\"\"\n",
        "\n",
        "\n",
        "            if monophonic == True:\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                    prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "\n",
        "                    truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "\n",
        "                    acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "\n",
        "                    for i in range(len(prediction[0,:])):\n",
        "                      acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                      accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "                    \n",
        "                    \"\"\"\n",
        "                    pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "\n",
        "                    acc_v0 = accuracy_score(torch.tensor(pred_v0), np.squeeze(voices[:,:,:,0]).argmax(dim=1).cpu())\n",
        "                    acc_v1 = accuracy_score(torch.tensor(pred_v1), np.squeeze(voices[:,:,:,1]).argmax(dim=1).cpu())\n",
        "                    acc_v2 = accuracy_score(torch.tensor(pred_v2), np.squeeze(voices[:,:,:,2]).argmax(dim=1).cpu())\n",
        "                    if nbr_voices == 4:\n",
        "                        acc_v3 = accuracy_score(torch.tensor(pred_v3), np.squeeze(voices[:,:,:,3]).argmax(dim=1).cpu())\n",
        "                    \n",
        "                    # normalize according to the number of sequences in the batch (atm len(lens)==1)\n",
        "                    accuracy_v0_sum += acc_v0 / len(lens)\n",
        "                    accuracy_v1_sum += acc_v1 / len(lens)\n",
        "                    accuracy_v2_sum += acc_v2 / len(lens)\n",
        "                    if nbr_voices == 4:\n",
        "                        accuracy_v3_sum += acc_v3 / len(lens)\n",
        "                    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        train_loss = loss_sum / len(train_dataloader)\n",
        "\n",
        "        # normalize according to the number of batches\n",
        "        if monophonic == True:\n",
        "\n",
        "            train_acc_list = np.array(accuracy_sum_list) / len(train_dataloader)\n",
        "            train_acc_list[3] = accuracy_sum_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "            train_acc_list[4] = accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_acc\"].append(train_acc_list)\n",
        "            print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}, Train Accuracy_4 : {}\".format(train_loss, train_acc_list[0], train_acc_list[1], train_acc_list[2], train_acc_list[3],train_acc_list[4])) \n",
        "\n",
        "\n",
        "            \"\"\"\n",
        "            train_accuracy_v0 = accuracy_v0_sum / len(train_dataloader)\n",
        "            train_accuracy_v1 = accuracy_v1_sum / len(train_dataloader)\n",
        "            train_accuracy_v2 = accuracy_v2_sum / len(train_dataloader)\n",
        "            train_accuracy_v3 = accuracy_v3_sum / 18   ## bc only 18 pieces with len 3\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy_v0\"].append(train_accuracy_v0)\n",
        "            history[\"train_accuracy_v1\"].append(train_accuracy_v1)\n",
        "            history[\"train_accuracy_v2\"].append(train_accuracy_v2)\n",
        "            #if nbr_voices == 4:\n",
        "            history[\"train_accuracy_v3\"].append(train_accuracy_v3)\n",
        "            print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}\".format(train_loss, train_accuracy_v0, train_accuracy_v1, train_accuracy_v2, train_accuracy_v3)) \n",
        "            #else:\n",
        "            #    print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}\".format(train_loss, train_accuracy_v0, train_accuracy_v1, train_accuracy_v2)) \n",
        "            \"\"\"\n",
        "\n",
        "        if monophonic == False:\n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "\n",
        "        if monophonic == True:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_v0_sum = 0\n",
        "                accuracy_v1_sum = 0\n",
        "                accuracy_v2_sum = 0\n",
        "                accuracy_v3_sum = 0\n",
        "\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for voices, lens, nbr_voices in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "\n",
        "                        truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "\n",
        "                        acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "\n",
        "                        for i in range(len(prediction[0,:])):\n",
        "                          acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                          val_accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "\n",
        "                        #print(\"val_accuracy_sum_list[3]\",val_accuracy_sum_list[3])\n",
        "                    #val_acc_list = np.array(val_accuracy_sum_list) / len(train_dataloader)\n",
        "                    #val_acc_list[3] = val_acc_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "                    #val_acc_list[4] = val_acc_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "\n",
        "\n",
        "                #history[\"val_acc_new\"].append(val_acc_list)\n",
        "                #print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "\n",
        "                        # Predict the model's output on a batch\n",
        "                        pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "                            \n",
        "                        # compute the accuracy \n",
        "                        acc_v0 = accuracy_score(torch.tensor(pred_v0), np.squeeze(voices[:,:,:,0]).argmax(dim=1).cpu())\n",
        "                        acc_v1 = accuracy_score(torch.tensor(pred_v1), np.squeeze(voices[:,:,:,1]).argmax(dim=1).cpu())\n",
        "                        acc_v2 = accuracy_score(torch.tensor(pred_v2), np.squeeze(voices[:,:,:,2]).argmax(dim=1).cpu())\n",
        "                        if nbr_voices == 4:\n",
        "                            acc_v3 = accuracy_score(torch.tensor(pred_v3), np.squeeze(voices[:,:,:,3]).argmax(dim=1).cpu())\n",
        "                            \n",
        "                            \n",
        "                        # normalize according to the number of sequences in the batch (atm len(lens)==1)\n",
        "                        accuracy_v0_sum += acc_v0 / len(lens)\n",
        "                        accuracy_v1_sum += acc_v1 / len(lens)\n",
        "                        accuracy_v2_sum += acc_v2 / len(lens)\n",
        "                        if nbr_voices == 4:\n",
        "                            accuracy_v3_sum += acc_v3 / len(lens)\n",
        "\n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy_v0 = accuracy_v0_sum / len(val_dataloader)\n",
        "                    val_accuracy_v1 = accuracy_v1_sum / len(val_dataloader)\n",
        "                    val_accuracy_v2 = accuracy_v2_sum / len(val_dataloader)\n",
        "                    val_accuracy_v3 = accuracy_v3_sum / 18  ##len(val_dataloader). - bc 18 pieces only with voice 3\n",
        "\n",
        "\n",
        "                    val_acc_list = np.array(val_accuracy_sum_list) / len(val_dataloader)\n",
        "                    val_acc_list[3] = val_accuracy_sum_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "                    val_acc_list[4] = val_accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "                    \n",
        "\n",
        "\n",
        "                history[\"val_accuracy_v0\"].append(val_accuracy_v0)\n",
        "                history[\"val_accuracy_v1\"].append(val_accuracy_v1)\n",
        "                history[\"val_accuracy_v2\"].append(val_accuracy_v2)\n",
        "                #if nbr_voices == 4:\n",
        "                history[\"val_accuracy_v3\"].append(val_accuracy_v3)\n",
        "                print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}\".format(val_accuracy_v0, val_accuracy_v1, val_accuracy_v2, val_accuracy_v3))\n",
        "                #else:\n",
        "                #    print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}\".format(val_accuracy_v0, val_accuracy_v1, val_accuracy_v2))\n",
        "\n",
        "\n",
        "                history[\"val_acc_new\"].append(val_acc_list)\n",
        "                print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "        if monophonic == False:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_sum = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    for voices, lens, nbr_voices in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "                        \n",
        "                        # Predict the model's output on a batch\n",
        "\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                        v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                        mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                        \n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "\n",
        "                        \"\"\"\n",
        "                        pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "                        if nbr_voices == 4: \n",
        "                            v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2), torch.tensor(pred_v3)], dim=2)\n",
        "                        if nbr_voices ==3:\n",
        "                            v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2)], dim=2)\n",
        "                        v_pred_argm = v_pred_comb.argmax(dim=2)\n",
        "                        mask_pred = (v_pred_comb.sum(axis=2) == 0).numpy()\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)                      \n",
        "                        if nbr_voices == 4:                   \n",
        "                            v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu(), np.squeeze(voices[:,:,:,3]).cpu()], dim=2)\n",
        "                        if nbr_voices ==3:\n",
        "                            v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu()], dim=2)\n",
        "                        v_ori_argm = v_ori_comb.argmax(dim=2)\n",
        "                        mask_ori = (v_ori_comb.sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)\n",
        "                        accuracy_sum += acc \n",
        "                        \"\"\"\n",
        "                        \n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "\n",
        "                history[\"val_accuracy\"].append(val_accuracy)  \n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # save the model\n",
        "        torch.save(model, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "nfDV8MKGHE3J"
      }
    }
  ]
}