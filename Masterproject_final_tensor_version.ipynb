{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Masterproject.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aim56009/AI-MA_project/blob/main/Masterproject_final_tensor_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ],
      "metadata": {
        "id": "SsyC2uB0KfaT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDUwCmeIW8i1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199419e8-2a19-4db7-bd03-b0a99c013a80"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import torchvision.transforms.functional as TF \n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import click\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "#!pip install partitura\n",
        "! pip install git+https://github.com/CPJKU/partitura.git@develop\n",
        "import partitura\n",
        "import statistics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/CPJKU/partitura.git@develop\n",
            "  Cloning https://github.com/CPJKU/partitura.git (to revision develop) to /tmp/pip-req-build-59gf9g9_\n",
            "  Running command git clone -q https://github.com/CPJKU/partitura.git /tmp/pip-req-build-59gf9g9_\n",
            "  Running command git checkout -b develop --track origin/develop\n",
            "  Switched to a new branch 'develop'\n",
            "  Branch 'develop' set up to track remote branch 'develop' from 'origin'.\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from partitura==0.4.0) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from partitura==0.4.0) (1.4.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from partitura==0.4.0) (4.2.6)\n",
            "Requirement already satisfied: lark-parser in /usr/local/lib/python3.7/dist-packages (from partitura==0.4.0) (0.12.0)\n",
            "Requirement already satisfied: xmlschema in /usr/local/lib/python3.7/dist-packages (from partitura==0.4.0) (1.11.2)\n",
            "Requirement already satisfied: mido in /usr/local/lib/python3.7/dist-packages (from partitura==0.4.0) (1.2.10)\n",
            "Requirement already satisfied: elementpath<3.0.0,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from xmlschema->partitura==0.4.0) (2.5.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsFs8dyqXBx2"
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/aim56009/AI-MA_project.git"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path_to_musicxml = \"AI-MA_project/chorales_converted/chor001.xml\"\n",
        "#part = partitura.load_musicxml(path_to_musicxml)\n",
        "#partitura.save_score_midi(part,\"chor001_5.mid\",5)"
      ],
      "metadata": {
        "id": "j6dq9ptQGmHB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYpz1MOIOgtk"
      },
      "source": [
        "# Dataloader - Set the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygWXNSrCbRQi"
      },
      "source": [
        "fugues = False\n",
        "\n",
        "if fugues == True:\n",
        "    PATH_TO_DATA = \"AI-MA_project/bach_pr_fugues\"\n",
        "else:\n",
        "    PATH_TO_DATA = \"AI-MA_project/pianoroll_88\"\n",
        "\n",
        "batch_size = 1 \n",
        "workers = 0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicDataset_new(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        self.name_list = [\"1f01\",\"1f02\",\"1f03\",\"1f04\",\"1f05\",\"1f06\",\"1f07\",\"1f08\",\"1f09\",\"1f10\",\"1f11\",\"1f12\",\"1f13\",\"1f14\",\"1f15\",\"1f16\",\"1f17\",\"1f18\",\"1f19\",\"1f20\",\"1f21\",\"1f22\",\"1f23\",\"1f24\",\"2f01\",\"2f02\",\"2f03\",\"2f04\",\"2f05\",\"2f06\",\"2f07\",\"2f08\",\"2f09\",\"2f10\",\"2f11\",\"2f12\",\"2f13\",\"2f14\",\"2f15\",\"2f16\",\"2f17\",\"2f18\",\"2f19\",\"2f20\",\"2f21\",\"2f22\",\"2f23\",\"2f24\"]\n",
        "        self.name_list_voice_3 =  ['1f01', '1f05', '1f12', '1f14', '1f16', '1f17', '1f18', '1f23', '1f24', '2f02', '2f05', '2f07', '2f08', '2f09', '2f16', '2f17',  '2f22', '2f23']\n",
        "        labels = [\"voice_0\", \"voice_1\", \"voice_2\", \"voice_3\", \"voice_all\"]\n",
        "        self.labels = labels\n",
        "        self.pr_dict = {}\n",
        "        len_list = []\n",
        "        nbr_voices_list = []\n",
        "        file_names_list = []\n",
        "\n",
        "        for iLabel in range(len(labels)):\n",
        "            \n",
        "            if iLabel == 4:   \n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\")))   \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: ### normal sollte es egal sein wenn voice_4 bei manchen nicht existiert - wenn nicht condition einfÃ¼hren damit das funktioniert\n",
        "                        loaded_obj = pickle.load(f)  \n",
        "                        voice_files.append(loaded_obj) \n",
        "                        len_list.append(len(loaded_obj.T))\n",
        "\n",
        "                        file_names_list.append(name[-8:-4])\n",
        "\n",
        "                    if \"AI-MA_project/bach_pr_fugues/voice_3/voice_3_\" + name[49:53] + \".pkl\" in sorted(glob.glob(os.path.join(PATH_TO_DATA, \"voice_3\", \"*.pkl\"))):\n",
        "                        nbr_voices_list.append(4)\n",
        "                    else:\n",
        "                        nbr_voices_list.append(3)\n",
        "                        \n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                self.pr_dict[\"length\"] = len_list\n",
        "                self.pr_dict[\"nbr_voices\"] = nbr_voices_list\n",
        "                self.pr_dict[\"name\"] = file_names_list\n",
        "                #print(self.pr_dict[\"name\"])\n",
        "\n",
        "\n",
        "            if iLabel == 3:  \n",
        "                voice_files = []\n",
        "                file_names_3 = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                file_names_2 = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[2], \"*.pkl\")))   \n",
        "                \n",
        "                ###### loop over all filnames in voices_2 and if an element there is not present in voices_3: append \"missing\" to the voice_files of label=3 => important bc. self.pr_dict[voice_3] has then len 42 and otherwise it would only have len 18  .. these \"missing\" el are not considered later in the dataloader (if len=3 is a diff case of get_idx)\n",
        "                for name in file_names_2:\n",
        "                    if name[45:49] in self.name_list_voice_3:\n",
        "                      correct_name_3 = \"AI-MA_project/bach_pr_fugues/voice_3/voice_3_\" + name[45:49] + \".pkl\"\n",
        "                      with open(correct_name_3 ,'rb') as f:  \n",
        "                            loaded_obj = pickle.load(f)  \n",
        "                            voice_files.append(loaded_obj)\n",
        "                    else:\n",
        "                      voice_files.append(\"missing\")\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                \n",
        "\n",
        "                \n",
        "            else:\n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: \n",
        "                          loaded_obj = pickle.load(f)     \n",
        "                          voice_files.append(loaded_obj)\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pr_dict[self.labels[0]])\n",
        "\n",
        "    def __getitem__(self, idx):      \n",
        "        out_list = []\n",
        "        \n",
        "        if self.pr_dict[\"nbr_voices\"][idx] == 4:\n",
        "            for key, value in self.pr_dict.items():\n",
        "              out_list.append(self.pr_dict[key][idx])\n",
        "                              \n",
        "            v0 = torch.tensor(out_list[0].T)\n",
        "            v1 = torch.tensor(out_list[1].T)\n",
        "            v2 = torch.tensor(out_list[2].T)\n",
        "            v3 = torch.tensor(out_list[3].T)\n",
        "            v_all = torch.tensor(out_list[4].T) \n",
        "            length = self.pr_dict[\"length\"][idx]\n",
        "            nbr_voices = self.pr_dict[\"nbr_voices\"][idx]\n",
        "            file_name = self.pr_dict[\"name\"][idx]\n",
        "\n",
        "            voices = torch.stack([v0, v1, v2, v3, v_all], dim=2)\n",
        "            \n",
        "            return (voices, length, nbr_voices, file_name)\n",
        "        \n",
        "        if self.pr_dict[\"nbr_voices\"][idx] == 3:\n",
        "\n",
        "            for key, value in self.pr_dict.items():\n",
        "                if key != \"voice_3\":\n",
        "                  out_list.append(self.pr_dict[key][idx]) \n",
        "            \n",
        "            v0 = torch.tensor(out_list[0].T)\n",
        "            v1 = torch.tensor(out_list[1].T)\n",
        "            v2 = torch.tensor(out_list[2].T)\n",
        "            v3 = torch.zeros(v2.shape)\n",
        "            v_all = torch.tensor(out_list[3].T) \n",
        "            length = self.pr_dict[\"length\"][idx]\n",
        "            nbr_voices = self.pr_dict[\"nbr_voices\"][idx]\n",
        "            file_name = self.pr_dict[\"name\"][idx]\n",
        "            \n",
        "            voices = torch.stack([v0, v1, v2, v3, v_all], dim=2)\n",
        "\n",
        "            \n",
        "            return (voices, length, nbr_voices, file_name)\n",
        "        "
      ],
      "metadata": {
        "id": "3FxK6qr1FqIl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicDataset_chor(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        labels = [\"voice_0\", \"voice_1\", \"voice_2\", \"voice_3\", \"voice_all\"]\n",
        "        self.labels = labels\n",
        "        self.pr_dict = {}\n",
        "        len_list = []\n",
        "        nbr_voices_list = []\n",
        "        file_names_list = []\n",
        "\n",
        "        for iLabel in range(len(labels)):\n",
        "            \n",
        "            if iLabel == 4:   \n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\")))   \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: ### normal sollte es egal sein wenn voice_4 bei manchen nicht existiert - wenn nicht condition einfÃ¼hren damit das funktioniert\n",
        "                        loaded_obj = pickle.load(f)  \n",
        "                        voice_files.append(loaded_obj) \n",
        "                        len_list.append(len(loaded_obj.T))\n",
        "                        file_names_list.append(name[-7:-4])      # e.g. name = AI-MA_project/pianoroll_88/voice_all/voice_all_001.pkl\n",
        "\n",
        "                        \n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                self.pr_dict[\"length\"] = len_list\n",
        "                self.pr_dict[\"name\"] = file_names_list\n",
        "                #print(self.pr_dict[\"name\"])\n",
        "              \n",
        "\n",
        "            else:\n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: \n",
        "                        loaded_obj = pickle.load(f)     \n",
        "                        voice_files.append(loaded_obj)\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pr_dict[self.labels[0]])\n",
        "\n",
        "    def __getitem__(self, idx):      \n",
        "        out_list = []\n",
        "        \n",
        "        for key, value in self.pr_dict.items():\n",
        "            out_list.append(self.pr_dict[key][idx])\n",
        "                            \n",
        "        v0 = torch.tensor(out_list[0].T)\n",
        "        v1 = torch.tensor(out_list[1].T)\n",
        "        v2 = torch.tensor(out_list[2].T)\n",
        "        v3 = torch.tensor(out_list[3].T)\n",
        "        v_all = torch.tensor(out_list[4].T) \n",
        "        length = self.pr_dict[\"length\"][idx]\n",
        "        file_name = self.pr_dict[\"name\"][idx]\n",
        "\n",
        "        voices = torch.stack([v0, v1, v2, v3, v_all], dim=2)\n",
        "        \n",
        "        return (voices, length, 4, file_name)     # 4 bc nbr voices is always 4"
      ],
      "metadata": {
        "id": "3uQnok3VGngZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oTPIsBwPAJg"
      },
      "source": [
        "if fugues == True:\n",
        "    dataset = MusicDataset_new(PATH_TO_DATA)\n",
        "else:\n",
        "    dataset = MusicDataset_chor(PATH_TO_DATA)\n",
        "\n",
        "loader = torch.utils.data.DataLoader(dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for i, sample_batched in enumerate(loader):\n",
        "    all_voices, length, nbr_voices = sample_batched\n",
        "    if nbr_voices ==3:\n",
        "      print(i,nbr_voices,all_voices.shape)\n",
        "    else:\n",
        "      print(i,nbr_voices)\n",
        "\"\"\"\n",
        "for i, sample_batched in enumerate(loader):\n",
        "    if i == 1:\n",
        "        all_voices, length, nbr_voices, file_name = sample_batched\n",
        "        print(file_name[0],nbr_voices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXsRYzQSUuQU",
        "outputId": "7c59a99f-b4e6-481b-d043-be159718d8bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "002 tensor([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pianoroll_0 = all_voices.squeeze()[:,:,0].numpy()\n",
        "pianoroll_1 = all_voices.squeeze()[:,:,1].numpy()\n",
        "pianoroll_2 = all_voices.squeeze()[:,:,2].numpy()\n",
        "pianoroll_3 = all_voices.squeeze()[:,:,3].numpy()\n",
        "pianoroll_all = all_voices.squeeze()[:,:,-1].numpy()\n",
        "\n",
        "time_unit = \"beat\"\n",
        "time_div = 12\n",
        "piano_range = True"
      ],
      "metadata": {
        "id": "fR2HaA_BqeHw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, figsize=(20, 10))\n",
        "ax.imshow(pianoroll_all, origin=\"lower\", cmap='gray', interpolation='nearest', aspect='auto')\n",
        "ax.set_xlabel(f'Time ({time_unit}s/{time_div})')\n",
        "ax.set_ylabel('Piano key' if piano_range else 'MIDI pitch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "sRoyBJJVqX_u",
        "outputId": "3121f169-ab85-4150-d60b-b5bdda2e9d39"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for i, sample_batched in enumerate(loader):\n",
        "    all_voices, length, nbr_voices = sample_batched\n",
        "    if nbr_voices ==3:\n",
        "      print(i,nbr_voices,all_voices.shape)\n",
        "    else:\n",
        "      print(i,nbr_voices)\n",
        "\n",
        "for i, sample_batched in enumerate(loader):\n",
        "  if i ==10:\n",
        "    all_voices, length, nbr_voices, _ = sample_batched\n",
        "    all_voices_pr = all_voices[0,:,:,-1].numpy()\n",
        "    \n",
        "    note_array = partitura.utils.pianoroll_to_notearray(all_voices[0,:,:,-1].numpy(), time_div=12, time_unit='beat')\n",
        "    print(note_array.shape)\n",
        "    print(note_array[:10])\n",
        "    print(note_array.dtype.names)\n",
        "\n",
        "    #print(i,nbr_voices,all_voices.shape)\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "b4QCaMEi3nw7",
        "outputId": "c080ae3d-9ff7-43be-9636-14e5dd28498f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor i, sample_batched in enumerate(loader):\\n    all_voices, length, nbr_voices = sample_batched\\n    if nbr_voices ==3:\\n      print(i,nbr_voices,all_voices.shape)\\n    else:\\n      print(i,nbr_voices)\\n\\nfor i, sample_batched in enumerate(loader):\\n  if i ==10:\\n    all_voices, length, nbr_voices, _ = sample_batched\\n    all_voices_pr = all_voices[0,:,:,-1].numpy()\\n    \\n    note_array = partitura.utils.pianoroll_to_notearray(all_voices[0,:,:,-1].numpy(), time_div=12, time_unit='beat')\\n    print(note_array.shape)\\n    print(note_array[:10])\\n    print(note_array.dtype.names)\\n\\n    #print(i,nbr_voices,all_voices.shape)\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Music - Model\n"
      ],
      "metadata": {
        "id": "JNqxeacDwxNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define UNET "
      ],
      "metadata": {
        "id": "QAIfIM69VHI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels=1, classes=1):\n",
        "        super(UNET, self).__init__()\n",
        "        self.layers = [in_channels, 64, 128, 256, 512, 1024]\n",
        "        \n",
        "        self.double_conv_downs = nn.ModuleList([self.__double_conv(layer, layer_n) for layer, layer_n in zip(self.layers[:-1], self.layers[1:])])\n",
        "        \n",
        "        self.up_trans = nn.ModuleList([nn.ConvTranspose2d(layer, layer_n, kernel_size=2, stride=2) for layer, layer_n in zip(self.layers[::-1][:-2], self.layers[::-1][1:-1])])\n",
        "            \n",
        "        self.double_conv_ups = nn.ModuleList([self.__double_conv(layer, layer//2) for layer in self.layers[::-1][:-2]])\n",
        "        \n",
        "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.final_conv = nn.Conv2d(64, classes, kernel_size=1)\n",
        "\n",
        "        \n",
        "    def __double_conv(self, in_channels, out_channels):\n",
        "        conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        return conv\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # down layers\n",
        "        concat_layers = []\n",
        "        \n",
        "        for down in self.double_conv_downs:\n",
        "            x = down(x)\n",
        "            if down != self.double_conv_downs[-1]:\n",
        "                concat_layers.append(x)\n",
        "                x = self.max_pool_2x2(x)\n",
        "        \n",
        "        concat_layers = concat_layers[::-1]\n",
        "        \n",
        "        # up layers\n",
        "        for up_trans, double_conv_up, concat_layer  in zip(self.up_trans, self.double_conv_ups, concat_layers):\n",
        "            x = up_trans(x)\n",
        "            if x.shape != concat_layer.shape:\n",
        "                x = TF.resize(x, concat_layer.shape[2:])\n",
        "            \n",
        "            concatenated = torch.cat((concat_layer, x), dim=1)\n",
        "            x = double_conv_up(concatenated)\n",
        "            \n",
        "        x = self.final_conv(x)\n",
        "        \n",
        "        return x "
      ],
      "metadata": {
        "id": "XMdlm0_Vyyhc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_0 = []\n",
        "loss_1 = []\n",
        "loss_2 = []\n",
        "loss_3 = []\n",
        "class MusicNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, network_type,output_dim=88, hidden_dim=300, rnn_depth=1, cell_type=\"GRU\"):                 \n",
        "        super(MusicNetwork, self).__init__()\n",
        "\n",
        "        self.network_type = network_type\n",
        "        self.n_out = output_dim\n",
        "        input_dim = output_dim \n",
        "        rnn_cell = nn.GRU\n",
        "        self.rnn = rnn_cell(input_size=input_dim, hidden_size=hidden_dim, num_layers=rnn_depth, batch_first=True)\n",
        "        self.cnn = UNET(in_channels=1, classes=4)\n",
        "        self.top_layer_voice_0 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_1 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_2 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_3 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.loss = nn.CrossEntropyLoss(reduction=\"mean\")                       # use weight parameters maybe take 1/88       \n",
        "\n",
        "    \n",
        "\n",
        "    def compute_outputs(self, sentences, sentences_len):\n",
        "        if self.network_type == \"RNN\":\n",
        "          rnn_out ,_= self.rnn(sentences)     \n",
        "          out_0 = self.top_layer_voice_0(rnn_out)\n",
        "          out_1 = self.top_layer_voice_1(rnn_out)\n",
        "          out_2 = self.top_layer_voice_2(rnn_out)\n",
        "          out_3 = self.top_layer_voice_3(rnn_out)\n",
        "\n",
        "          return torch.stack([out_0, out_1, out_2, out_3], dim=1)\n",
        "\n",
        "        else: \n",
        "          sentences = sentences[:,None]\n",
        "          out = self.cnn(sentences)\n",
        "          return out                      ### squeeze output here before returning                                       \n",
        "        \n",
        "\n",
        "    def forward(self, voices, sentences_len, nbr_voices):            \n",
        "\n",
        "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
        "        scores_comb = self.compute_outputs(voices[:,:,:,-1], sentences_len)\n",
        "\n",
        "        # Flatten the outputs and the labels, to compute the loss.\n",
        "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
        "        score_0  = scores_comb[:,0,:,:].view(-1, self.n_out)\n",
        "        score_1  = scores_comb[:,1,:,:].view(-1, self.n_out)\n",
        "        score_2  = scores_comb[:,2,:,:].view(-1, self.n_out)\n",
        "        score_3  = scores_comb[:,3,:,:].view(-1, self.n_out)\n",
        "\n",
        "\n",
        "        v0 = voices[:,:,:,0].squeeze()\n",
        "        v1 = voices[:,:,:,1].squeeze()\n",
        "        v2 = voices[:,:,:,2].squeeze()\n",
        "        v3 = voices[:,:,:,3].squeeze()    ### v3 is automatically tensor containing only 0 bc dataloader does this for pieces with 3 voices\n",
        "        \n",
        "\n",
        "        \"\"\"\n",
        "        if nbr_voices==4:\n",
        "            v3 = voices[:,:,:,3].squeeze()\n",
        "        else:\n",
        "            v3 = torch.zeros(v0.shape,  device=\"cuda\")\n",
        "        \"\"\"\n",
        "\n",
        "        loss = self.loss(score_0, v0) +  self.loss(score_1, v1) +  self.loss(score_2, v2) +  self.loss(score_3, v3) #*1.5\n",
        "            \n",
        "        loss_0.append(self.loss(score_0, v0).cpu().detach().numpy())\n",
        "        loss_1.append(self.loss(score_1, v1).cpu().detach().numpy())\n",
        "        loss_2.append(self.loss(score_2, v2).cpu().detach().numpy())\n",
        "        loss_3.append(self.loss(score_3, v3).cpu().detach().numpy())\n",
        "        print(\"self.loss(score_0, v0)\",self.loss(score_0, v0).cpu().detach().numpy())\n",
        "        print(\"self.loss(score_1, v1)\",self.loss(score_1, v1).cpu().detach().numpy())\n",
        "        print(\"self.loss(score_2, v2)\",self.loss(score_2, v2).cpu().detach().numpy())\n",
        "        print(\"self.loss(score_3, v3)\",self.loss(score_3, v3).cpu().detach().numpy())\n",
        "\n",
        "        print(\"loss\",loss) \n",
        "\n",
        "\n",
        "        return loss   #change also to matrix version\n",
        "        \n",
        "\n",
        "\n",
        "    def predict(self, sentences, sentences_len,monophonic=True):\n",
        "\n",
        "        # Compute the outputs from the linear units.\n",
        "\n",
        "        scores_comb = self.compute_outputs(sentences, sentences_len)\n",
        "\n",
        "        if monophonic==False:\n",
        "            sum = scores_comb * sentences[:,None,:,:]\n",
        "            return np.squeeze(sum.cpu().numpy())\n",
        "            \n",
        "\n",
        "        else:\n",
        "            sum_tensor = scores_comb * sentences[:,None,:,:]\n",
        "            prediction = np.squeeze(sum_tensor.cpu().numpy())                # prediction is of shape 4,T,88 and contains a probability for the result to belong to one of the 4 voices -> taking argmax: gives the voice with the highes probability\n",
        "            v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "            \n",
        "            mask_pred = np.squeeze(sentences)== 0\n",
        "            v_pred_argm[mask_pred] = -1\n",
        "\n",
        "            return v_pred_argm \n",
        "                       "
      ],
      "metadata": {
        "id": "CviiPTPOPW04"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= \"CNN\"\n",
        "lr = 0.0001  \n",
        "monophonic = True\n",
        "his = start_experiment(10, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "79cPe11WL6J0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f56a8e63-dbe9-49f9-9283-9d6401cc09d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= \"CNN\"\\nlr = 0.0001  \\nmonophonic = True\\nhis = start_experiment(10, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07I2QbRDbUlA"
      },
      "source": [
        "# Define Training Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHESuQEQbVRB"
      },
      "source": [
        "def train(epochs, lr, hidden_dim, momentum, rnn_depth, device, rnn_cell, weight_decay,network_type, train_dataloader, val_dataloader=None):\n",
        "    \n",
        "    output_dim = 88\n",
        "    model = MusicNetwork(network_type, output_dim, hidden_dim, rnn_depth, cell_type)              \n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = lr_scheduler.MultiStepLR(optimizer, [epochs // 2], gamma=0.1, verbose=True)\n",
        "\n",
        "    history = training_loop(model, optimizer, train_dataloader,monophonic, epochs=epochs, val_dataloader=val_dataloader, device=device, scheduler=scheduler)\n",
        "\n",
        "    return model, history"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG_ONds0bkt-"
      },
      "source": [
        "def training_loop(model,optimizer, train_dataloader, monophonic, epochs=50, val_dataloader=None, device=None, scheduler=None):\n",
        "    if device is None:\n",
        "        device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "        print(f\"Training on device: {device}\")\n",
        "\n",
        "    print(\"monophonic set to:\",monophonic)\n",
        "    model = model.to(device)\n",
        "    history = defaultdict(list)\n",
        "\n",
        "    for i_epoch in range(1, epochs + 1):\n",
        "        loss_sum = 0\n",
        "\n",
        "        accuracy_sum_list = [0 for i in range(5)]                                   ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "        val_accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "\n",
        "        accuracy_v_all_sum = 0\n",
        "        model.train()\n",
        "        accuracy_sum = 0\n",
        "                \n",
        "        for idx, (voices, lens, nbr_voices, _) in enumerate(train_dataloader):  \n",
        "            \n",
        "            voices = voices.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            loss = model.forward(voices, lens, nbr_voices)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()    \n",
        "\n",
        "            if monophonic == False:\n",
        "                with torch.no_grad():\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                    mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                    \n",
        "                    single_voices = voices[:,:,:,:-1]             \n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "\n",
        "            if monophonic == True:\n",
        "                with torch.no_grad():\n",
        "                    ### before\n",
        "                    #prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                    #prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "                    #truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "                    #acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "                    #for i in range(len(prediction[0,:])):\n",
        "                    #  acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                    #  accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "\n",
        "                    #prediction = model.predict(voices, lens, monophonic)                    #for voice vise masking\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)         #for mixed voice masking        \n",
        "\n",
        "\n",
        "                    ## ground truth in shape 1280x88 -> mixed voice\n",
        "                    single_voices = voices[:,:,:,:-1]\n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    truth = v_ori_argm       \n",
        "\n",
        "                    # outsource accurcy to further down -> just a placeholder right now\n",
        "                    v_pred_flat = torch.flatten(prediction, start_dim=0, end_dim=-1)\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "\n",
        "\n",
        "        train_loss = loss_sum / len(train_dataloader)\n",
        "\n",
        "        # normalize according to the number of batches\n",
        "        if monophonic == True:\n",
        "\n",
        "            #train_acc_list = np.array(accuracy_sum_list) / len(train_dataloader)\n",
        "            #train_acc_list[3] = accuracy_sum_list[3] / 18                        ## bc only 18 pieces with len 3\n",
        "            #train_acc_list[4] = accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "            #history[\"train_loss\"].append(train_loss)\n",
        "            #history[\"train_acc\"].append(train_acc_list)\n",
        "            #print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}, Train Accuracy_4 : {}\".format(train_loss, train_acc_list[0], train_acc_list[1], train_acc_list[2], train_acc_list[3],train_acc_list[4])) \n",
        "            \n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "        if monophonic == False:\n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "\n",
        "        if monophonic == True:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for voices, lens, nbr_voices, _ in val_dataloader:\n",
        "                        voices = voices.to(device).float()\n",
        "                        ### before\n",
        "                        #prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        #prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "                        #truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "                        #acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "                        #for i in range(len(prediction[0,:])):\n",
        "                        #  acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                        #  val_accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "                    #val_acc_list = np.array(val_accuracy_sum_list) / len(val_dataloader)\n",
        "                    #val_acc_list[3] = val_accuracy_sum_list[3] / 18                         ## bc only 18 pieces with len 3\n",
        "                    #val_acc_list[4] = val_accuracy_sum_list[4] / 2                          ##### CHECK IF 2 or 3 pieces with len 4\n",
        "                #history[\"val_acc\"].append(val_acc_list)\n",
        "                #print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "\n",
        "                        #prediction = model.predict(voices, lens, monophonic)                #for voice vise masking\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)     # for masking with mixed voice\n",
        "\n",
        "\n",
        "\n",
        "                        ## ground truth in shape 1280x88 -> mixed voice\n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        truth = v_ori_argm       \n",
        "\n",
        "                        # outsource accurcy to further down -> just a placeholder right now\n",
        "                        v_pred_flat = torch.flatten(prediction, start_dim=0, end_dim=-1)\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "                    \n",
        "                history[\"val_acc\"].append(val_accuracy)\n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "\n",
        "        if monophonic == False:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_sum = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    for voices, lens, nbr_voices, _ in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "                        \n",
        "                        # Predict the model's output on a batch\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                        v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                        mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                        \n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "                        \n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "\n",
        "                history[\"val_accuracy\"].append(val_accuracy)  \n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "        \n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "    # save the model\n",
        "    #torch.save(model, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "    torch.save({'model_state_dict': model.state_dict()}, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "\n",
        "    return history"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= \"RNN\"\n",
        "monophonic = True\n",
        "his = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ge8pY70uHxF9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "04a1de6c-860c-4057-fb0a-d4cf05528dbe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= \"RNN\"\\nmonophonic = True\\nhis = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= [\"CNN\",\"RNN\"]\n",
        "monophonic_list = [True,False]\n",
        "\n",
        "for net in network_type:\n",
        "    for monophonic in monophonic_list: \n",
        "        print(\"network set to:\",net,\"monophnic:\",monophonic)\n",
        "        start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, net, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2Bs6-iNEBu8o",
        "outputId": "44078d10-f127-4b52-87e7-ef81a3de3da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= [\"CNN\",\"RNN\"]\\nmonophonic_list = [True,False]\\n\\nfor net in network_type:\\n    for monophonic in monophonic_list: \\n        print(\"network set to:\",net,\"monophnic:\",monophonic)\\n        start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, net, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sBoQnA6bo71"
      },
      "source": [
        "def start_experiment( epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell, decay,network_type, learn_all):\n",
        "    \n",
        "    trainer = partial(train,epochs, lr, hidden_dim, momentum, rnn_depth, device, cell, decay, network_type)\n",
        "\n",
        "    if learn_all == True:\n",
        "        print(\"Learning from full dataset\")\n",
        "        if fugues == True:\n",
        "        ### uncomment for fugues ###\n",
        "            train_dataset = MusicDataset_new(PATH_TO_DATA) \n",
        "        ### uncomment for chorals ###\n",
        "        else:\n",
        "            train_dataset = MusicDataset_chor(PATH_TO_DATA) \n",
        "\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "                \n",
        "        _, history = trainer(train_dataloader)\n",
        "\n",
        "    \n",
        "    else:\n",
        "        # Divide train and validation set\n",
        "        ### uncomment for fugues ###\n",
        "        if fugues == True:\n",
        "            dataset = MusicDataset_new(PATH_TO_DATA) \n",
        "        ### uncomment for chorals ###\n",
        "        else:\n",
        "            dataset = MusicDataset_chor(PATH_TO_DATA)\n",
        "        \n",
        "        \n",
        "        train_dataset, validation_dataset = sklearn.model_selection.train_test_split(dataset, test_size=0.15, random_state=10,)\n",
        "\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "        val_dataloader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "\n",
        "        print(\"train_dataloader\",len(train_dataloader),\"val_dataloader\",len(val_dataloader))\n",
        "        _, history = trainer(train_dataloader, val_dataloader)\n",
        "\n",
        "    return history, val_dataloader"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgtn-a7bMTf7"
      },
      "source": [
        "# Hyperparameter choice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNI9b6jKLpOX"
      },
      "source": [
        "model = MusicNetwork\n",
        "epochs = 10\n",
        "lr = 0.00001 # was 0.001\n",
        "momentum = 0.9\n",
        "decay = 1e-4\n",
        "hidden_dim = 300\n",
        "bs = 1\n",
        "rnn_depth = 2 \n",
        "device = None                 #if None:  choses device automatically\n",
        "cell_type = \"GRU\"\n",
        "optimizer = \"Adam\"\n",
        "learn_all = \"False\"           # False -> uses train and valid set\n",
        "network_type= \"CNN\"\n",
        "\n",
        "monophonic = True"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the Experiment"
      ],
      "metadata": {
        "id": "bdetlQP-LoRX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1LTlFJddpwm",
        "outputId": "c421d6a2-7cdb-4899-b8a8-62856d6d8dd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "his, val_dataloader = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "self.loss(score_2, v2) 0.02509583\n",
            "self.loss(score_3, v3) 0.012657613\n",
            "loss tensor(0.1157, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.026296366\n",
            "self.loss(score_1, v1) 0.028849805\n",
            "self.loss(score_2, v2) 0.026749333\n",
            "self.loss(score_3, v3) 0.009535166\n",
            "loss tensor(0.0914, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015017664\n",
            "self.loss(score_1, v1) 0.014163189\n",
            "self.loss(score_2, v2) 0.025819054\n",
            "self.loss(score_3, v3) 0.01349248\n",
            "loss tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.042233545\n",
            "self.loss(score_1, v1) 0.025965255\n",
            "self.loss(score_2, v2) 0.038744543\n",
            "self.loss(score_3, v3) 0.010937158\n",
            "loss tensor(0.1179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0134497015\n",
            "self.loss(score_1, v1) 0.06658437\n",
            "self.loss(score_2, v2) 0.052615985\n",
            "self.loss(score_3, v3) 0.0120484615\n",
            "loss tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015790336\n",
            "self.loss(score_1, v1) 0.011500057\n",
            "self.loss(score_2, v2) 0.008230256\n",
            "self.loss(score_3, v3) 0.010941054\n",
            "loss tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018987687\n",
            "self.loss(score_1, v1) 0.029536638\n",
            "self.loss(score_2, v2) 0.01505252\n",
            "self.loss(score_3, v3) 0.012361108\n",
            "loss tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07127167\n",
            "self.loss(score_1, v1) 0.018600097\n",
            "self.loss(score_2, v2) 0.028729152\n",
            "self.loss(score_3, v3) 0.015887596\n",
            "loss tensor(0.1345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015264076\n",
            "self.loss(score_1, v1) 0.029839117\n",
            "self.loss(score_2, v2) 0.025830187\n",
            "self.loss(score_3, v3) 0.012795559\n",
            "loss tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016784761\n",
            "self.loss(score_1, v1) 0.018164707\n",
            "self.loss(score_2, v2) 0.0075484887\n",
            "self.loss(score_3, v3) 0.0075947824\n",
            "loss tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013609714\n",
            "self.loss(score_1, v1) 0.015904583\n",
            "self.loss(score_2, v2) 0.018352691\n",
            "self.loss(score_3, v3) 0.010915509\n",
            "loss tensor(0.0588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009321542\n",
            "self.loss(score_1, v1) 0.007552138\n",
            "self.loss(score_2, v2) 0.011967168\n",
            "self.loss(score_3, v3) 0.012018855\n",
            "loss tensor(0.0409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0069257356\n",
            "self.loss(score_1, v1) 0.008130984\n",
            "self.loss(score_2, v2) 0.012279122\n",
            "self.loss(score_3, v3) 0.0090667065\n",
            "loss tensor(0.0364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06442758\n",
            "self.loss(score_1, v1) 0.035985876\n",
            "self.loss(score_2, v2) 0.07584794\n",
            "self.loss(score_3, v3) 0.014662151\n",
            "loss tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010870531\n",
            "self.loss(score_1, v1) 0.047639955\n",
            "self.loss(score_2, v2) 0.03270656\n",
            "self.loss(score_3, v3) 0.02279973\n",
            "loss tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013202477\n",
            "self.loss(score_1, v1) 0.007923315\n",
            "self.loss(score_2, v2) 0.0064828894\n",
            "self.loss(score_3, v3) 0.009077238\n",
            "loss tensor(0.0367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0143290395\n",
            "self.loss(score_1, v1) 0.018499257\n",
            "self.loss(score_2, v2) 0.028853215\n",
            "self.loss(score_3, v3) 0.017570466\n",
            "loss tensor(0.0793, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010745255\n",
            "self.loss(score_1, v1) 0.02259212\n",
            "self.loss(score_2, v2) 0.023856454\n",
            "self.loss(score_3, v3) 0.1048085\n",
            "loss tensor(0.1620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007791666\n",
            "self.loss(score_1, v1) 0.012514032\n",
            "self.loss(score_2, v2) 0.020365503\n",
            "self.loss(score_3, v3) 0.012146494\n",
            "loss tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.063789286\n",
            "self.loss(score_1, v1) 0.029109333\n",
            "self.loss(score_2, v2) 0.103296965\n",
            "self.loss(score_3, v3) 0.013445697\n",
            "loss tensor(0.2096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012431946\n",
            "self.loss(score_1, v1) 0.009595365\n",
            "self.loss(score_2, v2) 0.012392375\n",
            "self.loss(score_3, v3) 0.011999746\n",
            "loss tensor(0.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.030480677\n",
            "self.loss(score_1, v1) 0.040713444\n",
            "self.loss(score_2, v2) 0.024855137\n",
            "self.loss(score_3, v3) 0.010324717\n",
            "loss tensor(0.1064, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012456559\n",
            "self.loss(score_1, v1) 0.011514245\n",
            "self.loss(score_2, v2) 0.005713453\n",
            "self.loss(score_3, v3) 0.0059443177\n",
            "loss tensor(0.0356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009965487\n",
            "self.loss(score_1, v1) 0.011454145\n",
            "self.loss(score_2, v2) 0.011960836\n",
            "self.loss(score_3, v3) 0.009953677\n",
            "loss tensor(0.0433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008659172\n",
            "self.loss(score_1, v1) 0.01543743\n",
            "self.loss(score_2, v2) 0.012423388\n",
            "self.loss(score_3, v3) 0.0094916625\n",
            "loss tensor(0.0460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011226062\n",
            "self.loss(score_1, v1) 0.027037242\n",
            "self.loss(score_2, v2) 0.044257615\n",
            "self.loss(score_3, v3) 0.012934141\n",
            "loss tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010937146\n",
            "self.loss(score_1, v1) 0.011070782\n",
            "self.loss(score_2, v2) 0.020054614\n",
            "self.loss(score_3, v3) 0.0103834495\n",
            "loss tensor(0.0524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01857804\n",
            "self.loss(score_1, v1) 0.02639605\n",
            "self.loss(score_2, v2) 0.014631731\n",
            "self.loss(score_3, v3) 0.009708655\n",
            "loss tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017459385\n",
            "self.loss(score_1, v1) 0.011259931\n",
            "self.loss(score_2, v2) 0.009811622\n",
            "self.loss(score_3, v3) 0.011016893\n",
            "loss tensor(0.0495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011404077\n",
            "self.loss(score_1, v1) 0.027316395\n",
            "self.loss(score_2, v2) 0.061398737\n",
            "self.loss(score_3, v3) 0.1205644\n",
            "loss tensor(0.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011391938\n",
            "self.loss(score_1, v1) 0.016003864\n",
            "self.loss(score_2, v2) 0.021163285\n",
            "self.loss(score_3, v3) 0.014293296\n",
            "loss tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009396495\n",
            "self.loss(score_1, v1) 0.008499425\n",
            "self.loss(score_2, v2) 0.009848433\n",
            "self.loss(score_3, v3) 0.009135642\n",
            "loss tensor(0.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021963155\n",
            "self.loss(score_1, v1) 0.022208229\n",
            "self.loss(score_2, v2) 0.010192288\n",
            "self.loss(score_3, v3) 0.009642076\n",
            "loss tensor(0.0640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010561102\n",
            "self.loss(score_1, v1) 0.009821819\n",
            "self.loss(score_2, v2) 0.02334206\n",
            "self.loss(score_3, v3) 0.009684517\n",
            "loss tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009030601\n",
            "self.loss(score_1, v1) 0.01711326\n",
            "self.loss(score_2, v2) 0.019720104\n",
            "self.loss(score_3, v3) 0.016066447\n",
            "loss tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011656534\n",
            "self.loss(score_1, v1) 0.023514155\n",
            "self.loss(score_2, v2) 0.028932631\n",
            "self.loss(score_3, v3) 0.009015591\n",
            "loss tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008295094\n",
            "self.loss(score_1, v1) 0.015074487\n",
            "self.loss(score_2, v2) 0.013436913\n",
            "self.loss(score_3, v3) 0.008605317\n",
            "loss tensor(0.0454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015882326\n",
            "self.loss(score_1, v1) 0.028263371\n",
            "self.loss(score_2, v2) 0.030503917\n",
            "self.loss(score_3, v3) 0.015177593\n",
            "loss tensor(0.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012982832\n",
            "self.loss(score_1, v1) 0.023591485\n",
            "self.loss(score_2, v2) 0.01970839\n",
            "self.loss(score_3, v3) 0.016281584\n",
            "loss tensor(0.0726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010989682\n",
            "self.loss(score_1, v1) 0.021491833\n",
            "self.loss(score_2, v2) 0.060491852\n",
            "self.loss(score_3, v3) 0.04685197\n",
            "loss tensor(0.1398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018060045\n",
            "self.loss(score_1, v1) 0.010986048\n",
            "self.loss(score_2, v2) 0.014221982\n",
            "self.loss(score_3, v3) 0.010840264\n",
            "loss tensor(0.0541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.02901671\n",
            "self.loss(score_1, v1) 0.025353879\n",
            "self.loss(score_2, v2) 0.00952932\n",
            "self.loss(score_3, v3) 0.008300008\n",
            "loss tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.023127057\n",
            "self.loss(score_1, v1) 0.048018083\n",
            "self.loss(score_2, v2) 0.041051254\n",
            "self.loss(score_3, v3) 0.010399428\n",
            "loss tensor(0.1226, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06648003\n",
            "self.loss(score_1, v1) 0.07778364\n",
            "self.loss(score_2, v2) 0.08255963\n",
            "self.loss(score_3, v3) 0.01366678\n",
            "loss tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014325537\n",
            "self.loss(score_1, v1) 0.026148597\n",
            "self.loss(score_2, v2) 0.009954402\n",
            "self.loss(score_3, v3) 0.007728013\n",
            "loss tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.022956965\n",
            "self.loss(score_1, v1) 0.037186787\n",
            "self.loss(score_2, v2) 0.029813182\n",
            "self.loss(score_3, v3) 0.010259585\n",
            "loss tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0056470404\n",
            "self.loss(score_1, v1) 0.029185142\n",
            "self.loss(score_2, v2) 0.022392293\n",
            "self.loss(score_3, v3) 0.00802793\n",
            "loss tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0199526\n",
            "self.loss(score_1, v1) 0.041820694\n",
            "self.loss(score_2, v2) 0.020517763\n",
            "self.loss(score_3, v3) 0.010527361\n",
            "loss tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0117803635\n",
            "self.loss(score_1, v1) 0.011201744\n",
            "self.loss(score_2, v2) 0.018512508\n",
            "self.loss(score_3, v3) 0.011858954\n",
            "loss tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008946224\n",
            "self.loss(score_1, v1) 0.0112700015\n",
            "self.loss(score_2, v2) 0.010608328\n",
            "self.loss(score_3, v3) 0.0075687454\n",
            "loss tensor(0.0384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.024379686\n",
            "self.loss(score_1, v1) 0.021046251\n",
            "self.loss(score_2, v2) 0.014380507\n",
            "self.loss(score_3, v3) 0.010446379\n",
            "loss tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.022179134\n",
            "self.loss(score_1, v1) 0.030286845\n",
            "self.loss(score_2, v2) 0.03645176\n",
            "self.loss(score_3, v3) 0.009593796\n",
            "loss tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009335283\n",
            "self.loss(score_1, v1) 0.008923796\n",
            "self.loss(score_2, v2) 0.013078406\n",
            "self.loss(score_3, v3) 0.013289802\n",
            "loss tensor(0.0446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019440379\n",
            "self.loss(score_1, v1) 0.015661262\n",
            "self.loss(score_2, v2) 0.015260993\n",
            "self.loss(score_3, v3) 0.009558442\n",
            "loss tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010343979\n",
            "self.loss(score_1, v1) 0.009819969\n",
            "self.loss(score_2, v2) 0.013887286\n",
            "self.loss(score_3, v3) 0.01329339\n",
            "loss tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016897518\n",
            "self.loss(score_1, v1) 0.05847088\n",
            "self.loss(score_2, v2) 0.062013138\n",
            "self.loss(score_3, v3) 0.013719347\n",
            "loss tensor(0.1511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 0.10363389782987203, Train Accuracy : 0.9992291548954698\n",
            " Validation Accuracy : 6.6019371407272525\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.007113134\n",
            "self.loss(score_1, v1) 0.023701377\n",
            "self.loss(score_2, v2) 0.07097379\n",
            "self.loss(score_3, v3) 0.040840816\n",
            "loss tensor(0.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0067959367\n",
            "self.loss(score_1, v1) 0.012438323\n",
            "self.loss(score_2, v2) 0.124242246\n",
            "self.loss(score_3, v3) 0.034248978\n",
            "loss tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.039285004\n",
            "self.loss(score_1, v1) 0.075725734\n",
            "self.loss(score_2, v2) 0.11627456\n",
            "self.loss(score_3, v3) 0.007099125\n",
            "loss tensor(0.2384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.030846892\n",
            "self.loss(score_1, v1) 0.037133303\n",
            "self.loss(score_2, v2) 0.022400431\n",
            "self.loss(score_3, v3) 0.011499276\n",
            "loss tensor(0.1019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013100264\n",
            "self.loss(score_1, v1) 0.06060596\n",
            "self.loss(score_2, v2) 0.036371574\n",
            "self.loss(score_3, v3) 0.008218857\n",
            "loss tensor(0.1183, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008280249\n",
            "self.loss(score_1, v1) 0.007705671\n",
            "self.loss(score_2, v2) 0.008426673\n",
            "self.loss(score_3, v3) 0.0077009425\n",
            "loss tensor(0.0321, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008660053\n",
            "self.loss(score_1, v1) 0.008379741\n",
            "self.loss(score_2, v2) 0.01032487\n",
            "self.loss(score_3, v3) 0.008783822\n",
            "loss tensor(0.0361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013712514\n",
            "self.loss(score_1, v1) 0.011594344\n",
            "self.loss(score_2, v2) 0.007977299\n",
            "self.loss(score_3, v3) 0.006905613\n",
            "loss tensor(0.0402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01090862\n",
            "self.loss(score_1, v1) 0.01334468\n",
            "self.loss(score_2, v2) 0.014621705\n",
            "self.loss(score_3, v3) 0.010880965\n",
            "loss tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009912664\n",
            "self.loss(score_1, v1) 0.010159432\n",
            "self.loss(score_2, v2) 0.015946828\n",
            "self.loss(score_3, v3) 0.01447453\n",
            "loss tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.031682834\n",
            "self.loss(score_1, v1) 0.08350569\n",
            "self.loss(score_2, v2) 0.04190731\n",
            "self.loss(score_3, v3) 0.012163985\n",
            "loss tensor(0.1693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01289643\n",
            "self.loss(score_1, v1) 0.014757876\n",
            "self.loss(score_2, v2) 0.015016278\n",
            "self.loss(score_3, v3) 0.009505644\n",
            "loss tensor(0.0522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014590476\n",
            "self.loss(score_1, v1) 0.043435294\n",
            "self.loss(score_2, v2) 0.060738217\n",
            "self.loss(score_3, v3) 0.010023602\n",
            "loss tensor(0.1288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.026012193\n",
            "self.loss(score_1, v1) 0.025452558\n",
            "self.loss(score_2, v2) 0.036004394\n",
            "self.loss(score_3, v3) 0.011336252\n",
            "loss tensor(0.0988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009099724\n",
            "self.loss(score_1, v1) 0.0136203505\n",
            "self.loss(score_2, v2) 0.017840657\n",
            "self.loss(score_3, v3) 0.008594807\n",
            "loss tensor(0.0492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.02221675\n",
            "self.loss(score_1, v1) 0.027028754\n",
            "self.loss(score_2, v2) 0.011988476\n",
            "self.loss(score_3, v3) 0.012347399\n",
            "loss tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01303412\n",
            "self.loss(score_1, v1) 0.01516668\n",
            "self.loss(score_2, v2) 0.013400539\n",
            "self.loss(score_3, v3) 0.012047294\n",
            "loss tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010585756\n",
            "self.loss(score_1, v1) 0.014773051\n",
            "self.loss(score_2, v2) 0.015086041\n",
            "self.loss(score_3, v3) 0.010449862\n",
            "loss tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.054897618\n",
            "self.loss(score_1, v1) 0.06758523\n",
            "self.loss(score_2, v2) 0.1077666\n",
            "self.loss(score_3, v3) 0.014853224\n",
            "loss tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014020019\n",
            "self.loss(score_1, v1) 0.03812208\n",
            "self.loss(score_2, v2) 0.05409256\n",
            "self.loss(score_3, v3) 0.0146491\n",
            "loss tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013295557\n",
            "self.loss(score_1, v1) 0.01472313\n",
            "self.loss(score_2, v2) 0.014068134\n",
            "self.loss(score_3, v3) 0.00938005\n",
            "loss tensor(0.0515, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.029535227\n",
            "self.loss(score_1, v1) 0.026880259\n",
            "self.loss(score_2, v2) 0.010653473\n",
            "self.loss(score_3, v3) 0.011596691\n",
            "loss tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007946837\n",
            "self.loss(score_1, v1) 0.016810326\n",
            "self.loss(score_2, v2) 0.027414178\n",
            "self.loss(score_3, v3) 0.013937139\n",
            "loss tensor(0.0661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007628181\n",
            "self.loss(score_1, v1) 0.0064313626\n",
            "self.loss(score_2, v2) 0.00783219\n",
            "self.loss(score_3, v3) 0.008014261\n",
            "loss tensor(0.0299, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009765549\n",
            "self.loss(score_1, v1) 0.008938964\n",
            "self.loss(score_2, v2) 0.007942794\n",
            "self.loss(score_3, v3) 0.008305271\n",
            "loss tensor(0.0350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010691775\n",
            "self.loss(score_1, v1) 0.013785407\n",
            "self.loss(score_2, v2) 0.017827861\n",
            "self.loss(score_3, v3) 0.009973818\n",
            "loss tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.043449033\n",
            "self.loss(score_1, v1) 0.027498944\n",
            "self.loss(score_2, v2) 0.022714222\n",
            "self.loss(score_3, v3) 0.011936651\n",
            "loss tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00887377\n",
            "self.loss(score_1, v1) 0.01325338\n",
            "self.loss(score_2, v2) 0.01409399\n",
            "self.loss(score_3, v3) 0.011231277\n",
            "loss tensor(0.0475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019821284\n",
            "self.loss(score_1, v1) 0.027730225\n",
            "self.loss(score_2, v2) 0.026778582\n",
            "self.loss(score_3, v3) 0.013988964\n",
            "loss tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009999989\n",
            "self.loss(score_1, v1) 0.011909326\n",
            "self.loss(score_2, v2) 0.027712727\n",
            "self.loss(score_3, v3) 0.011297441\n",
            "loss tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.02529551\n",
            "self.loss(score_1, v1) 0.07007915\n",
            "self.loss(score_2, v2) 0.074374124\n",
            "self.loss(score_3, v3) 0.009401085\n",
            "loss tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010608017\n",
            "self.loss(score_1, v1) 0.008495\n",
            "self.loss(score_2, v2) 0.011921508\n",
            "self.loss(score_3, v3) 0.009358118\n",
            "loss tensor(0.0404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0646253\n",
            "self.loss(score_1, v1) 0.1564996\n",
            "self.loss(score_2, v2) 0.15518732\n",
            "self.loss(score_3, v3) 0.3333217\n",
            "loss tensor(0.7096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015063831\n",
            "self.loss(score_1, v1) 0.008592721\n",
            "self.loss(score_2, v2) 0.010072202\n",
            "self.loss(score_3, v3) 0.011253981\n",
            "loss tensor(0.0450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011101102\n",
            "self.loss(score_1, v1) 0.011400258\n",
            "self.loss(score_2, v2) 0.021933617\n",
            "self.loss(score_3, v3) 0.010674481\n",
            "loss tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011231524\n",
            "self.loss(score_1, v1) 0.01171959\n",
            "self.loss(score_2, v2) 0.016030638\n",
            "self.loss(score_3, v3) 0.012243923\n",
            "loss tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009194053\n",
            "self.loss(score_1, v1) 0.010667908\n",
            "self.loss(score_2, v2) 0.012352335\n",
            "self.loss(score_3, v3) 0.012488376\n",
            "loss tensor(0.0447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010284175\n",
            "self.loss(score_1, v1) 0.025843233\n",
            "self.loss(score_2, v2) 0.032464433\n",
            "self.loss(score_3, v3) 0.01693753\n",
            "loss tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.030246973\n",
            "self.loss(score_1, v1) 0.022120275\n",
            "self.loss(score_2, v2) 0.01275332\n",
            "self.loss(score_3, v3) 0.011766294\n",
            "loss tensor(0.0769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0117570255\n",
            "self.loss(score_1, v1) 0.027406618\n",
            "self.loss(score_2, v2) 0.034660537\n",
            "self.loss(score_3, v3) 0.10084101\n",
            "loss tensor(0.1747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017018653\n",
            "self.loss(score_1, v1) 0.021484882\n",
            "self.loss(score_2, v2) 0.0076119397\n",
            "self.loss(score_3, v3) 0.0059153256\n",
            "loss tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07537636\n",
            "self.loss(score_1, v1) 0.13795394\n",
            "self.loss(score_2, v2) 0.09878027\n",
            "self.loss(score_3, v3) 0.0077247787\n",
            "loss tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0119355265\n",
            "self.loss(score_1, v1) 0.0110660475\n",
            "self.loss(score_2, v2) 0.010510262\n",
            "self.loss(score_3, v3) 0.014712553\n",
            "loss tensor(0.0482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0077338605\n",
            "self.loss(score_1, v1) 0.011026627\n",
            "self.loss(score_2, v2) 0.012119609\n",
            "self.loss(score_3, v3) 0.010369536\n",
            "loss tensor(0.0412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011391333\n",
            "self.loss(score_1, v1) 0.011020993\n",
            "self.loss(score_2, v2) 0.014957671\n",
            "self.loss(score_3, v3) 0.014293865\n",
            "loss tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010084133\n",
            "self.loss(score_1, v1) 0.014672551\n",
            "self.loss(score_2, v2) 0.016888374\n",
            "self.loss(score_3, v3) 0.007851984\n",
            "loss tensor(0.0495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009712503\n",
            "self.loss(score_1, v1) 0.011471458\n",
            "self.loss(score_2, v2) 0.014156647\n",
            "self.loss(score_3, v3) 0.012250615\n",
            "loss tensor(0.0476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.027916284\n",
            "self.loss(score_1, v1) 0.024145152\n",
            "self.loss(score_2, v2) 0.06857175\n",
            "self.loss(score_3, v3) 0.009525067\n",
            "loss tensor(0.1302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0072223726\n",
            "self.loss(score_1, v1) 0.0055042454\n",
            "self.loss(score_2, v2) 0.010315852\n",
            "self.loss(score_3, v3) 0.007786722\n",
            "loss tensor(0.0308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014176941\n",
            "self.loss(score_1, v1) 0.021916237\n",
            "self.loss(score_2, v2) 0.019123806\n",
            "self.loss(score_3, v3) 0.01607341\n",
            "loss tensor(0.0713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.020743545\n",
            "self.loss(score_1, v1) 0.041426614\n",
            "self.loss(score_2, v2) 0.03009839\n",
            "self.loss(score_3, v3) 0.02145925\n",
            "loss tensor(0.1137, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009149053\n",
            "self.loss(score_1, v1) 0.009250318\n",
            "self.loss(score_2, v2) 0.011004877\n",
            "self.loss(score_3, v3) 0.011541555\n",
            "loss tensor(0.0409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.030765235\n",
            "self.loss(score_1, v1) 0.047985762\n",
            "self.loss(score_2, v2) 0.106920294\n",
            "self.loss(score_3, v3) 0.13725793\n",
            "loss tensor(0.3229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01640335\n",
            "self.loss(score_1, v1) 0.010302826\n",
            "self.loss(score_2, v2) 0.011111355\n",
            "self.loss(score_3, v3) 0.012383298\n",
            "loss tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13045578\n",
            "self.loss(score_1, v1) 0.09055073\n",
            "self.loss(score_2, v2) 0.05384389\n",
            "self.loss(score_3, v3) 0.016719915\n",
            "loss tensor(0.2916, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012470012\n",
            "self.loss(score_1, v1) 0.013416589\n",
            "self.loss(score_2, v2) 0.023166174\n",
            "self.loss(score_3, v3) 0.012235955\n",
            "loss tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019063601\n",
            "self.loss(score_1, v1) 0.025866589\n",
            "self.loss(score_2, v2) 0.016302286\n",
            "self.loss(score_3, v3) 0.011292124\n",
            "loss tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01293564\n",
            "self.loss(score_1, v1) 0.039556522\n",
            "self.loss(score_2, v2) 0.047369923\n",
            "self.loss(score_3, v3) 0.011293677\n",
            "loss tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019112816\n",
            "self.loss(score_1, v1) 0.022452585\n",
            "self.loss(score_2, v2) 0.01570583\n",
            "self.loss(score_3, v3) 0.0066252183\n",
            "loss tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009293611\n",
            "self.loss(score_1, v1) 0.007666419\n",
            "self.loss(score_2, v2) 0.011121863\n",
            "self.loss(score_3, v3) 0.013725943\n",
            "loss tensor(0.0418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008021528\n",
            "self.loss(score_1, v1) 0.10189164\n",
            "self.loss(score_2, v2) 0.04778744\n",
            "self.loss(score_3, v3) 0.005012213\n",
            "loss tensor(0.1627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.022778457\n",
            "self.loss(score_1, v1) 0.06634276\n",
            "self.loss(score_2, v2) 0.019061705\n",
            "self.loss(score_3, v3) 0.011741389\n",
            "loss tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010394989\n",
            "self.loss(score_1, v1) 0.009085443\n",
            "self.loss(score_2, v2) 0.010872961\n",
            "self.loss(score_3, v3) 0.010071908\n",
            "loss tensor(0.0404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17514043\n",
            "self.loss(score_1, v1) 0.07285458\n",
            "self.loss(score_2, v2) 0.042419307\n",
            "self.loss(score_3, v3) 0.033127807\n",
            "loss tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017051816\n",
            "self.loss(score_1, v1) 0.059469514\n",
            "self.loss(score_2, v2) 0.039308358\n",
            "self.loss(score_3, v3) 0.0132451905\n",
            "loss tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053337395\n",
            "self.loss(score_1, v1) 0.034317147\n",
            "self.loss(score_2, v2) 0.047302246\n",
            "self.loss(score_3, v3) 0.012523815\n",
            "loss tensor(0.1475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014682705\n",
            "self.loss(score_1, v1) 0.03750933\n",
            "self.loss(score_2, v2) 0.03971819\n",
            "self.loss(score_3, v3) 0.012886065\n",
            "loss tensor(0.1048, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0109616285\n",
            "self.loss(score_1, v1) 0.0129996985\n",
            "self.loss(score_2, v2) 0.017059557\n",
            "self.loss(score_3, v3) 0.009779751\n",
            "loss tensor(0.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016640551\n",
            "self.loss(score_1, v1) 0.014411613\n",
            "self.loss(score_2, v2) 0.012686109\n",
            "self.loss(score_3, v3) 0.008019623\n",
            "loss tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014081745\n",
            "self.loss(score_1, v1) 0.03918354\n",
            "self.loss(score_2, v2) 0.028665736\n",
            "self.loss(score_3, v3) 0.01055473\n",
            "loss tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009528996\n",
            "self.loss(score_1, v1) 0.012406208\n",
            "self.loss(score_2, v2) 0.026269386\n",
            "self.loss(score_3, v3) 0.010653631\n",
            "loss tensor(0.0589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06146559\n",
            "self.loss(score_1, v1) 0.093773834\n",
            "self.loss(score_2, v2) 0.03617648\n",
            "self.loss(score_3, v3) 0.01021215\n",
            "loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.020405577\n",
            "self.loss(score_1, v1) 0.04602458\n",
            "self.loss(score_2, v2) 0.03654701\n",
            "self.loss(score_3, v3) 0.015014575\n",
            "loss tensor(0.1180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01649471\n",
            "self.loss(score_1, v1) 0.13918696\n",
            "self.loss(score_2, v2) 0.096364476\n",
            "self.loss(score_3, v3) 0.034288544\n",
            "loss tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009069636\n",
            "self.loss(score_1, v1) 0.011614576\n",
            "self.loss(score_2, v2) 0.016201327\n",
            "self.loss(score_3, v3) 0.008797939\n",
            "loss tensor(0.0457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008431092\n",
            "self.loss(score_1, v1) 0.006061626\n",
            "self.loss(score_2, v2) 0.009204877\n",
            "self.loss(score_3, v3) 0.0074413023\n",
            "loss tensor(0.0311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014294447\n",
            "self.loss(score_1, v1) 0.019242128\n",
            "self.loss(score_2, v2) 0.010221888\n",
            "self.loss(score_3, v3) 0.011759702\n",
            "loss tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011579022\n",
            "self.loss(score_1, v1) 0.011338822\n",
            "self.loss(score_2, v2) 0.0151130315\n",
            "self.loss(score_3, v3) 0.011997925\n",
            "loss tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012161667\n",
            "self.loss(score_1, v1) 0.029021809\n",
            "self.loss(score_2, v2) 0.024667332\n",
            "self.loss(score_3, v3) 0.00992967\n",
            "loss tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0083932\n",
            "self.loss(score_1, v1) 0.010920268\n",
            "self.loss(score_2, v2) 0.009127923\n",
            "self.loss(score_3, v3) 0.006578335\n",
            "loss tensor(0.0350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05185209\n",
            "self.loss(score_1, v1) 0.054998748\n",
            "self.loss(score_2, v2) 0.04054428\n",
            "self.loss(score_3, v3) 0.012152232\n",
            "loss tensor(0.1595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01031235\n",
            "self.loss(score_1, v1) 0.014664288\n",
            "self.loss(score_2, v2) 0.013902923\n",
            "self.loss(score_3, v3) 0.009872441\n",
            "loss tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008505593\n",
            "self.loss(score_1, v1) 0.0105292685\n",
            "self.loss(score_2, v2) 0.008843228\n",
            "self.loss(score_3, v3) 0.009186932\n",
            "loss tensor(0.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014364557\n",
            "self.loss(score_1, v1) 0.017459262\n",
            "self.loss(score_2, v2) 0.013247337\n",
            "self.loss(score_3, v3) 0.009226971\n",
            "loss tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010043527\n",
            "self.loss(score_1, v1) 0.043888617\n",
            "self.loss(score_2, v2) 0.021720737\n",
            "self.loss(score_3, v3) 0.012009982\n",
            "loss tensor(0.0877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014508841\n",
            "self.loss(score_1, v1) 0.018875955\n",
            "self.loss(score_2, v2) 0.019286675\n",
            "self.loss(score_3, v3) 0.011815916\n",
            "loss tensor(0.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018087272\n",
            "self.loss(score_1, v1) 0.054150518\n",
            "self.loss(score_2, v2) 0.056839004\n",
            "self.loss(score_3, v3) 0.08539674\n",
            "loss tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01848321\n",
            "self.loss(score_1, v1) 0.018226618\n",
            "self.loss(score_2, v2) 0.023975184\n",
            "self.loss(score_3, v3) 0.009240043\n",
            "loss tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0074912854\n",
            "self.loss(score_1, v1) 0.008927317\n",
            "self.loss(score_2, v2) 0.01894391\n",
            "self.loss(score_3, v3) 0.012745855\n",
            "loss tensor(0.0481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008274719\n",
            "self.loss(score_1, v1) 0.035533033\n",
            "self.loss(score_2, v2) 0.02900659\n",
            "self.loss(score_3, v3) 0.010968452\n",
            "loss tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07939118\n",
            "self.loss(score_1, v1) 0.03445134\n",
            "self.loss(score_2, v2) 0.028903639\n",
            "self.loss(score_3, v3) 0.009119999\n",
            "loss tensor(0.1519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017003665\n",
            "self.loss(score_1, v1) 0.012730934\n",
            "self.loss(score_2, v2) 0.011078489\n",
            "self.loss(score_3, v3) 0.012130092\n",
            "loss tensor(0.0529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019280836\n",
            "self.loss(score_1, v1) 0.04347164\n",
            "self.loss(score_2, v2) 0.034936864\n",
            "self.loss(score_3, v3) 0.01532243\n",
            "loss tensor(0.1130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.068931885\n",
            "self.loss(score_1, v1) 0.024632514\n",
            "self.loss(score_2, v2) 0.0567456\n",
            "self.loss(score_3, v3) 0.03932614\n",
            "loss tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015923316\n",
            "self.loss(score_1, v1) 0.010450785\n",
            "self.loss(score_2, v2) 0.016963268\n",
            "self.loss(score_3, v3) 0.009269211\n",
            "loss tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058281567\n",
            "self.loss(score_1, v1) 0.05500386\n",
            "self.loss(score_2, v2) 0.016725168\n",
            "self.loss(score_3, v3) 0.009023247\n",
            "loss tensor(0.1390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015589203\n",
            "self.loss(score_1, v1) 0.04893388\n",
            "self.loss(score_2, v2) 0.03415326\n",
            "self.loss(score_3, v3) 0.013599437\n",
            "loss tensor(0.1123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01005712\n",
            "self.loss(score_1, v1) 0.00951746\n",
            "self.loss(score_2, v2) 0.008830193\n",
            "self.loss(score_3, v3) 0.009489114\n",
            "loss tensor(0.0379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008075791\n",
            "self.loss(score_1, v1) 0.013949377\n",
            "self.loss(score_2, v2) 0.017618202\n",
            "self.loss(score_3, v3) 0.0105759315\n",
            "loss tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.027097061\n",
            "self.loss(score_1, v1) 0.07056384\n",
            "self.loss(score_2, v2) 0.08449807\n",
            "self.loss(score_3, v3) 0.021328373\n",
            "loss tensor(0.2035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01030141\n",
            "self.loss(score_1, v1) 0.08581489\n",
            "self.loss(score_2, v2) 0.091001235\n",
            "self.loss(score_3, v3) 0.07058939\n",
            "loss tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.046065483\n",
            "self.loss(score_1, v1) 0.087065354\n",
            "self.loss(score_2, v2) 0.047327206\n",
            "self.loss(score_3, v3) 0.021647\n",
            "loss tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059873503\n",
            "self.loss(score_1, v1) 0.029830618\n",
            "self.loss(score_2, v2) 0.025597079\n",
            "self.loss(score_3, v3) 0.007842332\n",
            "loss tensor(0.1231, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.025745885\n",
            "self.loss(score_1, v1) 0.014010077\n",
            "self.loss(score_2, v2) 0.021433212\n",
            "self.loss(score_3, v3) 0.012135205\n",
            "loss tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0073590074\n",
            "self.loss(score_1, v1) 0.005582709\n",
            "self.loss(score_2, v2) 0.008420344\n",
            "self.loss(score_3, v3) 0.008008346\n",
            "loss tensor(0.0294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010151622\n",
            "self.loss(score_1, v1) 0.043619905\n",
            "self.loss(score_2, v2) 0.059282184\n",
            "self.loss(score_3, v3) 0.010977876\n",
            "loss tensor(0.1240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.020323925\n",
            "self.loss(score_1, v1) 0.113678485\n",
            "self.loss(score_2, v2) 0.03618966\n",
            "self.loss(score_3, v3) 0.025208483\n",
            "loss tensor(0.1954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011904892\n",
            "self.loss(score_1, v1) 0.009321538\n",
            "self.loss(score_2, v2) 0.009507262\n",
            "self.loss(score_3, v3) 0.01041343\n",
            "loss tensor(0.0411, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010734923\n",
            "self.loss(score_1, v1) 0.016185775\n",
            "self.loss(score_2, v2) 0.025878565\n",
            "self.loss(score_3, v3) 0.011295978\n",
            "loss tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008390091\n",
            "self.loss(score_1, v1) 0.116689034\n",
            "self.loss(score_2, v2) 0.15175332\n",
            "self.loss(score_3, v3) 0.12538102\n",
            "loss tensor(0.4022, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010958863\n",
            "self.loss(score_1, v1) 0.018528147\n",
            "self.loss(score_2, v2) 0.014494124\n",
            "self.loss(score_3, v3) 0.018649217\n",
            "loss tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016644478\n",
            "self.loss(score_1, v1) 0.013033582\n",
            "self.loss(score_2, v2) 0.044465322\n",
            "self.loss(score_3, v3) 0.09018191\n",
            "loss tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014362896\n",
            "self.loss(score_1, v1) 0.11168018\n",
            "self.loss(score_2, v2) 0.06258789\n",
            "self.loss(score_3, v3) 0.015705893\n",
            "loss tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0120890355\n",
            "self.loss(score_1, v1) 0.017190676\n",
            "self.loss(score_2, v2) 0.018460939\n",
            "self.loss(score_3, v3) 0.0107906265\n",
            "loss tensor(0.0585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015382625\n",
            "self.loss(score_1, v1) 0.0220748\n",
            "self.loss(score_2, v2) 0.020073522\n",
            "self.loss(score_3, v3) 0.013387638\n",
            "loss tensor(0.0709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0073953634\n",
            "self.loss(score_1, v1) 0.0064748637\n",
            "self.loss(score_2, v2) 0.012479226\n",
            "self.loss(score_3, v3) 0.008815183\n",
            "loss tensor(0.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013704822\n",
            "self.loss(score_1, v1) 0.017266141\n",
            "self.loss(score_2, v2) 0.010284986\n",
            "self.loss(score_3, v3) 0.012144462\n",
            "loss tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012888329\n",
            "self.loss(score_1, v1) 0.011705753\n",
            "self.loss(score_2, v2) 0.009552385\n",
            "self.loss(score_3, v3) 0.008855222\n",
            "loss tensor(0.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00859644\n",
            "self.loss(score_1, v1) 0.008567488\n",
            "self.loss(score_2, v2) 0.010022272\n",
            "self.loss(score_3, v3) 0.0049736532\n",
            "loss tensor(0.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00933306\n",
            "self.loss(score_1, v1) 0.015054119\n",
            "self.loss(score_2, v2) 0.0047827414\n",
            "self.loss(score_3, v3) 0.00472666\n",
            "loss tensor(0.0339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14909935\n",
            "self.loss(score_1, v1) 0.058822554\n",
            "self.loss(score_2, v2) 0.11718575\n",
            "self.loss(score_3, v3) 0.04405025\n",
            "loss tensor(0.3692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008037716\n",
            "self.loss(score_1, v1) 0.0075091706\n",
            "self.loss(score_2, v2) 0.008027148\n",
            "self.loss(score_3, v3) 0.0065046214\n",
            "loss tensor(0.0301, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011182914\n",
            "self.loss(score_1, v1) 0.030658524\n",
            "self.loss(score_2, v2) 0.01643066\n",
            "self.loss(score_3, v3) 0.00886362\n",
            "loss tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.005351592\n",
            "self.loss(score_1, v1) 0.011189081\n",
            "self.loss(score_2, v2) 0.008849962\n",
            "self.loss(score_3, v3) 0.006279355\n",
            "loss tensor(0.0317, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0077786413\n",
            "self.loss(score_1, v1) 0.013929117\n",
            "self.loss(score_2, v2) 0.012454017\n",
            "self.loss(score_3, v3) 0.010959163\n",
            "loss tensor(0.0451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019255336\n",
            "self.loss(score_1, v1) 0.023425356\n",
            "self.loss(score_2, v2) 0.029833712\n",
            "self.loss(score_3, v3) 0.02040894\n",
            "loss tensor(0.0929, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01689311\n",
            "self.loss(score_1, v1) 0.024946716\n",
            "self.loss(score_2, v2) 0.0279171\n",
            "self.loss(score_3, v3) 0.015956078\n",
            "loss tensor(0.0857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012347876\n",
            "self.loss(score_1, v1) 0.01782559\n",
            "self.loss(score_2, v2) 0.019083302\n",
            "self.loss(score_3, v3) 0.012988204\n",
            "loss tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016438331\n",
            "self.loss(score_1, v1) 0.01225355\n",
            "self.loss(score_2, v2) 0.008206948\n",
            "self.loss(score_3, v3) 0.008761909\n",
            "loss tensor(0.0457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011702093\n",
            "self.loss(score_1, v1) 0.0106541\n",
            "self.loss(score_2, v2) 0.008941396\n",
            "self.loss(score_3, v3) 0.010917474\n",
            "loss tensor(0.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009668948\n",
            "self.loss(score_1, v1) 0.0131958965\n",
            "self.loss(score_2, v2) 0.03618941\n",
            "self.loss(score_3, v3) 0.09902207\n",
            "loss tensor(0.1581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0073374724\n",
            "self.loss(score_1, v1) 0.01065683\n",
            "self.loss(score_2, v2) 0.012317087\n",
            "self.loss(score_3, v3) 0.007398851\n",
            "loss tensor(0.0377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0098178545\n",
            "self.loss(score_1, v1) 0.017197022\n",
            "self.loss(score_2, v2) 0.01854912\n",
            "self.loss(score_3, v3) 0.013136833\n",
            "loss tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009638533\n",
            "self.loss(score_1, v1) 0.032974273\n",
            "self.loss(score_2, v2) 0.083791815\n",
            "self.loss(score_3, v3) 0.050834518\n",
            "loss tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009849923\n",
            "self.loss(score_1, v1) 0.06591151\n",
            "self.loss(score_2, v2) 0.13236737\n",
            "self.loss(score_3, v3) 0.13139822\n",
            "loss tensor(0.3395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01607902\n",
            "self.loss(score_1, v1) 0.027996292\n",
            "self.loss(score_2, v2) 0.02444086\n",
            "self.loss(score_3, v3) 0.032644045\n",
            "loss tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013412061\n",
            "self.loss(score_1, v1) 0.032171275\n",
            "self.loss(score_2, v2) 0.022883518\n",
            "self.loss(score_3, v3) 0.016921123\n",
            "loss tensor(0.0854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008045662\n",
            "self.loss(score_1, v1) 0.00871089\n",
            "self.loss(score_2, v2) 0.010534362\n",
            "self.loss(score_3, v3) 0.008597447\n",
            "loss tensor(0.0359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011870194\n",
            "self.loss(score_1, v1) 0.021663066\n",
            "self.loss(score_2, v2) 0.029476104\n",
            "self.loss(score_3, v3) 0.020116486\n",
            "loss tensor(0.0831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009489965\n",
            "self.loss(score_1, v1) 0.013754736\n",
            "self.loss(score_2, v2) 0.016316393\n",
            "self.loss(score_3, v3) 0.007761463\n",
            "loss tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019450933\n",
            "self.loss(score_1, v1) 0.019803593\n",
            "self.loss(score_2, v2) 0.021139042\n",
            "self.loss(score_3, v3) 0.015880734\n",
            "loss tensor(0.0763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010857709\n",
            "self.loss(score_1, v1) 0.037934072\n",
            "self.loss(score_2, v2) 0.0349455\n",
            "self.loss(score_3, v3) 0.01232169\n",
            "loss tensor(0.0961, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013242786\n",
            "self.loss(score_1, v1) 0.014495441\n",
            "self.loss(score_2, v2) 0.012405237\n",
            "self.loss(score_3, v3) 0.009566286\n",
            "loss tensor(0.0497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010243365\n",
            "self.loss(score_1, v1) 0.016579702\n",
            "self.loss(score_2, v2) 0.025318492\n",
            "self.loss(score_3, v3) 0.0116496235\n",
            "loss tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016789246\n",
            "self.loss(score_1, v1) 0.06760375\n",
            "self.loss(score_2, v2) 0.05636636\n",
            "self.loss(score_3, v3) 0.028305916\n",
            "loss tensor(0.1691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010736034\n",
            "self.loss(score_1, v1) 0.01608166\n",
            "self.loss(score_2, v2) 0.0166277\n",
            "self.loss(score_3, v3) 0.011279337\n",
            "loss tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009686874\n",
            "self.loss(score_1, v1) 0.00805735\n",
            "self.loss(score_2, v2) 0.009853055\n",
            "self.loss(score_3, v3) 0.007898127\n",
            "loss tensor(0.0355, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018912613\n",
            "self.loss(score_1, v1) 0.03469729\n",
            "self.loss(score_2, v2) 0.026534792\n",
            "self.loss(score_3, v3) 0.013799138\n",
            "loss tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008728149\n",
            "self.loss(score_1, v1) 0.009798745\n",
            "self.loss(score_2, v2) 0.009873181\n",
            "self.loss(score_3, v3) 0.014928456\n",
            "loss tensor(0.0433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013293894\n",
            "self.loss(score_1, v1) 0.015187073\n",
            "self.loss(score_2, v2) 0.021258578\n",
            "self.loss(score_3, v3) 0.010864703\n",
            "loss tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09468345\n",
            "self.loss(score_1, v1) 0.08884044\n",
            "self.loss(score_2, v2) 0.037426535\n",
            "self.loss(score_3, v3) 0.0370773\n",
            "loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01629201\n",
            "self.loss(score_1, v1) 0.01638501\n",
            "self.loss(score_2, v2) 0.015289347\n",
            "self.loss(score_3, v3) 0.010203874\n",
            "loss tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.020749837\n",
            "self.loss(score_1, v1) 0.040227026\n",
            "self.loss(score_2, v2) 0.012969939\n",
            "self.loss(score_3, v3) 0.009519906\n",
            "loss tensor(0.0835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018742952\n",
            "self.loss(score_1, v1) 0.029124815\n",
            "self.loss(score_2, v2) 0.018388918\n",
            "self.loss(score_3, v3) 0.013161558\n",
            "loss tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.023176745\n",
            "self.loss(score_1, v1) 0.017837249\n",
            "self.loss(score_2, v2) 0.011977337\n",
            "self.loss(score_3, v3) 0.008970136\n",
            "loss tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016320871\n",
            "self.loss(score_1, v1) 0.01962017\n",
            "self.loss(score_2, v2) 0.010272365\n",
            "self.loss(score_3, v3) 0.0075042215\n",
            "loss tensor(0.0537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011258679\n",
            "self.loss(score_1, v1) 0.012335447\n",
            "self.loss(score_2, v2) 0.017856369\n",
            "self.loss(score_3, v3) 0.01442892\n",
            "loss tensor(0.0559, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014992132\n",
            "self.loss(score_1, v1) 0.057310898\n",
            "self.loss(score_2, v2) 0.046221666\n",
            "self.loss(score_3, v3) 0.008127737\n",
            "loss tensor(0.1267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0060960613\n",
            "self.loss(score_1, v1) 0.010012917\n",
            "self.loss(score_2, v2) 0.011844794\n",
            "self.loss(score_3, v3) 0.0073087118\n",
            "loss tensor(0.0353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015586363\n",
            "self.loss(score_1, v1) 0.036305875\n",
            "self.loss(score_2, v2) 0.029590147\n",
            "self.loss(score_3, v3) 0.012709937\n",
            "loss tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00837393\n",
            "self.loss(score_1, v1) 0.006623114\n",
            "self.loss(score_2, v2) 0.011564872\n",
            "self.loss(score_3, v3) 0.0087864725\n",
            "loss tensor(0.0353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008242569\n",
            "self.loss(score_1, v1) 0.0129106175\n",
            "self.loss(score_2, v2) 0.026281944\n",
            "self.loss(score_3, v3) 0.011677837\n",
            "loss tensor(0.0591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05854289\n",
            "self.loss(score_1, v1) 0.04186945\n",
            "self.loss(score_2, v2) 0.035962395\n",
            "self.loss(score_3, v3) 0.040804565\n",
            "loss tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00713287\n",
            "self.loss(score_1, v1) 0.014087127\n",
            "self.loss(score_2, v2) 0.018114673\n",
            "self.loss(score_3, v3) 0.011451887\n",
            "loss tensor(0.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0069108712\n",
            "self.loss(score_1, v1) 0.009517186\n",
            "self.loss(score_2, v2) 0.017157892\n",
            "self.loss(score_3, v3) 0.008293784\n",
            "loss tensor(0.0419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016821729\n",
            "self.loss(score_1, v1) 0.029997654\n",
            "self.loss(score_2, v2) 0.017879292\n",
            "self.loss(score_3, v3) 0.012295821\n",
            "loss tensor(0.0770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014391184\n",
            "self.loss(score_1, v1) 0.12861328\n",
            "self.loss(score_2, v2) 0.0776994\n",
            "self.loss(score_3, v3) 0.027860394\n",
            "loss tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016786741\n",
            "self.loss(score_1, v1) 0.013293462\n",
            "self.loss(score_2, v2) 0.011682767\n",
            "self.loss(score_3, v3) 0.011986803\n",
            "loss tensor(0.0537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012878892\n",
            "self.loss(score_1, v1) 0.039621234\n",
            "self.loss(score_2, v2) 0.047303863\n",
            "self.loss(score_3, v3) 0.011974328\n",
            "loss tensor(0.1118, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018861184\n",
            "self.loss(score_1, v1) 0.034491595\n",
            "self.loss(score_2, v2) 0.057730813\n",
            "self.loss(score_3, v3) 0.079563946\n",
            "loss tensor(0.1906, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008311825\n",
            "self.loss(score_1, v1) 0.094892286\n",
            "self.loss(score_2, v2) 0.07031829\n",
            "self.loss(score_3, v3) 0.06516041\n",
            "loss tensor(0.2387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0121488385\n",
            "self.loss(score_1, v1) 0.012959657\n",
            "self.loss(score_2, v2) 0.01739087\n",
            "self.loss(score_3, v3) 0.0091039\n",
            "loss tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0037621183\n",
            "self.loss(score_1, v1) 0.010402333\n",
            "self.loss(score_2, v2) 0.015744505\n",
            "self.loss(score_3, v3) 0.004951058\n",
            "loss tensor(0.0349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011800087\n",
            "self.loss(score_1, v1) 0.011078388\n",
            "self.loss(score_2, v2) 0.011346599\n",
            "self.loss(score_3, v3) 0.012473463\n",
            "loss tensor(0.0467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008503055\n",
            "self.loss(score_1, v1) 0.016535474\n",
            "self.loss(score_2, v2) 0.013613919\n",
            "self.loss(score_3, v3) 0.013485601\n",
            "loss tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00849663\n",
            "self.loss(score_1, v1) 0.0052181976\n",
            "self.loss(score_2, v2) 0.0068135485\n",
            "self.loss(score_3, v3) 0.010019716\n",
            "loss tensor(0.0305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008494664\n",
            "self.loss(score_1, v1) 0.007262391\n",
            "self.loss(score_2, v2) 0.0041839415\n",
            "self.loss(score_3, v3) 0.005797327\n",
            "loss tensor(0.0257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013008688\n",
            "self.loss(score_1, v1) 0.009317629\n",
            "self.loss(score_2, v2) 0.009173358\n",
            "self.loss(score_3, v3) 0.010111481\n",
            "loss tensor(0.0416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013371903\n",
            "self.loss(score_1, v1) 0.0151862735\n",
            "self.loss(score_2, v2) 0.012187964\n",
            "self.loss(score_3, v3) 0.011741189\n",
            "loss tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.005730949\n",
            "self.loss(score_1, v1) 0.0064186417\n",
            "self.loss(score_2, v2) 0.006077306\n",
            "self.loss(score_3, v3) 0.004604328\n",
            "loss tensor(0.0228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011297332\n",
            "self.loss(score_1, v1) 0.020019194\n",
            "self.loss(score_2, v2) 0.040199865\n",
            "self.loss(score_3, v3) 0.015094503\n",
            "loss tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016899511\n",
            "self.loss(score_1, v1) 0.053655703\n",
            "self.loss(score_2, v2) 0.007840496\n",
            "self.loss(score_3, v3) 0.0068526603\n",
            "loss tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008290037\n",
            "self.loss(score_1, v1) 0.008695547\n",
            "self.loss(score_2, v2) 0.009884284\n",
            "self.loss(score_3, v3) 0.008765206\n",
            "loss tensor(0.0356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010193275\n",
            "self.loss(score_1, v1) 0.015292122\n",
            "self.loss(score_2, v2) 0.0125201745\n",
            "self.loss(score_3, v3) 0.0129422555\n",
            "loss tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013673715\n",
            "self.loss(score_1, v1) 0.050262515\n",
            "self.loss(score_2, v2) 0.054835886\n",
            "self.loss(score_3, v3) 0.013708753\n",
            "loss tensor(0.1325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010233605\n",
            "self.loss(score_1, v1) 0.04728319\n",
            "self.loss(score_2, v2) 0.014160395\n",
            "self.loss(score_3, v3) 0.008532212\n",
            "loss tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010766917\n",
            "self.loss(score_1, v1) 0.02713467\n",
            "self.loss(score_2, v2) 0.015276082\n",
            "self.loss(score_3, v3) 0.0086798575\n",
            "loss tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012416828\n",
            "self.loss(score_1, v1) 0.016701499\n",
            "self.loss(score_2, v2) 0.015354297\n",
            "self.loss(score_3, v3) 0.012825142\n",
            "loss tensor(0.0573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0059338687\n",
            "self.loss(score_1, v1) 0.013685732\n",
            "self.loss(score_2, v2) 0.044027284\n",
            "self.loss(score_3, v3) 0.0054097227\n",
            "loss tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019576687\n",
            "self.loss(score_1, v1) 0.020591378\n",
            "self.loss(score_2, v2) 0.0070474353\n",
            "self.loss(score_3, v3) 0.008615187\n",
            "loss tensor(0.0558, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008452761\n",
            "self.loss(score_1, v1) 0.010046057\n",
            "self.loss(score_2, v2) 0.016406622\n",
            "self.loss(score_3, v3) 0.011178324\n",
            "loss tensor(0.0461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007387857\n",
            "self.loss(score_1, v1) 0.008183337\n",
            "self.loss(score_2, v2) 0.007936671\n",
            "self.loss(score_3, v3) 0.007845272\n",
            "loss tensor(0.0314, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.054942627\n",
            "self.loss(score_1, v1) 0.043227047\n",
            "self.loss(score_2, v2) 0.021288933\n",
            "self.loss(score_3, v3) 0.010009776\n",
            "loss tensor(0.1295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011429159\n",
            "self.loss(score_1, v1) 0.005848209\n",
            "self.loss(score_2, v2) 0.007311755\n",
            "self.loss(score_3, v3) 0.008162582\n",
            "loss tensor(0.0328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010026463\n",
            "self.loss(score_1, v1) 0.017748035\n",
            "self.loss(score_2, v2) 0.016557474\n",
            "self.loss(score_3, v3) 0.0131192645\n",
            "loss tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.024365153\n",
            "self.loss(score_1, v1) 0.09977022\n",
            "self.loss(score_2, v2) 0.12207815\n",
            "self.loss(score_3, v3) 0.09509209\n",
            "loss tensor(0.3413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011205269\n",
            "self.loss(score_1, v1) 0.008035392\n",
            "self.loss(score_2, v2) 0.009998354\n",
            "self.loss(score_3, v3) 0.008672764\n",
            "loss tensor(0.0379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053252537\n",
            "self.loss(score_1, v1) 0.045252576\n",
            "self.loss(score_2, v2) 0.06424875\n",
            "self.loss(score_3, v3) 0.009999123\n",
            "loss tensor(0.1728, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.024964016\n",
            "self.loss(score_1, v1) 0.03109402\n",
            "self.loss(score_2, v2) 0.057850324\n",
            "self.loss(score_3, v3) 0.007897874\n",
            "loss tensor(0.1218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013216853\n",
            "self.loss(score_1, v1) 0.020933831\n",
            "self.loss(score_2, v2) 0.018248187\n",
            "self.loss(score_3, v3) 0.016651446\n",
            "loss tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015600028\n",
            "self.loss(score_1, v1) 0.01169916\n",
            "self.loss(score_2, v2) 0.0046929587\n",
            "self.loss(score_3, v3) 0.006562124\n",
            "loss tensor(0.0386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018593987\n",
            "self.loss(score_1, v1) 0.055701934\n",
            "self.loss(score_2, v2) 0.07003879\n",
            "self.loss(score_3, v3) 0.00805965\n",
            "loss tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03025065\n",
            "self.loss(score_1, v1) 0.05708999\n",
            "self.loss(score_2, v2) 0.015389253\n",
            "self.loss(score_3, v3) 0.00951637\n",
            "loss tensor(0.1122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007994444\n",
            "self.loss(score_1, v1) 0.02146912\n",
            "self.loss(score_2, v2) 0.022265492\n",
            "self.loss(score_3, v3) 0.009934272\n",
            "loss tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.043311015\n",
            "self.loss(score_1, v1) 0.029881481\n",
            "self.loss(score_2, v2) 0.026860557\n",
            "self.loss(score_3, v3) 0.009231199\n",
            "loss tensor(0.1093, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015288045\n",
            "self.loss(score_1, v1) 0.030171046\n",
            "self.loss(score_2, v2) 0.011012678\n",
            "self.loss(score_3, v3) 0.008544667\n",
            "loss tensor(0.0650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015165135\n",
            "self.loss(score_1, v1) 0.013844154\n",
            "self.loss(score_2, v2) 0.007339175\n",
            "self.loss(score_3, v3) 0.008911876\n",
            "loss tensor(0.0453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014745338\n",
            "self.loss(score_1, v1) 0.013766697\n",
            "self.loss(score_2, v2) 0.091452725\n",
            "self.loss(score_3, v3) 0.01131686\n",
            "loss tensor(0.1313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.072113834\n",
            "self.loss(score_1, v1) 0.083039574\n",
            "self.loss(score_2, v2) 0.08883313\n",
            "self.loss(score_3, v3) 0.052452955\n",
            "loss tensor(0.2964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0074661598\n",
            "self.loss(score_1, v1) 0.010541283\n",
            "self.loss(score_2, v2) 0.014069178\n",
            "self.loss(score_3, v3) 0.008488996\n",
            "loss tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06271573\n",
            "self.loss(score_1, v1) 0.048883032\n",
            "self.loss(score_2, v2) 0.032896794\n",
            "self.loss(score_3, v3) 0.009956761\n",
            "loss tensor(0.1545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014370543\n",
            "self.loss(score_1, v1) 0.006668565\n",
            "self.loss(score_2, v2) 0.008958079\n",
            "self.loss(score_3, v3) 0.013230292\n",
            "loss tensor(0.0432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0109264515\n",
            "self.loss(score_1, v1) 0.02337571\n",
            "self.loss(score_2, v2) 0.013668427\n",
            "self.loss(score_3, v3) 0.0070894137\n",
            "loss tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0094592\n",
            "self.loss(score_1, v1) 0.009403011\n",
            "self.loss(score_2, v2) 0.012037668\n",
            "self.loss(score_3, v3) 0.0115091065\n",
            "loss tensor(0.0424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011398826\n",
            "self.loss(score_1, v1) 0.013654782\n",
            "self.loss(score_2, v2) 0.03472945\n",
            "self.loss(score_3, v3) 0.030061264\n",
            "loss tensor(0.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0072753034\n",
            "self.loss(score_1, v1) 0.00954072\n",
            "self.loss(score_2, v2) 0.010098119\n",
            "self.loss(score_3, v3) 0.0076084337\n",
            "loss tensor(0.0345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009429994\n",
            "self.loss(score_1, v1) 0.0074007506\n",
            "self.loss(score_2, v2) 0.009498342\n",
            "self.loss(score_3, v3) 0.007927854\n",
            "loss tensor(0.0343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077953145\n",
            "self.loss(score_1, v1) 0.08479471\n",
            "self.loss(score_2, v2) 0.105142616\n",
            "self.loss(score_3, v3) 0.034183353\n",
            "loss tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011461462\n",
            "self.loss(score_1, v1) 0.015984178\n",
            "self.loss(score_2, v2) 0.028525392\n",
            "self.loss(score_3, v3) 0.00831229\n",
            "loss tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008475827\n",
            "self.loss(score_1, v1) 0.007959504\n",
            "self.loss(score_2, v2) 0.0071202205\n",
            "self.loss(score_3, v3) 0.008990004\n",
            "loss tensor(0.0325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.025494596\n",
            "self.loss(score_1, v1) 0.014440506\n",
            "self.loss(score_2, v2) 0.016006242\n",
            "self.loss(score_3, v3) 0.011186954\n",
            "loss tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0116026485\n",
            "self.loss(score_1, v1) 0.01798289\n",
            "self.loss(score_2, v2) 0.011826695\n",
            "self.loss(score_3, v3) 0.012011411\n",
            "loss tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011139369\n",
            "self.loss(score_1, v1) 0.02254887\n",
            "self.loss(score_2, v2) 0.05173791\n",
            "self.loss(score_3, v3) 0.008227088\n",
            "loss tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017765462\n",
            "self.loss(score_1, v1) 0.024147613\n",
            "self.loss(score_2, v2) 0.01717581\n",
            "self.loss(score_3, v3) 0.00759868\n",
            "loss tensor(0.0667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017994624\n",
            "self.loss(score_1, v1) 0.027666092\n",
            "self.loss(score_2, v2) 0.06118174\n",
            "self.loss(score_3, v3) 0.01420888\n",
            "loss tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011722313\n",
            "self.loss(score_1, v1) 0.05432752\n",
            "self.loss(score_2, v2) 0.03997512\n",
            "self.loss(score_3, v3) 0.02549449\n",
            "loss tensor(0.1315, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017218862\n",
            "self.loss(score_1, v1) 0.030821346\n",
            "self.loss(score_2, v2) 0.039561473\n",
            "self.loss(score_3, v3) 0.06706186\n",
            "loss tensor(0.1547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05872385\n",
            "self.loss(score_1, v1) 0.048455607\n",
            "self.loss(score_2, v2) 0.1437891\n",
            "self.loss(score_3, v3) 0.0102891205\n",
            "loss tensor(0.2613, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011561444\n",
            "self.loss(score_1, v1) 0.048403546\n",
            "self.loss(score_2, v2) 0.018458499\n",
            "self.loss(score_3, v3) 0.014419387\n",
            "loss tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016724411\n",
            "self.loss(score_1, v1) 0.01559062\n",
            "self.loss(score_2, v2) 0.014208868\n",
            "self.loss(score_3, v3) 0.00793129\n",
            "loss tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.02349806\n",
            "self.loss(score_1, v1) 0.032512475\n",
            "self.loss(score_2, v2) 0.010104559\n",
            "self.loss(score_3, v3) 0.008615779\n",
            "loss tensor(0.0747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.004957275\n",
            "self.loss(score_1, v1) 0.0046110647\n",
            "self.loss(score_2, v2) 0.007874934\n",
            "self.loss(score_3, v3) 0.0062033436\n",
            "loss tensor(0.0236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008757682\n",
            "self.loss(score_1, v1) 0.011625188\n",
            "self.loss(score_2, v2) 0.02441887\n",
            "self.loss(score_3, v3) 0.009064373\n",
            "loss tensor(0.0539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.027400266\n",
            "self.loss(score_1, v1) 0.027256113\n",
            "self.loss(score_2, v2) 0.014382143\n",
            "self.loss(score_3, v3) 0.011023715\n",
            "loss tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010249138\n",
            "self.loss(score_1, v1) 0.022063345\n",
            "self.loss(score_2, v2) 0.021062266\n",
            "self.loss(score_3, v3) 0.012583135\n",
            "loss tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016221032\n",
            "self.loss(score_1, v1) 0.028437115\n",
            "self.loss(score_2, v2) 0.01885836\n",
            "self.loss(score_3, v3) 0.009269889\n",
            "loss tensor(0.0728, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010561335\n",
            "self.loss(score_1, v1) 0.015810098\n",
            "self.loss(score_2, v2) 0.02780188\n",
            "self.loss(score_3, v3) 0.008921387\n",
            "loss tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011651265\n",
            "self.loss(score_1, v1) 0.087991714\n",
            "self.loss(score_2, v2) 0.044448156\n",
            "self.loss(score_3, v3) 0.009643695\n",
            "loss tensor(0.1537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013742453\n",
            "self.loss(score_1, v1) 0.014212374\n",
            "self.loss(score_2, v2) 0.015817646\n",
            "self.loss(score_3, v3) 0.01046845\n",
            "loss tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009709503\n",
            "self.loss(score_1, v1) 0.0222473\n",
            "self.loss(score_2, v2) 0.021228917\n",
            "self.loss(score_3, v3) 0.012735829\n",
            "loss tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010879977\n",
            "self.loss(score_1, v1) 0.008072958\n",
            "self.loss(score_2, v2) 0.015123289\n",
            "self.loss(score_3, v3) 0.013841477\n",
            "loss tensor(0.0479, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0073736673\n",
            "self.loss(score_1, v1) 0.07991681\n",
            "self.loss(score_2, v2) 0.014405083\n",
            "self.loss(score_3, v3) 0.006891843\n",
            "loss tensor(0.1086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017603982\n",
            "self.loss(score_1, v1) 0.15719438\n",
            "self.loss(score_2, v2) 0.034680113\n",
            "self.loss(score_3, v3) 0.012100081\n",
            "loss tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009776938\n",
            "self.loss(score_1, v1) 0.0118519375\n",
            "self.loss(score_2, v2) 0.011684308\n",
            "self.loss(score_3, v3) 0.007736007\n",
            "loss tensor(0.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008370769\n",
            "self.loss(score_1, v1) 0.009470499\n",
            "self.loss(score_2, v2) 0.009497145\n",
            "self.loss(score_3, v3) 0.00524587\n",
            "loss tensor(0.0326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.023898361\n",
            "self.loss(score_1, v1) 0.01716235\n",
            "self.loss(score_2, v2) 0.011441552\n",
            "self.loss(score_3, v3) 0.0100763105\n",
            "loss tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.02056722\n",
            "self.loss(score_1, v1) 0.028552538\n",
            "self.loss(score_2, v2) 0.013357541\n",
            "self.loss(score_3, v3) 0.012494466\n",
            "loss tensor(0.0750, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056586694\n",
            "self.loss(score_1, v1) 0.041115817\n",
            "self.loss(score_2, v2) 0.03422357\n",
            "self.loss(score_3, v3) 0.01476489\n",
            "loss tensor(0.1467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015594893\n",
            "self.loss(score_1, v1) 0.00921978\n",
            "self.loss(score_2, v2) 0.014290819\n",
            "self.loss(score_3, v3) 0.013595985\n",
            "loss tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011209822\n",
            "self.loss(score_1, v1) 0.02068918\n",
            "self.loss(score_2, v2) 0.029141355\n",
            "self.loss(score_3, v3) 0.010767372\n",
            "loss tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007724999\n",
            "self.loss(score_1, v1) 0.0061927335\n",
            "self.loss(score_2, v2) 0.007256397\n",
            "self.loss(score_3, v3) 0.006476574\n",
            "loss tensor(0.0277, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01869139\n",
            "self.loss(score_1, v1) 0.12973891\n",
            "self.loss(score_2, v2) 0.12501486\n",
            "self.loss(score_3, v3) 0.026688287\n",
            "loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015701989\n",
            "self.loss(score_1, v1) 0.014978641\n",
            "self.loss(score_2, v2) 0.016546048\n",
            "self.loss(score_3, v3) 0.009502657\n",
            "loss tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011805418\n",
            "self.loss(score_1, v1) 0.010533346\n",
            "self.loss(score_2, v2) 0.011417394\n",
            "self.loss(score_3, v3) 0.012953618\n",
            "loss tensor(0.0467, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019762129\n",
            "self.loss(score_1, v1) 0.041542538\n",
            "self.loss(score_2, v2) 0.033215057\n",
            "self.loss(score_3, v3) 0.021383695\n",
            "loss tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009394657\n",
            "self.loss(score_1, v1) 0.017339537\n",
            "self.loss(score_2, v2) 0.037031375\n",
            "self.loss(score_3, v3) 0.013376825\n",
            "loss tensor(0.0771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05789917\n",
            "self.loss(score_1, v1) 0.03005902\n",
            "self.loss(score_2, v2) 0.03137938\n",
            "self.loss(score_3, v3) 0.012041934\n",
            "loss tensor(0.1314, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.032442793\n",
            "self.loss(score_1, v1) 0.017637935\n",
            "self.loss(score_2, v2) 0.01480287\n",
            "self.loss(score_3, v3) 0.011536783\n",
            "loss tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.025699586\n",
            "self.loss(score_1, v1) 0.04552331\n",
            "self.loss(score_2, v2) 0.023228789\n",
            "self.loss(score_3, v3) 0.01177881\n",
            "loss tensor(0.1062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.025062809\n",
            "self.loss(score_1, v1) 0.026068276\n",
            "self.loss(score_2, v2) 0.02354837\n",
            "self.loss(score_3, v3) 0.008900512\n",
            "loss tensor(0.0836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013401963\n",
            "self.loss(score_1, v1) 0.013224788\n",
            "self.loss(score_2, v2) 0.022969682\n",
            "self.loss(score_3, v3) 0.012761621\n",
            "loss tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.036909323\n",
            "self.loss(score_1, v1) 0.023087408\n",
            "self.loss(score_2, v2) 0.032674033\n",
            "self.loss(score_3, v3) 0.010201225\n",
            "loss tensor(0.1029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012881739\n",
            "self.loss(score_1, v1) 0.062388483\n",
            "self.loss(score_2, v2) 0.049156327\n",
            "self.loss(score_3, v3) 0.011358242\n",
            "loss tensor(0.1358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015065122\n",
            "self.loss(score_1, v1) 0.01068237\n",
            "self.loss(score_2, v2) 0.0076599657\n",
            "self.loss(score_3, v3) 0.010349861\n",
            "loss tensor(0.0438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01788258\n",
            "self.loss(score_1, v1) 0.025032304\n",
            "self.loss(score_2, v2) 0.013897216\n",
            "self.loss(score_3, v3) 0.011702245\n",
            "loss tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06254618\n",
            "self.loss(score_1, v1) 0.017713232\n",
            "self.loss(score_2, v2) 0.025257241\n",
            "self.loss(score_3, v3) 0.015246054\n",
            "loss tensor(0.1208, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014310656\n",
            "self.loss(score_1, v1) 0.024679394\n",
            "self.loss(score_2, v2) 0.021045314\n",
            "self.loss(score_3, v3) 0.012264118\n",
            "loss tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015193058\n",
            "self.loss(score_1, v1) 0.015270816\n",
            "self.loss(score_2, v2) 0.007121708\n",
            "self.loss(score_3, v3) 0.0070509487\n",
            "loss tensor(0.0446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012645547\n",
            "self.loss(score_1, v1) 0.014494575\n",
            "self.loss(score_2, v2) 0.016814377\n",
            "self.loss(score_3, v3) 0.01023073\n",
            "loss tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008837687\n",
            "self.loss(score_1, v1) 0.006992681\n",
            "self.loss(score_2, v2) 0.011120327\n",
            "self.loss(score_3, v3) 0.011394283\n",
            "loss tensor(0.0383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006607647\n",
            "self.loss(score_1, v1) 0.007434198\n",
            "self.loss(score_2, v2) 0.011126125\n",
            "self.loss(score_3, v3) 0.008801125\n",
            "loss tensor(0.0340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06231107\n",
            "self.loss(score_1, v1) 0.03166661\n",
            "self.loss(score_2, v2) 0.06879572\n",
            "self.loss(score_3, v3) 0.013567865\n",
            "loss tensor(0.1763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010067841\n",
            "self.loss(score_1, v1) 0.040719677\n",
            "self.loss(score_2, v2) 0.028676104\n",
            "self.loss(score_3, v3) 0.02099721\n",
            "loss tensor(0.1005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012530242\n",
            "self.loss(score_1, v1) 0.0074057677\n",
            "self.loss(score_2, v2) 0.0059811627\n",
            "self.loss(score_3, v3) 0.008495535\n",
            "loss tensor(0.0344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013324032\n",
            "self.loss(score_1, v1) 0.01660306\n",
            "self.loss(score_2, v2) 0.026568536\n",
            "self.loss(score_3, v3) 0.015483126\n",
            "loss tensor(0.0720, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009870955\n",
            "self.loss(score_1, v1) 0.020429792\n",
            "self.loss(score_2, v2) 0.022678524\n",
            "self.loss(score_3, v3) 0.0994288\n",
            "loss tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007411753\n",
            "self.loss(score_1, v1) 0.010949005\n",
            "self.loss(score_2, v2) 0.018467646\n",
            "self.loss(score_3, v3) 0.011287491\n",
            "loss tensor(0.0481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05719972\n",
            "self.loss(score_1, v1) 0.022968689\n",
            "self.loss(score_2, v2) 0.095577486\n",
            "self.loss(score_3, v3) 0.012136931\n",
            "loss tensor(0.1879, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01160625\n",
            "self.loss(score_1, v1) 0.008872114\n",
            "self.loss(score_2, v2) 0.011486557\n",
            "self.loss(score_3, v3) 0.011348253\n",
            "loss tensor(0.0433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.027657997\n",
            "self.loss(score_1, v1) 0.035472527\n",
            "self.loss(score_2, v2) 0.022067638\n",
            "self.loss(score_3, v3) 0.009625733\n",
            "loss tensor(0.0948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0118151335\n",
            "self.loss(score_1, v1) 0.010588712\n",
            "self.loss(score_2, v2) 0.005244701\n",
            "self.loss(score_3, v3) 0.0055507068\n",
            "loss tensor(0.0332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009488174\n",
            "self.loss(score_1, v1) 0.010900724\n",
            "self.loss(score_2, v2) 0.011091059\n",
            "self.loss(score_3, v3) 0.009421944\n",
            "loss tensor(0.0409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0081453\n",
            "self.loss(score_1, v1) 0.012394342\n",
            "self.loss(score_2, v2) 0.011293157\n",
            "self.loss(score_3, v3) 0.009051175\n",
            "loss tensor(0.0409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010334694\n",
            "self.loss(score_1, v1) 0.023560297\n",
            "self.loss(score_2, v2) 0.03738742\n",
            "self.loss(score_3, v3) 0.01180159\n",
            "loss tensor(0.0831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010557815\n",
            "self.loss(score_1, v1) 0.010500639\n",
            "self.loss(score_2, v2) 0.019029275\n",
            "self.loss(score_3, v3) 0.009820525\n",
            "loss tensor(0.0499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01736547\n",
            "self.loss(score_1, v1) 0.024112612\n",
            "self.loss(score_2, v2) 0.013183929\n",
            "self.loss(score_3, v3) 0.009009969\n",
            "loss tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01662532\n",
            "self.loss(score_1, v1) 0.010462647\n",
            "self.loss(score_2, v2) 0.009181493\n",
            "self.loss(score_3, v3) 0.010279839\n",
            "loss tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010784542\n",
            "self.loss(score_1, v1) 0.022354536\n",
            "self.loss(score_2, v2) 0.05789282\n",
            "self.loss(score_3, v3) 0.11576198\n",
            "loss tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010866519\n",
            "self.loss(score_1, v1) 0.014837052\n",
            "self.loss(score_2, v2) 0.019149413\n",
            "self.loss(score_3, v3) 0.013712975\n",
            "loss tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008809466\n",
            "self.loss(score_1, v1) 0.007744423\n",
            "self.loss(score_2, v2) 0.009018981\n",
            "self.loss(score_3, v3) 0.008569445\n",
            "loss tensor(0.0341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0206893\n",
            "self.loss(score_1, v1) 0.020467026\n",
            "self.loss(score_2, v2) 0.009315123\n",
            "self.loss(score_3, v3) 0.00903821\n",
            "loss tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009966691\n",
            "self.loss(score_1, v1) 0.009414786\n",
            "self.loss(score_2, v2) 0.017819874\n",
            "self.loss(score_3, v3) 0.009025189\n",
            "loss tensor(0.0462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008566738\n",
            "self.loss(score_1, v1) 0.015489966\n",
            "self.loss(score_2, v2) 0.018260982\n",
            "self.loss(score_3, v3) 0.015029303\n",
            "loss tensor(0.0573, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0113268765\n",
            "self.loss(score_1, v1) 0.020977937\n",
            "self.loss(score_2, v2) 0.025658078\n",
            "self.loss(score_3, v3) 0.008581771\n",
            "loss tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007869497\n",
            "self.loss(score_1, v1) 0.013633325\n",
            "self.loss(score_2, v2) 0.012306149\n",
            "self.loss(score_3, v3) 0.0081603415\n",
            "loss tensor(0.0420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0148763005\n",
            "self.loss(score_1, v1) 0.025918942\n",
            "self.loss(score_2, v2) 0.027455054\n",
            "self.loss(score_3, v3) 0.014083984\n",
            "loss tensor(0.0823, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012023602\n",
            "self.loss(score_1, v1) 0.021134377\n",
            "self.loss(score_2, v2) 0.01789183\n",
            "self.loss(score_3, v3) 0.015440647\n",
            "loss tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010365158\n",
            "self.loss(score_1, v1) 0.019596918\n",
            "self.loss(score_2, v2) 0.057016227\n",
            "self.loss(score_3, v3) 0.044885516\n",
            "loss tensor(0.1319, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017347023\n",
            "self.loss(score_1, v1) 0.0097189\n",
            "self.loss(score_2, v2) 0.013393675\n",
            "self.loss(score_3, v3) 0.010171111\n",
            "loss tensor(0.0506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.027820265\n",
            "self.loss(score_1, v1) 0.024026733\n",
            "self.loss(score_2, v2) 0.008863162\n",
            "self.loss(score_3, v3) 0.0077729397\n",
            "loss tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.022529773\n",
            "self.loss(score_1, v1) 0.044097356\n",
            "self.loss(score_2, v2) 0.03750177\n",
            "self.loss(score_3, v3) 0.009909315\n",
            "loss tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06386034\n",
            "self.loss(score_1, v1) 0.06805014\n",
            "self.loss(score_2, v2) 0.075083084\n",
            "self.loss(score_3, v3) 0.012555854\n",
            "loss tensor(0.2195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013125196\n",
            "self.loss(score_1, v1) 0.023912946\n",
            "self.loss(score_2, v2) 0.009171737\n",
            "self.loss(score_3, v3) 0.0072367545\n",
            "loss tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019466978\n",
            "self.loss(score_1, v1) 0.033455458\n",
            "self.loss(score_2, v2) 0.026780935\n",
            "self.loss(score_3, v3) 0.009656205\n",
            "loss tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0053151604\n",
            "self.loss(score_1, v1) 0.026500206\n",
            "self.loss(score_2, v2) 0.019039381\n",
            "self.loss(score_3, v3) 0.007482647\n",
            "loss tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017788881\n",
            "self.loss(score_1, v1) 0.03395318\n",
            "self.loss(score_2, v2) 0.014695396\n",
            "self.loss(score_3, v3) 0.0100078\n",
            "loss tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011188601\n",
            "self.loss(score_1, v1) 0.010250695\n",
            "self.loss(score_2, v2) 0.015688088\n",
            "self.loss(score_3, v3) 0.011238128\n",
            "loss tensor(0.0484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008534482\n",
            "self.loss(score_1, v1) 0.010222559\n",
            "self.loss(score_2, v2) 0.009889801\n",
            "self.loss(score_3, v3) 0.0070963274\n",
            "loss tensor(0.0357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.023573603\n",
            "self.loss(score_1, v1) 0.020172648\n",
            "self.loss(score_2, v2) 0.013130346\n",
            "self.loss(score_3, v3) 0.0098141385\n",
            "loss tensor(0.0667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.020863349\n",
            "self.loss(score_1, v1) 0.028587703\n",
            "self.loss(score_2, v2) 0.033147812\n",
            "self.loss(score_3, v3) 0.00903612\n",
            "loss tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008809751\n",
            "self.loss(score_1, v1) 0.0084414305\n",
            "self.loss(score_2, v2) 0.012065344\n",
            "self.loss(score_3, v3) 0.012488482\n",
            "loss tensor(0.0418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018463774\n",
            "self.loss(score_1, v1) 0.01444505\n",
            "self.loss(score_2, v2) 0.014246952\n",
            "self.loss(score_3, v3) 0.008978924\n",
            "loss tensor(0.0561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009724073\n",
            "self.loss(score_1, v1) 0.009034357\n",
            "self.loss(score_2, v2) 0.0130230095\n",
            "self.loss(score_3, v3) 0.012551405\n",
            "loss tensor(0.0443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015881902\n",
            "self.loss(score_1, v1) 0.05317204\n",
            "self.loss(score_2, v2) 0.056436628\n",
            "self.loss(score_3, v3) 0.012985039\n",
            "loss tensor(0.1385, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 0.09340929457099195, Train Accuracy : 0.9992643428089238\n",
            " Validation Accuracy : 6.6021414989956995\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.0066861887\n",
            "self.loss(score_1, v1) 0.020608978\n",
            "self.loss(score_2, v2) 0.06587429\n",
            "self.loss(score_3, v3) 0.040431477\n",
            "loss tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00646854\n",
            "self.loss(score_1, v1) 0.011621107\n",
            "self.loss(score_2, v2) 0.1195897\n",
            "self.loss(score_3, v3) 0.030587794\n",
            "loss tensor(0.1683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03553619\n",
            "self.loss(score_1, v1) 0.06761004\n",
            "self.loss(score_2, v2) 0.104867026\n",
            "self.loss(score_3, v3) 0.0067227506\n",
            "loss tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.027241252\n",
            "self.loss(score_1, v1) 0.033108193\n",
            "self.loss(score_2, v2) 0.020004138\n",
            "self.loss(score_3, v3) 0.010830478\n",
            "loss tensor(0.0912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011644721\n",
            "self.loss(score_1, v1) 0.054329384\n",
            "self.loss(score_2, v2) 0.03188418\n",
            "self.loss(score_3, v3) 0.007740496\n",
            "loss tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007835682\n",
            "self.loss(score_1, v1) 0.0071279383\n",
            "self.loss(score_2, v2) 0.00779011\n",
            "self.loss(score_3, v3) 0.0072160354\n",
            "loss tensor(0.0300, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008218426\n",
            "self.loss(score_1, v1) 0.007779225\n",
            "self.loss(score_2, v2) 0.009668653\n",
            "self.loss(score_3, v3) 0.008271045\n",
            "loss tensor(0.0339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013000748\n",
            "self.loss(score_1, v1) 0.010718234\n",
            "self.loss(score_2, v2) 0.007412767\n",
            "self.loss(score_3, v3) 0.006419793\n",
            "loss tensor(0.0376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010123332\n",
            "self.loss(score_1, v1) 0.012455563\n",
            "self.loss(score_2, v2) 0.013564791\n",
            "self.loss(score_3, v3) 0.010323278\n",
            "loss tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0093921535\n",
            "self.loss(score_1, v1) 0.009434411\n",
            "self.loss(score_2, v2) 0.014928283\n",
            "self.loss(score_3, v3) 0.013705742\n",
            "loss tensor(0.0475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.029313143\n",
            "self.loss(score_1, v1) 0.06908522\n",
            "self.loss(score_2, v2) 0.034433536\n",
            "self.loss(score_3, v3) 0.010988147\n",
            "loss tensor(0.1438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012120329\n",
            "self.loss(score_1, v1) 0.013860934\n",
            "self.loss(score_2, v2) 0.013565648\n",
            "self.loss(score_3, v3) 0.008972859\n",
            "loss tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013853004\n",
            "self.loss(score_1, v1) 0.039658677\n",
            "self.loss(score_2, v2) 0.054676656\n",
            "self.loss(score_3, v3) 0.0096977465\n",
            "loss tensor(0.1179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.023186915\n",
            "self.loss(score_1, v1) 0.02299717\n",
            "self.loss(score_2, v2) 0.0322729\n",
            "self.loss(score_3, v3) 0.010818803\n",
            "loss tensor(0.0893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0085621895\n",
            "self.loss(score_1, v1) 0.012704882\n",
            "self.loss(score_2, v2) 0.016600508\n",
            "self.loss(score_3, v3) 0.008215192\n",
            "loss tensor(0.0461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01891647\n",
            "self.loss(score_1, v1) 0.023137625\n",
            "self.loss(score_2, v2) 0.01070226\n",
            "self.loss(score_3, v3) 0.01174009\n",
            "loss tensor(0.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012281975\n",
            "self.loss(score_1, v1) 0.014107772\n",
            "self.loss(score_2, v2) 0.012448392\n",
            "self.loss(score_3, v3) 0.011407976\n",
            "loss tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010109578\n",
            "self.loss(score_1, v1) 0.013545107\n",
            "self.loss(score_2, v2) 0.013662638\n",
            "self.loss(score_3, v3) 0.009882138\n",
            "loss tensor(0.0472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05529919\n",
            "self.loss(score_1, v1) 0.061450835\n",
            "self.loss(score_2, v2) 0.09677523\n",
            "self.loss(score_3, v3) 0.014007201\n",
            "loss tensor(0.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012772656\n",
            "self.loss(score_1, v1) 0.032259516\n",
            "self.loss(score_2, v2) 0.040453587\n",
            "self.loss(score_3, v3) 0.012890302\n",
            "loss tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01259263\n",
            "self.loss(score_1, v1) 0.013664137\n",
            "self.loss(score_2, v2) 0.013078713\n",
            "self.loss(score_3, v3) 0.00877515\n",
            "loss tensor(0.0481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.025542626\n",
            "self.loss(score_1, v1) 0.023464179\n",
            "self.loss(score_2, v2) 0.009836853\n",
            "self.loss(score_3, v3) 0.010876068\n",
            "loss tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007521856\n",
            "self.loss(score_1, v1) 0.015718453\n",
            "self.loss(score_2, v2) 0.024904609\n",
            "self.loss(score_3, v3) 0.013305466\n",
            "loss tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00724338\n",
            "self.loss(score_1, v1) 0.0057961573\n",
            "self.loss(score_2, v2) 0.0071479776\n",
            "self.loss(score_3, v3) 0.007624613\n",
            "loss tensor(0.0278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00914614\n",
            "self.loss(score_1, v1) 0.008383903\n",
            "self.loss(score_2, v2) 0.007364708\n",
            "self.loss(score_3, v3) 0.0077524693\n",
            "loss tensor(0.0326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01014213\n",
            "self.loss(score_1, v1) 0.012646182\n",
            "self.loss(score_2, v2) 0.016413733\n",
            "self.loss(score_3, v3) 0.009343332\n",
            "loss tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.038832672\n",
            "self.loss(score_1, v1) 0.024403905\n",
            "self.loss(score_2, v2) 0.02044843\n",
            "self.loss(score_3, v3) 0.011484109\n",
            "loss tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008442276\n",
            "self.loss(score_1, v1) 0.01195964\n",
            "self.loss(score_2, v2) 0.012920181\n",
            "self.loss(score_3, v3) 0.010583848\n",
            "loss tensor(0.0439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018151611\n",
            "self.loss(score_1, v1) 0.024634732\n",
            "self.loss(score_2, v2) 0.024195643\n",
            "self.loss(score_3, v3) 0.013154018\n",
            "loss tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009307546\n",
            "self.loss(score_1, v1) 0.01092915\n",
            "self.loss(score_2, v2) 0.02458556\n",
            "self.loss(score_3, v3) 0.010704756\n",
            "loss tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.024272006\n",
            "self.loss(score_1, v1) 0.06308756\n",
            "self.loss(score_2, v2) 0.06460887\n",
            "self.loss(score_3, v3) 0.008872072\n",
            "loss tensor(0.1608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009985872\n",
            "self.loss(score_1, v1) 0.007827905\n",
            "self.loss(score_2, v2) 0.011190355\n",
            "self.loss(score_3, v3) 0.008846824\n",
            "loss tensor(0.0379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051448446\n",
            "self.loss(score_1, v1) 0.12600242\n",
            "self.loss(score_2, v2) 0.1279712\n",
            "self.loss(score_3, v3) 0.2884698\n",
            "loss tensor(0.5939, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014274305\n",
            "self.loss(score_1, v1) 0.008070437\n",
            "self.loss(score_2, v2) 0.00930332\n",
            "self.loss(score_3, v3) 0.010703961\n",
            "loss tensor(0.0424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01038103\n",
            "self.loss(score_1, v1) 0.010430734\n",
            "self.loss(score_2, v2) 0.019756924\n",
            "self.loss(score_3, v3) 0.010029757\n",
            "loss tensor(0.0506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01063249\n",
            "self.loss(score_1, v1) 0.010783423\n",
            "self.loss(score_2, v2) 0.014811227\n",
            "self.loss(score_3, v3) 0.011540216\n",
            "loss tensor(0.0478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008692894\n",
            "self.loss(score_1, v1) 0.009740542\n",
            "self.loss(score_2, v2) 0.011494054\n",
            "self.loss(score_3, v3) 0.01177332\n",
            "loss tensor(0.0417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009699604\n",
            "self.loss(score_1, v1) 0.022517778\n",
            "self.loss(score_2, v2) 0.027988464\n",
            "self.loss(score_3, v3) 0.01617288\n",
            "loss tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.026455611\n",
            "self.loss(score_1, v1) 0.019582594\n",
            "self.loss(score_2, v2) 0.011867079\n",
            "self.loss(score_3, v3) 0.010921308\n",
            "loss tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011343266\n",
            "self.loss(score_1, v1) 0.023260351\n",
            "self.loss(score_2, v2) 0.032102875\n",
            "self.loss(score_3, v3) 0.0974428\n",
            "loss tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014242737\n",
            "self.loss(score_1, v1) 0.016447602\n",
            "self.loss(score_2, v2) 0.007529368\n",
            "self.loss(score_3, v3) 0.0055416836\n",
            "loss tensor(0.0438, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06287382\n",
            "self.loss(score_1, v1) 0.12116826\n",
            "self.loss(score_2, v2) 0.08744998\n",
            "self.loss(score_3, v3) 0.007346974\n",
            "loss tensor(0.2788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011402123\n",
            "self.loss(score_1, v1) 0.009667906\n",
            "self.loss(score_2, v2) 0.009920805\n",
            "self.loss(score_3, v3) 0.013805726\n",
            "loss tensor(0.0448, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0072949002\n",
            "self.loss(score_1, v1) 0.010233612\n",
            "self.loss(score_2, v2) 0.011090655\n",
            "self.loss(score_3, v3) 0.0098076165\n",
            "loss tensor(0.0384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010644847\n",
            "self.loss(score_1, v1) 0.010392702\n",
            "self.loss(score_2, v2) 0.013501764\n",
            "self.loss(score_3, v3) 0.013433498\n",
            "loss tensor(0.0480, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009341908\n",
            "self.loss(score_1, v1) 0.013079704\n",
            "self.loss(score_2, v2) 0.015048904\n",
            "self.loss(score_3, v3) 0.007418194\n",
            "loss tensor(0.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009122357\n",
            "self.loss(score_1, v1) 0.010818223\n",
            "self.loss(score_2, v2) 0.0135263335\n",
            "self.loss(score_3, v3) 0.011496879\n",
            "loss tensor(0.0450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.030214284\n",
            "self.loss(score_1, v1) 0.020967538\n",
            "self.loss(score_2, v2) 0.061422203\n",
            "self.loss(score_3, v3) 0.008852456\n",
            "loss tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006816561\n",
            "self.loss(score_1, v1) 0.0049879462\n",
            "self.loss(score_2, v2) 0.009422529\n",
            "self.loss(score_3, v3) 0.0073780403\n",
            "loss tensor(0.0286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013340818\n",
            "self.loss(score_1, v1) 0.019077554\n",
            "self.loss(score_2, v2) 0.017922813\n",
            "self.loss(score_3, v3) 0.014799685\n",
            "loss tensor(0.0651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019041354\n",
            "self.loss(score_1, v1) 0.035767376\n",
            "self.loss(score_2, v2) 0.025848007\n",
            "self.loss(score_3, v3) 0.018983897\n",
            "loss tensor(0.0996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008536887\n",
            "self.loss(score_1, v1) 0.008365207\n",
            "self.loss(score_2, v2) 0.010309846\n",
            "self.loss(score_3, v3) 0.010959797\n",
            "loss tensor(0.0382, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.030343432\n",
            "self.loss(score_1, v1) 0.043198694\n",
            "self.loss(score_2, v2) 0.09165716\n",
            "self.loss(score_3, v3) 0.13278615\n",
            "loss tensor(0.2980, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015624085\n",
            "self.loss(score_1, v1) 0.0096003525\n",
            "self.loss(score_2, v2) 0.010353775\n",
            "self.loss(score_3, v3) 0.01159846\n",
            "loss tensor(0.0472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.122242205\n",
            "self.loss(score_1, v1) 0.07813746\n",
            "self.loss(score_2, v2) 0.05043464\n",
            "self.loss(score_3, v3) 0.015745968\n",
            "loss tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01180622\n",
            "self.loss(score_1, v1) 0.012082431\n",
            "self.loss(score_2, v2) 0.021302363\n",
            "self.loss(score_3, v3) 0.011528088\n",
            "loss tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017116472\n",
            "self.loss(score_1, v1) 0.022787336\n",
            "self.loss(score_2, v2) 0.015204816\n",
            "self.loss(score_3, v3) 0.010589601\n",
            "loss tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012450861\n",
            "self.loss(score_1, v1) 0.03438959\n",
            "self.loss(score_2, v2) 0.04075306\n",
            "self.loss(score_3, v3) 0.010671991\n",
            "loss tensor(0.0983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017718276\n",
            "self.loss(score_1, v1) 0.02049041\n",
            "self.loss(score_2, v2) 0.013623116\n",
            "self.loss(score_3, v3) 0.0061556487\n",
            "loss tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008634625\n",
            "self.loss(score_1, v1) 0.007095884\n",
            "self.loss(score_2, v2) 0.010449451\n",
            "self.loss(score_3, v3) 0.012535784\n",
            "loss tensor(0.0387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0075294543\n",
            "self.loss(score_1, v1) 0.09165098\n",
            "self.loss(score_2, v2) 0.043890018\n",
            "self.loss(score_3, v3) 0.0047047804\n",
            "loss tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.02071454\n",
            "self.loss(score_1, v1) 0.06105945\n",
            "self.loss(score_2, v2) 0.017527573\n",
            "self.loss(score_3, v3) 0.011162074\n",
            "loss tensor(0.1105, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009754954\n",
            "self.loss(score_1, v1) 0.008286673\n",
            "self.loss(score_2, v2) 0.010081283\n",
            "self.loss(score_3, v3) 0.0095233135\n",
            "loss tensor(0.0376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15001675\n",
            "self.loss(score_1, v1) 0.06477439\n",
            "self.loss(score_2, v2) 0.04152103\n",
            "self.loss(score_3, v3) 0.03149115\n",
            "loss tensor(0.2878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015911404\n",
            "self.loss(score_1, v1) 0.05078139\n",
            "self.loss(score_2, v2) 0.032215875\n",
            "self.loss(score_3, v3) 0.012471262\n",
            "loss tensor(0.1114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052519422\n",
            "self.loss(score_1, v1) 0.031094706\n",
            "self.loss(score_2, v2) 0.04203086\n",
            "self.loss(score_3, v3) 0.011842176\n",
            "loss tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013731356\n",
            "self.loss(score_1, v1) 0.03355702\n",
            "self.loss(score_2, v2) 0.035799578\n",
            "self.loss(score_3, v3) 0.012461759\n",
            "loss tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009708036\n",
            "self.loss(score_1, v1) 0.0115799\n",
            "self.loss(score_2, v2) 0.015614678\n",
            "self.loss(score_3, v3) 0.009244034\n",
            "loss tensor(0.0461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015433675\n",
            "self.loss(score_1, v1) 0.013007021\n",
            "self.loss(score_2, v2) 0.011386189\n",
            "self.loss(score_3, v3) 0.007606697\n",
            "loss tensor(0.0474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013246718\n",
            "self.loss(score_1, v1) 0.03610645\n",
            "self.loss(score_2, v2) 0.025386749\n",
            "self.loss(score_3, v3) 0.010055569\n",
            "loss tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00890392\n",
            "self.loss(score_1, v1) 0.011547587\n",
            "self.loss(score_2, v2) 0.023510829\n",
            "self.loss(score_3, v3) 0.010069252\n",
            "loss tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051919974\n",
            "self.loss(score_1, v1) 0.07718428\n",
            "self.loss(score_2, v2) 0.030094447\n",
            "self.loss(score_3, v3) 0.009597177\n",
            "loss tensor(0.1688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017772207\n",
            "self.loss(score_1, v1) 0.041084073\n",
            "self.loss(score_2, v2) 0.03257504\n",
            "self.loss(score_3, v3) 0.0141704315\n",
            "loss tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014613379\n",
            "self.loss(score_1, v1) 0.11582102\n",
            "self.loss(score_2, v2) 0.07882691\n",
            "self.loss(score_3, v3) 0.032751705\n",
            "loss tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008534093\n",
            "self.loss(score_1, v1) 0.010700383\n",
            "self.loss(score_2, v2) 0.014721058\n",
            "self.loss(score_3, v3) 0.008290732\n",
            "loss tensor(0.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008011697\n",
            "self.loss(score_1, v1) 0.005558023\n",
            "self.loss(score_2, v2) 0.008535607\n",
            "self.loss(score_3, v3) 0.006982684\n",
            "loss tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013295104\n",
            "self.loss(score_1, v1) 0.01694404\n",
            "self.loss(score_2, v2) 0.009092276\n",
            "self.loss(score_3, v3) 0.010890481\n",
            "loss tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010922444\n",
            "self.loss(score_1, v1) 0.010458529\n",
            "self.loss(score_2, v2) 0.013431019\n",
            "self.loss(score_3, v3) 0.011204491\n",
            "loss tensor(0.0460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011126097\n",
            "self.loss(score_1, v1) 0.02569573\n",
            "self.loss(score_2, v2) 0.021966428\n",
            "self.loss(score_3, v3) 0.009271608\n",
            "loss tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0077667586\n",
            "self.loss(score_1, v1) 0.009893765\n",
            "self.loss(score_2, v2) 0.008358011\n",
            "self.loss(score_3, v3) 0.0061331224\n",
            "loss tensor(0.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.046647456\n",
            "self.loss(score_1, v1) 0.04911395\n",
            "self.loss(score_2, v2) 0.03740135\n",
            "self.loss(score_3, v3) 0.011392291\n",
            "loss tensor(0.1446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009722175\n",
            "self.loss(score_1, v1) 0.01346914\n",
            "self.loss(score_2, v2) 0.012645332\n",
            "self.loss(score_3, v3) 0.009246392\n",
            "loss tensor(0.0451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008030058\n",
            "self.loss(score_1, v1) 0.0096936645\n",
            "self.loss(score_2, v2) 0.008141474\n",
            "self.loss(score_3, v3) 0.008465272\n",
            "loss tensor(0.0343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013413731\n",
            "self.loss(score_1, v1) 0.015892802\n",
            "self.loss(score_2, v2) 0.012064433\n",
            "self.loss(score_3, v3) 0.008643705\n",
            "loss tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009424869\n",
            "self.loss(score_1, v1) 0.03691589\n",
            "self.loss(score_2, v2) 0.017900744\n",
            "self.loss(score_3, v3) 0.01148682\n",
            "loss tensor(0.0757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013601646\n",
            "self.loss(score_1, v1) 0.016346294\n",
            "self.loss(score_2, v2) 0.017901847\n",
            "self.loss(score_3, v3) 0.011142114\n",
            "loss tensor(0.0590, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01767547\n",
            "self.loss(score_1, v1) 0.048740905\n",
            "self.loss(score_2, v2) 0.053509302\n",
            "self.loss(score_3, v3) 0.076501705\n",
            "loss tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016538873\n",
            "self.loss(score_1, v1) 0.015823247\n",
            "self.loss(score_2, v2) 0.021928204\n",
            "self.loss(score_3, v3) 0.008806297\n",
            "loss tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0069639958\n",
            "self.loss(score_1, v1) 0.007958416\n",
            "self.loss(score_2, v2) 0.01710403\n",
            "self.loss(score_3, v3) 0.011891805\n",
            "loss tensor(0.0439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00782222\n",
            "self.loss(score_1, v1) 0.03163951\n",
            "self.loss(score_2, v2) 0.024653267\n",
            "self.loss(score_3, v3) 0.010391703\n",
            "loss tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07399184\n",
            "self.loss(score_1, v1) 0.031208497\n",
            "self.loss(score_2, v2) 0.02623352\n",
            "self.loss(score_3, v3) 0.008532002\n",
            "loss tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015458235\n",
            "self.loss(score_1, v1) 0.011652835\n",
            "self.loss(score_2, v2) 0.010096177\n",
            "self.loss(score_3, v3) 0.01150579\n",
            "loss tensor(0.0487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017068505\n",
            "self.loss(score_1, v1) 0.03853068\n",
            "self.loss(score_2, v2) 0.031310562\n",
            "self.loss(score_3, v3) 0.014538783\n",
            "loss tensor(0.1014, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.062665746\n",
            "self.loss(score_1, v1) 0.021062791\n",
            "self.loss(score_2, v2) 0.059622597\n",
            "self.loss(score_3, v3) 0.03376038\n",
            "loss tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015137449\n",
            "self.loss(score_1, v1) 0.0096569825\n",
            "self.loss(score_2, v2) 0.015288923\n",
            "self.loss(score_3, v3) 0.008706555\n",
            "loss tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052803148\n",
            "self.loss(score_1, v1) 0.047108606\n",
            "self.loss(score_2, v2) 0.014554684\n",
            "self.loss(score_3, v3) 0.0084096715\n",
            "loss tensor(0.1229, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014665814\n",
            "self.loss(score_1, v1) 0.044093225\n",
            "self.loss(score_2, v2) 0.030436393\n",
            "self.loss(score_3, v3) 0.012821407\n",
            "loss tensor(0.1020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009501217\n",
            "self.loss(score_1, v1) 0.008816175\n",
            "self.loss(score_2, v2) 0.007982042\n",
            "self.loss(score_3, v3) 0.008853002\n",
            "loss tensor(0.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007597172\n",
            "self.loss(score_1, v1) 0.012468427\n",
            "self.loss(score_2, v2) 0.015973844\n",
            "self.loss(score_3, v3) 0.010025495\n",
            "loss tensor(0.0461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.02400597\n",
            "self.loss(score_1, v1) 0.062559955\n",
            "self.loss(score_2, v2) 0.073379196\n",
            "self.loss(score_3, v3) 0.019943103\n",
            "loss tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009579166\n",
            "self.loss(score_1, v1) 0.073090546\n",
            "self.loss(score_2, v2) 0.07709365\n",
            "self.loss(score_3, v3) 0.064432606\n",
            "loss tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03994453\n",
            "self.loss(score_1, v1) 0.07629704\n",
            "self.loss(score_2, v2) 0.04442142\n",
            "self.loss(score_3, v3) 0.020093035\n",
            "loss tensor(0.1808, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058493\n",
            "self.loss(score_1, v1) 0.02749666\n",
            "self.loss(score_2, v2) 0.02310687\n",
            "self.loss(score_3, v3) 0.0073582414\n",
            "loss tensor(0.1165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.024112167\n",
            "self.loss(score_1, v1) 0.01280629\n",
            "self.loss(score_2, v2) 0.019224659\n",
            "self.loss(score_3, v3) 0.0114083905\n",
            "loss tensor(0.0676, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0069339527\n",
            "self.loss(score_1, v1) 0.0051369765\n",
            "self.loss(score_2, v2) 0.0077781966\n",
            "self.loss(score_3, v3) 0.0075107994\n",
            "loss tensor(0.0274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009729992\n",
            "self.loss(score_1, v1) 0.037601523\n",
            "self.loss(score_2, v2) 0.04973096\n",
            "self.loss(score_3, v3) 0.010430769\n",
            "loss tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017639056\n",
            "self.loss(score_1, v1) 0.096225165\n",
            "self.loss(score_2, v2) 0.030997995\n",
            "self.loss(score_3, v3) 0.02656843\n",
            "loss tensor(0.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011225514\n",
            "self.loss(score_1, v1) 0.008554292\n",
            "self.loss(score_2, v2) 0.008695407\n",
            "self.loss(score_3, v3) 0.009817373\n",
            "loss tensor(0.0383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009992401\n",
            "self.loss(score_1, v1) 0.0140191065\n",
            "self.loss(score_2, v2) 0.023904208\n",
            "self.loss(score_3, v3) 0.0106186895\n",
            "loss tensor(0.0585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007916162\n",
            "self.loss(score_1, v1) 0.10649355\n",
            "self.loss(score_2, v2) 0.120600395\n",
            "self.loss(score_3, v3) 0.10806176\n",
            "loss tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010125819\n",
            "self.loss(score_1, v1) 0.017377447\n",
            "self.loss(score_2, v2) 0.012966432\n",
            "self.loss(score_3, v3) 0.017348373\n",
            "loss tensor(0.0578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015610248\n",
            "self.loss(score_1, v1) 0.012460453\n",
            "self.loss(score_2, v2) 0.04094318\n",
            "self.loss(score_3, v3) 0.08466214\n",
            "loss tensor(0.1537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013224378\n",
            "self.loss(score_1, v1) 0.09568469\n",
            "self.loss(score_2, v2) 0.054717537\n",
            "self.loss(score_3, v3) 0.017079901\n",
            "loss tensor(0.1807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011336934\n",
            "self.loss(score_1, v1) 0.016002534\n",
            "self.loss(score_2, v2) 0.017194357\n",
            "self.loss(score_3, v3) 0.010134273\n",
            "loss tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014510746\n",
            "self.loss(score_1, v1) 0.019216217\n",
            "self.loss(score_2, v2) 0.018126715\n",
            "self.loss(score_3, v3) 0.012581227\n",
            "loss tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007059504\n",
            "self.loss(score_1, v1) 0.005850513\n",
            "self.loss(score_2, v2) 0.0111868745\n",
            "self.loss(score_3, v3) 0.008367649\n",
            "loss tensor(0.0325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012760351\n",
            "self.loss(score_1, v1) 0.015262675\n",
            "self.loss(score_2, v2) 0.009084564\n",
            "self.loss(score_3, v3) 0.011321349\n",
            "loss tensor(0.0484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01220874\n",
            "self.loss(score_1, v1) 0.010811196\n",
            "self.loss(score_2, v2) 0.008825366\n",
            "self.loss(score_3, v3) 0.008295891\n",
            "loss tensor(0.0401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007972045\n",
            "self.loss(score_1, v1) 0.007474997\n",
            "self.loss(score_2, v2) 0.00863158\n",
            "self.loss(score_3, v3) 0.0046705366\n",
            "loss tensor(0.0287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00875052\n",
            "self.loss(score_1, v1) 0.013575972\n",
            "self.loss(score_2, v2) 0.0043545444\n",
            "self.loss(score_3, v3) 0.004436376\n",
            "loss tensor(0.0311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13931148\n",
            "self.loss(score_1, v1) 0.052112333\n",
            "self.loss(score_2, v2) 0.10469422\n",
            "self.loss(score_3, v3) 0.039684914\n",
            "loss tensor(0.3358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0074329088\n",
            "self.loss(score_1, v1) 0.0067157126\n",
            "self.loss(score_2, v2) 0.007306012\n",
            "self.loss(score_3, v3) 0.006111719\n",
            "loss tensor(0.0276, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009748536\n",
            "self.loss(score_1, v1) 0.02687086\n",
            "self.loss(score_2, v2) 0.014780107\n",
            "self.loss(score_3, v3) 0.008344702\n",
            "loss tensor(0.0597, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0050277696\n",
            "self.loss(score_1, v1) 0.010481349\n",
            "self.loss(score_2, v2) 0.00819671\n",
            "self.loss(score_3, v3) 0.005911974\n",
            "loss tensor(0.0296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0073111528\n",
            "self.loss(score_1, v1) 0.01304048\n",
            "self.loss(score_2, v2) 0.01163694\n",
            "self.loss(score_3, v3) 0.010344923\n",
            "loss tensor(0.0423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017595215\n",
            "self.loss(score_1, v1) 0.019966904\n",
            "self.loss(score_2, v2) 0.02689631\n",
            "self.loss(score_3, v3) 0.018883992\n",
            "loss tensor(0.0833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015142602\n",
            "self.loss(score_1, v1) 0.021861877\n",
            "self.loss(score_2, v2) 0.023521861\n",
            "self.loss(score_3, v3) 0.014675683\n",
            "loss tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011651987\n",
            "self.loss(score_1, v1) 0.0159496\n",
            "self.loss(score_2, v2) 0.017354293\n",
            "self.loss(score_3, v3) 0.01228318\n",
            "loss tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015386811\n",
            "self.loss(score_1, v1) 0.010855696\n",
            "self.loss(score_2, v2) 0.0072922376\n",
            "self.loss(score_3, v3) 0.008229057\n",
            "loss tensor(0.0418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010891241\n",
            "self.loss(score_1, v1) 0.009621676\n",
            "self.loss(score_2, v2) 0.008280827\n",
            "self.loss(score_3, v3) 0.010206158\n",
            "loss tensor(0.0390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009183732\n",
            "self.loss(score_1, v1) 0.012357742\n",
            "self.loss(score_2, v2) 0.031383265\n",
            "self.loss(score_3, v3) 0.08882898\n",
            "loss tensor(0.1418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006844278\n",
            "self.loss(score_1, v1) 0.009554274\n",
            "self.loss(score_2, v2) 0.011075746\n",
            "self.loss(score_3, v3) 0.007004365\n",
            "loss tensor(0.0345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009275183\n",
            "self.loss(score_1, v1) 0.0154699115\n",
            "self.loss(score_2, v2) 0.016887885\n",
            "self.loss(score_3, v3) 0.012474582\n",
            "loss tensor(0.0541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009045351\n",
            "self.loss(score_1, v1) 0.030116608\n",
            "self.loss(score_2, v2) 0.079845674\n",
            "self.loss(score_3, v3) 0.048914995\n",
            "loss tensor(0.1679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009172077\n",
            "self.loss(score_1, v1) 0.059315033\n",
            "self.loss(score_2, v2) 0.10750702\n",
            "self.loss(score_3, v3) 0.12529238\n",
            "loss tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014357746\n",
            "self.loss(score_1, v1) 0.02345927\n",
            "self.loss(score_2, v2) 0.020991853\n",
            "self.loss(score_3, v3) 0.03155162\n",
            "loss tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012360172\n",
            "self.loss(score_1, v1) 0.027928453\n",
            "self.loss(score_2, v2) 0.020992244\n",
            "self.loss(score_3, v3) 0.016071307\n",
            "loss tensor(0.0774, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0075484915\n",
            "self.loss(score_1, v1) 0.0077596926\n",
            "self.loss(score_2, v2) 0.009756625\n",
            "self.loss(score_3, v3) 0.008043582\n",
            "loss tensor(0.0331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011256169\n",
            "self.loss(score_1, v1) 0.019339893\n",
            "self.loss(score_2, v2) 0.027127475\n",
            "self.loss(score_3, v3) 0.018706696\n",
            "loss tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008795156\n",
            "self.loss(score_1, v1) 0.012236272\n",
            "self.loss(score_2, v2) 0.014810602\n",
            "self.loss(score_3, v3) 0.0073149474\n",
            "loss tensor(0.0432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017722556\n",
            "self.loss(score_1, v1) 0.017815065\n",
            "self.loss(score_2, v2) 0.018440237\n",
            "self.loss(score_3, v3) 0.01496218\n",
            "loss tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0101832\n",
            "self.loss(score_1, v1) 0.03371791\n",
            "self.loss(score_2, v2) 0.029672196\n",
            "self.loss(score_3, v3) 0.011837011\n",
            "loss tensor(0.0854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012310911\n",
            "self.loss(score_1, v1) 0.013369607\n",
            "self.loss(score_2, v2) 0.011399338\n",
            "self.loss(score_3, v3) 0.008974455\n",
            "loss tensor(0.0461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009573519\n",
            "self.loss(score_1, v1) 0.014284459\n",
            "self.loss(score_2, v2) 0.023355428\n",
            "self.loss(score_3, v3) 0.010942756\n",
            "loss tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015786914\n",
            "self.loss(score_1, v1) 0.058792952\n",
            "self.loss(score_2, v2) 0.042862743\n",
            "self.loss(score_3, v3) 0.027090607\n",
            "loss tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010113637\n",
            "self.loss(score_1, v1) 0.014312107\n",
            "self.loss(score_2, v2) 0.015268214\n",
            "self.loss(score_3, v3) 0.010674207\n",
            "loss tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009133912\n",
            "self.loss(score_1, v1) 0.007337398\n",
            "self.loss(score_2, v2) 0.009059726\n",
            "self.loss(score_3, v3) 0.0073826327\n",
            "loss tensor(0.0329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017167464\n",
            "self.loss(score_1, v1) 0.029491374\n",
            "self.loss(score_2, v2) 0.024743084\n",
            "self.loss(score_3, v3) 0.012748467\n",
            "loss tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0079834685\n",
            "self.loss(score_1, v1) 0.008475105\n",
            "self.loss(score_2, v2) 0.009167396\n",
            "self.loss(score_3, v3) 0.01413039\n",
            "loss tensor(0.0398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01217137\n",
            "self.loss(score_1, v1) 0.013288999\n",
            "self.loss(score_2, v2) 0.01957269\n",
            "self.loss(score_3, v3) 0.010204062\n",
            "loss tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.079701304\n",
            "self.loss(score_1, v1) 0.07559446\n",
            "self.loss(score_2, v2) 0.03193754\n",
            "self.loss(score_3, v3) 0.035858534\n",
            "loss tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015380234\n",
            "self.loss(score_1, v1) 0.014801343\n",
            "self.loss(score_2, v2) 0.014304898\n",
            "self.loss(score_3, v3) 0.009525634\n",
            "loss tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01860869\n",
            "self.loss(score_1, v1) 0.036071215\n",
            "self.loss(score_2, v2) 0.0120489\n",
            "self.loss(score_3, v3) 0.008975116\n",
            "loss tensor(0.0757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01609403\n",
            "self.loss(score_1, v1) 0.023830723\n",
            "self.loss(score_2, v2) 0.016196296\n",
            "self.loss(score_3, v3) 0.012071431\n",
            "loss tensor(0.0682, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021538612\n",
            "self.loss(score_1, v1) 0.016777905\n",
            "self.loss(score_2, v2) 0.011251407\n",
            "self.loss(score_3, v3) 0.008452315\n",
            "loss tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015250829\n",
            "self.loss(score_1, v1) 0.01747042\n",
            "self.loss(score_2, v2) 0.00956665\n",
            "self.loss(score_3, v3) 0.006970144\n",
            "loss tensor(0.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010650396\n",
            "self.loss(score_1, v1) 0.011528613\n",
            "self.loss(score_2, v2) 0.016735563\n",
            "self.loss(score_3, v3) 0.013620453\n",
            "loss tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013766396\n",
            "self.loss(score_1, v1) 0.04840674\n",
            "self.loss(score_2, v2) 0.04220061\n",
            "self.loss(score_3, v3) 0.0076634325\n",
            "loss tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0057814647\n",
            "self.loss(score_1, v1) 0.008904264\n",
            "self.loss(score_2, v2) 0.010481688\n",
            "self.loss(score_3, v3) 0.006832197\n",
            "loss tensor(0.0320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01437834\n",
            "self.loss(score_1, v1) 0.030651765\n",
            "self.loss(score_2, v2) 0.025027247\n",
            "self.loss(score_3, v3) 0.011782515\n",
            "loss tensor(0.0818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007896809\n",
            "self.loss(score_1, v1) 0.0060868375\n",
            "self.loss(score_2, v2) 0.010786131\n",
            "self.loss(score_3, v3) 0.008145512\n",
            "loss tensor(0.0329, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0078163715\n",
            "self.loss(score_1, v1) 0.012122333\n",
            "self.loss(score_2, v2) 0.024158293\n",
            "self.loss(score_3, v3) 0.011090151\n",
            "loss tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.054998953\n",
            "self.loss(score_1, v1) 0.038679533\n",
            "self.loss(score_2, v2) 0.034124814\n",
            "self.loss(score_3, v3) 0.03836204\n",
            "loss tensor(0.1662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006735239\n",
            "self.loss(score_1, v1) 0.012795066\n",
            "self.loss(score_2, v2) 0.01619019\n",
            "self.loss(score_3, v3) 0.0109038595\n",
            "loss tensor(0.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006545734\n",
            "self.loss(score_1, v1) 0.008456701\n",
            "self.loss(score_2, v2) 0.015675075\n",
            "self.loss(score_3, v3) 0.0076815602\n",
            "loss tensor(0.0384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015681004\n",
            "self.loss(score_1, v1) 0.02565101\n",
            "self.loss(score_2, v2) 0.016053151\n",
            "self.loss(score_3, v3) 0.011690004\n",
            "loss tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012750392\n",
            "self.loss(score_1, v1) 0.107812285\n",
            "self.loss(score_2, v2) 0.06287803\n",
            "self.loss(score_3, v3) 0.025602724\n",
            "loss tensor(0.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015540608\n",
            "self.loss(score_1, v1) 0.0125291115\n",
            "self.loss(score_2, v2) 0.010993683\n",
            "self.loss(score_3, v3) 0.011140157\n",
            "loss tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0119475685\n",
            "self.loss(score_1, v1) 0.03768266\n",
            "self.loss(score_2, v2) 0.044179015\n",
            "self.loss(score_3, v3) 0.011359853\n",
            "loss tensor(0.1052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018023977\n",
            "self.loss(score_1, v1) 0.030776713\n",
            "self.loss(score_2, v2) 0.051463537\n",
            "self.loss(score_3, v3) 0.0776692\n",
            "loss tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007796313\n",
            "self.loss(score_1, v1) 0.08511132\n",
            "self.loss(score_2, v2) 0.05761814\n",
            "self.loss(score_3, v3) 0.059737995\n",
            "loss tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011516158\n",
            "self.loss(score_1, v1) 0.012126694\n",
            "self.loss(score_2, v2) 0.016248431\n",
            "self.loss(score_3, v3) 0.008547214\n",
            "loss tensor(0.0484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.003541493\n",
            "self.loss(score_1, v1) 0.009182755\n",
            "self.loss(score_2, v2) 0.014511742\n",
            "self.loss(score_3, v3) 0.0046500517\n",
            "loss tensor(0.0319, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011149351\n",
            "self.loss(score_1, v1) 0.010200421\n",
            "self.loss(score_2, v2) 0.0105065415\n",
            "self.loss(score_3, v3) 0.011686564\n",
            "loss tensor(0.0435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008050777\n",
            "self.loss(score_1, v1) 0.01315975\n",
            "self.loss(score_2, v2) 0.013274263\n",
            "self.loss(score_3, v3) 0.012635225\n",
            "loss tensor(0.0471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008025708\n",
            "self.loss(score_1, v1) 0.004807866\n",
            "self.loss(score_2, v2) 0.0063151363\n",
            "self.loss(score_3, v3) 0.009337862\n",
            "loss tensor(0.0285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008158492\n",
            "self.loss(score_1, v1) 0.006655689\n",
            "self.loss(score_2, v2) 0.0038180086\n",
            "self.loss(score_3, v3) 0.0054110927\n",
            "loss tensor(0.0240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012097153\n",
            "self.loss(score_1, v1) 0.00844196\n",
            "self.loss(score_2, v2) 0.008415638\n",
            "self.loss(score_3, v3) 0.009494619\n",
            "loss tensor(0.0384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012360631\n",
            "self.loss(score_1, v1) 0.013501742\n",
            "self.loss(score_2, v2) 0.011425611\n",
            "self.loss(score_3, v3) 0.011065281\n",
            "loss tensor(0.0484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.005395142\n",
            "self.loss(score_1, v1) 0.0058132475\n",
            "self.loss(score_2, v2) 0.005532567\n",
            "self.loss(score_3, v3) 0.0042854957\n",
            "loss tensor(0.0210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010746405\n",
            "self.loss(score_1, v1) 0.018025896\n",
            "self.loss(score_2, v2) 0.034355614\n",
            "self.loss(score_3, v3) 0.014178729\n",
            "loss tensor(0.0773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014612718\n",
            "self.loss(score_1, v1) 0.045310978\n",
            "self.loss(score_2, v2) 0.0072967997\n",
            "self.loss(score_3, v3) 0.0062977085\n",
            "loss tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0076950053\n",
            "self.loss(score_1, v1) 0.008008595\n",
            "self.loss(score_2, v2) 0.009293743\n",
            "self.loss(score_3, v3) 0.008175277\n",
            "loss tensor(0.0332, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009551978\n",
            "self.loss(score_1, v1) 0.013509199\n",
            "self.loss(score_2, v2) 0.011802994\n",
            "self.loss(score_3, v3) 0.01200422\n",
            "loss tensor(0.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012871076\n",
            "self.loss(score_1, v1) 0.04668649\n",
            "self.loss(score_2, v2) 0.04833679\n",
            "self.loss(score_3, v3) 0.012813908\n",
            "loss tensor(0.1207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0095014265\n",
            "self.loss(score_1, v1) 0.03985562\n",
            "self.loss(score_2, v2) 0.012724852\n",
            "self.loss(score_3, v3) 0.008027396\n",
            "loss tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00946703\n",
            "self.loss(score_1, v1) 0.023672149\n",
            "self.loss(score_2, v2) 0.013902515\n",
            "self.loss(score_3, v3) 0.008176118\n",
            "loss tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011392475\n",
            "self.loss(score_1, v1) 0.015212966\n",
            "self.loss(score_2, v2) 0.014488118\n",
            "self.loss(score_3, v3) 0.011954804\n",
            "loss tensor(0.0530, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0055933977\n",
            "self.loss(score_1, v1) 0.011515429\n",
            "self.loss(score_2, v2) 0.034268152\n",
            "self.loss(score_3, v3) 0.0050856057\n",
            "loss tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018503048\n",
            "self.loss(score_1, v1) 0.019155052\n",
            "self.loss(score_2, v2) 0.0064926264\n",
            "self.loss(score_3, v3) 0.007981205\n",
            "loss tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007886904\n",
            "self.loss(score_1, v1) 0.008905502\n",
            "self.loss(score_2, v2) 0.014809178\n",
            "self.loss(score_3, v3) 0.010644745\n",
            "loss tensor(0.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0068822154\n",
            "self.loss(score_1, v1) 0.007594114\n",
            "self.loss(score_2, v2) 0.007400371\n",
            "self.loss(score_3, v3) 0.0073849135\n",
            "loss tensor(0.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049948193\n",
            "self.loss(score_1, v1) 0.039290387\n",
            "self.loss(score_2, v2) 0.019443871\n",
            "self.loss(score_3, v3) 0.009317734\n",
            "loss tensor(0.1180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010807561\n",
            "self.loss(score_1, v1) 0.005344933\n",
            "self.loss(score_2, v2) 0.0066681746\n",
            "self.loss(score_3, v3) 0.0075975433\n",
            "loss tensor(0.0304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009351273\n",
            "self.loss(score_1, v1) 0.016112957\n",
            "self.loss(score_2, v2) 0.01496592\n",
            "self.loss(score_3, v3) 0.012389106\n",
            "loss tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.022602687\n",
            "self.loss(score_1, v1) 0.090295814\n",
            "self.loss(score_2, v2) 0.09850473\n",
            "self.loss(score_3, v3) 0.08463752\n",
            "loss tensor(0.2960, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010500543\n",
            "self.loss(score_1, v1) 0.0073333136\n",
            "self.loss(score_2, v2) 0.009174014\n",
            "self.loss(score_3, v3) 0.0079886215\n",
            "loss tensor(0.0350, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050223727\n",
            "self.loss(score_1, v1) 0.040392596\n",
            "self.loss(score_2, v2) 0.06206801\n",
            "self.loss(score_3, v3) 0.009155659\n",
            "loss tensor(0.1618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.025904387\n",
            "self.loss(score_1, v1) 0.027362261\n",
            "self.loss(score_2, v2) 0.051138885\n",
            "self.loss(score_3, v3) 0.0073380372\n",
            "loss tensor(0.1117, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012382636\n",
            "self.loss(score_1, v1) 0.01821588\n",
            "self.loss(score_2, v2) 0.01700755\n",
            "self.loss(score_3, v3) 0.015261305\n",
            "loss tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014714892\n",
            "self.loss(score_1, v1) 0.010720245\n",
            "self.loss(score_2, v2) 0.0042989547\n",
            "self.loss(score_3, v3) 0.0060446574\n",
            "loss tensor(0.0358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017336806\n",
            "self.loss(score_1, v1) 0.049873006\n",
            "self.loss(score_2, v2) 0.06286976\n",
            "self.loss(score_3, v3) 0.0075800857\n",
            "loss tensor(0.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.026080089\n",
            "self.loss(score_1, v1) 0.05053401\n",
            "self.loss(score_2, v2) 0.013842678\n",
            "self.loss(score_3, v3) 0.008948867\n",
            "loss tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0075010443\n",
            "self.loss(score_1, v1) 0.018934837\n",
            "self.loss(score_2, v2) 0.020239748\n",
            "self.loss(score_3, v3) 0.00938739\n",
            "loss tensor(0.0561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03744608\n",
            "self.loss(score_1, v1) 0.028509691\n",
            "self.loss(score_2, v2) 0.022765703\n",
            "self.loss(score_3, v3) 0.008649436\n",
            "loss tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014256802\n",
            "self.loss(score_1, v1) 0.028135976\n",
            "self.loss(score_2, v2) 0.009746208\n",
            "self.loss(score_3, v3) 0.008064061\n",
            "loss tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014194504\n",
            "self.loss(score_1, v1) 0.012954828\n",
            "self.loss(score_2, v2) 0.0068164407\n",
            "self.loss(score_3, v3) 0.0082769105\n",
            "loss tensor(0.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013881326\n",
            "self.loss(score_1, v1) 0.012780292\n",
            "self.loss(score_2, v2) 0.0893647\n",
            "self.loss(score_3, v3) 0.010701753\n",
            "loss tensor(0.1267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06807916\n",
            "self.loss(score_1, v1) 0.07123861\n",
            "self.loss(score_2, v2) 0.08244658\n",
            "self.loss(score_3, v3) 0.046527326\n",
            "loss tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0070221904\n",
            "self.loss(score_1, v1) 0.009477655\n",
            "self.loss(score_2, v2) 0.013288982\n",
            "self.loss(score_3, v3) 0.00806573\n",
            "loss tensor(0.0379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055222712\n",
            "self.loss(score_1, v1) 0.04420542\n",
            "self.loss(score_2, v2) 0.029076396\n",
            "self.loss(score_3, v3) 0.009509014\n",
            "loss tensor(0.1380, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013495118\n",
            "self.loss(score_1, v1) 0.006180462\n",
            "self.loss(score_2, v2) 0.008409719\n",
            "self.loss(score_3, v3) 0.012467091\n",
            "loss tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010447154\n",
            "self.loss(score_1, v1) 0.02235671\n",
            "self.loss(score_2, v2) 0.0124355545\n",
            "self.loss(score_3, v3) 0.0066081686\n",
            "loss tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008919272\n",
            "self.loss(score_1, v1) 0.0086697\n",
            "self.loss(score_2, v2) 0.011294422\n",
            "self.loss(score_3, v3) 0.010749722\n",
            "loss tensor(0.0396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010501047\n",
            "self.loss(score_1, v1) 0.012585252\n",
            "self.loss(score_2, v2) 0.031291828\n",
            "self.loss(score_3, v3) 0.02766629\n",
            "loss tensor(0.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006830264\n",
            "self.loss(score_1, v1) 0.008474955\n",
            "self.loss(score_2, v2) 0.009483051\n",
            "self.loss(score_3, v3) 0.007142341\n",
            "loss tensor(0.0319, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008887832\n",
            "self.loss(score_1, v1) 0.006750557\n",
            "self.loss(score_2, v2) 0.008729589\n",
            "self.loss(score_3, v3) 0.0074048177\n",
            "loss tensor(0.0318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07359623\n",
            "self.loss(score_1, v1) 0.07244596\n",
            "self.loss(score_2, v2) 0.09754134\n",
            "self.loss(score_3, v3) 0.031815052\n",
            "loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010766521\n",
            "self.loss(score_1, v1) 0.014186201\n",
            "self.loss(score_2, v2) 0.0244387\n",
            "self.loss(score_3, v3) 0.00771395\n",
            "loss tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007902506\n",
            "self.loss(score_1, v1) 0.0073601548\n",
            "self.loss(score_2, v2) 0.0066021266\n",
            "self.loss(score_3, v3) 0.008462069\n",
            "loss tensor(0.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.023444057\n",
            "self.loss(score_1, v1) 0.013632264\n",
            "self.loss(score_2, v2) 0.014808606\n",
            "self.loss(score_3, v3) 0.010523161\n",
            "loss tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010828816\n",
            "self.loss(score_1, v1) 0.016325908\n",
            "self.loss(score_2, v2) 0.011059465\n",
            "self.loss(score_3, v3) 0.011195636\n",
            "loss tensor(0.0494, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011335041\n",
            "self.loss(score_1, v1) 0.02078682\n",
            "self.loss(score_2, v2) 0.042322095\n",
            "self.loss(score_3, v3) 0.0076671243\n",
            "loss tensor(0.0821, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017053489\n",
            "self.loss(score_1, v1) 0.022353917\n",
            "self.loss(score_2, v2) 0.015190531\n",
            "self.loss(score_3, v3) 0.007048557\n",
            "loss tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018259717\n",
            "self.loss(score_1, v1) 0.025079347\n",
            "self.loss(score_2, v2) 0.053512983\n",
            "self.loss(score_3, v3) 0.013193384\n",
            "loss tensor(0.1100, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010720197\n",
            "self.loss(score_1, v1) 0.047146205\n",
            "self.loss(score_2, v2) 0.03535914\n",
            "self.loss(score_3, v3) 0.025783528\n",
            "loss tensor(0.1190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01608154\n",
            "self.loss(score_1, v1) 0.02571097\n",
            "self.loss(score_2, v2) 0.03508981\n",
            "self.loss(score_3, v3) 0.06335235\n",
            "loss tensor(0.1402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.064825416\n",
            "self.loss(score_1, v1) 0.044988967\n",
            "self.loss(score_2, v2) 0.117149994\n",
            "self.loss(score_3, v3) 0.009949867\n",
            "loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010841024\n",
            "self.loss(score_1, v1) 0.04276129\n",
            "self.loss(score_2, v2) 0.016621904\n",
            "self.loss(score_3, v3) 0.013626834\n",
            "loss tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015947858\n",
            "self.loss(score_1, v1) 0.014222534\n",
            "self.loss(score_2, v2) 0.013102618\n",
            "self.loss(score_3, v3) 0.007433927\n",
            "loss tensor(0.0507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021573687\n",
            "self.loss(score_1, v1) 0.03002584\n",
            "self.loss(score_2, v2) 0.009215381\n",
            "self.loss(score_3, v3) 0.00800726\n",
            "loss tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0046668593\n",
            "self.loss(score_1, v1) 0.004226638\n",
            "self.loss(score_2, v2) 0.007247688\n",
            "self.loss(score_3, v3) 0.005866077\n",
            "loss tensor(0.0220, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008096404\n",
            "self.loss(score_1, v1) 0.010538014\n",
            "self.loss(score_2, v2) 0.02292728\n",
            "self.loss(score_3, v3) 0.00845628\n",
            "loss tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.024480749\n",
            "self.loss(score_1, v1) 0.023747599\n",
            "self.loss(score_2, v2) 0.013157418\n",
            "self.loss(score_3, v3) 0.010381064\n",
            "loss tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009582705\n",
            "self.loss(score_1, v1) 0.019554958\n",
            "self.loss(score_2, v2) 0.019225255\n",
            "self.loss(score_3, v3) 0.011678638\n",
            "loss tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015014799\n",
            "self.loss(score_1, v1) 0.02540417\n",
            "self.loss(score_2, v2) 0.017166626\n",
            "self.loss(score_3, v3) 0.008762274\n",
            "loss tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009518903\n",
            "self.loss(score_1, v1) 0.013166484\n",
            "self.loss(score_2, v2) 0.023761893\n",
            "self.loss(score_3, v3) 0.008429044\n",
            "loss tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010427536\n",
            "self.loss(score_1, v1) 0.08300521\n",
            "self.loss(score_2, v2) 0.038973667\n",
            "self.loss(score_3, v3) 0.009086536\n",
            "loss tensor(0.1415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012680531\n",
            "self.loss(score_1, v1) 0.012362424\n",
            "self.loss(score_2, v2) 0.013886982\n",
            "self.loss(score_3, v3) 0.009539741\n",
            "loss tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008911251\n",
            "self.loss(score_1, v1) 0.019578254\n",
            "self.loss(score_2, v2) 0.01900839\n",
            "self.loss(score_3, v3) 0.012050128\n",
            "loss tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010218746\n",
            "self.loss(score_1, v1) 0.007390292\n",
            "self.loss(score_2, v2) 0.013964469\n",
            "self.loss(score_3, v3) 0.012775103\n",
            "loss tensor(0.0443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006949051\n",
            "self.loss(score_1, v1) 0.07494107\n",
            "self.loss(score_2, v2) 0.013260288\n",
            "self.loss(score_3, v3) 0.0064267693\n",
            "loss tensor(0.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0159544\n",
            "self.loss(score_1, v1) 0.14790708\n",
            "self.loss(score_2, v2) 0.031352866\n",
            "self.loss(score_3, v3) 0.011199752\n",
            "loss tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009092668\n",
            "self.loss(score_1, v1) 0.010838186\n",
            "self.loss(score_2, v2) 0.01067821\n",
            "self.loss(score_3, v3) 0.0072147883\n",
            "loss tensor(0.0378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0075808945\n",
            "self.loss(score_1, v1) 0.008197971\n",
            "self.loss(score_2, v2) 0.008599759\n",
            "self.loss(score_3, v3) 0.0049581975\n",
            "loss tensor(0.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.022645952\n",
            "self.loss(score_1, v1) 0.016523212\n",
            "self.loss(score_2, v2) 0.010681726\n",
            "self.loss(score_3, v3) 0.009483931\n",
            "loss tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017353812\n",
            "self.loss(score_1, v1) 0.023026373\n",
            "self.loss(score_2, v2) 0.011162696\n",
            "self.loss(score_3, v3) 0.011842519\n",
            "loss tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053575203\n",
            "self.loss(score_1, v1) 0.03674279\n",
            "self.loss(score_2, v2) 0.030904228\n",
            "self.loss(score_3, v3) 0.014068609\n",
            "loss tensor(0.1353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014811866\n",
            "self.loss(score_1, v1) 0.00849736\n",
            "self.loss(score_2, v2) 0.013121455\n",
            "self.loss(score_3, v3) 0.012519951\n",
            "loss tensor(0.0490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010451846\n",
            "self.loss(score_1, v1) 0.01901586\n",
            "self.loss(score_2, v2) 0.026653467\n",
            "self.loss(score_3, v3) 0.010213459\n",
            "loss tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0071483217\n",
            "self.loss(score_1, v1) 0.0055669225\n",
            "self.loss(score_2, v2) 0.0066416725\n",
            "self.loss(score_3, v3) 0.0060411724\n",
            "loss tensor(0.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017261807\n",
            "self.loss(score_1, v1) 0.11392564\n",
            "self.loss(score_2, v2) 0.11341514\n",
            "self.loss(score_3, v3) 0.025940927\n",
            "loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014024822\n",
            "self.loss(score_1, v1) 0.013369952\n",
            "self.loss(score_2, v2) 0.01568022\n",
            "self.loss(score_3, v3) 0.008913375\n",
            "loss tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011190556\n",
            "self.loss(score_1, v1) 0.009747542\n",
            "self.loss(score_2, v2) 0.01051561\n",
            "self.loss(score_3, v3) 0.012058905\n",
            "loss tensor(0.0435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018223304\n",
            "self.loss(score_1, v1) 0.03579247\n",
            "self.loss(score_2, v2) 0.028273238\n",
            "self.loss(score_3, v3) 0.01889703\n",
            "loss tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008879194\n",
            "self.loss(score_1, v1) 0.015802518\n",
            "self.loss(score_2, v2) 0.03164396\n",
            "self.loss(score_3, v3) 0.012654216\n",
            "loss tensor(0.0690, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0541679\n",
            "self.loss(score_1, v1) 0.027028445\n",
            "self.loss(score_2, v2) 0.03019074\n",
            "self.loss(score_3, v3) 0.011195639\n",
            "loss tensor(0.1226, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.029644694\n",
            "self.loss(score_1, v1) 0.016366303\n",
            "self.loss(score_2, v2) 0.01386242\n",
            "self.loss(score_3, v3) 0.010970724\n",
            "loss tensor(0.0708, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.024042504\n",
            "self.loss(score_1, v1) 0.040726747\n",
            "self.loss(score_2, v2) 0.021496668\n",
            "self.loss(score_3, v3) 0.010964434\n",
            "loss tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.023662776\n",
            "self.loss(score_1, v1) 0.023499578\n",
            "self.loss(score_2, v2) 0.020814141\n",
            "self.loss(score_3, v3) 0.0083191795\n",
            "loss tensor(0.0763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012165625\n",
            "self.loss(score_1, v1) 0.012236707\n",
            "self.loss(score_2, v2) 0.020155873\n",
            "self.loss(score_3, v3) 0.012114568\n",
            "loss tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.032264527\n",
            "self.loss(score_1, v1) 0.020412365\n",
            "self.loss(score_2, v2) 0.028016422\n",
            "self.loss(score_3, v3) 0.009506005\n",
            "loss tensor(0.0902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012298727\n",
            "self.loss(score_1, v1) 0.058069352\n",
            "self.loss(score_2, v2) 0.04557309\n",
            "self.loss(score_3, v3) 0.010718658\n",
            "loss tensor(0.1267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014253307\n",
            "self.loss(score_1, v1) 0.00985284\n",
            "self.loss(score_2, v2) 0.0071105994\n",
            "self.loss(score_3, v3) 0.009730493\n",
            "loss tensor(0.0409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01683182\n",
            "self.loss(score_1, v1) 0.02177943\n",
            "self.loss(score_2, v2) 0.012880398\n",
            "self.loss(score_3, v3) 0.011050964\n",
            "loss tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052925617\n",
            "self.loss(score_1, v1) 0.017136231\n",
            "self.loss(score_2, v2) 0.02321546\n",
            "self.loss(score_3, v3) 0.014419129\n",
            "loss tensor(0.1077, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013313511\n",
            "self.loss(score_1, v1) 0.021804301\n",
            "self.loss(score_2, v2) 0.018596001\n",
            "self.loss(score_3, v3) 0.011601973\n",
            "loss tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013843654\n",
            "self.loss(score_1, v1) 0.013143604\n",
            "self.loss(score_2, v2) 0.006656604\n",
            "self.loss(score_3, v3) 0.0065499893\n",
            "loss tensor(0.0402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011695666\n",
            "self.loss(score_1, v1) 0.0133758485\n",
            "self.loss(score_2, v2) 0.015407218\n",
            "self.loss(score_3, v3) 0.009563048\n",
            "loss tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008307529\n",
            "self.loss(score_1, v1) 0.0064443867\n",
            "self.loss(score_2, v2) 0.010237102\n",
            "self.loss(score_3, v3) 0.010739373\n",
            "loss tensor(0.0357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0062442576\n",
            "self.loss(score_1, v1) 0.0068136547\n",
            "self.loss(score_2, v2) 0.01006334\n",
            "self.loss(score_3, v3) 0.008490606\n",
            "loss tensor(0.0316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060704853\n",
            "self.loss(score_1, v1) 0.027808696\n",
            "self.loss(score_2, v2) 0.062321\n",
            "self.loss(score_3, v3) 0.012684451\n",
            "loss tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009268923\n",
            "self.loss(score_1, v1) 0.03473625\n",
            "self.loss(score_2, v2) 0.025337487\n",
            "self.loss(score_3, v3) 0.019463161\n",
            "loss tensor(0.0888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011776299\n",
            "self.loss(score_1, v1) 0.0069049783\n",
            "self.loss(score_2, v2) 0.0055160895\n",
            "self.loss(score_3, v3) 0.007948933\n",
            "loss tensor(0.0321, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012410354\n",
            "self.loss(score_1, v1) 0.014901394\n",
            "self.loss(score_2, v2) 0.024419995\n",
            "self.loss(score_3, v3) 0.013742291\n",
            "loss tensor(0.0655, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009041479\n",
            "self.loss(score_1, v1) 0.0188508\n",
            "self.loss(score_2, v2) 0.021349749\n",
            "self.loss(score_3, v3) 0.09310165\n",
            "loss tensor(0.1423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006999475\n",
            "self.loss(score_1, v1) 0.0097587\n",
            "self.loss(score_2, v2) 0.01672575\n",
            "self.loss(score_3, v3) 0.010441101\n",
            "loss tensor(0.0439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052415602\n",
            "self.loss(score_1, v1) 0.018873872\n",
            "self.loss(score_2, v2) 0.088090606\n",
            "self.loss(score_3, v3) 0.011106215\n",
            "loss tensor(0.1705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01075853\n",
            "self.loss(score_1, v1) 0.00818395\n",
            "self.loss(score_2, v2) 0.010631345\n",
            "self.loss(score_3, v3) 0.010651454\n",
            "loss tensor(0.0402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0244315\n",
            "self.loss(score_1, v1) 0.031680487\n",
            "self.loss(score_2, v2) 0.019931251\n",
            "self.loss(score_3, v3) 0.008979971\n",
            "loss tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011137722\n",
            "self.loss(score_1, v1) 0.009727602\n",
            "self.loss(score_2, v2) 0.0047973297\n",
            "self.loss(score_3, v3) 0.0051560733\n",
            "loss tensor(0.0308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008955181\n",
            "self.loss(score_1, v1) 0.010260635\n",
            "self.loss(score_2, v2) 0.010289452\n",
            "self.loss(score_3, v3) 0.008881918\n",
            "loss tensor(0.0384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0076164147\n",
            "self.loss(score_1, v1) 0.01039153\n",
            "self.loss(score_2, v2) 0.010366117\n",
            "self.loss(score_3, v3) 0.008550184\n",
            "loss tensor(0.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009465053\n",
            "self.loss(score_1, v1) 0.02050847\n",
            "self.loss(score_2, v2) 0.03173821\n",
            "self.loss(score_3, v3) 0.010751969\n",
            "loss tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010155783\n",
            "self.loss(score_1, v1) 0.010108184\n",
            "self.loss(score_2, v2) 0.017917093\n",
            "self.loss(score_3, v3) 0.0092438515\n",
            "loss tensor(0.0474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01609474\n",
            "self.loss(score_1, v1) 0.02195456\n",
            "self.loss(score_2, v2) 0.012004717\n",
            "self.loss(score_3, v3) 0.008361553\n",
            "loss tensor(0.0584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015715066\n",
            "self.loss(score_1, v1) 0.009671977\n",
            "self.loss(score_2, v2) 0.0085672\n",
            "self.loss(score_3, v3) 0.009568676\n",
            "loss tensor(0.0435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010139501\n",
            "self.loss(score_1, v1) 0.018819809\n",
            "self.loss(score_2, v2) 0.05351914\n",
            "self.loss(score_3, v3) 0.10968326\n",
            "loss tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010237939\n",
            "self.loss(score_1, v1) 0.013853138\n",
            "self.loss(score_2, v2) 0.017373716\n",
            "self.loss(score_3, v3) 0.013027366\n",
            "loss tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008206058\n",
            "self.loss(score_1, v1) 0.0070448085\n",
            "self.loss(score_2, v2) 0.008284658\n",
            "self.loss(score_3, v3) 0.008006461\n",
            "loss tensor(0.0315, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019311223\n",
            "self.loss(score_1, v1) 0.018866906\n",
            "self.loss(score_2, v2) 0.008550132\n",
            "self.loss(score_3, v3) 0.008447355\n",
            "loss tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009328097\n",
            "self.loss(score_1, v1) 0.009012878\n",
            "self.loss(score_2, v2) 0.014527303\n",
            "self.loss(score_3, v3) 0.008405041\n",
            "loss tensor(0.0413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008069319\n",
            "self.loss(score_1, v1) 0.014029527\n",
            "self.loss(score_2, v2) 0.017035445\n",
            "self.loss(score_3, v3) 0.014014508\n",
            "loss tensor(0.0531, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01086636\n",
            "self.loss(score_1, v1) 0.0189422\n",
            "self.loss(score_2, v2) 0.022604555\n",
            "self.loss(score_3, v3) 0.008187177\n",
            "loss tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0073877443\n",
            "self.loss(score_1, v1) 0.012415424\n",
            "self.loss(score_2, v2) 0.011295287\n",
            "self.loss(score_3, v3) 0.0077164234\n",
            "loss tensor(0.0388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013845927\n",
            "self.loss(score_1, v1) 0.023545375\n",
            "self.loss(score_2, v2) 0.024844302\n",
            "self.loss(score_3, v3) 0.013052494\n",
            "loss tensor(0.0753, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011136828\n",
            "self.loss(score_1, v1) 0.018644078\n",
            "self.loss(score_2, v2) 0.01635697\n",
            "self.loss(score_3, v3) 0.014618052\n",
            "loss tensor(0.0608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009701659\n",
            "self.loss(score_1, v1) 0.018241877\n",
            "self.loss(score_2, v2) 0.052614726\n",
            "self.loss(score_3, v3) 0.04223958\n",
            "loss tensor(0.1228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016562775\n",
            "self.loss(score_1, v1) 0.008764815\n",
            "self.loss(score_2, v2) 0.012609243\n",
            "self.loss(score_3, v3) 0.009490719\n",
            "loss tensor(0.0474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.026593845\n",
            "self.loss(score_1, v1) 0.02264733\n",
            "self.loss(score_2, v2) 0.0082458705\n",
            "self.loss(score_3, v3) 0.007251513\n",
            "loss tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021598168\n",
            "self.loss(score_1, v1) 0.03990465\n",
            "self.loss(score_2, v2) 0.033653725\n",
            "self.loss(score_3, v3) 0.009398958\n",
            "loss tensor(0.1046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05933815\n",
            "self.loss(score_1, v1) 0.058586746\n",
            "self.loss(score_2, v2) 0.06895291\n",
            "self.loss(score_3, v3) 0.01130513\n",
            "loss tensor(0.1982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011951014\n",
            "self.loss(score_1, v1) 0.021064933\n",
            "self.loss(score_2, v2) 0.008455416\n",
            "self.loss(score_3, v3) 0.00675894\n",
            "loss tensor(0.0482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016487865\n",
            "self.loss(score_1, v1) 0.02972193\n",
            "self.loss(score_2, v2) 0.023897024\n",
            "self.loss(score_3, v3) 0.009021294\n",
            "loss tensor(0.0791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0049604615\n",
            "self.loss(score_1, v1) 0.023822919\n",
            "self.loss(score_2, v2) 0.016264496\n",
            "self.loss(score_3, v3) 0.006932947\n",
            "loss tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01573455\n",
            "self.loss(score_1, v1) 0.028842218\n",
            "self.loss(score_2, v2) 0.011930612\n",
            "self.loss(score_3, v3) 0.009430091\n",
            "loss tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010540408\n",
            "self.loss(score_1, v1) 0.009354565\n",
            "self.loss(score_2, v2) 0.013394982\n",
            "self.loss(score_3, v3) 0.010568976\n",
            "loss tensor(0.0439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008061895\n",
            "self.loss(score_1, v1) 0.009406046\n",
            "self.loss(score_2, v2) 0.009221243\n",
            "self.loss(score_3, v3) 0.0066273883\n",
            "loss tensor(0.0333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.02264241\n",
            "self.loss(score_1, v1) 0.01931483\n",
            "self.loss(score_2, v2) 0.011940481\n",
            "self.loss(score_3, v3) 0.009167187\n",
            "loss tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01947485\n",
            "self.loss(score_1, v1) 0.026857276\n",
            "self.loss(score_2, v2) 0.02990866\n",
            "self.loss(score_3, v3) 0.008474167\n",
            "loss tensor(0.0847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00824193\n",
            "self.loss(score_1, v1) 0.0079195015\n",
            "self.loss(score_2, v2) 0.0110500865\n",
            "self.loss(score_3, v3) 0.011662532\n",
            "loss tensor(0.0389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01745496\n",
            "self.loss(score_1, v1) 0.013341848\n",
            "self.loss(score_2, v2) 0.013264094\n",
            "self.loss(score_3, v3) 0.008394254\n",
            "loss tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009080431\n",
            "self.loss(score_1, v1) 0.008312216\n",
            "self.loss(score_2, v2) 0.012181481\n",
            "self.loss(score_3, v3) 0.011757211\n",
            "loss tensor(0.0413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014905449\n",
            "self.loss(score_1, v1) 0.049109932\n",
            "self.loss(score_2, v2) 0.050832905\n",
            "self.loss(score_3, v3) 0.012186322\n",
            "loss tensor(0.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 0.08449249722917748, Train Accuracy : 0.9992929234339315\n",
            " Validation Accuracy : 6.602306416634922\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.0062499563\n",
            "self.loss(score_1, v1) 0.017748797\n",
            "self.loss(score_2, v2) 0.06124827\n",
            "self.loss(score_3, v3) 0.03991028\n",
            "loss tensor(0.1252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0061160517\n",
            "self.loss(score_1, v1) 0.010985048\n",
            "self.loss(score_2, v2) 0.11505697\n",
            "self.loss(score_3, v3) 0.027233548\n",
            "loss tensor(0.1594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03310567\n",
            "self.loss(score_1, v1) 0.061039943\n",
            "self.loss(score_2, v2) 0.09254731\n",
            "self.loss(score_3, v3) 0.0063302997\n",
            "loss tensor(0.1930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.02402837\n",
            "self.loss(score_1, v1) 0.029298846\n",
            "self.loss(score_2, v2) 0.01797479\n",
            "self.loss(score_3, v3) 0.010173803\n",
            "loss tensor(0.0815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010212856\n",
            "self.loss(score_1, v1) 0.048490927\n",
            "self.loss(score_2, v2) 0.02828396\n",
            "self.loss(score_3, v3) 0.0072620753\n",
            "loss tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007361514\n",
            "self.loss(score_1, v1) 0.0065821945\n",
            "self.loss(score_2, v2) 0.0071708327\n",
            "self.loss(score_3, v3) 0.006718821\n",
            "loss tensor(0.0278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007771128\n",
            "self.loss(score_1, v1) 0.0072017037\n",
            "self.loss(score_2, v2) 0.008977945\n",
            "self.loss(score_3, v3) 0.0077485237\n",
            "loss tensor(0.0317, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012198627\n",
            "self.loss(score_1, v1) 0.009828933\n",
            "self.loss(score_2, v2) 0.0068548974\n",
            "self.loss(score_3, v3) 0.0059637185\n",
            "loss tensor(0.0348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009355542\n",
            "self.loss(score_1, v1) 0.011493961\n",
            "self.loss(score_2, v2) 0.0125873145\n",
            "self.loss(score_3, v3) 0.009710114\n",
            "loss tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008841492\n",
            "self.loss(score_1, v1) 0.008750295\n",
            "self.loss(score_2, v2) 0.013803584\n",
            "self.loss(score_3, v3) 0.012871727\n",
            "loss tensor(0.0443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.026897626\n",
            "self.loss(score_1, v1) 0.05605126\n",
            "self.loss(score_2, v2) 0.028206782\n",
            "self.loss(score_3, v3) 0.009942102\n",
            "loss tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011370693\n",
            "self.loss(score_1, v1) 0.012951605\n",
            "self.loss(score_2, v2) 0.012306269\n",
            "self.loss(score_3, v3) 0.008405165\n",
            "loss tensor(0.0450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013000562\n",
            "self.loss(score_1, v1) 0.036253903\n",
            "self.loss(score_2, v2) 0.048808027\n",
            "self.loss(score_3, v3) 0.00928602\n",
            "loss tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.020473454\n",
            "self.loss(score_1, v1) 0.020517262\n",
            "self.loss(score_2, v2) 0.02904405\n",
            "self.loss(score_3, v3) 0.010242817\n",
            "loss tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008011301\n",
            "self.loss(score_1, v1) 0.011842967\n",
            "self.loss(score_2, v2) 0.015425492\n",
            "self.loss(score_3, v3) 0.0078042597\n",
            "loss tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016187457\n",
            "self.loss(score_1, v1) 0.019868623\n",
            "self.loss(score_2, v2) 0.009635474\n",
            "self.loss(score_3, v3) 0.011132857\n",
            "loss tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011530964\n",
            "self.loss(score_1, v1) 0.013045021\n",
            "self.loss(score_2, v2) 0.011482027\n",
            "self.loss(score_3, v3) 0.010759642\n",
            "loss tensor(0.0468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009583548\n",
            "self.loss(score_1, v1) 0.012448547\n",
            "self.loss(score_2, v2) 0.01236081\n",
            "self.loss(score_3, v3) 0.009316319\n",
            "loss tensor(0.0437, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055403173\n",
            "self.loss(score_1, v1) 0.055855915\n",
            "self.loss(score_2, v2) 0.085973844\n",
            "self.loss(score_3, v3) 0.012969616\n",
            "loss tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011574328\n",
            "self.loss(score_1, v1) 0.027159946\n",
            "self.loss(score_2, v2) 0.030946221\n",
            "self.loss(score_3, v3) 0.0114667155\n",
            "loss tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011873834\n",
            "self.loss(score_1, v1) 0.012627705\n",
            "self.loss(score_2, v2) 0.012065687\n",
            "self.loss(score_3, v3) 0.008193616\n",
            "loss tensor(0.0448, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021879267\n",
            "self.loss(score_1, v1) 0.020463277\n",
            "self.loss(score_2, v2) 0.009048678\n",
            "self.loss(score_3, v3) 0.010164935\n",
            "loss tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0070627755\n",
            "self.loss(score_1, v1) 0.014514549\n",
            "self.loss(score_2, v2) 0.023073329\n",
            "self.loss(score_3, v3) 0.012456772\n",
            "loss tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006826239\n",
            "self.loss(score_1, v1) 0.0052240468\n",
            "self.loss(score_2, v2) 0.00652553\n",
            "self.loss(score_3, v3) 0.0072145597\n",
            "loss tensor(0.0258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008510083\n",
            "self.loss(score_1, v1) 0.007819289\n",
            "self.loss(score_2, v2) 0.0067884075\n",
            "self.loss(score_3, v3) 0.0072030136\n",
            "loss tensor(0.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009530511\n",
            "self.loss(score_1, v1) 0.011592202\n",
            "self.loss(score_2, v2) 0.015095062\n",
            "self.loss(score_3, v3) 0.008709382\n",
            "loss tensor(0.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.033375464\n",
            "self.loss(score_1, v1) 0.021040747\n",
            "self.loss(score_2, v2) 0.018341074\n",
            "self.loss(score_3, v3) 0.011018902\n",
            "loss tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00794688\n",
            "self.loss(score_1, v1) 0.0108735375\n",
            "self.loss(score_2, v2) 0.011868466\n",
            "self.loss(score_3, v3) 0.009921439\n",
            "loss tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016577521\n",
            "self.loss(score_1, v1) 0.02179325\n",
            "self.loss(score_2, v2) 0.021859942\n",
            "self.loss(score_3, v3) 0.012332815\n",
            "loss tensor(0.0726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008662515\n",
            "self.loss(score_1, v1) 0.010032154\n",
            "self.loss(score_2, v2) 0.021171609\n",
            "self.loss(score_3, v3) 0.010064465\n",
            "loss tensor(0.0499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.02327735\n",
            "self.loss(score_1, v1) 0.056539543\n",
            "self.loss(score_2, v2) 0.05546565\n",
            "self.loss(score_3, v3) 0.008328031\n",
            "loss tensor(0.1436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009339452\n",
            "self.loss(score_1, v1) 0.0072152517\n",
            "self.loss(score_2, v2) 0.01043829\n",
            "self.loss(score_3, v3) 0.008284434\n",
            "loss tensor(0.0353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.041471686\n",
            "self.loss(score_1, v1) 0.10361559\n",
            "self.loss(score_2, v2) 0.10664376\n",
            "self.loss(score_3, v3) 0.24702664\n",
            "loss tensor(0.4988, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013444769\n",
            "self.loss(score_1, v1) 0.0075545087\n",
            "self.loss(score_2, v2) 0.008591799\n",
            "self.loss(score_3, v3) 0.010135041\n",
            "loss tensor(0.0397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009642564\n",
            "self.loss(score_1, v1) 0.009533459\n",
            "self.loss(score_2, v2) 0.017842378\n",
            "self.loss(score_3, v3) 0.009391767\n",
            "loss tensor(0.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01000067\n",
            "self.loss(score_1, v1) 0.009917808\n",
            "self.loss(score_2, v2) 0.013674055\n",
            "self.loss(score_3, v3) 0.010784613\n",
            "loss tensor(0.0444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008173873\n",
            "self.loss(score_1, v1) 0.0088426955\n",
            "self.loss(score_2, v2) 0.010672089\n",
            "self.loss(score_3, v3) 0.011032167\n",
            "loss tensor(0.0387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009088553\n",
            "self.loss(score_1, v1) 0.019437585\n",
            "self.loss(score_2, v2) 0.024569286\n",
            "self.loss(score_3, v3) 0.015153906\n",
            "loss tensor(0.0682, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.023454482\n",
            "self.loss(score_1, v1) 0.017555095\n",
            "self.loss(score_2, v2) 0.011000012\n",
            "self.loss(score_3, v3) 0.010122972\n",
            "loss tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010806049\n",
            "self.loss(score_1, v1) 0.019486832\n",
            "self.loss(score_2, v2) 0.029973987\n",
            "self.loss(score_3, v3) 0.09370503\n",
            "loss tensor(0.1540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012460432\n",
            "self.loss(score_1, v1) 0.013074385\n",
            "self.loss(score_2, v2) 0.0074096983\n",
            "self.loss(score_3, v3) 0.005164255\n",
            "loss tensor(0.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05437793\n",
            "self.loss(score_1, v1) 0.10551126\n",
            "self.loss(score_2, v2) 0.07513595\n",
            "self.loss(score_3, v3) 0.0068989443\n",
            "loss tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010810149\n",
            "self.loss(score_1, v1) 0.008521402\n",
            "self.loss(score_2, v2) 0.009351259\n",
            "self.loss(score_3, v3) 0.012818311\n",
            "loss tensor(0.0415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0068351887\n",
            "self.loss(score_1, v1) 0.009406494\n",
            "self.loss(score_2, v2) 0.010179098\n",
            "self.loss(score_3, v3) 0.009240297\n",
            "loss tensor(0.0357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009933192\n",
            "self.loss(score_1, v1) 0.009772926\n",
            "self.loss(score_2, v2) 0.012353034\n",
            "self.loss(score_3, v3) 0.012634635\n",
            "loss tensor(0.0447, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00861853\n",
            "self.loss(score_1, v1) 0.011689777\n",
            "self.loss(score_2, v2) 0.013627993\n",
            "self.loss(score_3, v3) 0.006945642\n",
            "loss tensor(0.0409, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008499984\n",
            "self.loss(score_1, v1) 0.01009023\n",
            "self.loss(score_2, v2) 0.012862051\n",
            "self.loss(score_3, v3) 0.010722637\n",
            "loss tensor(0.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03174864\n",
            "self.loss(score_1, v1) 0.01855296\n",
            "self.loss(score_2, v2) 0.05593698\n",
            "self.loss(score_3, v3) 0.008176706\n",
            "loss tensor(0.1144, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0063655525\n",
            "self.loss(score_1, v1) 0.004533378\n",
            "self.loss(score_2, v2) 0.008575612\n",
            "self.loss(score_3, v3) 0.0069705183\n",
            "loss tensor(0.0264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012481947\n",
            "self.loss(score_1, v1) 0.01677273\n",
            "self.loss(score_2, v2) 0.016977627\n",
            "self.loss(score_3, v3) 0.013641739\n",
            "loss tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017538846\n",
            "self.loss(score_1, v1) 0.031086471\n",
            "self.loss(score_2, v2) 0.022239488\n",
            "self.loss(score_3, v3) 0.016905412\n",
            "loss tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007925501\n",
            "self.loss(score_1, v1) 0.007569237\n",
            "self.loss(score_2, v2) 0.009642784\n",
            "self.loss(score_3, v3) 0.010346853\n",
            "loss tensor(0.0355, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.029846832\n",
            "self.loss(score_1, v1) 0.038694922\n",
            "self.loss(score_2, v2) 0.07808168\n",
            "self.loss(score_3, v3) 0.12785454\n",
            "loss tensor(0.2745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014833595\n",
            "self.loss(score_1, v1) 0.0089275995\n",
            "self.loss(score_2, v2) 0.009584795\n",
            "self.loss(score_3, v3) 0.010848669\n",
            "loss tensor(0.0442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.113691874\n",
            "self.loss(score_1, v1) 0.06730705\n",
            "self.loss(score_2, v2) 0.04678264\n",
            "self.loss(score_3, v3) 0.014761369\n",
            "loss tensor(0.2425, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0111171575\n",
            "self.loss(score_1, v1) 0.010855006\n",
            "self.loss(score_2, v2) 0.019422779\n",
            "self.loss(score_3, v3) 0.0107959\n",
            "loss tensor(0.0522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015380462\n",
            "self.loss(score_1, v1) 0.020214813\n",
            "self.loss(score_2, v2) 0.014149466\n",
            "self.loss(score_3, v3) 0.009886581\n",
            "loss tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011856783\n",
            "self.loss(score_1, v1) 0.029962607\n",
            "self.loss(score_2, v2) 0.035132993\n",
            "self.loss(score_3, v3) 0.010042458\n",
            "loss tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0162912\n",
            "self.loss(score_1, v1) 0.018732024\n",
            "self.loss(score_2, v2) 0.0118935425\n",
            "self.loss(score_3, v3) 0.0057023373\n",
            "loss tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007984758\n",
            "self.loss(score_1, v1) 0.0065557617\n",
            "self.loss(score_2, v2) 0.009720193\n",
            "self.loss(score_3, v3) 0.011306593\n",
            "loss tensor(0.0356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007041736\n",
            "self.loss(score_1, v1) 0.08080347\n",
            "self.loss(score_2, v2) 0.039948326\n",
            "self.loss(score_3, v3) 0.004388555\n",
            "loss tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.018679705\n",
            "self.loss(score_1, v1) 0.056594554\n",
            "self.loss(score_2, v2) 0.016195197\n",
            "self.loss(score_3, v3) 0.010623406\n",
            "loss tensor(0.1021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009112609\n",
            "self.loss(score_1, v1) 0.0075117266\n",
            "self.loss(score_2, v2) 0.009315034\n",
            "self.loss(score_3, v3) 0.0089209685\n",
            "loss tensor(0.0349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12746039\n",
            "self.loss(score_1, v1) 0.05667232\n",
            "self.loss(score_2, v2) 0.041754305\n",
            "self.loss(score_3, v3) 0.029645925\n",
            "loss tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014829431\n",
            "self.loss(score_1, v1) 0.04338073\n",
            "self.loss(score_2, v2) 0.027025048\n",
            "self.loss(score_3, v3) 0.011536872\n",
            "loss tensor(0.0968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050955616\n",
            "self.loss(score_1, v1) 0.02839556\n",
            "self.loss(score_2, v2) 0.037748013\n",
            "self.loss(score_3, v3) 0.011112745\n",
            "loss tensor(0.1282, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012763987\n",
            "self.loss(score_1, v1) 0.030279469\n",
            "self.loss(score_2, v2) 0.032161247\n",
            "self.loss(score_3, v3) 0.011955577\n",
            "loss tensor(0.0872, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008716968\n",
            "self.loss(score_1, v1) 0.01037383\n",
            "self.loss(score_2, v2) 0.014366789\n",
            "self.loss(score_3, v3) 0.008665257\n",
            "loss tensor(0.0421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014317538\n",
            "self.loss(score_1, v1) 0.011743001\n",
            "self.loss(score_2, v2) 0.010248304\n",
            "self.loss(score_3, v3) 0.007186454\n",
            "loss tensor(0.0435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012436932\n",
            "self.loss(score_1, v1) 0.03320088\n",
            "self.loss(score_2, v2) 0.022911517\n",
            "self.loss(score_3, v3) 0.009572256\n",
            "loss tensor(0.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008305588\n",
            "self.loss(score_1, v1) 0.010698958\n",
            "self.loss(score_2, v2) 0.021100614\n",
            "self.loss(score_3, v3) 0.0095312735\n",
            "loss tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.043436386\n",
            "self.loss(score_1, v1) 0.065267995\n",
            "self.loss(score_2, v2) 0.025797524\n",
            "self.loss(score_3, v3) 0.008876794\n",
            "loss tensor(0.1434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015753018\n",
            "self.loss(score_1, v1) 0.036386617\n",
            "self.loss(score_2, v2) 0.028908312\n",
            "self.loss(score_3, v3) 0.013460202\n",
            "loss tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013050954\n",
            "self.loss(score_1, v1) 0.09549222\n",
            "self.loss(score_2, v2) 0.067108154\n",
            "self.loss(score_3, v3) 0.03074795\n",
            "loss tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007987618\n",
            "self.loss(score_1, v1) 0.0098327845\n",
            "self.loss(score_2, v2) 0.013324786\n",
            "self.loss(score_3, v3) 0.007762629\n",
            "loss tensor(0.0389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007544159\n",
            "self.loss(score_1, v1) 0.005077548\n",
            "self.loss(score_2, v2) 0.007814752\n",
            "self.loss(score_3, v3) 0.0065210513\n",
            "loss tensor(0.0270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012320499\n",
            "self.loss(score_1, v1) 0.014894871\n",
            "self.loss(score_2, v2) 0.008167228\n",
            "self.loss(score_3, v3) 0.01000927\n",
            "loss tensor(0.0454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010244138\n",
            "self.loss(score_1, v1) 0.00964095\n",
            "self.loss(score_2, v2) 0.012040109\n",
            "self.loss(score_3, v3) 0.010422211\n",
            "loss tensor(0.0423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010177858\n",
            "self.loss(score_1, v1) 0.022884537\n",
            "self.loss(score_2, v2) 0.019328224\n",
            "self.loss(score_3, v3) 0.00859946\n",
            "loss tensor(0.0610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007202184\n",
            "self.loss(score_1, v1) 0.009006264\n",
            "self.loss(score_2, v2) 0.0075660045\n",
            "self.loss(score_3, v3) 0.005700775\n",
            "loss tensor(0.0295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.041147575\n",
            "self.loss(score_1, v1) 0.04363262\n",
            "self.loss(score_2, v2) 0.03501676\n",
            "self.loss(score_3, v3) 0.010466067\n",
            "loss tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009065612\n",
            "self.loss(score_1, v1) 0.012262351\n",
            "self.loss(score_2, v2) 0.011538022\n",
            "self.loss(score_3, v3) 0.008634332\n",
            "loss tensor(0.0415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0074956915\n",
            "self.loss(score_1, v1) 0.008825681\n",
            "self.loss(score_2, v2) 0.0075074676\n",
            "self.loss(score_3, v3) 0.007777415\n",
            "loss tensor(0.0316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012490419\n",
            "self.loss(score_1, v1) 0.014167959\n",
            "self.loss(score_2, v2) 0.011026892\n",
            "self.loss(score_3, v3) 0.008059631\n",
            "loss tensor(0.0457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008740895\n",
            "self.loss(score_1, v1) 0.030257443\n",
            "self.loss(score_2, v2) 0.01502446\n",
            "self.loss(score_3, v3) 0.010922223\n",
            "loss tensor(0.0649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012696117\n",
            "self.loss(score_1, v1) 0.014232929\n",
            "self.loss(score_2, v2) 0.016645309\n",
            "self.loss(score_3, v3) 0.010457655\n",
            "loss tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017154733\n",
            "self.loss(score_1, v1) 0.043978866\n",
            "self.loss(score_2, v2) 0.050803907\n",
            "self.loss(score_3, v3) 0.06745381\n",
            "loss tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014759706\n",
            "self.loss(score_1, v1) 0.014073011\n",
            "self.loss(score_2, v2) 0.020048494\n",
            "self.loss(score_3, v3) 0.008322562\n",
            "loss tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006423403\n",
            "self.loss(score_1, v1) 0.00711813\n",
            "self.loss(score_2, v2) 0.015482944\n",
            "self.loss(score_3, v3) 0.011002121\n",
            "loss tensor(0.0400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007321812\n",
            "self.loss(score_1, v1) 0.02794478\n",
            "self.loss(score_2, v2) 0.02097635\n",
            "self.loss(score_3, v3) 0.009792974\n",
            "loss tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.066717036\n",
            "self.loss(score_1, v1) 0.028723445\n",
            "self.loss(score_2, v2) 0.024011925\n",
            "self.loss(score_3, v3) 0.007933136\n",
            "loss tensor(0.1274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014072725\n",
            "self.loss(score_1, v1) 0.010633654\n",
            "self.loss(score_2, v2) 0.009282985\n",
            "self.loss(score_3, v3) 0.010822554\n",
            "loss tensor(0.0448, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015316099\n",
            "self.loss(score_1, v1) 0.034118578\n",
            "self.loss(score_2, v2) 0.027855042\n",
            "self.loss(score_3, v3) 0.013858957\n",
            "loss tensor(0.0911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057502132\n",
            "self.loss(score_1, v1) 0.01815769\n",
            "self.loss(score_2, v2) 0.062047817\n",
            "self.loss(score_3, v3) 0.029173851\n",
            "loss tensor(0.1669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014213877\n",
            "self.loss(score_1, v1) 0.008876191\n",
            "self.loss(score_2, v2) 0.013776817\n",
            "self.loss(score_3, v3) 0.008130991\n",
            "loss tensor(0.0450, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.047495537\n",
            "self.loss(score_1, v1) 0.039947502\n",
            "self.loss(score_2, v2) 0.012690399\n",
            "self.loss(score_3, v3) 0.007824768\n",
            "loss tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013757853\n",
            "self.loss(score_1, v1) 0.039264422\n",
            "self.loss(score_2, v2) 0.027082505\n",
            "self.loss(score_3, v3) 0.01207023\n",
            "loss tensor(0.0922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008871294\n",
            "self.loss(score_1, v1) 0.008017969\n",
            "self.loss(score_2, v2) 0.0072041266\n",
            "self.loss(score_3, v3) 0.008222395\n",
            "loss tensor(0.0323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0070949933\n",
            "self.loss(score_1, v1) 0.011157524\n",
            "self.loss(score_2, v2) 0.014568081\n",
            "self.loss(score_3, v3) 0.0094274795\n",
            "loss tensor(0.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021168556\n",
            "self.loss(score_1, v1) 0.054814756\n",
            "self.loss(score_2, v2) 0.06362897\n",
            "self.loss(score_3, v3) 0.018393528\n",
            "loss tensor(0.1580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008882236\n",
            "self.loss(score_1, v1) 0.060198035\n",
            "self.loss(score_2, v2) 0.063551836\n",
            "self.loss(score_3, v3) 0.056906916\n",
            "loss tensor(0.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.034823343\n",
            "self.loss(score_1, v1) 0.06653016\n",
            "self.loss(score_2, v2) 0.041648146\n",
            "self.loss(score_3, v3) 0.018477164\n",
            "loss tensor(0.1615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05609026\n",
            "self.loss(score_1, v1) 0.024900699\n",
            "self.loss(score_2, v2) 0.021156117\n",
            "self.loss(score_3, v3) 0.0068905978\n",
            "loss tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.022294099\n",
            "self.loss(score_1, v1) 0.011704595\n",
            "self.loss(score_2, v2) 0.017299533\n",
            "self.loss(score_3, v3) 0.010669863\n",
            "loss tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0064844596\n",
            "self.loss(score_1, v1) 0.0047169114\n",
            "self.loss(score_2, v2) 0.0071485303\n",
            "self.loss(score_3, v3) 0.006967761\n",
            "loss tensor(0.0253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009225307\n",
            "self.loss(score_1, v1) 0.032362673\n",
            "self.loss(score_2, v2) 0.04260816\n",
            "self.loss(score_3, v3) 0.0098285815\n",
            "loss tensor(0.0940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015429004\n",
            "self.loss(score_1, v1) 0.08160729\n",
            "self.loss(score_2, v2) 0.026795037\n",
            "self.loss(score_3, v3) 0.027359115\n",
            "loss tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010594283\n",
            "self.loss(score_1, v1) 0.007878663\n",
            "self.loss(score_2, v2) 0.007895104\n",
            "self.loss(score_3, v3) 0.009183133\n",
            "loss tensor(0.0356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009279258\n",
            "self.loss(score_1, v1) 0.012193344\n",
            "self.loss(score_2, v2) 0.02183077\n",
            "self.loss(score_3, v3) 0.009917166\n",
            "loss tensor(0.0532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0074432725\n",
            "self.loss(score_1, v1) 0.09620528\n",
            "self.loss(score_2, v2) 0.09797392\n",
            "self.loss(score_3, v3) 0.0916727\n",
            "loss tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009294977\n",
            "self.loss(score_1, v1) 0.016076742\n",
            "self.loss(score_2, v2) 0.011817085\n",
            "self.loss(score_3, v3) 0.016043179\n",
            "loss tensor(0.0532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014568869\n",
            "self.loss(score_1, v1) 0.011571464\n",
            "self.loss(score_2, v2) 0.037710927\n",
            "self.loss(score_3, v3) 0.07938252\n",
            "loss tensor(0.1432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012221681\n",
            "self.loss(score_1, v1) 0.08260449\n",
            "self.loss(score_2, v2) 0.04816407\n",
            "self.loss(score_3, v3) 0.018393308\n",
            "loss tensor(0.1614, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010628747\n",
            "self.loss(score_1, v1) 0.014774311\n",
            "self.loss(score_2, v2) 0.01586052\n",
            "self.loss(score_3, v3) 0.0094382735\n",
            "loss tensor(0.0507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013524944\n",
            "self.loss(score_1, v1) 0.016760683\n",
            "self.loss(score_2, v2) 0.016306994\n",
            "self.loss(score_3, v3) 0.011726129\n",
            "loss tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0066370484\n",
            "self.loss(score_1, v1) 0.0052443002\n",
            "self.loss(score_2, v2) 0.009965007\n",
            "self.loss(score_3, v3) 0.007886772\n",
            "loss tensor(0.0297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011821236\n",
            "self.loss(score_1, v1) 0.013578944\n",
            "self.loss(score_2, v2) 0.00810173\n",
            "self.loss(score_3, v3) 0.010395782\n",
            "loss tensor(0.0439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011478588\n",
            "self.loss(score_1, v1) 0.009984226\n",
            "self.loss(score_2, v2) 0.008056884\n",
            "self.loss(score_3, v3) 0.0076919566\n",
            "loss tensor(0.0372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0073312954\n",
            "self.loss(score_1, v1) 0.0065169623\n",
            "self.loss(score_2, v2) 0.0075317416\n",
            "self.loss(score_3, v3) 0.004344517\n",
            "loss tensor(0.0257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008214039\n",
            "self.loss(score_1, v1) 0.012236003\n",
            "self.loss(score_2, v2) 0.003940852\n",
            "self.loss(score_3, v3) 0.0041411733\n",
            "loss tensor(0.0285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12978527\n",
            "self.loss(score_1, v1) 0.045705624\n",
            "self.loss(score_2, v2) 0.09057425\n",
            "self.loss(score_3, v3) 0.034976892\n",
            "loss tensor(0.3010, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006872563\n",
            "self.loss(score_1, v1) 0.005992576\n",
            "self.loss(score_2, v2) 0.006617161\n",
            "self.loss(score_3, v3) 0.0056915614\n",
            "loss tensor(0.0252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008670536\n",
            "self.loss(score_1, v1) 0.023392985\n",
            "self.loss(score_2, v2) 0.013302076\n",
            "self.loss(score_3, v3) 0.0077850814\n",
            "loss tensor(0.0532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.004692926\n",
            "self.loss(score_1, v1) 0.009752638\n",
            "self.loss(score_2, v2) 0.007585289\n",
            "self.loss(score_3, v3) 0.0055137365\n",
            "loss tensor(0.0275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006873045\n",
            "self.loss(score_1, v1) 0.01190395\n",
            "self.loss(score_2, v2) 0.010811801\n",
            "self.loss(score_3, v3) 0.009673338\n",
            "loss tensor(0.0393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016509319\n",
            "self.loss(score_1, v1) 0.017360225\n",
            "self.loss(score_2, v2) 0.024182264\n",
            "self.loss(score_3, v3) 0.017385477\n",
            "loss tensor(0.0754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013455713\n",
            "self.loss(score_1, v1) 0.019199966\n",
            "self.loss(score_2, v2) 0.02016515\n",
            "self.loss(score_3, v3) 0.013287925\n",
            "loss tensor(0.0661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010966737\n",
            "self.loss(score_1, v1) 0.014380609\n",
            "self.loss(score_2, v2) 0.015766865\n",
            "self.loss(score_3, v3) 0.011557489\n",
            "loss tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014348335\n",
            "self.loss(score_1, v1) 0.009587248\n",
            "self.loss(score_2, v2) 0.006456761\n",
            "self.loss(score_3, v3) 0.0076871566\n",
            "loss tensor(0.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01011281\n",
            "self.loss(score_1, v1) 0.008676278\n",
            "self.loss(score_2, v2) 0.0076443767\n",
            "self.loss(score_3, v3) 0.009455067\n",
            "loss tensor(0.0359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008695707\n",
            "self.loss(score_1, v1) 0.01135591\n",
            "self.loss(score_2, v2) 0.02756224\n",
            "self.loss(score_3, v3) 0.07842244\n",
            "loss tensor(0.1260, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006389523\n",
            "self.loss(score_1, v1) 0.008490446\n",
            "self.loss(score_2, v2) 0.009874045\n",
            "self.loss(score_3, v3) 0.0065738373\n",
            "loss tensor(0.0313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008727364\n",
            "self.loss(score_1, v1) 0.013889695\n",
            "self.loss(score_2, v2) 0.015272011\n",
            "self.loss(score_3, v3) 0.011753833\n",
            "loss tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008460557\n",
            "self.loss(score_1, v1) 0.0271124\n",
            "self.loss(score_2, v2) 0.07538976\n",
            "self.loss(score_3, v3) 0.04702453\n",
            "loss tensor(0.1580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008498867\n",
            "self.loss(score_1, v1) 0.053088114\n",
            "self.loss(score_2, v2) 0.08444152\n",
            "self.loss(score_3, v3) 0.118458904\n",
            "loss tensor(0.2645, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013029437\n",
            "self.loss(score_1, v1) 0.019659128\n",
            "self.loss(score_2, v2) 0.018244997\n",
            "self.loss(score_3, v3) 0.030357506\n",
            "loss tensor(0.0813, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011414849\n",
            "self.loss(score_1, v1) 0.024255695\n",
            "self.loss(score_2, v2) 0.019048346\n",
            "self.loss(score_3, v3) 0.01514274\n",
            "loss tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0070603406\n",
            "self.loss(score_1, v1) 0.00697054\n",
            "self.loss(score_2, v2) 0.008951905\n",
            "self.loss(score_3, v3) 0.007482477\n",
            "loss tensor(0.0305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010597379\n",
            "self.loss(score_1, v1) 0.017088253\n",
            "self.loss(score_2, v2) 0.024708303\n",
            "self.loss(score_3, v3) 0.017195905\n",
            "loss tensor(0.0696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008113613\n",
            "self.loss(score_1, v1) 0.010861316\n",
            "self.loss(score_2, v2) 0.013419579\n",
            "self.loss(score_3, v3) 0.0068334453\n",
            "loss tensor(0.0392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016240265\n",
            "self.loss(score_1, v1) 0.016003953\n",
            "self.loss(score_2, v2) 0.016203811\n",
            "self.loss(score_3, v3) 0.014016839\n",
            "loss tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009509685\n",
            "self.loss(score_1, v1) 0.030098945\n",
            "self.loss(score_2, v2) 0.024909524\n",
            "self.loss(score_3, v3) 0.011333847\n",
            "loss tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011449934\n",
            "self.loss(score_1, v1) 0.012174119\n",
            "self.loss(score_2, v2) 0.010401956\n",
            "self.loss(score_3, v3) 0.008367743\n",
            "loss tensor(0.0424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008914099\n",
            "self.loss(score_1, v1) 0.0124349175\n",
            "self.loss(score_2, v2) 0.021364633\n",
            "self.loss(score_3, v3) 0.010195213\n",
            "loss tensor(0.0529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014720299\n",
            "self.loss(score_1, v1) 0.050475392\n",
            "self.loss(score_2, v2) 0.033617403\n",
            "self.loss(score_3, v3) 0.025835237\n",
            "loss tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009449963\n",
            "self.loss(score_1, v1) 0.012701673\n",
            "self.loss(score_2, v2) 0.014002342\n",
            "self.loss(score_3, v3) 0.00998698\n",
            "loss tensor(0.0461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008553989\n",
            "self.loss(score_1, v1) 0.0066661476\n",
            "self.loss(score_2, v2) 0.008275202\n",
            "self.loss(score_3, v3) 0.006873415\n",
            "loss tensor(0.0304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015544305\n",
            "self.loss(score_1, v1) 0.024970787\n",
            "self.loss(score_2, v2) 0.02293106\n",
            "self.loss(score_3, v3) 0.011771758\n",
            "loss tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007298941\n",
            "self.loss(score_1, v1) 0.007379176\n",
            "self.loss(score_2, v2) 0.008463203\n",
            "self.loss(score_3, v3) 0.013257065\n",
            "loss tensor(0.0364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0110854395\n",
            "self.loss(score_1, v1) 0.0115591055\n",
            "self.loss(score_2, v2) 0.01803396\n",
            "self.loss(score_3, v3) 0.009539607\n",
            "loss tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06638516\n",
            "self.loss(score_1, v1) 0.05934675\n",
            "self.loss(score_2, v2) 0.027356619\n",
            "self.loss(score_3, v3) 0.034528043\n",
            "loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0144224\n",
            "self.loss(score_1, v1) 0.013514608\n",
            "self.loss(score_2, v2) 0.01330927\n",
            "self.loss(score_3, v3) 0.008851951\n",
            "loss tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01691754\n",
            "self.loss(score_1, v1) 0.03220335\n",
            "self.loss(score_2, v2) 0.011113261\n",
            "self.loss(score_3, v3) 0.008411215\n",
            "loss tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014191693\n",
            "self.loss(score_1, v1) 0.019591168\n",
            "self.loss(score_2, v2) 0.014349975\n",
            "self.loss(score_3, v3) 0.011114496\n",
            "loss tensor(0.0592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019843094\n",
            "self.loss(score_1, v1) 0.015725013\n",
            "self.loss(score_2, v2) 0.010558749\n",
            "self.loss(score_3, v3) 0.007917343\n",
            "loss tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014223763\n",
            "self.loss(score_1, v1) 0.015550249\n",
            "self.loss(score_2, v2) 0.008833889\n",
            "self.loss(score_3, v3) 0.006449826\n",
            "loss tensor(0.0451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0099986065\n",
            "self.loss(score_1, v1) 0.010734143\n",
            "self.loss(score_2, v2) 0.015560518\n",
            "self.loss(score_3, v3) 0.012788857\n",
            "loss tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012554939\n",
            "self.loss(score_1, v1) 0.041218553\n",
            "self.loss(score_2, v2) 0.038530625\n",
            "self.loss(score_3, v3) 0.007181528\n",
            "loss tensor(0.0995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0054581487\n",
            "self.loss(score_1, v1) 0.0079781385\n",
            "self.loss(score_2, v2) 0.00929627\n",
            "self.loss(score_3, v3) 0.006346746\n",
            "loss tensor(0.0291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013089718\n",
            "self.loss(score_1, v1) 0.025785983\n",
            "self.loss(score_2, v2) 0.02164451\n",
            "self.loss(score_3, v3) 0.010877703\n",
            "loss tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0073936665\n",
            "self.loss(score_1, v1) 0.005546097\n",
            "self.loss(score_2, v2) 0.010044748\n",
            "self.loss(score_3, v3) 0.007533528\n",
            "loss tensor(0.0305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0073695336\n",
            "self.loss(score_1, v1) 0.011280672\n",
            "self.loss(score_2, v2) 0.021804562\n",
            "self.loss(score_3, v3) 0.0104253935\n",
            "loss tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051583197\n",
            "self.loss(score_1, v1) 0.035797816\n",
            "self.loss(score_2, v2) 0.03195359\n",
            "self.loss(score_3, v3) 0.035739977\n",
            "loss tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006327238\n",
            "self.loss(score_1, v1) 0.011603454\n",
            "self.loss(score_2, v2) 0.014485676\n",
            "self.loss(score_3, v3) 0.010203081\n",
            "loss tensor(0.0426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006155007\n",
            "self.loss(score_1, v1) 0.007623931\n",
            "self.loss(score_2, v2) 0.014175909\n",
            "self.loss(score_3, v3) 0.007097297\n",
            "loss tensor(0.0351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014611762\n",
            "self.loss(score_1, v1) 0.022295367\n",
            "self.loss(score_2, v2) 0.014551604\n",
            "self.loss(score_3, v3) 0.011034628\n",
            "loss tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011354839\n",
            "self.loss(score_1, v1) 0.08925108\n",
            "self.loss(score_2, v2) 0.050752845\n",
            "self.loss(score_3, v3) 0.023259224\n",
            "loss tensor(0.1746, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0142768705\n",
            "self.loss(score_1, v1) 0.011690085\n",
            "self.loss(score_2, v2) 0.010240745\n",
            "self.loss(score_3, v3) 0.010330522\n",
            "loss tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01101216\n",
            "self.loss(score_1, v1) 0.0358251\n",
            "self.loss(score_2, v2) 0.04141106\n",
            "self.loss(score_3, v3) 0.01074451\n",
            "loss tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016895927\n",
            "self.loss(score_1, v1) 0.027403027\n",
            "self.loss(score_2, v2) 0.046180245\n",
            "self.loss(score_3, v3) 0.075698264\n",
            "loss tensor(0.1662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0072699804\n",
            "self.loss(score_1, v1) 0.076291375\n",
            "self.loss(score_2, v2) 0.046486605\n",
            "self.loss(score_3, v3) 0.053926546\n",
            "loss tensor(0.1840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010889165\n",
            "self.loss(score_1, v1) 0.0113237025\n",
            "self.loss(score_2, v2) 0.014966179\n",
            "self.loss(score_3, v3) 0.007982569\n",
            "loss tensor(0.0452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0033222202\n",
            "self.loss(score_1, v1) 0.008175146\n",
            "self.loss(score_2, v2) 0.013348474\n",
            "self.loss(score_3, v3) 0.0043410324\n",
            "loss tensor(0.0292, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010459747\n",
            "self.loss(score_1, v1) 0.009303401\n",
            "self.loss(score_2, v2) 0.009697626\n",
            "self.loss(score_3, v3) 0.010905483\n",
            "loss tensor(0.0404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00756051\n",
            "self.loss(score_1, v1) 0.011042005\n",
            "self.loss(score_2, v2) 0.012851123\n",
            "self.loss(score_3, v3) 0.011775243\n",
            "loss tensor(0.0432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0075285807\n",
            "self.loss(score_1, v1) 0.0044036\n",
            "self.loss(score_2, v2) 0.005821309\n",
            "self.loss(score_3, v3) 0.008669564\n",
            "loss tensor(0.0264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007772614\n",
            "self.loss(score_1, v1) 0.0060865777\n",
            "self.loss(score_2, v2) 0.0034679377\n",
            "self.loss(score_3, v3) 0.005026633\n",
            "loss tensor(0.0224, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011212925\n",
            "self.loss(score_1, v1) 0.0076450724\n",
            "self.loss(score_2, v2) 0.007710064\n",
            "self.loss(score_3, v3) 0.008874159\n",
            "loss tensor(0.0354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011446706\n",
            "self.loss(score_1, v1) 0.012081469\n",
            "self.loss(score_2, v2) 0.010664904\n",
            "self.loss(score_3, v3) 0.010338378\n",
            "loss tensor(0.0445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.005055887\n",
            "self.loss(score_1, v1) 0.005234\n",
            "self.loss(score_2, v2) 0.005050007\n",
            "self.loss(score_3, v3) 0.003960816\n",
            "loss tensor(0.0193, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0101351645\n",
            "self.loss(score_1, v1) 0.016227508\n",
            "self.loss(score_2, v2) 0.02965291\n",
            "self.loss(score_3, v3) 0.013168186\n",
            "loss tensor(0.0692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012805658\n",
            "self.loss(score_1, v1) 0.03819854\n",
            "self.loss(score_2, v2) 0.0067813452\n",
            "self.loss(score_3, v3) 0.0057815127\n",
            "loss tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0071253893\n",
            "self.loss(score_1, v1) 0.00735964\n",
            "self.loss(score_2, v2) 0.008678226\n",
            "self.loss(score_3, v3) 0.007585076\n",
            "loss tensor(0.0307, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008912691\n",
            "self.loss(score_1, v1) 0.011849784\n",
            "self.loss(score_2, v2) 0.011164328\n",
            "self.loss(score_3, v3) 0.011089356\n",
            "loss tensor(0.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012092451\n",
            "self.loss(score_1, v1) 0.042844947\n",
            "self.loss(score_2, v2) 0.04287737\n",
            "self.loss(score_3, v3) 0.011894804\n",
            "loss tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008755018\n",
            "self.loss(score_1, v1) 0.0324402\n",
            "self.loss(score_2, v2) 0.011366163\n",
            "self.loss(score_3, v3) 0.007500122\n",
            "loss tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008439582\n",
            "self.loss(score_1, v1) 0.020565253\n",
            "self.loss(score_2, v2) 0.012639241\n",
            "self.loss(score_3, v3) 0.0076454175\n",
            "loss tensor(0.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010391552\n",
            "self.loss(score_1, v1) 0.013580712\n",
            "self.loss(score_2, v2) 0.01353029\n",
            "self.loss(score_3, v3) 0.011078436\n",
            "loss tensor(0.0486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.005263265\n",
            "self.loss(score_1, v1) 0.009946014\n",
            "self.loss(score_2, v2) 0.026548373\n",
            "self.loss(score_3, v3) 0.0047329986\n",
            "loss tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01745981\n",
            "self.loss(score_1, v1) 0.017871564\n",
            "self.loss(score_2, v2) 0.005960884\n",
            "self.loss(score_3, v3) 0.007360773\n",
            "loss tensor(0.0487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0073419227\n",
            "self.loss(score_1, v1) 0.007891694\n",
            "self.loss(score_2, v2) 0.013341319\n",
            "self.loss(score_3, v3) 0.010054302\n",
            "loss tensor(0.0386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0064230454\n",
            "self.loss(score_1, v1) 0.006986138\n",
            "self.loss(score_2, v2) 0.006853036\n",
            "self.loss(score_3, v3) 0.0068684067\n",
            "loss tensor(0.0271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.045114245\n",
            "self.loss(score_1, v1) 0.035788592\n",
            "self.loss(score_2, v2) 0.01729665\n",
            "self.loss(score_3, v3) 0.00865448\n",
            "loss tensor(0.1069, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010176008\n",
            "self.loss(score_1, v1) 0.0048767985\n",
            "self.loss(score_2, v2) 0.00607918\n",
            "self.loss(score_3, v3) 0.007011147\n",
            "loss tensor(0.0281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008700992\n",
            "self.loss(score_1, v1) 0.014592854\n",
            "self.loss(score_2, v2) 0.01363951\n",
            "self.loss(score_3, v3) 0.011559125\n",
            "loss tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.020523211\n",
            "self.loss(score_1, v1) 0.08054445\n",
            "self.loss(score_2, v2) 0.08209959\n",
            "self.loss(score_3, v3) 0.07478781\n",
            "loss tensor(0.2580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009814069\n",
            "self.loss(score_1, v1) 0.00666761\n",
            "self.loss(score_2, v2) 0.008392425\n",
            "self.loss(score_3, v3) 0.0072921314\n",
            "loss tensor(0.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04682792\n",
            "self.loss(score_1, v1) 0.035835996\n",
            "self.loss(score_2, v2) 0.060100093\n",
            "self.loss(score_3, v3) 0.008317509\n",
            "loss tensor(0.1511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.026483998\n",
            "self.loss(score_1, v1) 0.023949383\n",
            "self.loss(score_2, v2) 0.045737114\n",
            "self.loss(score_3, v3) 0.0067848675\n",
            "loss tensor(0.1030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01159249\n",
            "self.loss(score_1, v1) 0.016071832\n",
            "self.loss(score_2, v2) 0.015900133\n",
            "self.loss(score_3, v3) 0.013931995\n",
            "loss tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013838866\n",
            "self.loss(score_1, v1) 0.009823477\n",
            "self.loss(score_2, v2) 0.003927281\n",
            "self.loss(score_3, v3) 0.005545158\n",
            "loss tensor(0.0331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016147692\n",
            "self.loss(score_1, v1) 0.0436431\n",
            "self.loss(score_2, v2) 0.055750206\n",
            "self.loss(score_3, v3) 0.0070766415\n",
            "loss tensor(0.1226, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.022002859\n",
            "self.loss(score_1, v1) 0.044266965\n",
            "self.loss(score_2, v2) 0.012467508\n",
            "self.loss(score_3, v3) 0.008367772\n",
            "loss tensor(0.0871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007018918\n",
            "self.loss(score_1, v1) 0.016851474\n",
            "self.loss(score_2, v2) 0.01836783\n",
            "self.loss(score_3, v3) 0.008790327\n",
            "loss tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03191249\n",
            "self.loss(score_1, v1) 0.027242903\n",
            "self.loss(score_2, v2) 0.019632917\n",
            "self.loss(score_3, v3) 0.008009216\n",
            "loss tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013223124\n",
            "self.loss(score_1, v1) 0.026027618\n",
            "self.loss(score_2, v2) 0.00863837\n",
            "self.loss(score_3, v3) 0.0075616348\n",
            "loss tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013188842\n",
            "self.loss(score_1, v1) 0.011974852\n",
            "self.loss(score_2, v2) 0.0062841023\n",
            "self.loss(score_3, v3) 0.0076566623\n",
            "loss tensor(0.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012943572\n",
            "self.loss(score_1, v1) 0.012006469\n",
            "self.loss(score_2, v2) 0.0866782\n",
            "self.loss(score_3, v3) 0.010039028\n",
            "loss tensor(0.1217, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06435736\n",
            "self.loss(score_1, v1) 0.06087789\n",
            "self.loss(score_2, v2) 0.07703041\n",
            "self.loss(score_3, v3) 0.040755726\n",
            "loss tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006588369\n",
            "self.loss(score_1, v1) 0.008485585\n",
            "self.loss(score_2, v2) 0.012589233\n",
            "self.loss(score_3, v3) 0.007591764\n",
            "loss tensor(0.0353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.048725493\n",
            "self.loss(score_1, v1) 0.03953942\n",
            "self.loss(score_2, v2) 0.025501078\n",
            "self.loss(score_3, v3) 0.008961558\n",
            "loss tensor(0.1227, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01262322\n",
            "self.loss(score_1, v1) 0.0056953724\n",
            "self.loss(score_2, v2) 0.0078553315\n",
            "self.loss(score_3, v3) 0.011670646\n",
            "loss tensor(0.0378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009871226\n",
            "self.loss(score_1, v1) 0.02143443\n",
            "self.loss(score_2, v2) 0.011373266\n",
            "self.loss(score_3, v3) 0.006117312\n",
            "loss tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0083512515\n",
            "self.loss(score_1, v1) 0.008002454\n",
            "self.loss(score_2, v2) 0.010509809\n",
            "self.loss(score_3, v3) 0.009997756\n",
            "loss tensor(0.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009667967\n",
            "self.loss(score_1, v1) 0.011453177\n",
            "self.loss(score_2, v2) 0.027934475\n",
            "self.loss(score_3, v3) 0.024932908\n",
            "loss tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006366517\n",
            "self.loss(score_1, v1) 0.0075621568\n",
            "self.loss(score_2, v2) 0.008912192\n",
            "self.loss(score_3, v3) 0.006652153\n",
            "loss tensor(0.0295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008322956\n",
            "self.loss(score_1, v1) 0.006141422\n",
            "self.loss(score_2, v2) 0.007969919\n",
            "self.loss(score_3, v3) 0.0068797483\n",
            "loss tensor(0.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06869536\n",
            "self.loss(score_1, v1) 0.061449137\n",
            "self.loss(score_2, v2) 0.0918575\n",
            "self.loss(score_3, v3) 0.029448448\n",
            "loss tensor(0.2515, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010055167\n",
            "self.loss(score_1, v1) 0.012716741\n",
            "self.loss(score_2, v2) 0.020554341\n",
            "self.loss(score_3, v3) 0.0071162283\n",
            "loss tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0073292213\n",
            "self.loss(score_1, v1) 0.006746065\n",
            "self.loss(score_2, v2) 0.0060833506\n",
            "self.loss(score_3, v3) 0.007906376\n",
            "loss tensor(0.0281, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021270048\n",
            "self.loss(score_1, v1) 0.012829967\n",
            "self.loss(score_2, v2) 0.01367798\n",
            "self.loss(score_3, v3) 0.009858686\n",
            "loss tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010122288\n",
            "self.loss(score_1, v1) 0.014745336\n",
            "self.loss(score_2, v2) 0.010365291\n",
            "self.loss(score_3, v3) 0.010356398\n",
            "loss tensor(0.0456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011352818\n",
            "self.loss(score_1, v1) 0.019039925\n",
            "self.loss(score_2, v2) 0.034940373\n",
            "self.loss(score_3, v3) 0.007104643\n",
            "loss tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016330563\n",
            "self.loss(score_1, v1) 0.020703727\n",
            "self.loss(score_2, v2) 0.013489947\n",
            "self.loss(score_3, v3) 0.006496138\n",
            "loss tensor(0.0570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01867761\n",
            "self.loss(score_1, v1) 0.022682922\n",
            "self.loss(score_2, v2) 0.04650407\n",
            "self.loss(score_3, v3) 0.0121550085\n",
            "loss tensor(0.1000, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009803594\n",
            "self.loss(score_1, v1) 0.04183946\n",
            "self.loss(score_2, v2) 0.031280607\n",
            "self.loss(score_3, v3) 0.025525812\n",
            "loss tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014976696\n",
            "self.loss(score_1, v1) 0.021793937\n",
            "self.loss(score_2, v2) 0.031208903\n",
            "self.loss(score_3, v3) 0.059190847\n",
            "loss tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06793653\n",
            "self.loss(score_1, v1) 0.041423663\n",
            "self.loss(score_2, v2) 0.09926325\n",
            "self.loss(score_3, v3) 0.0094567705\n",
            "loss tensor(0.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010140973\n",
            "self.loss(score_1, v1) 0.03754361\n",
            "self.loss(score_2, v2) 0.015068844\n",
            "self.loss(score_3, v3) 0.012802871\n",
            "loss tensor(0.0756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015097183\n",
            "self.loss(score_1, v1) 0.012980424\n",
            "self.loss(score_2, v2) 0.011974636\n",
            "self.loss(score_3, v3) 0.006926924\n",
            "loss tensor(0.0470, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.019350672\n",
            "self.loss(score_1, v1) 0.027223568\n",
            "self.loss(score_2, v2) 0.008380163\n",
            "self.loss(score_3, v3) 0.007412492\n",
            "loss tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.004359929\n",
            "self.loss(score_1, v1) 0.0038538794\n",
            "self.loss(score_2, v2) 0.0066455062\n",
            "self.loss(score_3, v3) 0.005499635\n",
            "loss tensor(0.0204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0074905357\n",
            "self.loss(score_1, v1) 0.009535709\n",
            "self.loss(score_2, v2) 0.021207413\n",
            "self.loss(score_3, v3) 0.007834212\n",
            "loss tensor(0.0461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021687258\n",
            "self.loss(score_1, v1) 0.020577218\n",
            "self.loss(score_2, v2) 0.012007998\n",
            "self.loss(score_3, v3) 0.009731743\n",
            "loss tensor(0.0640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008902978\n",
            "self.loss(score_1, v1) 0.017372657\n",
            "self.loss(score_2, v2) 0.017460614\n",
            "self.loss(score_3, v3) 0.010821197\n",
            "loss tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013881014\n",
            "self.loss(score_1, v1) 0.02252816\n",
            "self.loss(score_2, v2) 0.015547421\n",
            "self.loss(score_3, v3) 0.0082377875\n",
            "loss tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008438493\n",
            "self.loss(score_1, v1) 0.010566981\n",
            "self.loss(score_2, v2) 0.019542694\n",
            "self.loss(score_3, v3) 0.00793155\n",
            "loss tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009425659\n",
            "self.loss(score_1, v1) 0.077978194\n",
            "self.loss(score_2, v2) 0.033600114\n",
            "self.loss(score_3, v3) 0.008551984\n",
            "loss tensor(0.1296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011759437\n",
            "self.loss(score_1, v1) 0.010874753\n",
            "self.loss(score_2, v2) 0.012212123\n",
            "self.loss(score_3, v3) 0.008653972\n",
            "loss tensor(0.0435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008184201\n",
            "self.loss(score_1, v1) 0.017386012\n",
            "self.loss(score_2, v2) 0.017200997\n",
            "self.loss(score_3, v3) 0.011314562\n",
            "loss tensor(0.0541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009512995\n",
            "self.loss(score_1, v1) 0.006752567\n",
            "self.loss(score_2, v2) 0.012850442\n",
            "self.loss(score_3, v3) 0.011727891\n",
            "loss tensor(0.0408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0065017142\n",
            "self.loss(score_1, v1) 0.069113545\n",
            "self.loss(score_2, v2) 0.01226087\n",
            "self.loss(score_3, v3) 0.0059389006\n",
            "loss tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014445699\n",
            "self.loss(score_1, v1) 0.13868436\n",
            "self.loss(score_2, v2) 0.028610954\n",
            "self.loss(score_3, v3) 0.010374731\n",
            "loss tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0084515335\n",
            "self.loss(score_1, v1) 0.009902892\n",
            "self.loss(score_2, v2) 0.0097631365\n",
            "self.loss(score_3, v3) 0.006675167\n",
            "loss tensor(0.0348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0068231714\n",
            "self.loss(score_1, v1) 0.0070987204\n",
            "self.loss(score_2, v2) 0.0077640084\n",
            "self.loss(score_3, v3) 0.0046410477\n",
            "loss tensor(0.0263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021224385\n",
            "self.loss(score_1, v1) 0.015657557\n",
            "self.loss(score_2, v2) 0.009937754\n",
            "self.loss(score_3, v3) 0.008845179\n",
            "loss tensor(0.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014783841\n",
            "self.loss(score_1, v1) 0.019029219\n",
            "self.loss(score_2, v2) 0.0095995385\n",
            "self.loss(score_3, v3) 0.011178218\n",
            "loss tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0503184\n",
            "self.loss(score_1, v1) 0.033104014\n",
            "self.loss(score_2, v2) 0.027768105\n",
            "self.loss(score_3, v3) 0.013439335\n",
            "loss tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013985666\n",
            "self.loss(score_1, v1) 0.007805127\n",
            "self.loss(score_2, v2) 0.011992112\n",
            "self.loss(score_3, v3) 0.011477233\n",
            "loss tensor(0.0453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009716697\n",
            "self.loss(score_1, v1) 0.017505495\n",
            "self.loss(score_2, v2) 0.024401948\n",
            "self.loss(score_3, v3) 0.009600395\n",
            "loss tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006593615\n",
            "self.loss(score_1, v1) 0.005017361\n",
            "self.loss(score_2, v2) 0.006063015\n",
            "self.loss(score_3, v3) 0.0055865967\n",
            "loss tensor(0.0233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015950501\n",
            "self.loss(score_1, v1) 0.09942297\n",
            "self.loss(score_2, v2) 0.10106249\n",
            "self.loss(score_3, v3) 0.02512767\n",
            "loss tensor(0.2416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012563145\n",
            "self.loss(score_1, v1) 0.011931148\n",
            "self.loss(score_2, v2) 0.01483005\n",
            "self.loss(score_3, v3) 0.00829926\n",
            "loss tensor(0.0476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010563036\n",
            "self.loss(score_1, v1) 0.008986972\n",
            "self.loss(score_2, v2) 0.009611712\n",
            "self.loss(score_3, v3) 0.011123766\n",
            "loss tensor(0.0403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01680304\n",
            "self.loss(score_1, v1) 0.030807797\n",
            "self.loss(score_2, v2) 0.023951612\n",
            "self.loss(score_3, v3) 0.016744474\n",
            "loss tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008344499\n",
            "self.loss(score_1, v1) 0.01434457\n",
            "self.loss(score_2, v2) 0.027524445\n",
            "self.loss(score_3, v3) 0.011943166\n",
            "loss tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049709573\n",
            "self.loss(score_1, v1) 0.024289656\n",
            "self.loss(score_2, v2) 0.029458763\n",
            "self.loss(score_3, v3) 0.010370554\n",
            "loss tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.026527904\n",
            "self.loss(score_1, v1) 0.014898148\n",
            "self.loss(score_2, v2) 0.012856448\n",
            "self.loss(score_3, v3) 0.010305335\n",
            "loss tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.022298515\n",
            "self.loss(score_1, v1) 0.036191665\n",
            "self.loss(score_2, v2) 0.01989873\n",
            "self.loss(score_3, v3) 0.010145199\n",
            "loss tensor(0.0885, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.022125179\n",
            "self.loss(score_1, v1) 0.021160075\n",
            "self.loss(score_2, v2) 0.018588169\n",
            "self.loss(score_3, v3) 0.007743306\n",
            "loss tensor(0.0696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.01113609\n",
            "self.loss(score_1, v1) 0.011218\n",
            "self.loss(score_2, v2) 0.017606277\n",
            "self.loss(score_3, v3) 0.011428695\n",
            "loss tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.028034618\n",
            "self.loss(score_1, v1) 0.01805747\n",
            "self.loss(score_2, v2) 0.024064668\n",
            "self.loss(score_3, v3) 0.008804817\n",
            "loss tensor(0.0790, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011730634\n",
            "self.loss(score_1, v1) 0.053648546\n",
            "self.loss(score_2, v2) 0.041820705\n",
            "self.loss(score_3, v3) 0.010079452\n",
            "loss tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013379734\n",
            "self.loss(score_1, v1) 0.009047085\n",
            "self.loss(score_2, v2) 0.0065715513\n",
            "self.loss(score_3, v3) 0.009077577\n",
            "loss tensor(0.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015820649\n",
            "self.loss(score_1, v1) 0.019374177\n",
            "self.loss(score_2, v2) 0.0118518295\n",
            "self.loss(score_3, v3) 0.010367403\n",
            "loss tensor(0.0574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0414324\n",
            "self.loss(score_1, v1) 0.016417176\n",
            "self.loss(score_2, v2) 0.02228879\n",
            "self.loss(score_3, v3) 0.013457476\n",
            "loss tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0122947665\n",
            "self.loss(score_1, v1) 0.01950505\n",
            "self.loss(score_2, v2) 0.016848458\n",
            "self.loss(score_3, v3) 0.010859997\n",
            "loss tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012528771\n",
            "self.loss(score_1, v1) 0.011471244\n",
            "self.loss(score_2, v2) 0.00620727\n",
            "self.loss(score_3, v3) 0.0060578263\n",
            "loss tensor(0.0363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010753123\n",
            "self.loss(score_1, v1) 0.012374631\n",
            "self.loss(score_2, v2) 0.014006896\n",
            "self.loss(score_3, v3) 0.008901348\n",
            "loss tensor(0.0460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0077508907\n",
            "self.loss(score_1, v1) 0.0059148273\n",
            "self.loss(score_2, v2) 0.009360025\n",
            "self.loss(score_3, v3) 0.010048901\n",
            "loss tensor(0.0331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0058462415\n",
            "self.loss(score_1, v1) 0.0061959503\n",
            "self.loss(score_2, v2) 0.009125125\n",
            "self.loss(score_3, v3) 0.008120084\n",
            "loss tensor(0.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05864886\n",
            "self.loss(score_1, v1) 0.02434271\n",
            "self.loss(score_2, v2) 0.056506053\n",
            "self.loss(score_3, v3) 0.011840929\n",
            "loss tensor(0.1513, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008515582\n",
            "self.loss(score_1, v1) 0.029705528\n",
            "self.loss(score_2, v2) 0.02242554\n",
            "self.loss(score_3, v3) 0.017981112\n",
            "loss tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010986283\n",
            "self.loss(score_1, v1) 0.006411929\n",
            "self.loss(score_2, v2) 0.005071267\n",
            "self.loss(score_3, v3) 0.0074031353\n",
            "loss tensor(0.0299, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.011559336\n",
            "self.loss(score_1, v1) 0.013370602\n",
            "self.loss(score_2, v2) 0.022441281\n",
            "self.loss(score_3, v3) 0.012108573\n",
            "loss tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008241951\n",
            "self.loss(score_1, v1) 0.01788051\n",
            "self.loss(score_2, v2) 0.020147165\n",
            "self.loss(score_3, v3) 0.08632451\n",
            "loss tensor(0.1326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.006563893\n",
            "self.loss(score_1, v1) 0.008714149\n",
            "self.loss(score_2, v2) 0.01502581\n",
            "self.loss(score_3, v3) 0.009584387\n",
            "loss tensor(0.0399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050021604\n",
            "self.loss(score_1, v1) 0.01594243\n",
            "self.loss(score_2, v2) 0.07998023\n",
            "self.loss(score_3, v3) 0.010221642\n",
            "loss tensor(0.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009924038\n",
            "self.loss(score_1, v1) 0.007509249\n",
            "self.loss(score_2, v2) 0.009767103\n",
            "self.loss(score_3, v3) 0.009904469\n",
            "loss tensor(0.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021210069\n",
            "self.loss(score_1, v1) 0.028081222\n",
            "self.loss(score_2, v2) 0.01797506\n",
            "self.loss(score_3, v3) 0.008357342\n",
            "loss tensor(0.0756, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010435064\n",
            "self.loss(score_1, v1) 0.0089004235\n",
            "self.loss(score_2, v2) 0.004364463\n",
            "self.loss(score_3, v3) 0.004753863\n",
            "loss tensor(0.0285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008375489\n",
            "self.loss(score_1, v1) 0.009605936\n",
            "self.loss(score_2, v2) 0.009454302\n",
            "self.loss(score_3, v3) 0.008352344\n",
            "loss tensor(0.0358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007057137\n",
            "self.loss(score_1, v1) 0.009091661\n",
            "self.loss(score_2, v2) 0.009552809\n",
            "self.loss(score_3, v3) 0.008001942\n",
            "loss tensor(0.0337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008689679\n",
            "self.loss(score_1, v1) 0.01785739\n",
            "self.loss(score_2, v2) 0.026882954\n",
            "self.loss(score_3, v3) 0.00974413\n",
            "loss tensor(0.0632, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009634994\n",
            "self.loss(score_1, v1) 0.009518301\n",
            "self.loss(score_2, v2) 0.016795982\n",
            "self.loss(score_3, v3) 0.008635579\n",
            "loss tensor(0.0446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014818427\n",
            "self.loss(score_1, v1) 0.019813279\n",
            "self.loss(score_2, v2) 0.010916682\n",
            "self.loss(score_3, v3) 0.0077225035\n",
            "loss tensor(0.0533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014721699\n",
            "self.loss(score_1, v1) 0.008907781\n",
            "self.loss(score_2, v2) 0.00797289\n",
            "self.loss(score_3, v3) 0.008858612\n",
            "loss tensor(0.0405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0094622\n",
            "self.loss(score_1, v1) 0.016289609\n",
            "self.loss(score_2, v2) 0.048507452\n",
            "self.loss(score_3, v3) 0.10251989\n",
            "loss tensor(0.1768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009569505\n",
            "self.loss(score_1, v1) 0.01280092\n",
            "self.loss(score_2, v2) 0.015699346\n",
            "self.loss(score_3, v3) 0.012278818\n",
            "loss tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.00761005\n",
            "self.loss(score_1, v1) 0.0063893287\n",
            "self.loss(score_2, v2) 0.0075637293\n",
            "self.loss(score_3, v3) 0.0074228994\n",
            "loss tensor(0.0290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017844371\n",
            "self.loss(score_1, v1) 0.01724735\n",
            "self.loss(score_2, v2) 0.007852039\n",
            "self.loss(score_3, v3) 0.007837659\n",
            "loss tensor(0.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008669715\n",
            "self.loss(score_1, v1) 0.008605185\n",
            "self.loss(score_2, v2) 0.012536534\n",
            "self.loss(score_3, v3) 0.0077883084\n",
            "loss tensor(0.0376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0075561865\n",
            "self.loss(score_1, v1) 0.012655075\n",
            "self.loss(score_2, v2) 0.01579825\n",
            "self.loss(score_3, v3) 0.012931201\n",
            "loss tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010385186\n",
            "self.loss(score_1, v1) 0.017030742\n",
            "self.loss(score_2, v2) 0.019714065\n",
            "self.loss(score_3, v3) 0.007783824\n",
            "loss tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0068975952\n",
            "self.loss(score_1, v1) 0.011303943\n",
            "self.loss(score_2, v2) 0.010321813\n",
            "self.loss(score_3, v3) 0.0072521274\n",
            "loss tensor(0.0358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.012826759\n",
            "self.loss(score_1, v1) 0.021227611\n",
            "self.loss(score_2, v2) 0.022445584\n",
            "self.loss(score_3, v3) 0.012012174\n",
            "loss tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010287731\n",
            "self.loss(score_1, v1) 0.016268441\n",
            "self.loss(score_2, v2) 0.014982892\n",
            "self.loss(score_3, v3) 0.013755134\n",
            "loss tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009020624\n",
            "self.loss(score_1, v1) 0.01706747\n",
            "self.loss(score_2, v2) 0.047808185\n",
            "self.loss(score_3, v3) 0.039081886\n",
            "loss tensor(0.1130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.015714392\n",
            "self.loss(score_1, v1) 0.007954835\n",
            "self.loss(score_2, v2) 0.011745368\n",
            "self.loss(score_3, v3) 0.008806729\n",
            "loss tensor(0.0442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.025276467\n",
            "self.loss(score_1, v1) 0.02132183\n",
            "self.loss(score_2, v2) 0.0076395306\n",
            "self.loss(score_3, v3) 0.0067086103\n",
            "loss tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.020466754\n",
            "self.loss(score_1, v1) 0.035731174\n",
            "self.loss(score_2, v2) 0.029640999\n",
            "self.loss(score_3, v3) 0.008880744\n",
            "loss tensor(0.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053468894\n",
            "self.loss(score_1, v1) 0.049990974\n",
            "self.loss(score_2, v2) 0.06328576\n",
            "self.loss(score_3, v3) 0.010081782\n",
            "loss tensor(0.1768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.010789939\n",
            "self.loss(score_1, v1) 0.01824127\n",
            "self.loss(score_2, v2) 0.0077734287\n",
            "self.loss(score_3, v3) 0.0062466124\n",
            "loss tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.014185266\n",
            "self.loss(score_1, v1) 0.026038218\n",
            "self.loss(score_2, v2) 0.02127388\n",
            "self.loss(score_3, v3) 0.008377765\n",
            "loss tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0046109287\n",
            "self.loss(score_1, v1) 0.021200895\n",
            "self.loss(score_2, v2) 0.013850372\n",
            "self.loss(score_3, v3) 0.0063688466\n",
            "loss tensor(0.0460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013897909\n",
            "self.loss(score_1, v1) 0.024855753\n",
            "self.loss(score_2, v2) 0.010177215\n",
            "self.loss(score_3, v3) 0.008801462\n",
            "loss tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.009845146\n",
            "self.loss(score_1, v1) 0.008525315\n",
            "self.loss(score_2, v2) 0.011659177\n",
            "self.loss(score_3, v3) 0.009857408\n",
            "loss tensor(0.0399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007576821\n",
            "self.loss(score_1, v1) 0.008647018\n",
            "self.loss(score_2, v2) 0.0085512595\n",
            "self.loss(score_3, v3) 0.0061411452\n",
            "loss tensor(0.0309, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021695089\n",
            "self.loss(score_1, v1) 0.018383313\n",
            "self.loss(score_2, v2) 0.010907501\n",
            "self.loss(score_3, v3) 0.008482812\n",
            "loss tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.017955264\n",
            "self.loss(score_1, v1) 0.025012376\n",
            "self.loss(score_2, v2) 0.026874429\n",
            "self.loss(score_3, v3) 0.007891941\n",
            "loss tensor(0.0777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.007666587\n",
            "self.loss(score_1, v1) 0.0073825535\n",
            "self.loss(score_2, v2) 0.010091201\n",
            "self.loss(score_3, v3) 0.010858272\n",
            "loss tensor(0.0360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.016467199\n",
            "self.loss(score_1, v1) 0.012316733\n",
            "self.loss(score_2, v2) 0.012299519\n",
            "self.loss(score_3, v3) 0.0077926824\n",
            "loss tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.008453099\n",
            "self.loss(score_1, v1) 0.0076276883\n",
            "self.loss(score_2, v2) 0.011355136\n",
            "self.loss(score_3, v3) 0.010919837\n",
            "loss tensor(0.0384, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.013932467\n",
            "self.loss(score_1, v1) 0.045589797\n",
            "self.loss(score_2, v2) 0.04588362\n",
            "self.loss(score_3, v3) 0.011286878\n",
            "loss tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 0.07630104221593423, Train Accuracy : 0.9993149488129045\n",
            " Validation Accuracy : 6.602431226896381\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_0,'-o')\n",
        "plt.plot(loss_1,'-o')\n",
        "plt.plot(loss_2,'-o')\n",
        "plt.plot(loss_3,'-o')\n",
        "plt.xlabel('sample')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['loss 0','loss 1','loss 2','loss 3'])\n",
        "plt.title('loss vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UPfmfthBjSZw",
        "outputId": "0dbde495-1453-44f4-8687-191edc4abb65"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3wU9bn48c+T3UBCyIVLgASwSL0iIlK8VJRSOYIao7X1WLUXpT21tVZRzw/FG0arVUuPSE9pra23VkEoxUsaFa+I0qogIIjIUSlWIJRrEggJSXa/vz9mNtndzF6S7GSzu8/79YokM7szz2TjM9/5zneerxhjUEoplX6ykh2AUkopd2iCV0qpNKUJXiml0pQmeKWUSlOa4JVSKk1pgldKqTSlCV4ljYhsEZH/SHYcPZmIXCEibyc7DpWaNMErFScRmSQifhE5EPb11WTHppQTb7IDUCrFbDfGDEt2EErFQ1vwqkcQkd4i8qCIbLe/HhSR3va6gSLyNxGpEZG9IvKWiGTZ624SkW0isl9ENonIZIdtnyIiO0TEE7TsQhFZZ39/soisEpE6Efm3iDzQyWNYJiL3ish79raeE5H+QevPF5EN9nEsE5Fjg9YNF5ElIrJLRPaIyG/Ctv0rEdknIv8UkXOCll8hIpvt4/+niHynM7Gr9KQJXvUUtwKnAmOBE4CTgdvsdf8NbAWKgcHALYARkaOBnwEnGWPyganAlvANG2PeBeqBM4MWXwbMt7+fC8w1xhQAXwYWdeE4vg/8ACgBWoBfA4jIUcAC4Dr7OF4AKkWkl33i+RvwOTACGAo8HbTNU4BNwEDgl8AjYsmzt3+OffynAWu7ELtKM5rgVU/xHeAuY8xOY8wu4E7ge/a6ZqyE+SVjTLMx5i1jFVHyAb2BUSKSbYzZYoz5LML2FwCXAohIPnCuvSyw/SNEZKAx5oAx5p0ocZbaLfDgr7yg9X82xnxojKkHbgcuthP4t4EqY8wrxphm4FdALlZSPhkoBWYYY+qNMY3GmOAbq58bY/5gjPEBT9i/i8H2Oj8wWkRyjTHVxpgNUWJXGUYTvOopSrFasAGf28sAZgOfAi/b3REzAYwxn2K1iCuAnSLytIiU4mw+8E272+ebwGpjTGB/PwSOAj4WkZUicl6UOLcbY4rCvuqD1n8RdgzZWC3vkOMzxvjt1w4FhmMl8ZYI+9wR9L6D9rd97f1+G/gJUC0iVSJyTJTYVYbRBK96iu3Al4J+PsxehjFmvzHmv40xI4HzgRsCfe3GmPnGmNPt9xrgfqeNG2M+wkqw5xDaPYMx5hNjzKXAIPv9i8Na5R0xPOwYmoHd4ccnImK/dhtWoj9MRDo86MEYs9QYcxZWq/5j4A+djFulIU3wqqdYANwmIsUiMhCYBTwJICLnicgRdlKsxeqa8YvI0SJypt0qbwQasLosIpkPTAcmAn8JLBSR74pIsd2qrrEXR9tONN8VkVEi0ge4C1hsd60sAspEZLKIZGPdVzgE/B14D6gG7hORPBHJEZEJsXYkIoNF5AL7ZHQIONCFuFUa0gSveoq7gVXAOmA9sNpeBnAk8CpWAvsH8FtjzBtY/e/3YbWQd2C1wG+Oso8FwNeA140xu4OWnw1sEJEDWDdcLzHGNETYRqnDOPhvBa3/M/C4HU8OcC2AMWYT8F3gf+14y4FyY0yTfQIoB44A/oV1Q/nbUY4jIAu4AevqYK99bFfF8T6VIUQn/FAqMURkGfCkMeaPyY5FKdAWvFJKpS1N8Eoplaa0i0YppdKUtuCVUipN9ahiYwMHDjQjRoxIdhhKKZUy3n///d3GmGKndT0qwY8YMYJVq1YlOwyllEoZIvJ5pHXaRaOUUmlKE7xSSqUpTfBKKZWmelQfvFJKRdPc3MzWrVtpbGxMdijdLicnh2HDhpGdnR33ezTBK6VSxtatW8nPz2fEiBFYtecygzGGPXv2sHXrVg4//PC435fyCf7ZNduYvXQT22saKC3KZcbUo/nGiUOTHZZSygWNjY0Zl9wBRIQBAwawa9euDr0vpRP8s2u2ccPCta31UbfVNHDDQmvGMk3ySqWnTEvuAZ057pRO8DcvWcfEL97nio9epLihhl25RTw+6hxuXpKlCV4plfFSehTNKZtXcv3qhQxuqCELGNxQw/WrF3LK5pXJDk0plab69u3rynYPHTrEt7/9bY444ghOOeUUtmzZ0uVtpnSC/8m6Z+llQiew6WX8/GTdszy7ZluSolJK9RTPrtnGhPte5/CZVUy47/UenRceeeQR+vXrx6effsr111/PTTfd1OVtpnSCL2h2nnSnoLmB6+y+eKVUZnp2zTZuXrKebTUNGKx7dDcvWZ+wJG+MYcaMGYwePZrjjz+ehQsXAlBdXc3EiRMZO3Yso0eP5q233sLn83HFFVe0vnbOnDnttvfcc89x+eWXA3DRRRfx2muv0dVqvyndBx/Lbc+u5+5vHJ/sMJRSLrizcgMfba+LuH7Nv2po8oVe4Tc0+7hx8ToWvPcvx/eMKi3gjvLj4tr/kiVLWLt2LR988AG7d+/mpJNOYuLEicyfP5+pU6dy66234vP5OHjwIGvXrmXbtm18+OGHANTU1LTb3rZt2xg+3Jqz3ev1UlhYyJ49exg4cGBc8ThJ6RZ8LE++4/whKqXSX3hyj7W8o95++20uvfRSPB4PgwcP5mtf+xorV67kpJNO4rHHHqOiooL169eTn5/PyJEj2bx5M9dccw0vvfQSBQUFCYkhlpRuwcczaEhb8Uqlp1gt7Qn3vc62mvbduEOLcln446+6FRYTJ05k+fLlVFVVccUVV3DDDTfw/e9/nw8++IClS5fy0EMPsWjRIh599NHQuIYO5YsvvmDYsGG0tLRQW1vLgAEDuhRLirfgnfunBMNVa/8KaCteqUw1Y+rR5GZ7QpblZnuYMfXohGz/jDPOYOHChfh8Pnbt2sXy5cs5+eST+fzzzxk8eDA/+tGP+K//+i9Wr17N7t278fv9fOtb3+Luu+9m9erV7bZ3/vnn88QTTwCwePFizjzzzC6P+U/pFnzhl+up/SyP9m154bwt/+B3Y78FWDdbdFy8Upkl8P+8W0+6X3jhhfzjH//ghBNOQET45S9/yZAhQ3jiiSeYPXs22dnZ9O3blz/96U9s27aNadOm4fdb3UP33ntvu+398Ic/5Hvf+x5HHHEE/fv35+mnn+5yjD1qTtbx48ebjkz4YSoK+fjpEpw6awxw7jd+BUBRbjZr75iSoCiVUsmyceNGjj322GSHkTROxy8i7xtjxju9PqW7aGq25Mb3uoZmlyNRSqmeJ6UT/L/fLyC+W6306AcclFLKDSmd4E1z/OHrg09KqUyT2gk+xvpJX7zfLXEopVRPlNIJvj4ncveMANesWdx9wSilVA+T0gn+kbMkais+1x96c1X74ZVSmSSlE3xHzfiL9sMrpbrGrXLBy5cvZ9y4cXi9XhYvTkzvQ0on+MveNHGOobE0J6YEhVIqVaxbBHNGQ0WR9e+6RcmOKKLDDjuMxx9/nMsuuyxh20zpBD8gciG5iLSbRqkMsW4RVF4LtV8Axvq38tqEJflElwseMWIEY8aMISsrcWk5pUsV7CmA4g4m+dlLN2nZAqXSwYszYcf6yOu3rgTfodBlzQ3w3M/g/Sec3zPkeDjnvrh2n+hywW5I6Rb8/ElCYwdPUU7V5ZRSaSg8ucda3kFaLthlm4/J4vf4ufb5+PviM3M+dqXSUKyW9pzRdvdMmMLhMK3KnZjofLlgN6R0C37igf2sGBX5EATT7mGnnlNaTSnlqsmzIDusXlV2rrU8ARJdLtgNKd2CX57XB0RozIZcx3piwhUfvciy4V/p7tCUUsk25mLr39fugtqtUDjMSu6B5V2U6HLBK1eu5MILL2Tfvn1UVlZyxx13sGHDhi7FmNLlgsc8PhojwrSlLZy92rn7xQ+U2WWDAx789li90apUCtJywRlULrjAPjeN/7RjfesVz3ftrKiUUqkgpRO8ZPcBoo+Hd0r8Wh9eKZUJXE/wIuIRkTUi8rdEb7vGZw153NM9I46UUiqldEcLfjqw0Y0NZ4kV/vxJ0YuOKaVUJnI1wYvIMKAM+KMb2/cb6470iuM8MV6plFKZx+0W/IPAjViDWRyJyJUiskpEVu3atatDGy/JK4n5Gm3bK6UylWsJXkTOA3YaY6JOq2SMedgYM94YM764uLhD+5g+bjo5npyor4mU3m97NkoNC6WUisCtcsEPPPAAo0aNYsyYMUyePJnPP/+8y9t0swU/AThfRLYATwNnisiTidxB2cgyKk6rgKhj+Z0HUD75zr8SGYpSqgeq2lzFlMVTGPPEGKYsnkLVZvdKFHTViSeeyKpVq1i3bh0XXXQRN954Y5e36VqCN8bcbIwZZowZAVwCvG6M+W6i91M2sowif/RC7zo3q1KZp2pzFRV/r6C6vhqDobq+moq/VyQsySe6XPDXv/51+vSxhn6feuqpbN26tcsxpnSpgoCZ+5vZn+OloLH9OgEtV6BUGrr/vfv5eO/HEdev27WOJn9TyLJGXyOzVsxi8f85z5h0TP9juOnkm+Lav5vlgh955BHOOeecuOKIplsedDLGLDPGnOfaDk64hMeizM9a3NA9tZeVUj1HeHKPtbyj3CoX/OSTT7Jq1SpmzJjR5RjTogU/d/e7VI/2cE1li5YDVipDxGppT1k8her66nbLS/JKeOzsx9wKq0vlgl999VXuuece3nzzTXr37t3lWFK6VEHAjvodQOR6NJr0lco8TqPscjw5TB83PSHbT3S54DVr1vDjH/+Y559/nkGDBiUkxrRowQ/JG+J4plZKZa6ykWUAzF09lx31OxiSN4Tp46a3Lu+qRJcLnjFjBgcOHOA///M/AWsS7ueff75LMaZ0ueCAqs1VzFx+Ewvv80VorRvO+cb/tFu65b7EfNBKqe6h5YIzqFxwQKwzcqRT2LNrtiU+GKWU6iHSIsEHRErkkWZsnfGXte4Fo5RSSZY2Cb7QbyIWvBGcH3Zqjv58lFJKpbS0SfA3j/wmkWpKCnDtOucHG5RSKl2lTYIvm/TzqOtzmxPzcINSSqWKtEnwseiNVqVUpsmYBB/pcaebl6zr5jiUUqnMrXLBDz30EMcffzxjx47l9NNP56OPPuryNjMowTtr0DutSqWt2spKPjlzMhuPHcUnZ06mtrIy2SFFdNlll7F+/XrWrl3LjTfeyA033NDlbaZVgt8ffe4PpVQGqa2spPr2WbRs3w7G0LJ9O9W3z0pYkk90ueDgAmT19fWIdL3ISlqUKgh47Czh2spIo96daZ0apVLTjl/8gkMbI5cLbvjgA0xT6OAK09hI9a23UbPoL47v6X3sMQy55Za49u9GueB58+bxwAMP0NTUxOuvvx5XHNGkVQt+xXEdPxxN8Eqlp/DkHmt5R7lRLvjqq6/ms88+4/777+fuu+/ucoxp1YLvDO2BVyo1xWppf3LmZKt7Joy3tJQv/flPboXVpXLBAZdccglXXXVVl2NJqxa8UkoFDLr+OiQn9Mac5OQw6PrrErL9RJcL/uSTT1q/r6qq4sgjj+xyjGnVgi/0+2nIhj7Nzutn7rmH+wbc2r1BKaWSorC8HICdcx6kpboab0kJg66/rnV5VyW6XPBvfvMbXn31VbKzs+nXrx9PPPFEl2NMi3LBAVWzSxg4v4iCBuf1ewvgO2f+qt1yLRusVGrQcsEZWC44oMw7gL4RkjtAUV37ZR69y6qUSlNpleCZPIt9keey5YDDOHmfgdueXe9eTEoplSTpleDHXEzLifUR6870iTA6asG7X7gWklIqsXpSt3J36sxxp1eCByYdE7kJ74kwJtKXoX8wSqWanJwc9uzZk3FJ3hjDnj17yMnp2OP6aTWKBoDJs+D3dyQ7CqWUC4YNG8bWrVvZtWtXskPpdjk5OQwbNqxD70m/BD/mYiBygv9T9j18v1mHSiqVirKzszn88MOTHUbKSLsumljOyNqQ7BCUUqpbpGWCjzz5Ntw9oMhxnU78oZRKN2mZ4CMNbRdgUUG+47rZSze5Fo9SSiVDWib4zthWE+UJKaWUSkEZl+AnbHAeK+lJQHF9pZTqSdIywdfnOidrAX70knMPvY6FV0qlm/RM8D+7JOKN1twIlSZ7aVEapVSaScsEP+mHs6KuPz/r7XbLmnzagldKpRfXEryI5IjIeyLygYhsEJE73dpXR51W9HSyQ1BKKde52YI/BJxpjDkBGAucLSKnuri/uM0p7pPsEJRSynWulSowVjWgA/aP2fZXt/SD1M6LXorgoI6YUUplAFf74EXEIyJrgZ3AK8aYdx1ec6WIrBKRVYkqILTzsSURH3aCyEMl9WlWpVQ6cTXBG2N8xpixwDDgZBEZ7fCah40x440x44uLixOy3+YDkS8UBJj2qvN6fZpVKZVOumUUjTGmBngDOLs79revIHoXTH6Eh1b1aValVDpxcxRNsYgU2d/nAmcBH7u1v2BPTpKYnf13eh/tjlCUUipp3GzBlwBviMg6YCVWH/zfXNxfq89Ojl0Uv1/BP7ohEqWUSh43R9GsA050a/vRTB83nd0F/4/iOuf1Brh7YD/Y261hKaVUt0rLJ1nLRpbx3KTsqN00DVk6VFIpld7SMsEDvDLKT0O28zrBeaikV5O+UiqNpG2CH9Liw+s83B0BLnuzffu+xa/1aJRS6SNtE/wt64RsX+T1AyL0z+vDTkqpdJG2CX7o6oKoT7PuKXBefvOSda7Eo5RS3S1tE3zLnghNdKxRNPO/5pz+G5oj9OsopVSKSdsE7y0pifkap7rwSimVLtI2wQ+6/rqI6wSY9orha0VPdV9ASinVzdI2wReWl0ddn98Icwb07aZolFKq+6Vtgo9HrSejD18plebSOsNJn9gzN4X3w+ujTkqpdJHWCb7kzoqI5QoCy3+R/YjjcqWUSnVpneALy8vxRWiSt9hHvizPE7J8aFGuy1EppVT3SOsED+Axzm3ybD8gwq/7F4Us//oxiZlVSimlki3tE7zE6FWv9oa24Oe/8y83w1FKqW6T9gm+o/zAd/6gk4EopVJfXAleRKaLSIFYHhGR1SIyxe3gEkKcW/DRbqau+ExnAlFKpb54W/A/MMbUAVOAfsD3gPtciyqRIvTB63BIpVS6izfBB/LhucCfjTEbSJEc6S0tdVzuF5iwwaonrBNwK6XSUbwJ/n0ReRkrwS8VkXys7uoer+/XJjou9xj48QuGr3/o47ueV7s5KqWUcl+8Cf6HwEzgJGPMQSAbmOZaVAl04M3lEdfltMBFy+HFvNhPvCqlVKqJN8F/FdhkjKkRke8CtwG17oWVOC3bt0ddP6COdmPhQWd2UkqlvngT/O+AgyJyAvDfwGfAn1yLKpE8nqir9xTADm/718xeusmtiJRSqlvEm+BbjDEGuAD4jTFmHpDvXlgJ5Is8MasB5k8SBrW0v52wvabBxaCUUsp98Sb4/SJyM9bwyCoRycLqh+/xIo2iCVgxKouL97YfEFSqNWmUUiku3gT/beAQ1nj4HcAwYLZrUSVQtJmdAv6dc4AXe80IWTZj6tFuhaSUUt0irgRvJ/WngEIROQ9oNMakRB98rJmdJnzkZ1FBPsfINp2jVSmVVuItVXAx8B7wn8DFwLsicpGbgXUHAS5bZj3pes+AIm70Lmpdd2flhiRFpZRSieGN83W3Yo2B3wkgIsXAq8BitwJLJIOJWFVyYB0gwsKCfE5o3At2GZp9B5u7L0CllHJBvH3wWYHkbtvTgfcm3VtjJWJxMX8g74vwYP9+3RWSUkq5Lt4k/ZKILBWRK0TkCqAKeMG9sBJr3jmRL1SygjL/Tm/KnLOUUiqmuLpojDEzRORbwAR70cPGmGfcCyuxhuSVAF/EfJ3HlxIjP5VSKi5xN1mNMX81xtxgf6VMcgeYPm56XK/Lk6aQn297dr0b4SilVLeImuBFZL+I1Dl87ReRuhjvHS4ib4jIRyKyQUTiy7IuKBtZFtfr9of9Nha8G7vVr5RSPVXULhpjTFfKEbQA/22MWW2XF35fRF4xxnzUhW12msG5gH3wzdchLT6Cz1q+CJOFKKVUKnDtrqIxptoYs9r+fj+wERjq1v5iiTQ7SetyYzj94MGQdZ4I0/0ppVQq6JZhIyIyAjgReNdh3ZUiskpEVu3atcu1GPxRcvWEDT4Q4c0+fUOWnzpSh00qpVKX6wleRPoCfwWus+d1DWGMedgYM94YM764uNi1OLIi9LYEP80aPkxyyx6tKKmUSl2uJngRycZK7k8ZY5a4ua9oaisro04gO8A+7ZS0tIQs36Ylg5VSKcy1BC8iAjwCbDTGPODWfuKxc86DUdcfyAGM4YywPnillEplbrbgJ2DVjz9TRNbaX+e6uL+IWqqro673+gAR3urTRytKKqXShpujaN42xogxZowxZqz9lZTyBt6Skqjrc+26YtVeDxOLnuqGiJRSyn0ZUXwlnkk/ABDh/uJ8vAVrWhfp5NtKqVSVEQm+sLyc3K+eGrGiZLDGrCx6Fy9t/fnWZ7RcgVIqNWVEggcY8dhjcb9Wsmtav69vijxpt1JK9WQZk+A7ItLkIEoplUo0wTvyJzsApZTqsoxK8NHa5dOWtj3kFP5L0RutSqlUlFEJngjFwwSY0jZwpl37ffbSTa6FpJRSbsmsBB+l/G9wrZpCX2iK364lC5RSKSijErynqCiu14U39EuLcl2IRiml3JVRCT7eW6e1WaG/lhlTj058MEop5bKMSvCmtjbq+gkbrDHv2dGKxyulVIrIqAQfrSaNANNetjrim7IMeUfeRd9jZpL35fuY9dqfuilCpZRKnIxK8LFq0uQ32t+IkOU9iAhk9arBP+AvVG2ucj9ApZRKoIxK8IXl5Z16n2Q1M3f13ARHo5RS7sqoBF9bWRl1/f4og2V21O9IcDRKKeWujErw0WZ2MsDmQZHfOyRvSOIDUkopF2VUgo82s5MAYz53Xmf82UwfN92doJRSyiUZleBjzewktA2VDDAGGqu/SdnIMhcjU0qpxMuoBB9rFI0AP3rRhC0zjBOtRaOUSj0ZleDjGUUTmJ+1lQj7ilfBukXuBKWUUi7JqAQP4C0t7fB7/u31cPDFWS5Eo5RS7sm4BB+rm8ap3qQAr2XVuRKPUkq5JeMSfKxuGqcqNH4R7hzYX59mVUqllIxL8J11KEu4950Hkh2GUkrFTRO8g+Dp+4LVNu3s5kiUUqrzNMGHCZ++L5i/Ob4JQ5RSqifIyAQfayRNlsOdVuPP5tCuqZ3aX9XmKqYsnsKYJ8YwZfEU7ctXSnWLjEzwsUbStHt9s5/G6m/Su3F8h/dVtbmKir9XUF1fjcFQXV9Nxd8ruiXJ64lFqcyWkQm+sLy8/cSrUdSSB0CzL95J/9rMXT2XRl9jyLJGX6Nj+eFEJuRknliUUj1DRiZ4wCoyE0FTWO4/lN1ATskS/HmrO7ybSGWGw5cnOiF35MSilEpPmZvgo+hl2o+kkaxmckoXdTjhRiozHL480Qk53hOLUip9ZWyCl6LII2IEmOrQWBcxHW5VTx83nRxPTsiyHE9Ou/LDiU7I8Z5YlFLpK2MTfMmttziWJQgQnMfDd7RVXTayjIrTKtr2m1dCxWkV7coPJzohx3ticYve4FUq+TI2wcciwNmr29eHB6iujzxxiJPgZP7yRS871pZPdEKO98TiBr3Bq1TP4FqCF5FHRWSniHzo1j66YuecBx3rzgQT4LJl7dv5WWE3aNu1VpfdDnNGQ0WR9W8cpYYDCVnsqAb3GdzlhBz83he/+WK3TVqiN3iV6hncbME/Dpzt4va7JNr0fcEGOhSRDB4s6dha/eczVLXsAQzUfgGV18a1r7ID9fT1W1v/67YdlB2oj+t98TBRO6QS26WiN3iV6hlcS/DGmOXAXre231Wxpu8L8Ds080ta2rptHFurWcLcfkE3cZsbYu9o3SKovBYx9umjbpt1YojR+q+trOSTMyez8dhRfHLmZGorK2PvK0yiu1T0Bq9SPUPS++BF5EoRWSUiq3bt2tVt+433aVYJb/gaQ7XXyxlPn0HV5ip21O9gwgYf8+a18PS9Lcyb18KEDT52eD0dC+i1u9qfCJobrOUR1FZWsvW2W2nZvh2MoWX7drbedqtjko/Wgk90l8r0cdPp7ekdsqw7b/AqpSxJT/DGmIeNMeONMeOLi4u7bb+F5eVInz4xX7enIGyBCAjUHKrh9hW3c9am3vz4BUNxnfXLLK6DH79gKFvX/uZsVLVbQ340EZYH+3z2L8g6FDrHYNahZj6f/Yv2L47SQ5PoLpWykWXc8JUbWn/uzhu8Sqk2SU/wyVRyZ0XU9QZYdUTk9c3+Zr7x2kFywkZT5rTApW8GJfjs3NjBFA4D2iYcMWHLnXh31nRoeSRudKlMPmwyAINyB0UcOaSUcldGJ/jC8nKyBg0iUvNWgAkbo2+jf61zfZrsevtXWzgcyn8dO5jJsyA7NzTBZ+dayyPYHX51EWV5tC6a6QNPIccfuj7Hb5g+8JSI70lE379Syl1uDpNcAPwDOFpEtorID93aV1ccvfzNqOvzY9wf3Vvo3Nfu7WO34K//EMZcHDuQMRdD+a/bhm7ml1gnhijvfXFKfxq9ocsavdbyjihb8ww377HvhxtDSXMLFbv3ULbmGcfX11ZWUn37rJC+/+rbZ2mSV6qHcXMUzaXGmBJjTLYxZpgx5hG39tVVvQZEHxHv9LATgMcYDo5toNkTmuQbPdkMGrO/44GMuZhAJ425vDLmieH0H9zCY+e13czcVQCPndeb039wS7vXRh0mWbuVc+oPApBjDC9v3U5Z/cGI/f875zyIaQy9KWsaG9k558Go8SqluldGd9EENO/3RlwnwLSXnZNjX5+fqSW7GXLSPloCv8kcH4XjGygcEcfQyAj7i1fZyDKmXnlP68933zicqVfe0/H+7sJhrenfhC13EukZgnifLVBKdQ9N8IBpcp6DNSC/0Xl5rSeLKcNKWXmcn50DrdQok+sYeXjX526N9WBSQDxlEABMlPLITJ4F3hx7v/YpJkr/f3NxYYeWK6WSI3LTNUN0qd9YhOpsLxUD+3OPWDdb7+3fj9VDB5KF9cRryfzTuaVhCsC2xNQAABsESURBVPN+38KAOljx29E8+TXDZ2P7MX1fDWW7tlJVPIy5/YrY0VyHZNkJ1nR8chHAejDqtbus7pXCYdA/jmuCMRfDof3wkd3FUjjcSu4RuogWTMzi4mcJGT3U6IVFE7MY07molVIuyPgWfCL6jRuzslonCanN8oAIfhEQYeTavRTNWdA6Tr5/rY8rX/Azcu1eZubBjwYPoKKPobq5FoOx3ge8sjX6zV9H9tOw1H4BGGo/2N36ANa/zjo3+sls1AUAGCHmjeGqI/fz+3PbThy7CuD35wpVR3b8voNWnVTKPRmf4OPtN3YqHRwsUgfIZcsMvR3GyV+2zIAI7+Tm0pjV/mP446b5ccX17Jptrd/vWHJL69OwtVtyqV5Z2Hpi8VVXs+WWm7jqxuMcE6mxK+zE0zE0JG8IK45ru7H8s596WHGcp8Pj5jtbIkGHaCoVn4xP8J7C2P3GgdLBUZN8hJ6QAQ7FykKWR5gbdmfDbk5fcDpnPH1GxNbts2u28fYzv239ebBpK/Wwc10+xhf68fZqNly6zO+YSOPr8beElzYW07lSBJ0pkaBDNJWKX0Yn+NrKSnwHDsT1WgGmrHFel+Nv6y8Pr13TrtSBw3KnWjYAtU211ByqaWvdvn17SFJeW/Uwd8nDbfsOOle0HHQenx84sbRLpNFuwoZpV2u+T/tSBIGbxA0tDRG7YDpTIkGHaCoVv4xO8DvnPAgt0btegmU55EBjoH/tiNZfZHh7fP4k4ZDDw0jzJ1mvnLDB51jLxmnsfaNpZu4797b+/F9NT9JHmhxjbX3QKkzwiWXHge1UzRvNlPmnc9pfzwIg3go6IbXmL6yKOHpnf/P+iF0wnSmRoEM0lYpfRif4ziSF8MQrAtuK/kVLuyIylhXHeXjonPY3JAN92JctM461bJwmGgHY0VTTOpHI0KzdEeMcNGY/EuXEAlY5gqX/9HHbg3tYcG8z8+a1cNoGP3e/c3eHbnz6/e1H/DS9+KrjVUnwlUNnSiREKvMcWK43bZVqk9EJPt6a8AECTHulfeIN7hpx6lFfMbqtu+Tqq70hNyhj9tGHMcCUYSX2hCKRFZ5/PiVXfbP15/ATC8C4jYZpLxF69fCiYeuS+R278RnWvVNbWUn93b+KeFUS6IIpW/MMFbvbjiNWiQSwyjxL79BSxJKTw6Drr9OpApUKk9EJftD11yE5ObFfGCRSbRpjZ/aOPInqNfH10Yewx97PLB7APf2L2t0cbf153+fk7f1j6/Jbf0RIcge47M34rh6cbnyufP73rd/vuOf4kJ93znkQGg9F3G5rF0ztVqskgi1WiQSwCsQVX9dWy99bWkrJz++isLw84k3bmW/N1Na8ykgZneALy8sp+fldeEtLI45mceLUP96RUSgB/YzVZeJUMCy4K8WRCAsL8qkKq2n/Ql4fpgwrZYxnG+eWtBUd2+8wFLMjVw/BNz5XPv97Rr9/W+vPg8xuRr9/W2uSj9T1NaDOqnUz/Z8fWnPV5vZzDiBKiWSAVUdZx7KzEK7+qYe3j8tqF2M4bc2rTJTRCR6sJH/k669x7MaP4poARICfPh8lnXcg0+8Sw4rjPI4PDYW3tp2DEf63f9vUgFV5fagY2J/qbC/GbukHFLe07yfvyNXDkOyC1onET1w9k9ygm7t+IFeaGL56NhC566umACp27aGsvp7aD3bzycJsNj5d0tpHX5XXhynDhzKmv0RscVdtruLBoKuJ4MQ9JG9IxBFJoBN/q8yT8Qk+WMmdFXG15L3AwvAE0okumsC+gpN5eB99LDs8bR/h3H5Fjg9NAVxU13446PxJQnPYrpyuHnLIYuLeaqbk+xgzYhjnDhtCVV7QydA+qQ0y1k3fQddfB717tdtu84n1zO1XxFX1Q9myqp89lFNa++iX7uxHtdeDIXKLe+7quRzyW90/gSGpgcR9S+3p/OTF6COSujLxtz5gpVKNJvggheXllP7yfmI1w8X+Kq6Dn1ZZCSTwjnZzuHaBJ46x6UOCeouqo8wD+0mv7LYf7M2uOM7DSye2LXK6eijy+bigtobn8nJCrgwqBvbHH7o5dspAwPo95l77k3bbnXFqPtXZXi5909DLoe//ojdj9/3vqN/heL9jR/0Ohj71Jr1DZzBsd0+hs7NU6QNWKhVpgg9TWF5OR9rh2T5rZI3pUNM9Puftr4+6PscYfjbigrYFUa4+3ujTNm1gSdDQxK3DrT+BT0YXtV09BJ1Ycv2GpX3z2l0ZhPxsoMl46JfdbA3hvP9wem2x5oWt7dt2VRJ4T2f7/sFK0K3RmdDl0fr+Iaz/f90i5yAi0AesVCrK+GqSiRBr1qfOGtXUxHMR1okxVNQeYsrm3/IpsYd7StBJy/h94PEGfgCg9lANTn8O1dnemE+57qMvg7Ia8TTbc8E27IWWbKCv4+v3FFhXP07LwxXgYcqjo9mRBUP8MDF3OMvteAJHFBg77y3xWS1sh+2WtPiYvnefPWqn3irKBvHNtkWUB6y2b7dOaoXDolbgVCoZtAWfYNKBR/5juXdAhFEmWI3XWwp7c9KXhnZ4uzuCunIO2K1qEzKYP+xKINKVgb34p6X5jP3SEE4YMZzjRwxnyrBS3s4N1JdvL96RQ16/n4OmmWqPWF1DHuG5xn8xocEaWikmdOy807DXRi98PEF4+YttIUMyaW6g6q274n4oKuIDVn1arKOs/cI6aXTwyiBe2v+vOkMTfAI0eHGliybWDd9ASeJEbzceOX5/W9+7J7REcnW2l9/0s4q4OSX4uEYOGUNfY2gOi7UxK4sPeltJ3EPo9IKBYa8BzcVF/P5cYcuXG60ROsNKGWOfgO7uX2SVaQ5+KGr5TVTNLnXswnE6eYjHHzo1Y3ODVYs/wbT/X3WWJngH3tLSDr0+twUK7EEqbuR5Rx1M0uJP4N1fY2gUabvZ6bTpGPHFGjmU7/dTG2FE0L7A8uD92mPnrXsoln/edSYrjvOw1etpN3x0YUF++/sKIsws7s+UfB9Vr84ISfLhJw9vnxZKTqptPzVjlIe0OiuZ/f965ZDaNME7GHT9dbFfFESAwbX2907JLoHdNu32HeemJQGt9qCNhSRwN05qzSIRxzIN8PlD9tviyWmbXjC45f3+YwB83LtXazJvHSd/n6/dOHlro/YooX59qXortDUefPI48nu9efs4CbkqqMrrE/Mhrc5IVoE1vXJIfZrgHRSWl1N06SUdek+2nSduX+Bn4b0t/PHBtuRx+oa2h4wck0oXxJ1cXTjHRG3Bd1Ivu3BZY1aW41VAjt9wfJ1dw9/AVv9AFjafwcEXZ0FFISy5st17GqQTlTuzspjbO/LnVHXihVQMHBByVXDbwAGcUdwn4YXOYhVYc4teOaQ+TfARlNxxB56iotgvtEnQvwIUNMDVlYbHf9XCNZVtGTBaUnFTpBNBIlrfiUzw2VG2NcjnZ8buer7b8BkAfoRzRvbhvpEfc+pgr32Dty3pBTaVa19BdbhyZ9hzBVXLbm/9/pYtz9CYFfrba8kSanwNCS90Nuj665Ds7JBlgQJrbtIrh9SnCT6Kwbfe0uFiZMG8Bvo0t0+iOS3ws8r4k/yEDT7+OKeFhfe2tLs6iLdlnsgkHODGw131WZFPOV852Mgf++Xwo5JB1n4D/xFrlA1h5RnW2k/THnuoid5+f4crdxZINlMeHc2Yx0dz+qPHcfuWtiqX/ji6vBJVGqGwvJzCi9uGXwYXWHNTJl45QHpdPeg4+CgC/wNtn3kz+BLb4vYYuKrSAL6QG4xP39vCngJryOCK4zxM2ODjqkpDr6AkWtBgPUELPlYelZhztFOOnrDBx2XLDAPqrO6YLAO7g2ILcEp1nU76URLni31zQYRBdrSx9rEk3xqHP6ylhUkHG9hTkO84/r4235Dj94fcdPX6/RyUZmo9VjyBfzsq+EGtqs1VzF09lx31OyjoVYCIUHuoliF5Q5g+bnrESVMA8k4aT81TT5E/ZQqrpt3IFUs3sX1FFaVFucyYejTfOLHjw2VjGXT9dVTfPisk2abzlQO0XT0Ejjlw9QC4fkJ1gyb4GFqT/IwbE77tXgamvWwl6oBA3/C1zxumvdLS+rpw2T6ra2HlUW3L5s1rYUAdrSeIYH+c64uYoJ0E+qtbuzTsGAJdTOBrq7/jEF9Xu34mbPAx7WVDvp1b9ufCY2dZcce77cDY/lfy+lDZVzhtkj/0mLDGyT85KYvGoBNLYYuPOk9W6LMBnSRA1bzRcHAvFcX9W/dT21Tb+prAEE3+9Q5lk37uuJ3VHy1kMPDqlpf58/uvMtSMYxuXsK2mgVtefoJfbXyNuuZdcZ0s4hX+t+8tLWXQ9dd1y5WD0wNrbl85QPSrB03waaqwvJx/3/MLfDU1Cd92fqOVzMMF+vGjNVIH1MFpH7XdwA20Tovr4JrnTUgi9JjQdUdtbeGxqW0f/9jNhqfvbWltqful7T3hAv3WgdV3/dlHvwOEXHkEVvZqbn/iiefkEu2q5dMSq6Ud71VCg90yt/br40cvGfo0wYHe8MjU0HjaTizWSTf4xBKVMZyxwc8lb5p2x1rRx5CTWxRyEgnXKMLcTxdTdqAeznsgZF3Vstup3PUu07GeSN6ZnUXdkNXc73mbPjRyZ/EAaputbVfXVzNz+Uzu+vsvmHXaLZSNLItw5VDDEJ9h+p69lHn7R3wK9+389xhpf//T7/yb4Z8s4Y2ZWZ2/cli3yHpWoHZrxKd/k3XlAOk3JaQYF4fwddT48ePNqlWrkh2Go9rKSlda8V1RlwO9W6yvjjLAr88XvrzdcF4nfuV++yu8heDHOjkd6A35h6z9BKe1JoHflVuJb9G9La3vCe4C6t1sJXQnuwrghfHC5a9bJxi/Q9dRYLu7CnA8sXznDR8XvGN4alIWz321rVvG6cQC0OyB35ZF3zbAT14wIZ+FIegEMSqLCR/5W7u8HE92xnDfrr2UTX0wJOlNeeQ4hm6GG//q57PB1u9mQJ1Vfvlvp8M+rzh2pS2a5GXIlw3P9TIRq4wGhvCWtPiYXjSWsosWtK6qWnY7Ff98hj/d72s95oF10Jzn57Dja/nbqAIeKRnIHv8BJqz3cOnyQwysM+wt9OC78mIm/XBWyK6qlt3O3M/+yg5PFkNafEzfV0NZk4HyX7dL8rWVleyouBN/fb11JWUMO3OLeH78BUz86ff4xolDeXbNNmYv3cT2mob4TjhxnFw+OXOy89VDaSlHvv5a5G1HE8d+u0JE3jfGjHdcpwk+ftV33knNgqe7fb/hSTKwrDEbcpsd3tCB7QYSQkfV5VhXH53pxKjLgcemCNMj1NV3Ot4AP9DipV01ysC6wCgmp3VLx8FjU72tCf7tY+HobW2JOtaJ5eqfelh0n8OQSi80ZUd+b7MHXj0Bvr6Odt1DwU/whndLNeR5+cNkHytGZfGVTw03LfbjC7uyahKQrLZhuuH7fehc4a3RsctPT9jg4zv2SeLggD48OuEQb40CRFpPasH8HsNrxwtjN1u/v/Df+yEv1Ew4SP2YfOb2K6K6udY6mQRfxRhDkd/Pz99vYejG4TRXb2dfgYcnv2ZYf3weP1uwnxM2h+5XPH56n+TntYHHc9TyTQyo87f+DR/ok8uI8QcZVLojJJFWba5i7jv3sqOphgKfHxGozcqibJ2PS1dkk13XQnNxIQsmZlHTVMNPXjT0am77JRugrlcf/vyVb3HWtZcDMHvpJo5a/zY/+PglBtTXkF1a4tx9tW6RVcKiOeiPIzvX8aTWWZrgE2jLtGk0/OOdbt1npIQXLRG6qUmgMSdyQouldfRNJ94bnuA6s9+GXtCnqf3vL9aJ5X/P79xJCdquNMLtKrCe5I119XD4DsP570XZQQR19hVEtCuHaUtbOHt1aPzBJx+nBA+xj3l3AfxlIly03PlKKta+w6+IAlp6+THNWY5Dav1ZhmEn17Cmdy88a/Lo34n9Ao6fs3j87DzSj2z30t/hpOb3wrDx+yg8YSBVJ17IvdVv2EX87PcDp23w8703Df3qDOLxgs/X5XsbmuATLFkt+WSIdPWAw/J02G8kdTlwqJdzFcx4RDtJx+qWqsuBnGbo1YmBXE6/s8CVzu4CWHUETF3tPF56l50YI53U3Nx3tCvEmCdTHJJvnPuNdcyx9m0wHOptaMrKom8D7UbEhd/kD2jKFvZdd0m7bq14aIJ3SXCiT1Zr2k3JTqgFje2Xu/17jpaIcXHf0Y7LzWP2E/lhmMA9js5eMXV13+lyzIFNxdpuXQ68cvcp3Hbe4x3afrQErw86dUHJHXdw7McbOfbjjQyd/Us3qgEkVaT+bLcZaO2HDtcd8TjWTnN539G27eZ+oyUAwb3kHs++k7XfRB9z4G8n1nbzG2Hrm++FPDHdVa4meBE5W0Q2icinIjLTzX0lW2F5OdkdrEKpnCXrxJLsfavMJsA1lYZ7Ny9J2DZdS/Ai4gHmAecAo4BLRWSUW/vrCZxqhoPVL5durXulVOIJMPd//DFfFy83W/AnA58aYzYbY5qAp4ELYrwnpQVqhntLS0EEb2kppbN/yaiPP6YhO3L5W6WUAivB5yawKoqbT7IOBb4I+nkrcEr4i0TkSuBKgMMOO8zFcLpHYXm543Cnr6z/iNrKSnbOeZCW7dsjjtlOx5u1SqnkSPpNVmPMw8aY8caY8cXFxckOx1WF5eUc+fprHPvxRo77eCPVV9/MQU+29cARVu2U+tHjaMrKCiwBu3sn3i+llApwswW/DRge9PMwe5myTb7m+3DN99st7/Aj2Lbaykq233IrprkLj7d28hoi/IGheF/b+T0qlX4M0Bj7weO4uTYOXkS8wP8Bk7ES+0rgMmPMhkjvSbVx8MrS2vVUXY23pO2R7eAiV4Eqh013vcxR77zcNt1erxyKv/UNdjz7N3o3HAjZbuA1kf5Cg+9qmAinCNO6Vk8hqudr9MC4DRs79J6kPegkIucCDwIe4FFjzD3RXq8JXimlOiZagne1XLAx5gXgBTf3oZRSylnSb7IqpZRyhyZ4pZRKU5rglVIqTWmCV0qpNNWjygWLyC7g806+fSCwO4HhdLdUjx9S/xhSPX5I/WNI9fih+4/hS8YYx6dEe1SC7woRWRVpqFAqSPX4IfWPIdXjh9Q/hlSPH3rWMWgXjVJKpSlN8EoplabSKcE/nOwAuijV44fUP4ZUjx9S/xhSPX7oQceQNn3wSimlQqVTC14ppVQQTfBKKZWmUj7Bp9LE3iKyRUTWi8haEVllL+svIq+IyCf2v/3s5SIiv7aPa52IjEtCvI+KyE4R+TBoWYfjFZHL7dd/IiKX94BjqBCRbfbnsNauehpYd7N9DJtEZGrQ8qT8nYnIcBF5Q0Q+EpENIjLdXp4Sn0OU+FPpM8gRkfdE5AP7GO60lx8uIu/a8SwUkV728t72z5/a60fEOjbXGGNS9gurDPFnwEigF/ABMCrZcUWJdwswMGzZL4GZ9vczgfvt788FXsQqi34q8G4S4p0IjAM+7Gy8QH9gs/1vP/v7fkk+hgrg/zm8dpT9N9QbONz+2/Ik8+8MKAHG2d/nY82xMCpVPoco8afSZyBAX/v7bOBd+3e7CLjEXv4QcJX9/U+Bh+zvLwEWRjs2N2NP9RZ8OkzsfQHwhP39E8A3gpb/yVjeAYpEpKQ7AzPGLAf2hi3uaLxTgVeMMXuNMfuAV4Cz3Y/eEuEYIrkAeNoYc8gY80/gU6y/saT9nRljqo0xq+3v9wMbseY7TonPIUr8kfTEz8AYYwKz0WTbXwY4E1hsLw//DAKfzWJgsogIkY/NName4J0m9o49t13yGOBlEXlfrMnGAQYbY6rt73cAg+3ve+qxdTTennocP7O7MB4NdG/Qw4/BvtQ/EasFmXKfQ1j8kEKfgYh4RGQtsBPr5PgZUGOMaXGIpzVWe30tMIAkHEOqJ/hUc7oxZhxwDnC1iEwMXmms67iUGbeaavEG+R3wZWAsUA38T3LDiU1E+gJ/Ba4zxtQFr0uFz8Eh/pT6DIwxPmPMWKy5pU8GjklySHFJ9QSfUhN7G2O22f/uBJ7B+kP5d6Drxf53p/3ynnpsHY23xx2HMebf9v+wfuAPtF0m98hjEJFsrOT4lDFmib04ZT4Hp/hT7TMIMMbUAG8AX8Xq/grMihccT2us9vpCYA9JOIZUT/ArgSPtu9m9sG5oPJ/kmByJSJ6I5Ae+B6YAH2LFGxjRcDnwnP3988D37VERpwK1QZfkydTReJcCU0Skn30ZPsVeljRh9zIuxPocwDqGS+xREIcDRwLvkcS/M7vv9hFgozHmgaBVKfE5RIo/xT6DYhEpsr/PBc7CupfwBnCR/bLwzyDw2VwEvG5fZUU6Nve4eQe3O76wRg38H1af2K3JjidKnCOx7qB/AGwIxIrVN/ca8AnwKtDftN25n2cf13pgfBJiXoB1+dyM1V/4w87EC/wA64bSp8C0HnAMf7ZjXIf1P11J0OtvtY9hE3BOsv/OgNOxul/WAWvtr3NT5XOIEn8qfQZjgDV2rB8Cs+zlI7ES9KfAX4De9vIc++dP7fUjYx2bW19aqkAppdJUqnfRKKWUikATvFJKpSlN8EoplaY0wSulVJrSBK+UUmlKE7xSCSIiy0SkR0y2rBRogldKqbSlCV6lNfsJ4iq7lveHIvJtEZklIivtnx+2n7YMtMDniMgqEdkoIieJyBKx6qffbb9mhIh8LCJP2a9ZLCJ9HPY7RUT+ISKrReQvdi0WpbqVJniV7s4GthtjTjDGjAZeAn5jjDnJ/jkXOC/o9U3GmPFY9b2fA64GRgNXiMgA+zVHA781xhwL1GHV/24lIgOB24D/MFZxuVXADa4doVIRaIJX6W49cJaI3C8iZxhjaoGv2zPtrMeq6X1c0OufD3rfBmPVMz+ENUFGoFDUF8aYFfb3T2I9jh/sVKzJHVbYJWYvB76U8CNTKgZv7JcolbqMMf8n1rR15wJ3i8hrWK3y8caYL0SkAqt2SMAh+19/0PeBnwP/v4TX9wj/WbAm17g0AYegVKdpC16lNREpBQ4aY54EZmNN3wew2+4XvyjimyM7TES+an9/GfB22Pp3gAkicoQdQ56IHNWJ/SjVJdqCV+nueGC2iPixKkpehTW12odYMyGt7MQ2N2FN2PIo8BHW5BWtjDG7ROQKYIGI9LYX34ZVCVGpbqPVJJXqAHvaub/ZN2iV6tG0i0YppdKUtuCVUipNaQteKaXSlCZ4pZRKU5rglVIqTWmCV0qpNKUJXiml0tT/B4dXEG8gbHPpAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy evalutaion F-scores"
      ],
      "metadata": {
        "id": "sJbWsH72N2Mb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. create folder with part object of all pieces \n",
        "2. load a piece from dataloader with true labels, the mixed piece and the part object \n",
        "3. create notearray from part object\n",
        "4. take 1 note from notearrray - input -> find corresponding frame by looking at time and pitch\n",
        "\n",
        "\n",
        "Output: pianoroll\n",
        "\n",
        "1 note in notearray could be mulitple bins\n",
        "\n",
        "take 1 note from notearrray - input -> find corresponding frame by looking at time and pitch\n",
        "\n",
        "note start at same time with different pitch -> different notes\n",
        "\n",
        "for each note array find corresponding matrix -> \n",
        "\n",
        "\n",
        "if note is only composed by 1 bin: save indx of vocie -> save it to note array\n",
        "\n",
        "if more than 1: look what are idx that compose this note -> majority note -> save it for the note array (if its 50/50 take it random -> count how often this happens) \n",
        "\n",
        "\n",
        "with idx : in note_array find which note corresponds to what voice"
      ],
      "metadata": {
        "id": "CFClch37N6nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MusicDataset_new(PATH_TO_DATA) #MusicDataset(PATH_TO_DATA)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "\n",
        "val_dataloader "
      ],
      "metadata": {
        "id": "afYHFVNMlMnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a461167-026c-4861-dfe7-263a1252b7fc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f7e46db8f10>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## makes cell output nothing\n",
        "%%capture  \n",
        "output_dim = 88\n",
        "model = MusicNetwork(network_type, output_dim, hidden_dim, rnn_depth, cell_type)  \n",
        "checkpoint = torch.load(\"./AI-MA_project/model_temp_epoch10.pkl\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "4TAhTQcpmx8m"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create dic with key:filename, val: part_obj  for fugues"
      ],
      "metadata": {
        "id": "5RVmMv6Q9CJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if PATH_TO_DATA == \"AI-MA_project/bach_pr_fugues\":\n",
        "    path_parts = \"AI-MA_project/bach_fugues\"\n",
        "    part_dic = {}\n",
        "\n",
        "    #### create a list with all filenames in the right order ####\n",
        "    file_names_part = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.mid'): continue\n",
        "        file_names_part.append(filename[3:7])\n",
        "    #print(file_names_part)\n",
        "\n",
        "    #### create a list with all part objects in the right order ####\n",
        "    part_list = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.mid'): continue\n",
        "        fullname = os.path.join(path_parts, filename)\n",
        "        part = partitura.load_score_midi(fullname)\n",
        "        part_list.append(part)\n",
        "    #print(part_list)\n",
        "\n",
        "    #### create a dict with keys:filenames , values: part object ####\n",
        "    for i in range(len(file_names_part)):\n",
        "        part_dic[file_names_part[i]] = part_list[i]\n",
        "    \n",
        "    print(part_dic.keys(),part_dic.values())"
      ],
      "metadata": {
        "id": "_XYM_KWu2qkX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create dic with key:filename, val: part_obj  for chorales"
      ],
      "metadata": {
        "id": "6D9oTp_lNQbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if PATH_TO_DATA == \"AI-MA_project/pianoroll_88\":\n",
        "    path_parts = \"AI-MA_project/chorales_converted\"\n",
        "    part_dic = {}\n",
        "\n",
        "    #### create a list with all filenames in the right order ####\n",
        "    file_names_part = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.xml'): continue\n",
        "        file_names_part.append(filename[4:7])\n",
        "    #print(file_names_part)\n",
        "\n",
        "    #### create a list with all part objects in the right order ####\n",
        "    part_list = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.xml'): continue\n",
        "        fullname = os.path.join(path_parts, filename)\n",
        "        part = partitura.load_musicxml(fullname)\n",
        "        part_list.append(part)\n",
        "    #print(part_list)\n",
        "\n",
        "    #### create a dict with keys:filenames , values: part object ####\n",
        "    for i in range(len(file_names_part)):\n",
        "        part_dic[file_names_part[i]] = part_list[i]\n",
        "    \n",
        "    print(\"part_dic.keys()\",part_dic.keys())\n",
        "    print(\"part_dic.values()\",part_dic.values())"
      ],
      "metadata": {
        "id": "_4q58c16NjbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate chorales"
      ],
      "metadata": {
        "id": "yphGmsr-NSV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluate chorals"
      ],
      "metadata": {
        "id": "v4TJGKiUs086"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_one_choral(model, train_dataloader, part_dic,F1):\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match                                      \n",
        "            \n",
        "            #if idx > 40: # or idx==2:\n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "\n",
        "                print(\"part:\",part)\n",
        "\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "                part_3 = part[3]\n",
        "                note_array_3 = part_3.note_array\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "                note_counter_3 += len(note_array_3)\n",
        "\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "                   \n",
        "                \n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):                    \n",
        "                    #### get only indices that are positive\n",
        "\n",
        "                    onset_beat = note_array[\"onset_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "\n",
        "                    if onset_beat[0] < 0:\n",
        "                        onset_beat -= onset_beat[0]  ### if 1st value of onset_beat is negative add the value of this entry to the whole entry (therefore -)\n",
        "\n",
        "                    duration_beat = note_array[\"duration_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    \n",
        "                    pitch_list = note_array[\"pitch\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "                    \n",
        "\n",
        "                    # do model prediction\n",
        "                    model.eval()\n",
        "                    voices = voices.to(device).float()\n",
        "                    monophonic=True\n",
        "                    with torch.no_grad():\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        label = ground_truth_label_list[el_note_arr]\n",
        "                \n",
        "                    for i in range(len(note_idx_start)):\n",
        "\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]                   \n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                        if i < len(note_idx_start)-1:\n",
        "                            start_second = note_idx_start[i+1]\n",
        "                            end_second =  note_idx_end[i+1]\n",
        "                            pitch_second = pitch_list[i+1]\n",
        "                            pred_list_second = prediction[start_second:end_second,pitch_second]\n",
        "\n",
        "                        result_second = all(elem == pred_list_second[0] for elem in pred_list_second)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result_second == False:\n",
        "                            major_, major_idx = torch.mode(pred_list_second,0)\n",
        "                            major_ = major_.numpy().tolist()\n",
        "                            pred_list_second = [major_ for i in pred_list_second]\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "                        \n",
        "                        if F1 == True:\n",
        "                            if pred_list_first[0] == pred_list_second[0]:   #the list might have diff lenghts as diff notes have diff lengths, so is ito oke to just take first elemet\n",
        "                                accordance_dict[str(label)].append(1)\n",
        "                            else:\n",
        "                                accordance_dict[str(label)].append(0)\n",
        "                        else:\n",
        "                            accordance_dict[str(label)].append(0)\n",
        "\n",
        "                if F1 == False:\n",
        "                    count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "                    for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                        counting = 0\n",
        "                        ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                        for j in range(len(total_predictions_dict[i])):\n",
        "                            if total_predictions_dict[i][j][0] == gt:\n",
        "                                counting +=1  \n",
        "                        count_dict_2[i].append(counting)\n",
        "\n",
        "                    acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                    acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                    acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "                    acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "\n",
        "                    print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                    print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                    print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "                    print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "                    \n",
        "                    acc_score_dict[\"0\"].append(acc_0)\n",
        "                    acc_score_dict[\"1\"].append(acc_1)\n",
        "                    acc_score_dict[\"2\"].append(acc_2)\n",
        "                    acc_score_dict[\"3\"].append(acc_3)\n",
        "                \n",
        "                if F1 == True:\n",
        "                    pred_0 = accordance_dict[\"0\"]\n",
        "                    pred_1 = accordance_dict[\"1\"]\n",
        "                    pred_2 = accordance_dict[\"2\"]                   \n",
        "                    truth_0 = [1 for i in range(len(accordance_dict[\"0\"]))]\n",
        "                    truth_1 = [1 for i in range(len(accordance_dict[\"1\"]))]\n",
        "                    truth_2 = [1 for i in range(len(accordance_dict[\"2\"]))]                  \n",
        "                    f1_v0 = sklearn.metrics.f1_score(truth_0, pred_0)\n",
        "                    f1_v1 = sklearn.metrics.f1_score(truth_1, pred_1)\n",
        "                    f1_v2 = sklearn.metrics.f1_score(truth_2, pred_2)                \n",
        "                    f_score_dict[\"0\"].append(f1_v0)\n",
        "                    f_score_dict[\"1\"].append(f1_v1)\n",
        "                    f_score_dict[\"2\"].append(f1_v2)\n",
        "                    print(\"f1_v0 , sample {}:\".format(idx),f1_v0)\n",
        "                    print(\"f1_v1 , sample {}:\".format(idx),f1_v1)\n",
        "                    print(\"f1_v2 , sample {}:\".format(idx),f1_v2)\n",
        "                    \n",
        "                    if len(part)==4:\n",
        "                        pred_3 = accordance_dict[\"3\"]\n",
        "                        truth_3 = [1 for i in range(len(accordance_dict[\"3\"]))]\n",
        "                        f1_v3 = sklearn.metrics.f1_score(truth_3, pred_3)\n",
        "                        f_score_dict[\"3\"].append(f1_v3)\n",
        "                        print(\"f1_v3 , sample {}:\".format(idx),f1_v3)\n",
        "    \n",
        "    if F1 == True:\n",
        "        return statistics.mean(f_score_dict[\"0\"]), statistics.mean(f_score_dict[\"1\"]), statistics.mean(f_score_dict[\"2\"]),statistics.mean(f_score_dict[\"3\"])\n",
        "    \n",
        "    if F1 == False:\n",
        "        print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "        print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "        return total_predictions_dict, acc_score_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])\n"
      ],
      "metadata": {
        "id": "UXr2DeiLSyLm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if fugues == False:\n",
        "    dict_pred , acc_score_dict, acc_0 , acc_1, acc_2, acc_3 = evaluate_one_choral(model,val_dataloader,part_dic,F1=False)\n",
        "    acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "ghAmXcXTTtD1",
        "outputId": "04bb6fa0-9a4a-429a-d687-e054ed1b60ec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ea3d534c0b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfugues\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdict_pred\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0macc_score_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0macc_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_one_choral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpart_dic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0macc_0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0macc_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0c07923f0d3d>\u001b[0m in \u001b[0;36mevaluate_one_choral\u001b[0;34m(model, train_dataloader, part_dic, F1)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mnote_array_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnote_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mnote_counter_0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_array_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mnote_counter_1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_array_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mnote_counter_2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_array_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'method' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if fugues == False:\n",
        "    plt.plot(acc_score_dict[\"0\"],'-o')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.legend(['Accuracy0'])\n",
        "    plt.title('Accuracy vs Epochs')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "J92mdaQG0MXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on F1 meassure"
      ],
      "metadata": {
        "id": "zYMy2JARxEBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if fugues == False:\n",
        "    acc_0 , acc_1, acc_2, acc_3 = evaluate_one_choral(model,val_dataloader,part_dic,F1=True)\n",
        "    acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "id": "RWxVG3XAYTcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluate fugues"
      ],
      "metadata": {
        "id": "TzTpXHznL02j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import statistics\n",
        "\n",
        "\n",
        "def evaluate_accuracy_for_all(model, train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match\n",
        "                                      \n",
        "                print(\"nbr_voices:\",nbr_voices)\n",
        "            #if idx == 0 or idx==2:\n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2]\n",
        "\n",
        "                if len(part)== 4:\n",
        "                    part_3 = part[3]\n",
        "                    note_array_3 = part_3.note_array\n",
        "                    note_counter_3 += len(note_array_3)\n",
        "                    list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "\n",
        "                   \n",
        "                \n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):\n",
        "                    onset_beat = note_array[\"onset_beat\"]\n",
        "                    duration_beat = note_array[\"duration_beat\"]\n",
        "                    pitch_list = note_array[\"pitch\"]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "\n",
        "                               \n",
        "                    # do model prediction\n",
        "                    model.eval()\n",
        "                    voices = voices.to(device).float()\n",
        "                    monophonic=True\n",
        "                    with torch.no_grad():\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        label = ground_truth_label_list[el_note_arr]\n",
        "\n",
        "                \n",
        "                    for i in range(len(note_idx_start)):\n",
        "\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "                        \n",
        "                        if i < len(note_idx_start)-1:\n",
        "                            start_second = note_idx_start[i+1]\n",
        "                            end_second =  note_idx_end[i+1]\n",
        "                            pitch_second = pitch_list[i+1]\n",
        "                            pred_list_second = prediction[start_second:end_second,pitch_second]\n",
        "\n",
        "\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "\n",
        "                        result_second = all(elem == pred_list_second[0] for elem in pred_list_second)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result_second == False:\n",
        "                            major_, major_idx = torch.mode(pred_list_second,0)\n",
        "                            major_ = major_.numpy().tolist()\n",
        "                            pred_list_second = [major_ for i in pred_list_second]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "\n",
        "                            \n",
        "                        if F1 == True:\n",
        "                            if pred_list_first[0] == pred_list_second[0]:   #the list might have diff lenghts as diff notes have diff lengths, so is ito oke to just take first elemet\n",
        "                                accordance_dict[str(label)].append(1)\n",
        "                            else:\n",
        "                                accordance_dict[str(label)].append(0)\n",
        "\n",
        "                if F1 == False:\n",
        "                    count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "                    for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                      counting = 0\n",
        "                      ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                      for j in range(len(total_predictions_dict[i])):\n",
        "                          if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                      count_dict_2[i].append(counting)\n",
        "\n",
        "                    acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                    acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                    acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "\n",
        "                    print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                    print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                    print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "\n",
        "                    if len(list_of_note_arrays)==4:\n",
        "                        acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "                        print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "                        acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "                    acc_score_dict[\"0\"].append(acc_0)\n",
        "                    acc_score_dict[\"1\"].append(acc_1)\n",
        "                    acc_score_dict[\"2\"].append(acc_2)\n",
        "\n",
        "                if F1 == True:\n",
        "                    pred_0 = accordance_dict[\"0\"]\n",
        "                    pred_1 = accordance_dict[\"1\"]\n",
        "                    pred_2 = accordance_dict[\"2\"]                   \n",
        "                    truth_0 = [1 for i in range(len(accordance_dict[\"0\"]))]\n",
        "                    truth_1 = [1 for i in range(len(accordance_dict[\"1\"]))]\n",
        "                    truth_2 = [1 for i in range(len(accordance_dict[\"2\"]))]                  \n",
        "                    f1_v0 = sklearn.metrics.f1_score(truth_0, pred_0)\n",
        "                    f1_v1 = sklearn.metrics.f1_score(truth_1, pred_1)\n",
        "                    f1_v2 = sklearn.metrics.f1_score(truth_2, pred_2)                \n",
        "                    f_score_dict[\"0\"].append(f1_v0)\n",
        "                    f_score_dict[\"1\"].append(f1_v1)\n",
        "                    f_score_dict[\"2\"].append(f1_v2)\n",
        "                    print(\"f1_v0 , sample {}:\".format(idx),f1_v0)\n",
        "                    print(\"f1_v1 , sample {}:\".format(idx),f1_v1)\n",
        "                    print(\"f1_v2 , sample {}:\".format(idx),f1_v2)\n",
        "                    if len(part)==4:\n",
        "                      pred_3 = accordance_dict[\"3\"]\n",
        "                      truth_3 = [1 for i in range(len(accordance_dict[\"3\"]))]\n",
        "                      f1_v3 = sklearn.metrics.f1_score(truth_3, pred_3)\n",
        "                      f_score_dict[\"3\"].append(f1_v3)\n",
        "                      print(\"f1_v3 , sample {}:\".format(idx),f1_v3)\n",
        "    \n",
        "    if F1 == True:\n",
        "        return statistics.mean(f_score_dict[\"0\"]), statistics.mean(f_score_dict[\"1\"]), statistics.mean(f_score_dict[\"2\"]),statistics.mean(f_score_dict[\"3\"])\n",
        "    \n",
        "    if F1 == False:\n",
        "        print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "        print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "        return total_predictions_dict, total_truth_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])\n",
        "        #return total_predictions_dict, total_truth_dict"
      ],
      "metadata": {
        "id": "0xbN5YU8nGT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, train_dataloader, part_dic,F1):\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader): \n",
        "        print(\"nbr_voices:\",nbr_voices)\n",
        "\n",
        "test(model,val_dataloader,part_dic,F1=False)"
      ],
      "metadata": {
        "id": "p0HZ9d5TO_Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if fugues == True:\n",
        "    dict_pred , dict_gt, acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_all(model,val_dataloader,part_dic,F1=False)\n",
        "    print(acc_0 , acc_1, acc_2, acc_3)"
      ],
      "metadata": {
        "id": "20MP5Gk5kc2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "id": "H9iWhIkMNjmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss3 * 1.5 = (0.8989219661919758, 0.7166572856993837, 0.8185917288474246, 0.0)"
      ],
      "metadata": {
        "id": "6nwnRTADQvQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 30 epoch, no loss modifier:\n",
        "#ACC:(0.9165209182020722,\n",
        "# 0.7864434689151618,\n",
        "# 0.8130949796045199,\n",
        "# 0.003652274754166715)\n",
        "\n",
        "# 20 epoch, no loss modifier:\n",
        "#(0.7962210840410273, 0.8669639629052727, 0.751302181991106, 0.0)\n",
        "\n",
        "# 20 ep, loss3 *1,5\n",
        "#(0.8721136343927623,\n",
        "# 0.8319586824413445,\n",
        "# 0.7563218924966578,\n",
        "# 0.09029535181592076)"
      ],
      "metadata": {
        "id": "6mCYnJLnHfYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluate fugues F1 score"
      ],
      "metadata": {
        "id": "52P6em3ANb1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if fugues == True:\n",
        "    f1_v0, f1_v1, f1_v2, f1_v3 = evaluate_accuracy_for_all(model,val_dataloader,part_dic,F1=True)\n",
        "    print(f1_v0, f1_v1, f1_v2, f1_v3)"
      ],
      "metadata": {
        "id": "FLLmyO6o5vW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "### take 0 -> compare to truth of 0,1,2,3 -> overall voice\n",
        "\n",
        "count_list = []\n",
        "\n",
        "count_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "truth_dic = {'0': 0, '1': 1, '2': 2, '3': 3 }\n",
        "\n",
        "voice_entry_list = [\"0\", \"1\", \"2\", \"3\"]\n",
        "for voice_entry_one in voice_entry_list:\n",
        "    for voice_entry_two in voice_entry_list:\n",
        "        count_list = []\n",
        "        #print(\"voices:\",voice_entry_one,voice_entry_two)\n",
        "        for i in range(len(dict_pred[voice_entry_one])):\n",
        "            if dict_pred[voice_entry_one][i][0] == truth_dic[voice_entry_two]:      #dict_truth[voice_entry_two][i][0]:\n",
        "                count_list.append(1)\n",
        "            else:\n",
        "                count_list.append(0)\n",
        "        count_dict[voice_entry_one].append(count_list)\n",
        "\n",
        "dictionary_sum={}\n",
        "for i in voice_entry_list:\n",
        "    v0_match,v1_match,v2_match,v3_match = count_dict[i]\n",
        "    sum_v0 = np.sum(v0_match)\n",
        "    sum_v1 = np.sum(v1_match)\n",
        "    sum_v2 = np.sum(v2_match)\n",
        "    sum_v3 = np.sum(v3_match)\n",
        "    dictionary_sum[\"v0\"] = sum_v0\n",
        "    dictionary_sum[\"v1\"] = sum_v1\n",
        "    dictionary_sum[\"v2\"] = sum_v2\n",
        "    dictionary_sum[\"v3\"] = sum_v3\n",
        "\n",
        "    val_list = list(dictionary_sum.values())\n",
        "    \n",
        "    print(\"voice{} matches with\".format(i))\n",
        "    print(\"dict\",dictionary_sum)\n",
        "\n",
        "    max_sum = max(sum_v0,sum_v1,sum_v2,sum_v3)\n",
        "\n",
        "\n",
        "    print(\"max_sum\", val_list.index(max_sum) )\n",
        "\n",
        "    print(\"accuracy voice{}:\".format(i), max_sum/(sum_v0+sum_v1+sum_v2+sum_v3) )\n",
        "    print(\"________________\")\n",
        "    print(\" \")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BoQcV_i038DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR MONOPHONIC F1\n",
        "\n",
        "# start with GT\n",
        "# look at first note in pred-> save note label\n",
        "# look at second note in pred-> if same note as before : SUCESS if it is not: FAIL\n",
        " # DO This for all 4 voices\n",
        " ## in GT there is always the same voice following -> would always be an array of 1\n",
        "\n",
        "## POLYPHONIC \n",
        "\n",
        "# prbl after 1 note there can be multiple diff voices .. chords"
      ],
      "metadata": {
        "id": "-bR7gcej90qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "you have the ground truth on the different parts that you get when you import your score. Each part correspond to a voice. So if your note array contains all notes of all voices, you have for each note in your note array a number that is the ground truth voice (that you take from the part) and a number that is the predicted voice (that you take from the maximum vote)."
      ],
      "metadata": {
        "id": "Z5q305YzvjMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "start time, duration , pitch to separate \n",
        "\n",
        "use the onset_beat and duration_beat\n",
        "\n",
        "multiply them according to the values set when producing the pianorolls \n",
        "\n",
        "-> get the position in the pianoroll\n",
        "\n",
        "time_div = 12\n",
        "\n"
      ],
      "metadata": {
        "id": "EmvxtyaVKG27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "A94mchm4LV6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"val_accuracy_v0\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v1\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v2\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v3\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Accuracy0','Accuracy1','Accuracy2','Accuracy3'])\n",
        "plt.title('Accuracy vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1TgJDHaxAgYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"val_accuracy\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend('Accuracy')\n",
        "plt.title('Accuracy vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OxMs8GEfMvPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"train_loss\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Loss'])\n",
        "plt.title('Loss vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqMcJT5aFL01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chew chorals\n",
        "\n"
      ],
      "metadata": {
        "id": "fS4tzYkxr06Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_chew_pr (file_name, sentences):\n",
        "    path = \"AI-MA_project/chorales_converted/\"\n",
        "    fullname = os.path.join(path, \"chor\"+ file_name +\".xml\")\n",
        "    part = partitura.load_musicxml(fullname)\n",
        "        \n",
        "\n",
        "    ### apply chews method ### \n",
        "    chew_sep = partitura.musicanalysis.estimate_voices(part, monophonic_voices=True)\n",
        "\n",
        "    ### seperate the results -> e.g. pos_zero = all positions where chew prediction says voice 0 ####\n",
        "    pos_zero = np.where(chew_sep==1)\n",
        "    pos_one = np.where(chew_sep==2)\n",
        "    pos_two = np.where(chew_sep==3)\n",
        "    pos_three = np.where(chew_sep==4)\n",
        "\n",
        "    ### create notearray object that contain only the corresponding voice ###\n",
        "    part_zero = partitura.utils.ensure_notearray(part)[pos_zero]\n",
        "    part_one = partitura.utils.ensure_notearray(part)[pos_one]\n",
        "    part_two = partitura.utils.ensure_notearray(part)[pos_two]\n",
        "    part_three = partitura.utils.ensure_notearray(part)[pos_three]\n",
        "\n",
        "    ### create pr representation of all voices ###\n",
        "    pr_zero = partitura.utils.compute_pianoroll(part_zero, time_unit = \"beat\",time_div = 12,piano_range=True)\n",
        "    pr_zero = pr_zero.toarray()\n",
        "\n",
        "    pr_one = partitura.utils.compute_pianoroll(part_one, time_unit = \"beat\",time_div = 12,piano_range=True)\n",
        "    pr_one = pr_one.toarray()\n",
        "\n",
        "    pr_two = partitura.utils.compute_pianoroll(part_two, time_unit = \"beat\",time_div = 12,piano_range=True)\n",
        "    pr_two = pr_two.toarray()\n",
        "\n",
        "    pr_three = partitura.utils.compute_pianoroll(part_three, time_unit = \"beat\",time_div = 12,piano_range=True)\n",
        "    pr_three = pr_three.toarray()\n",
        "    \n",
        "\n",
        "    scores_comb = np.stack([pr_zero, pr_one, pr_two, pr_three], axis=0)\n",
        "    scores_comb = np.swapaxes(scores_comb, 1, 2)\n",
        "    scores_comb = scores_comb[None,:,:,:]\n",
        "    scores_comb = torch.from_numpy(scores_comb)\n",
        "\n",
        "    #print(\"scores_comb.shape\",scores_comb.shape)\n",
        "    #print(\"sentences[:,None,:,:].shape\",sentences[:,None,:,:].shape)\n",
        "\n",
        "    sum_tensor = scores_comb * sentences[:,None,:,:]\n",
        "    prediction = np.squeeze(sum_tensor.cpu().numpy())                # prediction is of shape 4,T,88 and contains a probability for the result to belong to one of the 4 voices -> taking argmax: gives the voice with the highes probability\n",
        "    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "    \n",
        "    mask_pred = np.squeeze(sentences)== 0\n",
        "    v_pred_argm[mask_pred] = -1\n",
        "\n",
        "    return v_pred_argm "
      ],
      "metadata": {
        "id": "55-Dy39Cwg5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_chew(model, train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match           \n",
        "            if idx != 26 and idx != 27: # or idx==2:                \n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "                part_3 = part[3]\n",
        "                note_array_3 = part_3.note_array\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "                note_counter_3 += len(note_array_3)\n",
        "\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "\n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):                    \n",
        "                    #### get only indices that are positive\n",
        "                    onset_beat = note_array[\"onset_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "\n",
        "                    if onset_beat[0] < 0:\n",
        "                        onset_beat -= onset_beat[0]  ### if 1st value of onset_beat is negative add the value of this entry to the whole entry (therefore -)\n",
        "\n",
        "                    duration_beat = note_array[\"duration_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    \n",
        "                    pitch_list = note_array[\"pitch\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "                    \n",
        "\n",
        "                    ################################### MODEL PREDICTION ###################################\n",
        "\n",
        "                    \n",
        "                    \n",
        "                    prediction = calculate_chew_pr(file_name,voices[:,:,:,-1]) \n",
        "\n",
        "                    label = ground_truth_label_list[el_note_arr]\n",
        "                \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    for i in range(len(note_idx_start)):\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "                        accordance_dict[str(label)].append(0)\n",
        "\n",
        "                count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "                for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                    counting = 0\n",
        "                    ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                    for j in range(len(total_predictions_dict[i])):\n",
        "                        if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                    count_dict_2[i].append(counting)\n",
        "\n",
        "                acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "                acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "\n",
        "                #print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                #print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                #print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "                #print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        " \n",
        "                acc_score_dict[\"0\"].append(acc_0)\n",
        "                acc_score_dict[\"1\"].append(acc_1)\n",
        "                acc_score_dict[\"2\"].append(acc_2)\n",
        "                acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "    print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "    print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "    return total_predictions_dict, acc_score_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])"
      ],
      "metadata": {
        "id": "NVvLm9pdryYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sampel 26&27 dont work "
      ],
      "metadata": {
        "id": "yD0w6nJQ82iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if fugues == False:\n",
        "    dict_pred , acc_score_dict, acc_0 , acc_1, acc_2, acc_3 = evaluate_chew(model,val_dataloader,part_dic,F1=False)\n",
        "    print(acc_0 , acc_1, acc_2, acc_3)"
      ],
      "metadata": {
        "id": "UD11ziChvL_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# McLeod chorals"
      ],
      "metadata": {
        "id": "9ejZujau-TXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mcleod_pr (file_name, sentences):\n",
        "    path = \"AI-MA_project/hmm_sep/\"\n",
        "    fullname = os.path.join(path, \"chor\"+ file_name +\".mid\")\n",
        "        \n",
        "\n",
        "    ### apply chews method ### \n",
        "    part_hmm = partitura.load_score_midi(fullname,part_voice_assign_mode=2)\n",
        "    voice_info = partitura.utils.note_array_from_part(part_hmm)[\"voice\"]\n",
        "\n",
        "    ### seperate the results -> e.g. pos_zero = all positions where chew prediction says voice 0 ####\n",
        "    pos_0 = np.where(voice_info==1)\n",
        "    pos_1 = np.where(voice_info==2)\n",
        "    pos_2 = np.where(voice_info==3)\n",
        "    pos_3 = np.where(voice_info==4)\n",
        "\n",
        "    ### create notearray object that contain only the corresponding voice ###\n",
        "    note_array_0= partitura.utils.ensure_notearray(part_hmm)[pos_0]\n",
        "    note_array_1 = partitura.utils.ensure_notearray(part_hmm)[pos_1]\n",
        "    note_array_2 = partitura.utils.ensure_notearray(part_hmm)[pos_2]\n",
        "    note_array_3 = partitura.utils.ensure_notearray(part_hmm)[pos_3]\n",
        "\n",
        "\n",
        "    ### create pr representation of all voices ###\n",
        "    pr_zero = partitura.utils.compute_pianoroll(note_array_0, time_unit = \"beat\",time_div = 12,piano_range=True)\n",
        "    pr_zero = pr_zero.toarray()\n",
        "\n",
        "    pr_one = partitura.utils.compute_pianoroll(note_array_1, time_unit = \"beat\",time_div = 12,piano_range=True)\n",
        "    pr_one = pr_one.toarray()\n",
        "\n",
        "    pr_two = partitura.utils.compute_pianoroll(note_array_2, time_unit = \"beat\",time_div = 12,piano_range=True)\n",
        "    pr_two = pr_two.toarray()\n",
        "\n",
        "    pr_three = partitura.utils.compute_pianoroll(note_array_3, time_unit = \"beat\",time_div = 12,piano_range=True)\n",
        "    pr_three = pr_three.toarray()\n",
        "    \n",
        "\n",
        "    scores_comb = np.stack([pr_zero, pr_one, pr_two, pr_three], axis=0)\n",
        "    scores_comb = np.swapaxes(scores_comb, 1, 2)\n",
        "    scores_comb = scores_comb[None,:,:,:]\n",
        "    scores_comb = torch.from_numpy(scores_comb)\n",
        "\n",
        "    #print(\"scores_comb.shape\",scores_comb.shape)\n",
        "    #print(\"sentences[:,None,:,:].shape\",sentences[:,None,:,:].shape)\n",
        "\n",
        "    sum_tensor = scores_comb * sentences[:,None,:,:]\n",
        "    prediction = np.squeeze(sum_tensor.cpu().numpy())                # prediction is of shape 4,T,88 and contains a probability for the result to belong to one of the 4 voices -> taking argmax: gives the voice with the highes probability\n",
        "    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "    \n",
        "    mask_pred = np.squeeze(sentences)== 0\n",
        "    v_pred_argm[mask_pred] = -1\n",
        "\n",
        "    return v_pred_argm "
      ],
      "metadata": {
        "id": "pQP8pq9a-S6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_mc_leod(model, train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match           \n",
        "            if idx not in [16,17,18,27,28,32,44,45,48,49,50]: # and idx != 27: # or idx==2:                \n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "                part_3 = part[3]\n",
        "                note_array_3 = part_3.note_array\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "                note_counter_3 += len(note_array_3)\n",
        "\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "\n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):                    \n",
        "                    #### get only indices that are positive\n",
        "                    onset_beat = note_array[\"onset_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "\n",
        "                    if onset_beat[0] < 0:\n",
        "                        onset_beat -= onset_beat[0]  ### if 1st value of onset_beat is negative add the value of this entry to the whole entry (therefore -)\n",
        "\n",
        "                    duration_beat = note_array[\"duration_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    \n",
        "                    pitch_list = note_array[\"pitch\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "                    \n",
        "\n",
        "                    ################################### MODEL PREDICTION ###################################                   \n",
        "                    prediction = calculate_mcleod_pr(file_name,voices[:,:,:,-1]) \n",
        "                    label = ground_truth_label_list[el_note_arr]\n",
        "                \n",
        "\n",
        "                    for i in range(len(note_idx_start)):\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "                        accordance_dict[str(label)].append(0)\n",
        "\n",
        "                count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "                for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                    counting = 0\n",
        "                    ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                    for j in range(len(total_predictions_dict[i])):\n",
        "                        if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                    count_dict_2[i].append(counting)\n",
        "\n",
        "                acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "                acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "\n",
        "                print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "                print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        " \n",
        "                acc_score_dict[\"0\"].append(acc_0)\n",
        "                acc_score_dict[\"1\"].append(acc_1)\n",
        "                acc_score_dict[\"2\"].append(acc_2)\n",
        "                acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "    print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "    print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "    return total_predictions_dict, acc_score_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])"
      ],
      "metadata": {
        "id": "2igkR5SI-Z1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "does not work for samples 16,17,18,27,28,32,44,45,48,49,50"
      ],
      "metadata": {
        "id": "g1JC5yeMBnnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if fugues == False:\n",
        "    dict_pred , acc_score_dict, acc_0 , acc_1, acc_2, acc_3 = evaluate_mc_leod(model,val_dataloader,part_dic,F1=False)\n",
        "    print(acc_0 , acc_1, acc_2, acc_3)"
      ],
      "metadata": {
        "id": "oxRr270dC_mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chew fugues"
      ],
      "metadata": {
        "id": "uenr6Uavaic3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_chew_pr_fugue (file_name, sentences, nbr_voices):\n",
        "    path = \"AI-MA_project/bach_fugues/\"\n",
        "    fullname = os.path.join(path, \"wtc\"+ file_name +\".mid\")\n",
        "\n",
        "    part = partitura.load_score_midi(fullname)\n",
        "\n",
        "\n",
        "    ### apply chews method ### \n",
        "    chew_sep = partitura.musicanalysis.estimate_voices(part, monophonic_voices=True)\n",
        "\n",
        "    ### seperate the results -> e.g. pos_zero = all positions where chew prediction says voice 0 ####\n",
        "    pos_0 = np.where(chew_sep==1)\n",
        "    pos_1 = np.where(chew_sep==2)\n",
        "    pos_2 = np.where(chew_sep==3)\n",
        "    if nbr_voices ==4:\n",
        "        pos_3 = np.where(chew_sep==4)\n",
        "\n",
        "    ### create notearray object that contain only the corresponding voice ###\n",
        "    \n",
        "    note_array_0 = partitura.utils.ensure_notearray(part)[pos_0]\n",
        "    note_array_1 = partitura.utils.ensure_notearray(part)[pos_1]\n",
        "    note_array_2 = partitura.utils.ensure_notearray(part)[pos_2]\n",
        "    if nbr_voices==4:\n",
        "        note_array_3 = partitura.utils.ensure_notearray(part)[pos_3]\n",
        "\n",
        "\n",
        "    ### create pr representation of all voices ###\n",
        "    onset_beat_0 = note_array_0['onset_beat'][-1]\n",
        "    duration_beat_0 = note_array_0['duration_beat'][-1]\n",
        "    beat_0 = onset_beat_0 + duration_beat_0\n",
        "    \n",
        "    onset_beat_1 = note_array_1['onset_beat'][-1]\n",
        "    duration_beat_1 = note_array_1['duration_beat'][-1]\n",
        "    beat_1 = onset_beat_1 + duration_beat_1\n",
        "    \n",
        "    onset_beat_2 = note_array_2['onset_beat'][-1]\n",
        "    duration_beat_2 = note_array_2['duration_beat'][-1]\n",
        "    beat_2 = onset_beat_2 + duration_beat_2\n",
        "\n",
        "    pr_zero = partitura.utils.compute_pianoroll(note_array_0, time_unit = \"beat\",time_div = 12,piano_range=True,remove_silence=False,end_time=beat_0)\n",
        "    pr_zero = pr_zero.toarray()\n",
        "\n",
        "    pr_one = partitura.utils.compute_pianoroll(note_array_1, time_unit = \"beat\",time_div = 12,piano_range=True,remove_silence=False,end_time=beat_1)\n",
        "    pr_one = pr_one.toarray()\n",
        "\n",
        "    pr_two = partitura.utils.compute_pianoroll(note_array_2, time_unit = \"beat\",time_div = 12,piano_range=True,remove_silence=False,end_time=beat_2)\n",
        "    pr_two = pr_two.toarray()\n",
        "\n",
        "    if nbr_voices==4:\n",
        "        onset_beat_3 = note_array_3['onset_beat'][-1]\n",
        "        duration_beat_3 = note_array_3['duration_beat'][-1]\n",
        "        beat_3 = onset_beat_3 + duration_beat_3\n",
        "        pr_three = partitura.utils.compute_pianoroll(note_array_3, time_unit = \"beat\",time_div = 12,piano_range=True,remove_silence=False,end_time=beat_3)\n",
        "        pr_three = pr_three.toarray()\n",
        "    else:\n",
        "        pr_three = np.zeros(pr_two.shape)\n",
        "\n",
        "    scores_comb = np.stack([pr_zero, pr_one, pr_two, pr_three], axis=0)\n",
        "    scores_comb = np.swapaxes(scores_comb, 1, 2)\n",
        "    scores_comb = scores_comb[None,:,:,:]\n",
        "    scores_comb = torch.from_numpy(scores_comb)\n",
        "\n",
        "    sum_tensor = scores_comb * sentences[:,None,:,:]\n",
        "    prediction = np.squeeze(sum_tensor.cpu().numpy())                # prediction is of shape 4,T,88 and contains a probability for the result to belong to one of the 4 voices -> taking argmax: gives the voice with the highes probability\n",
        "    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0)) \n",
        "    mask_pred = np.squeeze(sentences)== 0\n",
        "    v_pred_argm[mask_pred] = -1\n",
        "\n",
        "    return v_pred_argm "
      ],
      "metadata": {
        "id": "vNsE3VVMa9Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_chew_fugue( train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match           \n",
        "            if idx != 26 and idx != 27: # or idx==2:                \n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                \n",
        "                part_1 = part[1]\n",
        "                part_2 = part[2]\n",
        "\n",
        "                note_array_0 = partitura.utils.note_array_from_part(part_0)\n",
        "                note_array_1 = partitura.utils.note_array_from_part(part_1)\n",
        "                note_array_2 = partitura.utils.note_array_from_part(part_2)\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2]\n",
        "\n",
        "\n",
        "                if len(part) == 4:\n",
        "                    part_3 = part[3]\n",
        "                    note_array_3 = partitura.utils.note_array_from_part(part_3)\n",
        "                    list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "\n",
        "\n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):                    \n",
        "                    #### get only indices that are positive\n",
        "                    onset_beat = note_array[\"onset_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "\n",
        "                    if onset_beat[0] < 0:\n",
        "                        onset_beat -= onset_beat[0]  ### if 1st value of onset_beat is negative add the value of this entry to the whole entry (therefore -)\n",
        "\n",
        "                    duration_beat = note_array[\"duration_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    \n",
        "                    pitch_list = note_array[\"pitch\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "                    \n",
        "\n",
        "                    ################################### MODEL PREDICTION ###################################\n",
        "                    prediction = calculate_chew_pr_fugue(file_name,voices[:,:,:,-1],nbr_voices) \n",
        "                    label = ground_truth_label_list[el_note_arr]\n",
        "                \n",
        "\n",
        "\n",
        "                    for i in range(len(note_idx_start)):\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "                        accordance_dict[str(label)].append(0)\n",
        "\n",
        "                count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "                for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                    counting = 0\n",
        "                    ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                    for j in range(len(total_predictions_dict[i])):\n",
        "                        if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                    count_dict_2[i].append(counting)\n",
        "\n",
        "                acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "\n",
        "                print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        " \n",
        "                acc_score_dict[\"0\"].append(acc_0)\n",
        "                acc_score_dict[\"1\"].append(acc_1)\n",
        "                acc_score_dict[\"2\"].append(acc_2)\n",
        "\n",
        "                if len(list_of_note_arrays)==4:\n",
        "                        acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "                        print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "                        acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "    print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "    return total_predictions_dict, acc_score_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])"
      ],
      "metadata": {
        "id": "C50fX7xjasD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if fugues == True: \n",
        "    dict_pred , acc_score_dict, acc_0 , acc_1, acc_2, acc_3 = evaluate_chew_fugue(val_dataloader,part_dic,F1=False)\n",
        "    print(acc_0 , acc_1, acc_2, acc_3)"
      ],
      "metadata": {
        "id": "yWz4I9b7asVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# McLeod fugues"
      ],
      "metadata": {
        "id": "xofnsEX4DAME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mcleod_pr (file_name, sentences,nbr_voices):\n",
        "    path = \"AI-MA_project/bach_fugues/\"\n",
        "    fullname = os.path.join(path, \"wtc\"+ file_name +\".mid\")\n",
        "    ### apply chews method ### \n",
        "    part_hmm = partitura.load_score_midi(fullname,part_voice_assign_mode=2)\n",
        "    voice_info = partitura.utils.note_array_from_part(part_hmm)[\"voice\"]\n",
        "\n",
        "    ### seperate the results -> e.g. pos_zero = all positions where chew prediction says voice 0 ####\n",
        "    pos_0 = np.where(voice_info==1)\n",
        "    pos_1 = np.where(voice_info==2)\n",
        "    pos_2 = np.where(voice_info==3)\n",
        "    if nbr_voices ==4:\n",
        "        pos_3 = np.where(voice_info==4)\n",
        "\n",
        "    ### create notearray object that contain only the corresponding voice ###\n",
        "    note_array_0= partitura.utils.ensure_notearray(part_hmm)[pos_0]\n",
        "    note_array_1 = partitura.utils.ensure_notearray(part_hmm)[pos_1]\n",
        "    note_array_2 = partitura.utils.ensure_notearray(part_hmm)[pos_2]\n",
        "    if nbr_voices==4:\n",
        "        note_array_3 = partitura.utils.ensure_notearray(part_hmm)[pos_3]\n",
        "\n",
        "    ### create pr representation of all voices ###\n",
        "    onset_beat_0 = note_array_0['onset_beat'][-1]\n",
        "    duration_beat_0 = note_array_0['duration_beat'][-1]\n",
        "    beat_0 = onset_beat_0 + duration_beat_0\n",
        "    \n",
        "    onset_beat_1 = note_array_1['onset_beat'][-1]\n",
        "    duration_beat_1 = note_array_1['duration_beat'][-1]\n",
        "    beat_1 = onset_beat_1 + duration_beat_1\n",
        "    \n",
        "    onset_beat_2 = note_array_2['onset_beat'][-1]\n",
        "    duration_beat_2 = note_array_2['duration_beat'][-1]\n",
        "    beat_2 = onset_beat_2 + duration_beat_2\n",
        "\n",
        "    pr_zero = partitura.utils.compute_pianoroll(note_array_0, time_unit = \"beat\",time_div = 12,piano_range=True,remove_silence=False,end_time=beat_0)\n",
        "    pr_zero = pr_zero.toarray()\n",
        "\n",
        "    pr_one = partitura.utils.compute_pianoroll(note_array_1, time_unit = \"beat\",time_div = 12,piano_range=True,remove_silence=False,end_time=beat_1)\n",
        "    pr_one = pr_one.toarray()\n",
        "\n",
        "    pr_two = partitura.utils.compute_pianoroll(note_array_2, time_unit = \"beat\",time_div = 12,piano_range=True,remove_silence=False,end_time=beat_2)\n",
        "    pr_two = pr_two.toarray()\n",
        "\n",
        "    if nbr_voices==4:\n",
        "        onset_beat_3 = note_array_3['onset_beat'][-1]\n",
        "        duration_beat_3 = note_array_3['duration_beat'][-1]\n",
        "        beat_3 = onset_beat_3 + duration_beat_3\n",
        "        pr_three = partitura.utils.compute_pianoroll(note_array_3, time_unit = \"beat\",time_div = 12,piano_range=True,remove_silence=False,end_time=beat_3)\n",
        "        pr_three = pr_three.toarray()\n",
        "    else:\n",
        "        pr_three = np.zeros(pr_two.shape)\n",
        "\n",
        "    scores_comb = np.stack([pr_zero, pr_one, pr_two, pr_three], axis=0)\n",
        "    scores_comb = np.swapaxes(scores_comb, 1, 2)\n",
        "    scores_comb = scores_comb[None,:,:,:]\n",
        "    scores_comb = torch.from_numpy(scores_comb)\n",
        "\n",
        "    sum_tensor = scores_comb * sentences[:,None,:,:]\n",
        "    prediction = np.squeeze(sum_tensor.cpu().numpy())                # prediction is of shape 4,T,88 and contains a probability for the result to belong to one of the 4 voices -> taking argmax: gives the voice with the highes probability\n",
        "    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0)) \n",
        "    mask_pred = np.squeeze(sentences)== 0\n",
        "    v_pred_argm[mask_pred] = -1\n",
        "\n",
        "    return v_pred_argm "
      ],
      "metadata": {
        "id": "CU4iH-25aD5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_mc_leod_fugues(train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match           \n",
        "            #if idx not in [16,17,18,27,28,32,44,45,48,49,50]: # and idx != 27: # or idx==2:                \n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                \n",
        "                part_1 = part[1]\n",
        "                part_2 = part[2]\n",
        "\n",
        "                note_array_0 = partitura.utils.note_array_from_part(part_0)\n",
        "                note_array_1 = partitura.utils.note_array_from_part(part_1)\n",
        "                note_array_2 = partitura.utils.note_array_from_part(part_2)\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2]\n",
        "\n",
        "\n",
        "                if len(part) == 4:\n",
        "                    part_3 = part[3]\n",
        "                    note_array_3 = partitura.utils.note_array_from_part(part_3)\n",
        "\n",
        "                    list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "\n",
        "           \n",
        "                \n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "          \n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):                    \n",
        "                    #### get only indices that are positive\n",
        "                    onset_beat = note_array[\"onset_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "\n",
        "                    if onset_beat[0] < 0:\n",
        "                        onset_beat -= onset_beat[0]  ### if 1st value of onset_beat is negative add the value of this entry to the whole entry (therefore -)\n",
        "\n",
        "                    duration_beat = note_array[\"duration_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    \n",
        "                    pitch_list = note_array[\"pitch\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "                    \n",
        "\n",
        "                    ################################### MODEL PREDICTION ###################################                   \n",
        "                    prediction = calculate_mcleod_pr(file_name,voices[:,:,:,-1],nbr_voices) \n",
        "                    label = ground_truth_label_list[el_note_arr]\n",
        "                \n",
        "\n",
        "                    for i in range(len(note_idx_start)):\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "                        accordance_dict[str(label)].append(0)\n",
        "\n",
        "                count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "                for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                    counting = 0\n",
        "                    ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                    for j in range(len(total_predictions_dict[i])):\n",
        "                        if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                    count_dict_2[i].append(counting)\n",
        "\n",
        "                acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "\n",
        "                print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        " \n",
        "                acc_score_dict[\"0\"].append(acc_0)\n",
        "                acc_score_dict[\"1\"].append(acc_1)\n",
        "                acc_score_dict[\"2\"].append(acc_2)\n",
        "\n",
        "                if len(list_of_note_arrays)==4:\n",
        "                        acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "                        print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "                        acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "    print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "    return total_predictions_dict, acc_score_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])"
      ],
      "metadata": {
        "id": "DgFfq9Q4Csei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if fugues == True: \n",
        "    dict_pred , acc_score_dict, acc_0 , acc_1, acc_2, acc_3 = evaluate_mc_leod_fugues(val_dataloader,part_dic,F1=False)\n",
        "    print(acc_0 , acc_1, acc_2, acc_3)"
      ],
      "metadata": {
        "id": "5kSrFU8e-uol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old training loop - matrix and non matrix format"
      ],
      "metadata": {
        "id": "4olpdwzyG8dQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def training_loop(model,optimizer, train_dataloader, monophonic, epochs=50, val_dataloader=None, device=None, scheduler=None):\n",
        "    if device is None:\n",
        "        device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "        print(f\"Training on device: {device}\")\n",
        "\n",
        "    print(\"monophonic set to:\",monophonic)\n",
        "    model = model.to(device)\n",
        "    history = defaultdict(list)\n",
        "\n",
        "    for i_epoch in range(1, epochs + 1):\n",
        "        loss_sum = 0\n",
        "        #accuracy_v0_sum = 0\n",
        "        #accuracy_v1_sum = 0\n",
        "        #accuracy_v2_sum = 0\n",
        "        #accuracy_v3_sum = 0\n",
        "\n",
        "        accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "        val_accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "\n",
        "        accuracy_v_all_sum = 0\n",
        "        model.train()\n",
        "        accuracy_sum = 0\n",
        "        \n",
        "\n",
        "        for idx, (voices, lens, nbr_voices) in enumerate(train_dataloader):  \n",
        "            \n",
        "            voices = voices.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            loss = model.forward(voices, lens, nbr_voices)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()    \n",
        "\n",
        "            if monophonic == False:\n",
        "                with torch.no_grad():\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                    mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "\n",
        "                    \n",
        "                    single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "                    \"\"\"\n",
        "                    if nbr_voices == 4: \n",
        "                        v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2), torch.tensor(pred_v3)], dim=2)\n",
        "                    if nbr_voices ==3:\n",
        "                        v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2)], dim=2)\n",
        "                    v_pred_argm = v_pred_comb.argmax(dim=2)\n",
        "                    mask_pred = (v_pred_comb.sum(axis=2) == 0).numpy()\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                    print(\"v_pred_flat:\", v_pred_flat.shape)\n",
        "                    \"\"\"\n",
        "                    \"\"\"\n",
        "                    if nbr_voices == 4:                   \n",
        "                        v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu(), np.squeeze(voices[:,:,:,3]).cpu()], dim=2)\n",
        "                    if nbr_voices ==3:\n",
        "                        v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu()], dim=2)\n",
        "                    v_ori_argm = v_ori_comb.argmax(dim=2)\n",
        "                    mask_ori = (v_ori_comb.sum(axis=2) == 0).numpy()\n",
        "                    print(\"old mask\", mask_ori.shape)\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    print(\"v_ori_flat\", v_ori_flat.shape)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)   \n",
        "                    print(\"acc\",acc)                    \n",
        "                    accuracy_sum += acc \n",
        "                    \"\"\"\n",
        "\n",
        "\n",
        "            if monophonic == True:\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                    prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "\n",
        "                    truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "\n",
        "                    acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "\n",
        "                    for i in range(len(prediction[0,:])):\n",
        "                      acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                      accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "                    \n",
        "                    \"\"\"\n",
        "                    pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "\n",
        "                    acc_v0 = accuracy_score(torch.tensor(pred_v0), np.squeeze(voices[:,:,:,0]).argmax(dim=1).cpu())\n",
        "                    acc_v1 = accuracy_score(torch.tensor(pred_v1), np.squeeze(voices[:,:,:,1]).argmax(dim=1).cpu())\n",
        "                    acc_v2 = accuracy_score(torch.tensor(pred_v2), np.squeeze(voices[:,:,:,2]).argmax(dim=1).cpu())\n",
        "                    if nbr_voices == 4:\n",
        "                        acc_v3 = accuracy_score(torch.tensor(pred_v3), np.squeeze(voices[:,:,:,3]).argmax(dim=1).cpu())\n",
        "                    \n",
        "                    # normalize according to the number of sequences in the batch (atm len(lens)==1)\n",
        "                    accuracy_v0_sum += acc_v0 / len(lens)\n",
        "                    accuracy_v1_sum += acc_v1 / len(lens)\n",
        "                    accuracy_v2_sum += acc_v2 / len(lens)\n",
        "                    if nbr_voices == 4:\n",
        "                        accuracy_v3_sum += acc_v3 / len(lens)\n",
        "                    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        train_loss = loss_sum / len(train_dataloader)\n",
        "\n",
        "        # normalize according to the number of batches\n",
        "        if monophonic == True:\n",
        "\n",
        "            train_acc_list = np.array(accuracy_sum_list) / len(train_dataloader)\n",
        "            train_acc_list[3] = accuracy_sum_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "            train_acc_list[4] = accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_acc\"].append(train_acc_list)\n",
        "            print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}, Train Accuracy_4 : {}\".format(train_loss, train_acc_list[0], train_acc_list[1], train_acc_list[2], train_acc_list[3],train_acc_list[4])) \n",
        "\n",
        "\n",
        "            \"\"\"\n",
        "            train_accuracy_v0 = accuracy_v0_sum / len(train_dataloader)\n",
        "            train_accuracy_v1 = accuracy_v1_sum / len(train_dataloader)\n",
        "            train_accuracy_v2 = accuracy_v2_sum / len(train_dataloader)\n",
        "            train_accuracy_v3 = accuracy_v3_sum / 18   ## bc only 18 pieces with len 3\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy_v0\"].append(train_accuracy_v0)\n",
        "            history[\"train_accuracy_v1\"].append(train_accuracy_v1)\n",
        "            history[\"train_accuracy_v2\"].append(train_accuracy_v2)\n",
        "            #if nbr_voices == 4:\n",
        "            history[\"train_accuracy_v3\"].append(train_accuracy_v3)\n",
        "            print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}\".format(train_loss, train_accuracy_v0, train_accuracy_v1, train_accuracy_v2, train_accuracy_v3)) \n",
        "            #else:\n",
        "            #    print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}\".format(train_loss, train_accuracy_v0, train_accuracy_v1, train_accuracy_v2)) \n",
        "            \"\"\"\n",
        "\n",
        "        if monophonic == False:\n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "\n",
        "        if monophonic == True:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_v0_sum = 0\n",
        "                accuracy_v1_sum = 0\n",
        "                accuracy_v2_sum = 0\n",
        "                accuracy_v3_sum = 0\n",
        "\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for voices, lens, nbr_voices in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "\n",
        "                        truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "\n",
        "                        acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "\n",
        "                        for i in range(len(prediction[0,:])):\n",
        "                          acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                          val_accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "\n",
        "                        #print(\"val_accuracy_sum_list[3]\",val_accuracy_sum_list[3])\n",
        "                    #val_acc_list = np.array(val_accuracy_sum_list) / len(train_dataloader)\n",
        "                    #val_acc_list[3] = val_acc_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "                    #val_acc_list[4] = val_acc_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "\n",
        "\n",
        "                #history[\"val_acc_new\"].append(val_acc_list)\n",
        "                #print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "\n",
        "                        # Predict the model's output on a batch\n",
        "                        pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "                            \n",
        "                        # compute the accuracy \n",
        "                        acc_v0 = accuracy_score(torch.tensor(pred_v0), np.squeeze(voices[:,:,:,0]).argmax(dim=1).cpu())\n",
        "                        acc_v1 = accuracy_score(torch.tensor(pred_v1), np.squeeze(voices[:,:,:,1]).argmax(dim=1).cpu())\n",
        "                        acc_v2 = accuracy_score(torch.tensor(pred_v2), np.squeeze(voices[:,:,:,2]).argmax(dim=1).cpu())\n",
        "                        if nbr_voices == 4:\n",
        "                            acc_v3 = accuracy_score(torch.tensor(pred_v3), np.squeeze(voices[:,:,:,3]).argmax(dim=1).cpu())\n",
        "                            \n",
        "                            \n",
        "                        # normalize according to the number of sequences in the batch (atm len(lens)==1)\n",
        "                        accuracy_v0_sum += acc_v0 / len(lens)\n",
        "                        accuracy_v1_sum += acc_v1 / len(lens)\n",
        "                        accuracy_v2_sum += acc_v2 / len(lens)\n",
        "                        if nbr_voices == 4:\n",
        "                            accuracy_v3_sum += acc_v3 / len(lens)\n",
        "\n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy_v0 = accuracy_v0_sum / len(val_dataloader)\n",
        "                    val_accuracy_v1 = accuracy_v1_sum / len(val_dataloader)\n",
        "                    val_accuracy_v2 = accuracy_v2_sum / len(val_dataloader)\n",
        "                    val_accuracy_v3 = accuracy_v3_sum / 18  ##len(val_dataloader). - bc 18 pieces only with voice 3\n",
        "\n",
        "\n",
        "                    val_acc_list = np.array(val_accuracy_sum_list) / len(val_dataloader)\n",
        "                    val_acc_list[3] = val_accuracy_sum_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "                    val_acc_list[4] = val_accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "                    \n",
        "\n",
        "\n",
        "                history[\"val_accuracy_v0\"].append(val_accuracy_v0)\n",
        "                history[\"val_accuracy_v1\"].append(val_accuracy_v1)\n",
        "                history[\"val_accuracy_v2\"].append(val_accuracy_v2)\n",
        "                #if nbr_voices == 4:\n",
        "                history[\"val_accuracy_v3\"].append(val_accuracy_v3)\n",
        "                print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}\".format(val_accuracy_v0, val_accuracy_v1, val_accuracy_v2, val_accuracy_v3))\n",
        "                #else:\n",
        "                #    print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}\".format(val_accuracy_v0, val_accuracy_v1, val_accuracy_v2))\n",
        "\n",
        "\n",
        "                history[\"val_acc_new\"].append(val_acc_list)\n",
        "                print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "        if monophonic == False:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_sum = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    for voices, lens, nbr_voices in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "                        \n",
        "                        # Predict the model's output on a batch\n",
        "\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                        v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                        mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                        \n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "\n",
        "                        \"\"\"\n",
        "                        pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "                        if nbr_voices == 4: \n",
        "                            v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2), torch.tensor(pred_v3)], dim=2)\n",
        "                        if nbr_voices ==3:\n",
        "                            v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2)], dim=2)\n",
        "                        v_pred_argm = v_pred_comb.argmax(dim=2)\n",
        "                        mask_pred = (v_pred_comb.sum(axis=2) == 0).numpy()\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)                      \n",
        "                        if nbr_voices == 4:                   \n",
        "                            v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu(), np.squeeze(voices[:,:,:,3]).cpu()], dim=2)\n",
        "                        if nbr_voices ==3:\n",
        "                            v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu()], dim=2)\n",
        "                        v_ori_argm = v_ori_comb.argmax(dim=2)\n",
        "                        mask_ori = (v_ori_comb.sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)\n",
        "                        accuracy_sum += acc \n",
        "                        \"\"\"\n",
        "                        \n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "\n",
        "                history[\"val_accuracy\"].append(val_accuracy)  \n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # save the model\n",
        "        torch.save(model, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "nfDV8MKGHE3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "class MusicDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        labels = [\"voice_0\", \"voice_1\", \"voice_2\", \"voice_3\", \"voice_all\"]\n",
        "        self.labels = labels\n",
        "        self.pr_dict = {}\n",
        "        len_list = []\n",
        "\n",
        "        for iLabel in range(len(labels)):\n",
        "            \n",
        "            if iLabel == 4:   \n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\")))   \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: ### normal sollte es egal sein wenn voice_4 bei manchen nicht existiert - wenn nicht condition einfÃ¼hren damit das funktioniert\n",
        "                        loaded_obj = pickle.load(f)  \n",
        "                        voice_files.append(loaded_obj) \n",
        "                        len_list.append(len(loaded_obj.T))\n",
        "                        \n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                self.pr_dict[\"length\"] = len_list\n",
        "    \n",
        "            else:\n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: \n",
        "                        loaded_obj = pickle.load(f)     \n",
        "                        voice_files.append(loaded_obj)\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      \n",
        "        return len(self.pr_dict[self.labels[0]])\n",
        "  \n",
        "\n",
        "    def __getitem__(self, idx):          \n",
        "\n",
        "        out_list = []\n",
        "        for key, value in self.pr_dict.items():\n",
        "            out_list.append(self.pr_dict[key][idx])    \n",
        "\n",
        "        v0 = torch.tensor(out_list[0].T)\n",
        "        v1 = torch.tensor(out_list[1].T)\n",
        "        v2 = torch.tensor(out_list[2].T)\n",
        "        v3 = torch.tensor(out_list[3].T)\n",
        "        v_all = torch.tensor(out_list[4].T) \n",
        "        length = self.pr_dict[\"length\"][idx]\n",
        "\n",
        "\n",
        "        return (v0, v1, v2, v3, v_all, length)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "x2lFUuw719EC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}