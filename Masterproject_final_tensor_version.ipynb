{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Masterproject.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aim56009/AI-MA_project/blob/main/Masterproject_final_tensor_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ],
      "metadata": {
        "id": "SsyC2uB0KfaT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDUwCmeIW8i1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e592532-fe92-4fa9-a08e-9226b9f946fd"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import torchvision.transforms.functional as TF \n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import click\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install partitura\n",
        "import partitura\n",
        "import statistics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting partitura\n",
            "  Downloading partitura-0.4.0-py3-none-any.whl (218 kB)\n",
            "\u001b[K     |████████████████████████████████| 218 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from partitura) (1.4.1)\n",
            "Collecting xmlschema\n",
            "  Downloading xmlschema-1.11.1-py3-none-any.whl (334 kB)\n",
            "\u001b[K     |████████████████████████████████| 334 kB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from partitura) (1.21.6)\n",
            "Collecting lark-parser\n",
            "  Downloading lark_parser-0.12.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 54.1 MB/s \n",
            "\u001b[?25hCollecting mido\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from partitura) (4.2.6)\n",
            "Collecting elementpath<3.0.0,>=2.5.0\n",
            "  Downloading elementpath-2.5.3-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 71.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: elementpath, xmlschema, mido, lark-parser, partitura\n",
            "Successfully installed elementpath-2.5.3 lark-parser-0.12.0 mido-1.2.10 partitura-0.4.0 xmlschema-1.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsFs8dyqXBx2"
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/aim56009/AI-MA_project.git"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYpz1MOIOgtk"
      },
      "source": [
        "# Dataloader - Set the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygWXNSrCbRQi"
      },
      "source": [
        "#PATH_TO_DATA = \"AI-MA_project/bach_pr_fugues\"\n",
        "PATH_TO_DATA = \"AI-MA_project/pianoroll_88\"\n",
        "\n",
        "batch_size = 1 \n",
        "workers = 0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1-u8zYd-gyo"
      },
      "source": [
        "class MusicDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        labels = [\"voice_0\", \"voice_1\", \"voice_2\", \"voice_3\", \"voice_all\"]\n",
        "        self.labels = labels\n",
        "        self.pr_dict = {}\n",
        "        len_list = []\n",
        "\n",
        "        for iLabel in range(len(labels)):\n",
        "            \n",
        "            if iLabel == 4:   \n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\")))   \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: ### normal sollte es egal sein wenn voice_4 bei manchen nicht existiert - wenn nicht condition einführen damit das funktioniert\n",
        "                        loaded_obj = pickle.load(f)  \n",
        "                        voice_files.append(loaded_obj) \n",
        "                        len_list.append(len(loaded_obj.T))\n",
        "                        \n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                self.pr_dict[\"length\"] = len_list\n",
        "    \n",
        "            else:\n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: \n",
        "                        loaded_obj = pickle.load(f)     \n",
        "                        voice_files.append(loaded_obj)\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      \n",
        "        return len(self.pr_dict[self.labels[0]])\n",
        "  \n",
        "\n",
        "    def __getitem__(self, idx):          \n",
        "\n",
        "        out_list = []\n",
        "        for key, value in self.pr_dict.items():\n",
        "            out_list.append(self.pr_dict[key][idx])    \n",
        "\n",
        "        v0 = torch.tensor(out_list[0].T)\n",
        "        v1 = torch.tensor(out_list[1].T)\n",
        "        v2 = torch.tensor(out_list[2].T)\n",
        "        v3 = torch.tensor(out_list[3].T)\n",
        "        v_all = torch.tensor(out_list[4].T) \n",
        "        length = self.pr_dict[\"length\"][idx]\n",
        "\n",
        "\n",
        "        return (v0, v1, v2, v3, v_all, length)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicDataset_new(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        self.name_list = [\"1f01\",\"1f02\",\"1f03\",\"1f04\",\"1f05\",\"1f06\",\"1f07\",\"1f08\",\"1f09\",\"1f10\",\"1f11\",\"1f12\",\"1f13\",\"1f14\",\"1f15\",\"1f16\",\"1f17\",\"1f18\",\"1f19\",\"1f20\",\"1f21\",\"1f22\",\"1f23\",\"1f24\",\"2f01\",\"2f02\",\"2f03\",\"2f04\",\"2f05\",\"2f06\",\"2f07\",\"2f08\",\"2f09\",\"2f10\",\"2f11\",\"2f12\",\"2f13\",\"2f14\",\"2f15\",\"2f16\",\"2f17\",\"2f18\",\"2f19\",\"2f20\",\"2f21\",\"2f22\",\"2f23\",\"2f24\"]\n",
        "        self.name_list_voice_3 =  ['1f01', '1f05', '1f12', '1f14', '1f16', '1f17', '1f18', '1f23', '1f24', '2f02', '2f05', '2f07', '2f08', '2f09', '2f16', '2f17',  '2f22', '2f23']\n",
        "        labels = [\"voice_0\", \"voice_1\", \"voice_2\", \"voice_3\", \"voice_all\"]\n",
        "        self.labels = labels\n",
        "        self.pr_dict = {}\n",
        "        len_list = []\n",
        "        nbr_voices_list = []\n",
        "        file_names_list = []\n",
        "\n",
        "        for iLabel in range(len(labels)):\n",
        "            \n",
        "            if iLabel == 4:   \n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\")))   \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: ### normal sollte es egal sein wenn voice_4 bei manchen nicht existiert - wenn nicht condition einführen damit das funktioniert\n",
        "                        loaded_obj = pickle.load(f)  \n",
        "                        voice_files.append(loaded_obj) \n",
        "                        len_list.append(len(loaded_obj.T))\n",
        "\n",
        "                        file_names_list.append(name[-8:-4])\n",
        "\n",
        "                    if \"AI-MA_project/bach_pr_fugues/voice_3/voice_3_\" + name[49:53] + \".pkl\" in sorted(glob.glob(os.path.join(PATH_TO_DATA, \"voice_3\", \"*.pkl\"))):\n",
        "                        nbr_voices_list.append(4)\n",
        "                    else:\n",
        "                        nbr_voices_list.append(3)\n",
        "                        \n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                self.pr_dict[\"length\"] = len_list\n",
        "                self.pr_dict[\"nbr_voices\"] = nbr_voices_list\n",
        "                self.pr_dict[\"name\"] = file_names_list\n",
        "                #print(self.pr_dict[\"name\"])\n",
        "\n",
        "\n",
        "            if iLabel == 3:  \n",
        "                voice_files = []\n",
        "                file_names_3 = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                file_names_2 = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[2], \"*.pkl\")))   \n",
        "                \n",
        "                ###### loop over all filnames in voices_2 and if an element there is not present in voices_3: append \"missing\" to the voice_files of label=3 => important bc. self.pr_dict[voice_3] has then len 42 and otherwise it would only have len 18  .. these \"missing\" el are not considered later in the dataloader (if len=3 is a diff case of get_idx)\n",
        "                for name in file_names_2:\n",
        "                    if name[45:49] in self.name_list_voice_3:\n",
        "                      correct_name_3 = \"AI-MA_project/bach_pr_fugues/voice_3/voice_3_\" + name[45:49] + \".pkl\"\n",
        "                      with open(correct_name_3 ,'rb') as f:  \n",
        "                            loaded_obj = pickle.load(f)  \n",
        "                            voice_files.append(loaded_obj)\n",
        "                    else:\n",
        "                      voice_files.append(\"missing\")\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                \n",
        "\n",
        "                \n",
        "            else:\n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: \n",
        "                          loaded_obj = pickle.load(f)     \n",
        "                          voice_files.append(loaded_obj)\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pr_dict[self.labels[0]])\n",
        "\n",
        "    def __getitem__(self, idx):      \n",
        "        out_list = []\n",
        "        \n",
        "        if self.pr_dict[\"nbr_voices\"][idx] == 4:\n",
        "            for key, value in self.pr_dict.items():\n",
        "              out_list.append(self.pr_dict[key][idx])\n",
        "                              \n",
        "            v0 = torch.tensor(out_list[0].T)\n",
        "            v1 = torch.tensor(out_list[1].T)\n",
        "            v2 = torch.tensor(out_list[2].T)\n",
        "            v3 = torch.tensor(out_list[3].T)\n",
        "            v_all = torch.tensor(out_list[4].T) \n",
        "            length = self.pr_dict[\"length\"][idx]\n",
        "            nbr_voices = self.pr_dict[\"nbr_voices\"][idx]\n",
        "            file_name = self.pr_dict[\"name\"][idx]\n",
        "\n",
        "            voices = torch.stack([v0, v1, v2, v3, v_all], dim=2)\n",
        "            \n",
        "            return (voices, length, nbr_voices, file_name)\n",
        "        \n",
        "        if self.pr_dict[\"nbr_voices\"][idx] == 3:\n",
        "\n",
        "            for key, value in self.pr_dict.items():\n",
        "                if key != \"voice_3\":\n",
        "                  out_list.append(self.pr_dict[key][idx]) \n",
        "            \n",
        "            v0 = torch.tensor(out_list[0].T)\n",
        "            v1 = torch.tensor(out_list[1].T)\n",
        "            v2 = torch.tensor(out_list[2].T)\n",
        "            v3 = torch.zeros(v2.shape)\n",
        "            v_all = torch.tensor(out_list[3].T) \n",
        "            length = self.pr_dict[\"length\"][idx]\n",
        "            nbr_voices = self.pr_dict[\"nbr_voices\"][idx]\n",
        "            file_name = self.pr_dict[\"name\"][idx]\n",
        "            \n",
        "            voices = torch.stack([v0, v1, v2, v3, v_all], dim=2)\n",
        "\n",
        "            \n",
        "            return (voices, length, nbr_voices, file_name)\n",
        "        "
      ],
      "metadata": {
        "id": "3FxK6qr1FqIl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicDataset_chor(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        labels = [\"voice_0\", \"voice_1\", \"voice_2\", \"voice_3\", \"voice_all\"]\n",
        "        self.labels = labels\n",
        "        self.pr_dict = {}\n",
        "        len_list = []\n",
        "        nbr_voices_list = []\n",
        "        file_names_list = []\n",
        "\n",
        "        for iLabel in range(len(labels)):\n",
        "            \n",
        "            if iLabel == 4:   \n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\")))   \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: ### normal sollte es egal sein wenn voice_4 bei manchen nicht existiert - wenn nicht condition einführen damit das funktioniert\n",
        "                        loaded_obj = pickle.load(f)  \n",
        "                        voice_files.append(loaded_obj) \n",
        "                        len_list.append(len(loaded_obj.T))\n",
        "                        file_names_list.append(name[-7:-4])      # e.g. name = AI-MA_project/pianoroll_88/voice_all/voice_all_001.pkl\n",
        "\n",
        "                        \n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                self.pr_dict[\"length\"] = len_list\n",
        "                self.pr_dict[\"name\"] = file_names_list\n",
        "                #print(self.pr_dict[\"name\"])\n",
        "              \n",
        "\n",
        "            else:\n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: \n",
        "                        loaded_obj = pickle.load(f)     \n",
        "                        voice_files.append(loaded_obj)\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pr_dict[self.labels[0]])\n",
        "\n",
        "    def __getitem__(self, idx):      \n",
        "        out_list = []\n",
        "        \n",
        "        for key, value in self.pr_dict.items():\n",
        "            out_list.append(self.pr_dict[key][idx])\n",
        "                            \n",
        "        v0 = torch.tensor(out_list[0].T)\n",
        "        v1 = torch.tensor(out_list[1].T)\n",
        "        v2 = torch.tensor(out_list[2].T)\n",
        "        v3 = torch.tensor(out_list[3].T)\n",
        "        v_all = torch.tensor(out_list[4].T) \n",
        "        length = self.pr_dict[\"length\"][idx]\n",
        "        file_name = self.pr_dict[\"name\"][idx]\n",
        "\n",
        "        voices = torch.stack([v0, v1, v2, v3, v_all], dim=2)\n",
        "        \n",
        "        return (voices, length, 4, file_name)     # 4 bc nbr voices is always 4"
      ],
      "metadata": {
        "id": "3uQnok3VGngZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oTPIsBwPAJg"
      },
      "source": [
        "dataset = MusicDataset_chor(PATH_TO_DATA)\n",
        "#dataset = MusicDataset_new(PATH_TO_DATA)\n",
        "loader = torch.utils.data.DataLoader(dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for i, sample_batched in enumerate(loader):\n",
        "    all_voices, length, nbr_voices = sample_batched\n",
        "    if nbr_voices ==3:\n",
        "      print(i,nbr_voices,all_voices.shape)\n",
        "    else:\n",
        "      print(i,nbr_voices)\n",
        "\"\"\"\n",
        "for i, sample_batched in enumerate(loader):\n",
        "    if i == 1:\n",
        "        all_voices, length, nbr_voices, file_name = sample_batched\n",
        "        print(file_name[0],nbr_voices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXsRYzQSUuQU",
        "outputId": "5a3c0760-a293-4a3c-8976-da891d8a2ce2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "002 tensor([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pianoroll_0 = all_voices.squeeze()[:,:,0].numpy()\n",
        "pianoroll_1 = all_voices.squeeze()[:,:,1].numpy()\n",
        "pianoroll_2 = all_voices.squeeze()[:,:,2].numpy()\n",
        "pianoroll_3 = all_voices.squeeze()[:,:,3].numpy()\n",
        "pianoroll_all = all_voices.squeeze()[:,:,-1].numpy()\n",
        "\n",
        "time_unit = \"beat\"\n",
        "time_div = 12\n",
        "piano_range = True"
      ],
      "metadata": {
        "id": "fR2HaA_BqeHw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, figsize=(20, 10))\n",
        "ax.imshow(pianoroll_all, origin=\"lower\", cmap='gray', interpolation='nearest', aspect='auto')\n",
        "ax.set_xlabel(f'Time ({time_unit}s/{time_div})')\n",
        "ax.set_ylabel('Piano key' if piano_range else 'MIDI pitch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "sRoyBJJVqX_u",
        "outputId": "544912aa-1800-4b73-c95a-5d930cdd115e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for i, sample_batched in enumerate(loader):\n",
        "    all_voices, length, nbr_voices = sample_batched\n",
        "    if nbr_voices ==3:\n",
        "      print(i,nbr_voices,all_voices.shape)\n",
        "    else:\n",
        "      print(i,nbr_voices)\n",
        "\n",
        "for i, sample_batched in enumerate(loader):\n",
        "  if i ==10:\n",
        "    all_voices, length, nbr_voices, _ = sample_batched\n",
        "    all_voices_pr = all_voices[0,:,:,-1].numpy()\n",
        "    \n",
        "    note_array = partitura.utils.pianoroll_to_notearray(all_voices[0,:,:,-1].numpy(), time_div=12, time_unit='beat')\n",
        "    print(note_array.shape)\n",
        "    print(note_array[:10])\n",
        "    print(note_array.dtype.names)\n",
        "\n",
        "    #print(i,nbr_voices,all_voices.shape)\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "b4QCaMEi3nw7",
        "outputId": "3c95ed5c-a15b-43ad-e33a-b5fce9b801e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor i, sample_batched in enumerate(loader):\\n    all_voices, length, nbr_voices = sample_batched\\n    if nbr_voices ==3:\\n      print(i,nbr_voices,all_voices.shape)\\n    else:\\n      print(i,nbr_voices)\\n\\nfor i, sample_batched in enumerate(loader):\\n  if i ==10:\\n    all_voices, length, nbr_voices, _ = sample_batched\\n    all_voices_pr = all_voices[0,:,:,-1].numpy()\\n    \\n    note_array = partitura.utils.pianoroll_to_notearray(all_voices[0,:,:,-1].numpy(), time_div=12, time_unit='beat')\\n    print(note_array.shape)\\n    print(note_array[:10])\\n    print(note_array.dtype.names)\\n\\n    #print(i,nbr_voices,all_voices.shape)\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Music - Model\n"
      ],
      "metadata": {
        "id": "JNqxeacDwxNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define UNET "
      ],
      "metadata": {
        "id": "QAIfIM69VHI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels=1, classes=1):\n",
        "        super(UNET, self).__init__()\n",
        "        self.layers = [in_channels, 64, 128, 256, 512, 1024]\n",
        "        \n",
        "        self.double_conv_downs = nn.ModuleList([self.__double_conv(layer, layer_n) for layer, layer_n in zip(self.layers[:-1], self.layers[1:])])\n",
        "        \n",
        "        self.up_trans = nn.ModuleList([nn.ConvTranspose2d(layer, layer_n, kernel_size=2, stride=2) for layer, layer_n in zip(self.layers[::-1][:-2], self.layers[::-1][1:-1])])\n",
        "            \n",
        "        self.double_conv_ups = nn.ModuleList([self.__double_conv(layer, layer//2) for layer in self.layers[::-1][:-2]])\n",
        "        \n",
        "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.final_conv = nn.Conv2d(64, classes, kernel_size=1)\n",
        "\n",
        "        \n",
        "    def __double_conv(self, in_channels, out_channels):\n",
        "        conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        return conv\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # down layers\n",
        "        concat_layers = []\n",
        "        \n",
        "        for down in self.double_conv_downs:\n",
        "            x = down(x)\n",
        "            if down != self.double_conv_downs[-1]:\n",
        "                concat_layers.append(x)\n",
        "                x = self.max_pool_2x2(x)\n",
        "        \n",
        "        concat_layers = concat_layers[::-1]\n",
        "        \n",
        "        # up layers\n",
        "        for up_trans, double_conv_up, concat_layer  in zip(self.up_trans, self.double_conv_ups, concat_layers):\n",
        "            x = up_trans(x)\n",
        "            if x.shape != concat_layer.shape:\n",
        "                x = TF.resize(x, concat_layer.shape[2:])\n",
        "            \n",
        "            concatenated = torch.cat((concat_layer, x), dim=1)\n",
        "            x = double_conv_up(concatenated)\n",
        "            \n",
        "        x = self.final_conv(x)\n",
        "        \n",
        "        return x "
      ],
      "metadata": {
        "id": "XMdlm0_Vyyhc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_0 = []\n",
        "loss_1 = []\n",
        "loss_2 = []\n",
        "loss_3 = []\n",
        "class MusicNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, network_type,output_dim=88, hidden_dim=300, rnn_depth=1, cell_type=\"GRU\"):                 \n",
        "        super(MusicNetwork, self).__init__()\n",
        "\n",
        "        self.network_type = network_type\n",
        "        self.n_out = output_dim\n",
        "        input_dim = output_dim \n",
        "        rnn_cell = nn.GRU\n",
        "        self.rnn = rnn_cell(input_size=input_dim, hidden_size=hidden_dim, num_layers=rnn_depth, batch_first=True)\n",
        "        self.cnn = UNET(in_channels=1, classes=4)\n",
        "        self.top_layer_voice_0 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_1 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_2 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_3 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.loss = nn.CrossEntropyLoss(reduction=\"mean\")                       # use weight parameters maybe take 1/88       \n",
        "\n",
        "    \n",
        "\n",
        "    def compute_outputs(self, sentences, sentences_len):\n",
        "        if self.network_type == \"RNN\":\n",
        "          rnn_out ,_= self.rnn(sentences)     \n",
        "          out_0 = self.top_layer_voice_0(rnn_out)\n",
        "          out_1 = self.top_layer_voice_1(rnn_out)\n",
        "          out_2 = self.top_layer_voice_2(rnn_out)\n",
        "          out_3 = self.top_layer_voice_3(rnn_out)\n",
        "\n",
        "          return torch.stack([out_0, out_1, out_2, out_3], dim=1)\n",
        "\n",
        "        else: \n",
        "          sentences = sentences[:,None]\n",
        "          out = self.cnn(sentences)\n",
        "          return out                      ### squeeze output here before returning                                       \n",
        "        \n",
        "\n",
        "    def forward(self, voices, sentences_len, nbr_voices):            \n",
        "\n",
        "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
        "        scores_comb = self.compute_outputs(voices[:,:,:,-1], sentences_len)\n",
        "\n",
        "        # Flatten the outputs and the labels, to compute the loss.\n",
        "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
        "        score_0  = scores_comb[:,0,:,:].view(-1, self.n_out)\n",
        "        score_1  = scores_comb[:,1,:,:].view(-1, self.n_out)\n",
        "        score_2  = scores_comb[:,2,:,:].view(-1, self.n_out)\n",
        "        score_3  = scores_comb[:,3,:,:].view(-1, self.n_out)\n",
        "\n",
        "\n",
        "        v0 = voices[:,:,:,0].squeeze()\n",
        "        v1 = voices[:,:,:,1].squeeze()\n",
        "        v2 = voices[:,:,:,2].squeeze()\n",
        "        v3 = voices[:,:,:,3].squeeze()\n",
        "\n",
        "        #print(\"nbr_voices\",nbr_voices)\n",
        "\n",
        "\n",
        "        if nbr_voices==4:\n",
        "            loss = self.loss(score_0, v0) +  self.loss(score_1, v1) +  self.loss(score_2, v2) + 1.5* self.loss(score_3, v3) \n",
        "            \n",
        "            loss_0.append(self.loss(score_0, v0).cpu().detach().numpy())\n",
        "            loss_1.append(self.loss(score_1, v1).cpu().detach().numpy())\n",
        "            loss_2.append(self.loss(score_2, v2).cpu().detach().numpy())\n",
        "            loss_3.append(self.loss(score_3, v3).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_0, v0)\",self.loss(score_0, v0).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_0, v1)\",self.loss(score_1, v1).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_0, v2)\",self.loss(score_2, v2).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_2, v3)\",self.loss(score_3, v3).cpu().detach().numpy())\n",
        "            print(\"loss\",loss)      \n",
        "        else:\n",
        "            loss = self.loss(score_0, v0) + self.loss(score_1, v1) + self.loss(score_2, v2) \n",
        "        \n",
        "        return loss   #change also to matrix version\n",
        "        \n",
        "\n",
        "\n",
        "    def predict(self, sentences, sentences_len,monophonic=True):\n",
        "\n",
        "        # Compute the outputs from the linear units.\n",
        "\n",
        "        scores_comb = self.compute_outputs(sentences, sentences_len)\n",
        "\n",
        "        if monophonic==False:\n",
        "            sum = scores_comb * sentences[:,None,:,:]\n",
        "            return np.squeeze(sum.cpu().numpy())\n",
        "            \n",
        "\n",
        "        else:\n",
        "            # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
        "            #predicted = scores_comb.argmax(dim=3)\n",
        "            #return np.squeeze(predicted.cpu().numpy())\n",
        "\n",
        "            sum_tensor = scores_comb * sentences[:,None,:,:]\n",
        "            prediction = np.squeeze(sum_tensor.cpu().numpy())                # prediction is of shape 4,T,88 and contains a probability for the result to belong to one of the 4 voices -> taking argmax: gives the voice with the highes probability\n",
        "            v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "            \n",
        "            mask_pred = np.squeeze(sentences)== 0\n",
        "            v_pred_argm[mask_pred] = -1\n",
        "\n",
        "            return v_pred_argm \n",
        "                       "
      ],
      "metadata": {
        "id": "CviiPTPOPW04"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= \"CNN\"\n",
        "lr = 0.0001  \n",
        "monophonic = True\n",
        "his = start_experiment(10, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "79cPe11WL6J0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4d1e6047-47be-4f85-fe17-36a38d9e37f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= \"CNN\"\\nlr = 0.0001  \\nmonophonic = True\\nhis = start_experiment(10, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07I2QbRDbUlA"
      },
      "source": [
        "# Define Training Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHESuQEQbVRB"
      },
      "source": [
        "def train(epochs, lr, hidden_dim, momentum, rnn_depth, device, rnn_cell, weight_decay,network_type, train_dataloader, val_dataloader=None):\n",
        "    \n",
        "    output_dim = 88\n",
        "    model = MusicNetwork(network_type, output_dim, hidden_dim, rnn_depth, cell_type)              \n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = lr_scheduler.MultiStepLR(optimizer, [epochs // 2], gamma=0.1, verbose=True)\n",
        "\n",
        "    history = training_loop(model, optimizer, train_dataloader,monophonic, epochs=epochs, val_dataloader=val_dataloader, device=device, scheduler=scheduler)\n",
        "\n",
        "    return model, history"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG_ONds0bkt-"
      },
      "source": [
        "def training_loop(model,optimizer, train_dataloader, monophonic, epochs=50, val_dataloader=None, device=None, scheduler=None):\n",
        "    if device is None:\n",
        "        device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "        print(f\"Training on device: {device}\")\n",
        "\n",
        "    print(\"monophonic set to:\",monophonic)\n",
        "    model = model.to(device)\n",
        "    history = defaultdict(list)\n",
        "\n",
        "    for i_epoch in range(1, epochs + 1):\n",
        "        loss_sum = 0\n",
        "\n",
        "        accuracy_sum_list = [0 for i in range(5)]                                   ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "        val_accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "\n",
        "        accuracy_v_all_sum = 0\n",
        "        model.train()\n",
        "        accuracy_sum = 0\n",
        "        \n",
        "        \n",
        "        for idx, (voices, lens, nbr_voices, _) in enumerate(train_dataloader):  \n",
        "            \n",
        "            voices = voices.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            loss = model.forward(voices, lens, nbr_voices)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()    \n",
        "\n",
        "            if monophonic == False:\n",
        "                with torch.no_grad():\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                    mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                    \n",
        "                    single_voices = voices[:,:,:,:-1]             \n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "\n",
        "            if monophonic == True:\n",
        "                with torch.no_grad():\n",
        "                    ### before\n",
        "                    #prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                    #prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "                    #truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "                    #acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "                    #for i in range(len(prediction[0,:])):\n",
        "                    #  acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                    #  accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "\n",
        "                    #prediction = model.predict(voices, lens, monophonic)                    #for voice vise masking\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)         #for mixed voice masking        \n",
        "\n",
        "\n",
        "                    ## ground truth in shape 1280x88 -> mixed voice\n",
        "                    single_voices = voices[:,:,:,:-1]\n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    truth = v_ori_argm       \n",
        "\n",
        "                    # outsource accurcy to further down -> just a placeholder right now\n",
        "                    v_pred_flat = torch.flatten(prediction, start_dim=0, end_dim=-1)\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "\n",
        "\n",
        "        train_loss = loss_sum / len(train_dataloader)\n",
        "\n",
        "        # normalize according to the number of batches\n",
        "        if monophonic == True:\n",
        "\n",
        "            #train_acc_list = np.array(accuracy_sum_list) / len(train_dataloader)\n",
        "            #train_acc_list[3] = accuracy_sum_list[3] / 18                        ## bc only 18 pieces with len 3\n",
        "            #train_acc_list[4] = accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "            #history[\"train_loss\"].append(train_loss)\n",
        "            #history[\"train_acc\"].append(train_acc_list)\n",
        "            #print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}, Train Accuracy_4 : {}\".format(train_loss, train_acc_list[0], train_acc_list[1], train_acc_list[2], train_acc_list[3],train_acc_list[4])) \n",
        "            \n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "        if monophonic == False:\n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "\n",
        "        if monophonic == True:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for voices, lens, nbr_voices, _ in val_dataloader:\n",
        "                        voices = voices.to(device).float()\n",
        "                        ### before\n",
        "                        #prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        #prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "                        #truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "                        #acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "                        #for i in range(len(prediction[0,:])):\n",
        "                        #  acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                        #  val_accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "                    #val_acc_list = np.array(val_accuracy_sum_list) / len(val_dataloader)\n",
        "                    #val_acc_list[3] = val_accuracy_sum_list[3] / 18                         ## bc only 18 pieces with len 3\n",
        "                    #val_acc_list[4] = val_accuracy_sum_list[4] / 2                          ##### CHECK IF 2 or 3 pieces with len 4\n",
        "                #history[\"val_acc\"].append(val_acc_list)\n",
        "                #print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "\n",
        "                        #prediction = model.predict(voices, lens, monophonic)                #for voice vise masking\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)     # for masking with mixed voice\n",
        "\n",
        "\n",
        "\n",
        "                        ## ground truth in shape 1280x88 -> mixed voice\n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        truth = v_ori_argm       \n",
        "\n",
        "                        # outsource accurcy to further down -> just a placeholder right now\n",
        "                        v_pred_flat = torch.flatten(prediction, start_dim=0, end_dim=-1)\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "                    \n",
        "                history[\"val_acc\"].append(val_accuracy)\n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "\n",
        "        if monophonic == False:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_sum = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    for voices, lens, nbr_voices, _ in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "                        \n",
        "                        # Predict the model's output on a batch\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                        v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                        mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                        \n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "                        \n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "\n",
        "                history[\"val_accuracy\"].append(val_accuracy)  \n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "        \n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "    # save the model\n",
        "    #torch.save(model, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "    torch.save({'model_state_dict': model.state_dict()}, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "\n",
        "    return history"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= \"RNN\"\n",
        "monophonic = True\n",
        "his = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ge8pY70uHxF9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fce0ceb5-137e-43da-dce7-dd6358ffae5d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= \"RNN\"\\nmonophonic = True\\nhis = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= [\"CNN\",\"RNN\"]\n",
        "monophonic_list = [True,False]\n",
        "\n",
        "for net in network_type:\n",
        "    for monophonic in monophonic_list: \n",
        "        print(\"network set to:\",net,\"monophnic:\",monophonic)\n",
        "        start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, net, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2Bs6-iNEBu8o",
        "outputId": "50f8e2d8-35eb-40b3-9c2d-eaf87dfab127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= [\"CNN\",\"RNN\"]\\nmonophonic_list = [True,False]\\n\\nfor net in network_type:\\n    for monophonic in monophonic_list: \\n        print(\"network set to:\",net,\"monophnic:\",monophonic)\\n        start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, net, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sBoQnA6bo71"
      },
      "source": [
        "def start_experiment( epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell, decay,network_type, learn_all):\n",
        "    \n",
        "    trainer = partial(train,epochs, lr, hidden_dim, momentum, rnn_depth, device, cell, decay, network_type)\n",
        "\n",
        "    if learn_all == True:\n",
        "        print(\"Learning from full dataset\")\n",
        "        ### uncomment for fugues ###\n",
        "        #train_dataset = MusicDataset_new(PATH_TO_DATA) \n",
        "        ### uncomment for chorals ###\n",
        "        train_dataset = MusicDataset_chor(PATH_TO_DATA) \n",
        "\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "                \n",
        "        _, history = trainer(train_dataloader)\n",
        "\n",
        "    \n",
        "    else:\n",
        "        # Divide train and validation set\n",
        "        ### uncomment for fugues ###\n",
        "        #dataset = MusicDataset_new(PATH_TO_DATA) \n",
        "        ### uncomment for chorals ###\n",
        "        dataset = MusicDataset_chor(PATH_TO_DATA)\n",
        "        \n",
        "        \n",
        "        train_dataset, validation_dataset = sklearn.model_selection.train_test_split(dataset, test_size=0.15, random_state=10,)\n",
        "\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "        val_dataloader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "\n",
        "        print(\"train_dataloader\",len(train_dataloader),\"val_dataloader\",len(val_dataloader))\n",
        "\n",
        "        \"\"\"\n",
        "        path_train, path_validation = sklearn.model_selection.train_test_split(PATH_TO_DATA, test_size=0.15, random_state=10,)\n",
        "\n",
        "        print(\"Train and validation lenghts: \", len(path_train), len(path_validation))\n",
        "        #train_dataset = MusicDataset_new(PATH_TO_DATA) #MusicDataset(PATH_TO_DATA)\n",
        "        train_dataset = MusicDataset_new(path_train)\n",
        "        validation_dataset = MusicDataset_new(path_validation) #MusicDataset(path_validation)\n",
        "\n",
        "        \n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "        val_dataloader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "        \"\"\"\n",
        "        \n",
        "        _, history = trainer(train_dataloader, val_dataloader)\n",
        "\n",
        "    return history, val_dataloader"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgtn-a7bMTf7"
      },
      "source": [
        "# Hyperparameter choice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNI9b6jKLpOX"
      },
      "source": [
        "model = MusicNetwork\n",
        "epochs = 5\n",
        "lr = 0.00001 # was 0.001\n",
        "momentum = 0.9\n",
        "decay = 1e-4\n",
        "hidden_dim = 300\n",
        "bs = 1\n",
        "rnn_depth = 2 \n",
        "device = None                 #if None:  choses device automatically\n",
        "cell_type = \"GRU\"\n",
        "optimizer = \"Adam\"\n",
        "learn_all = \"False\"           # False -> uses train and valid set\n",
        "network_type= \"CNN\"\n",
        "\n",
        "monophonic = True"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the Experiment"
      ],
      "metadata": {
        "id": "bdetlQP-LoRX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1LTlFJddpwm",
        "outputId": "2974984d-95d2-4bb2-90a4-14e128885ea5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "his, val_dataloader = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "self.loss(score_0, v2) 0.19183777\n",
            "self.loss(score_2, v3) 0.0734436\n",
            "loss tensor(0.7566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12495957\n",
            "self.loss(score_0, v1) 0.18491904\n",
            "self.loss(score_0, v2) 0.17496087\n",
            "self.loss(score_2, v3) 0.050262097\n",
            "loss tensor(0.5602, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08888954\n",
            "self.loss(score_0, v1) 0.14074372\n",
            "self.loss(score_0, v2) 0.13115871\n",
            "self.loss(score_2, v3) 0.054375887\n",
            "loss tensor(0.4424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2671977\n",
            "self.loss(score_0, v1) 0.2517163\n",
            "self.loss(score_0, v2) 0.16061781\n",
            "self.loss(score_2, v3) 0.05324289\n",
            "loss tensor(0.7594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09286711\n",
            "self.loss(score_0, v1) 0.31135684\n",
            "self.loss(score_0, v2) 0.27455378\n",
            "self.loss(score_2, v3) 0.051433846\n",
            "loss tensor(0.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14479534\n",
            "self.loss(score_0, v1) 0.15263617\n",
            "self.loss(score_0, v2) 0.10572469\n",
            "self.loss(score_2, v3) 0.06092192\n",
            "loss tensor(0.4945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11241635\n",
            "self.loss(score_0, v1) 0.19456913\n",
            "self.loss(score_0, v2) 0.13138531\n",
            "self.loss(score_2, v3) 0.062791504\n",
            "loss tensor(0.5326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14703356\n",
            "self.loss(score_0, v1) 0.28216806\n",
            "self.loss(score_0, v2) 0.27634037\n",
            "self.loss(score_2, v3) 0.07054746\n",
            "loss tensor(0.8114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16920568\n",
            "self.loss(score_0, v1) 0.27711636\n",
            "self.loss(score_0, v2) 0.19988279\n",
            "self.loss(score_2, v3) 0.06268828\n",
            "loss tensor(0.7402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19645783\n",
            "self.loss(score_0, v1) 0.18750082\n",
            "self.loss(score_0, v2) 0.11429861\n",
            "self.loss(score_2, v3) 0.04576006\n",
            "loss tensor(0.5669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1176879\n",
            "self.loss(score_0, v1) 0.1532184\n",
            "self.loss(score_0, v2) 0.17153336\n",
            "self.loss(score_2, v3) 0.057369027\n",
            "loss tensor(0.5285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09470942\n",
            "self.loss(score_0, v1) 0.11110974\n",
            "self.loss(score_0, v2) 0.110865\n",
            "self.loss(score_2, v3) 0.05213363\n",
            "loss tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073445976\n",
            "self.loss(score_0, v1) 0.10421513\n",
            "self.loss(score_0, v2) 0.15134482\n",
            "self.loss(score_2, v3) 0.042885873\n",
            "loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14496407\n",
            "self.loss(score_0, v1) 0.35907283\n",
            "self.loss(score_0, v2) 0.355565\n",
            "self.loss(score_2, v3) 0.060043294\n",
            "loss tensor(0.9497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.101276286\n",
            "self.loss(score_0, v1) 0.43301982\n",
            "self.loss(score_0, v2) 0.40632144\n",
            "self.loss(score_2, v3) 0.07222081\n",
            "loss tensor(1.0489, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10539747\n",
            "self.loss(score_0, v1) 0.12242232\n",
            "self.loss(score_0, v2) 0.098924436\n",
            "self.loss(score_2, v3) 0.048165098\n",
            "loss tensor(0.3990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.104311235\n",
            "self.loss(score_0, v1) 0.2791797\n",
            "self.loss(score_0, v2) 0.31564847\n",
            "self.loss(score_2, v3) 0.044689514\n",
            "loss tensor(0.7662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19082105\n",
            "self.loss(score_0, v1) 0.23079762\n",
            "self.loss(score_0, v2) 0.17284375\n",
            "self.loss(score_2, v3) 0.24303597\n",
            "loss tensor(0.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08161368\n",
            "self.loss(score_0, v1) 0.11826337\n",
            "self.loss(score_0, v2) 0.18342954\n",
            "self.loss(score_2, v3) 0.056515444\n",
            "loss tensor(0.4681, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.20606764\n",
            "self.loss(score_0, v1) 0.23847464\n",
            "self.loss(score_0, v2) 0.14781968\n",
            "self.loss(score_2, v3) 0.069498144\n",
            "loss tensor(0.6966, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13635197\n",
            "self.loss(score_0, v1) 0.17677538\n",
            "self.loss(score_0, v2) 0.10305714\n",
            "self.loss(score_2, v3) 0.055812426\n",
            "loss tensor(0.4999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16009225\n",
            "self.loss(score_0, v1) 0.20131952\n",
            "self.loss(score_0, v2) 0.12556012\n",
            "self.loss(score_2, v3) 0.05599295\n",
            "loss tensor(0.5710, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08941237\n",
            "self.loss(score_0, v1) 0.086576\n",
            "self.loss(score_0, v2) 0.06887416\n",
            "self.loss(score_2, v3) 0.034413513\n",
            "loss tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.092933856\n",
            "self.loss(score_0, v1) 0.13773611\n",
            "self.loss(score_0, v2) 0.1862856\n",
            "self.loss(score_2, v3) 0.049697764\n",
            "loss tensor(0.4915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077571414\n",
            "self.loss(score_0, v1) 0.10555752\n",
            "self.loss(score_0, v2) 0.093732245\n",
            "self.loss(score_2, v3) 0.050305888\n",
            "loss tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0704616\n",
            "self.loss(score_0, v1) 0.54656994\n",
            "self.loss(score_0, v2) 0.4778747\n",
            "self.loss(score_2, v3) 0.050303236\n",
            "loss tensor(1.1704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.090685226\n",
            "self.loss(score_0, v1) 0.110190734\n",
            "self.loss(score_0, v2) 0.16582973\n",
            "self.loss(score_2, v3) 0.056632537\n",
            "loss tensor(0.4517, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.20470391\n",
            "self.loss(score_0, v1) 0.22562899\n",
            "self.loss(score_0, v2) 0.09943078\n",
            "self.loss(score_2, v3) 0.054007437\n",
            "loss tensor(0.6108, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1258313\n",
            "self.loss(score_0, v1) 0.14603949\n",
            "self.loss(score_0, v2) 0.101290226\n",
            "self.loss(score_2, v3) 0.070260085\n",
            "loss tensor(0.4786, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10003346\n",
            "self.loss(score_0, v1) 0.15021712\n",
            "self.loss(score_0, v2) 0.29830343\n",
            "self.loss(score_2, v3) 0.2578658\n",
            "loss tensor(0.9354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0918867\n",
            "self.loss(score_0, v1) 0.14089824\n",
            "self.loss(score_0, v2) 0.117420755\n",
            "self.loss(score_2, v3) 0.064583\n",
            "loss tensor(0.4471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07669579\n",
            "self.loss(score_0, v1) 0.10377476\n",
            "self.loss(score_0, v2) 0.0886082\n",
            "self.loss(score_2, v3) 0.055694852\n",
            "loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13122964\n",
            "self.loss(score_0, v1) 0.15127869\n",
            "self.loss(score_0, v2) 0.09596868\n",
            "self.loss(score_2, v3) 0.050884213\n",
            "loss tensor(0.4548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08740458\n",
            "self.loss(score_0, v1) 0.11805244\n",
            "self.loss(score_0, v2) 0.10455034\n",
            "self.loss(score_2, v3) 0.04829648\n",
            "loss tensor(0.3825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.078180954\n",
            "self.loss(score_0, v1) 0.22999284\n",
            "self.loss(score_0, v2) 0.21989425\n",
            "self.loss(score_2, v3) 0.074504875\n",
            "loss tensor(0.6398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.085876405\n",
            "self.loss(score_0, v1) 0.14776382\n",
            "self.loss(score_0, v2) 0.14934349\n",
            "self.loss(score_2, v3) 0.046764605\n",
            "loss tensor(0.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06884942\n",
            "self.loss(score_0, v1) 0.14386962\n",
            "self.loss(score_0, v2) 0.12364869\n",
            "self.loss(score_2, v3) 0.03793741\n",
            "loss tensor(0.3933, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.112027094\n",
            "self.loss(score_0, v1) 0.35048494\n",
            "self.loss(score_0, v2) 0.29391435\n",
            "self.loss(score_2, v3) 0.057429057\n",
            "loss tensor(0.8426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16109022\n",
            "self.loss(score_0, v1) 0.24793334\n",
            "self.loss(score_0, v2) 0.1497581\n",
            "self.loss(score_2, v3) 0.065246135\n",
            "loss tensor(0.6567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08320105\n",
            "self.loss(score_0, v1) 0.15492892\n",
            "self.loss(score_0, v2) 0.21970765\n",
            "self.loss(score_2, v3) 0.11567829\n",
            "loss tensor(0.6314, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10933513\n",
            "self.loss(score_0, v1) 0.104334496\n",
            "self.loss(score_0, v2) 0.17186466\n",
            "self.loss(score_2, v3) 0.05443681\n",
            "loss tensor(0.4672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.106971666\n",
            "self.loss(score_0, v1) 0.13109513\n",
            "self.loss(score_0, v2) 0.08990888\n",
            "self.loss(score_2, v3) 0.049585562\n",
            "loss tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1150528\n",
            "self.loss(score_0, v1) 0.19169733\n",
            "self.loss(score_0, v2) 0.20306872\n",
            "self.loss(score_2, v3) 0.046332616\n",
            "loss tensor(0.5793, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3123018\n",
            "self.loss(score_0, v1) 0.6440347\n",
            "self.loss(score_0, v2) 0.47883594\n",
            "self.loss(score_2, v3) 0.030212281\n",
            "loss tensor(1.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14974466\n",
            "self.loss(score_0, v1) 0.17018667\n",
            "self.loss(score_0, v2) 0.082833774\n",
            "self.loss(score_2, v3) 0.038821463\n",
            "loss tensor(0.4610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13988395\n",
            "self.loss(score_0, v1) 0.27786365\n",
            "self.loss(score_0, v2) 0.27883103\n",
            "self.loss(score_2, v3) 0.04549416\n",
            "loss tensor(0.7648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.047073\n",
            "self.loss(score_0, v1) 0.21852177\n",
            "self.loss(score_0, v2) 0.23930308\n",
            "self.loss(score_2, v3) 0.032151964\n",
            "loss tensor(0.5531, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.107908055\n",
            "self.loss(score_0, v1) 0.18616834\n",
            "self.loss(score_0, v2) 0.17389825\n",
            "self.loss(score_2, v3) 0.051640954\n",
            "loss tensor(0.5454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09160551\n",
            "self.loss(score_0, v1) 0.15305239\n",
            "self.loss(score_0, v2) 0.14429553\n",
            "self.loss(score_2, v3) 0.057293065\n",
            "loss tensor(0.4749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06301096\n",
            "self.loss(score_0, v1) 0.16209942\n",
            "self.loss(score_0, v2) 0.11727336\n",
            "self.loss(score_2, v3) 0.04155128\n",
            "loss tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09188195\n",
            "self.loss(score_0, v1) 0.14028265\n",
            "self.loss(score_0, v2) 0.11526152\n",
            "self.loss(score_2, v3) 0.048512693\n",
            "loss tensor(0.4202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.096383736\n",
            "self.loss(score_0, v1) 0.15727243\n",
            "self.loss(score_0, v2) 0.18739282\n",
            "self.loss(score_2, v3) 0.041635342\n",
            "loss tensor(0.5035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0770551\n",
            "self.loss(score_0, v1) 0.106211625\n",
            "self.loss(score_0, v2) 0.11808807\n",
            "self.loss(score_2, v3) 0.06230296\n",
            "loss tensor(0.3948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.101018734\n",
            "self.loss(score_0, v1) 0.1270877\n",
            "self.loss(score_0, v2) 0.12426088\n",
            "self.loss(score_2, v3) 0.04746999\n",
            "loss tensor(0.4236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077386975\n",
            "self.loss(score_0, v1) 0.09835607\n",
            "self.loss(score_0, v2) 0.13697079\n",
            "self.loss(score_2, v3) 0.057574872\n",
            "loss tensor(0.3991, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10720616\n",
            "self.loss(score_0, v1) 0.27048123\n",
            "self.loss(score_0, v2) 0.24826586\n",
            "self.loss(score_2, v3) 0.055414204\n",
            "loss tensor(0.7091, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 0.9909874475116183, Train Accuracy : 0.9987018733549683\n",
            " Validation Accuracy : 6.59881204954888\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.06657774\n",
            "self.loss(score_0, v1) 0.1713046\n",
            "self.loss(score_0, v2) 0.3054708\n",
            "self.loss(score_2, v3) 0.07376511\n",
            "loss tensor(0.6540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.063588575\n",
            "self.loss(score_0, v1) 0.09723635\n",
            "self.loss(score_0, v2) 0.18270217\n",
            "self.loss(score_2, v3) 0.09755263\n",
            "loss tensor(0.4899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.26778275\n",
            "self.loss(score_0, v1) 0.31617776\n",
            "self.loss(score_0, v2) 0.17289808\n",
            "self.loss(score_2, v3) 0.03829672\n",
            "loss tensor(0.8143, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18088639\n",
            "self.loss(score_0, v1) 0.27673212\n",
            "self.loss(score_0, v2) 0.17529102\n",
            "self.loss(score_2, v3) 0.05162951\n",
            "loss tensor(0.7104, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.078416206\n",
            "self.loss(score_0, v1) 0.22318825\n",
            "self.loss(score_0, v2) 0.24536121\n",
            "self.loss(score_2, v3) 0.036754098\n",
            "loss tensor(0.6021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07179251\n",
            "self.loss(score_0, v1) 0.0935488\n",
            "self.loss(score_0, v2) 0.07900998\n",
            "self.loss(score_2, v3) 0.04081025\n",
            "loss tensor(0.3056, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0688412\n",
            "self.loss(score_0, v1) 0.089553915\n",
            "self.loss(score_0, v2) 0.0803614\n",
            "self.loss(score_2, v3) 0.042206187\n",
            "loss tensor(0.3021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09377022\n",
            "self.loss(score_0, v1) 0.10224167\n",
            "self.loss(score_0, v2) 0.068416946\n",
            "self.loss(score_2, v3) 0.034379553\n",
            "loss tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08419335\n",
            "self.loss(score_0, v1) 0.11046815\n",
            "self.loss(score_0, v2) 0.12040424\n",
            "self.loss(score_2, v3) 0.04690372\n",
            "loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075038455\n",
            "self.loss(score_0, v1) 0.09672006\n",
            "self.loss(score_0, v2) 0.13565682\n",
            "self.loss(score_2, v3) 0.059641473\n",
            "loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12348644\n",
            "self.loss(score_0, v1) 0.42794105\n",
            "self.loss(score_0, v2) 0.31887937\n",
            "self.loss(score_2, v3) 0.048895225\n",
            "loss tensor(0.9436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.091196984\n",
            "self.loss(score_0, v1) 0.12553139\n",
            "self.loss(score_0, v2) 0.12117597\n",
            "self.loss(score_2, v3) 0.04198689\n",
            "loss tensor(0.4009, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09966266\n",
            "self.loss(score_0, v1) 0.1954363\n",
            "self.loss(score_0, v2) 0.18009648\n",
            "self.loss(score_2, v3) 0.041544452\n",
            "loss tensor(0.5375, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13569859\n",
            "self.loss(score_0, v1) 0.1719826\n",
            "self.loss(score_0, v2) 0.19460745\n",
            "self.loss(score_2, v3) 0.043946985\n",
            "loss tensor(0.5682, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07338058\n",
            "self.loss(score_0, v1) 0.10548002\n",
            "self.loss(score_0, v2) 0.11686464\n",
            "self.loss(score_2, v3) 0.038407963\n",
            "loss tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23353879\n",
            "self.loss(score_0, v1) 0.22852264\n",
            "self.loss(score_0, v2) 0.09748241\n",
            "self.loss(score_2, v3) 0.06121483\n",
            "loss tensor(0.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.097880006\n",
            "self.loss(score_0, v1) 0.13808985\n",
            "self.loss(score_0, v2) 0.09983352\n",
            "self.loss(score_2, v3) 0.046484537\n",
            "loss tensor(0.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08143533\n",
            "self.loss(score_0, v1) 0.13413773\n",
            "self.loss(score_0, v2) 0.115070835\n",
            "self.loss(score_2, v3) 0.044251185\n",
            "loss tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.36298925\n",
            "self.loss(score_0, v1) 0.38971028\n",
            "self.loss(score_0, v2) 0.2669155\n",
            "self.loss(score_2, v3) 0.056920644\n",
            "loss tensor(1.1050, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.104781725\n",
            "self.loss(score_0, v1) 0.17058717\n",
            "self.loss(score_0, v2) 0.20354755\n",
            "self.loss(score_2, v3) 0.054313198\n",
            "loss tensor(0.5604, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09836925\n",
            "self.loss(score_0, v1) 0.13382363\n",
            "self.loss(score_0, v2) 0.11302896\n",
            "self.loss(score_2, v3) 0.046910178\n",
            "loss tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15098807\n",
            "self.loss(score_0, v1) 0.15991618\n",
            "self.loss(score_0, v2) 0.09168905\n",
            "self.loss(score_2, v3) 0.05421759\n",
            "loss tensor(0.4839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0662423\n",
            "self.loss(score_0, v1) 0.09831005\n",
            "self.loss(score_0, v2) 0.19356662\n",
            "self.loss(score_2, v3) 0.048163466\n",
            "loss tensor(0.4304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06290763\n",
            "self.loss(score_0, v1) 0.08551517\n",
            "self.loss(score_0, v2) 0.09720121\n",
            "self.loss(score_2, v3) 0.03596339\n",
            "loss tensor(0.2996, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07520868\n",
            "self.loss(score_0, v1) 0.09478796\n",
            "self.loss(score_0, v2) 0.08636918\n",
            "self.loss(score_2, v3) 0.039185487\n",
            "loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07941696\n",
            "self.loss(score_0, v1) 0.120868504\n",
            "self.loss(score_0, v2) 0.118402585\n",
            "self.loss(score_2, v3) 0.05389091\n",
            "loss tensor(0.3995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.100629926\n",
            "self.loss(score_0, v1) 0.16052516\n",
            "self.loss(score_0, v2) 0.11963448\n",
            "self.loss(score_2, v3) 0.046285365\n",
            "loss tensor(0.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07187569\n",
            "self.loss(score_0, v1) 0.110245526\n",
            "self.loss(score_0, v2) 0.107402876\n",
            "self.loss(score_2, v3) 0.05400958\n",
            "loss tensor(0.3705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09854715\n",
            "self.loss(score_0, v1) 0.25031388\n",
            "self.loss(score_0, v2) 0.24943805\n",
            "self.loss(score_2, v3) 0.05959281\n",
            "loss tensor(0.6877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07406502\n",
            "self.loss(score_0, v1) 0.09552847\n",
            "self.loss(score_0, v2) 0.117243335\n",
            "self.loss(score_2, v3) 0.047703583\n",
            "loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09061382\n",
            "self.loss(score_0, v1) 0.3419263\n",
            "self.loss(score_0, v2) 0.26310387\n",
            "self.loss(score_2, v3) 0.043468546\n",
            "loss tensor(0.7608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08368111\n",
            "self.loss(score_0, v1) 0.10291672\n",
            "self.loss(score_0, v2) 0.07269257\n",
            "self.loss(score_2, v3) 0.045543976\n",
            "loss tensor(0.3276, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.4299084\n",
            "self.loss(score_0, v1) 0.56117123\n",
            "self.loss(score_0, v2) 0.6855631\n",
            "self.loss(score_2, v3) 0.9648507\n",
            "loss tensor(3.1239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09730403\n",
            "self.loss(score_0, v1) 0.097122185\n",
            "self.loss(score_0, v2) 0.08834768\n",
            "self.loss(score_2, v3) 0.049207132\n",
            "loss tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0774402\n",
            "self.loss(score_0, v1) 0.11654471\n",
            "self.loss(score_0, v2) 0.13046585\n",
            "self.loss(score_2, v3) 0.05070185\n",
            "loss tensor(0.4005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07945582\n",
            "self.loss(score_0, v1) 0.13330024\n",
            "self.loss(score_0, v2) 0.10650427\n",
            "self.loss(score_2, v3) 0.05410512\n",
            "loss tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07320584\n",
            "self.loss(score_0, v1) 0.11204235\n",
            "self.loss(score_0, v2) 0.09759632\n",
            "self.loss(score_2, v3) 0.05678928\n",
            "loss tensor(0.3680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0802591\n",
            "self.loss(score_0, v1) 0.17178975\n",
            "self.loss(score_0, v2) 0.19324906\n",
            "self.loss(score_2, v3) 0.053459402\n",
            "loss tensor(0.5255, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15458935\n",
            "self.loss(score_0, v1) 0.19779235\n",
            "self.loss(score_0, v2) 0.09457124\n",
            "self.loss(score_2, v3) 0.0552201\n",
            "loss tensor(0.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08292658\n",
            "self.loss(score_0, v1) 0.14767827\n",
            "self.loss(score_0, v2) 0.23089187\n",
            "self.loss(score_2, v3) 0.19269201\n",
            "loss tensor(0.7505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16051184\n",
            "self.loss(score_0, v1) 0.17707883\n",
            "self.loss(score_0, v2) 0.05825391\n",
            "self.loss(score_2, v3) 0.03252508\n",
            "loss tensor(0.4446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.27931425\n",
            "self.loss(score_0, v1) 0.6033267\n",
            "self.loss(score_0, v2) 0.39099368\n",
            "self.loss(score_2, v3) 0.040852062\n",
            "loss tensor(1.3349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08598481\n",
            "self.loss(score_0, v1) 0.13841772\n",
            "self.loss(score_0, v2) 0.11499552\n",
            "self.loss(score_2, v3) 0.057363622\n",
            "loss tensor(0.4254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.064564876\n",
            "self.loss(score_0, v1) 0.08913887\n",
            "self.loss(score_0, v2) 0.10161701\n",
            "self.loss(score_2, v3) 0.043094553\n",
            "loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08366117\n",
            "self.loss(score_0, v1) 0.10300176\n",
            "self.loss(score_0, v2) 0.12007075\n",
            "self.loss(score_2, v3) 0.049470734\n",
            "loss tensor(0.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.078197144\n",
            "self.loss(score_0, v1) 0.11545228\n",
            "self.loss(score_0, v2) 0.09893557\n",
            "self.loss(score_2, v3) 0.04000559\n",
            "loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07073902\n",
            "self.loss(score_0, v1) 0.104814574\n",
            "self.loss(score_0, v2) 0.09024215\n",
            "self.loss(score_2, v3) 0.057459857\n",
            "loss tensor(0.3520, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08595854\n",
            "self.loss(score_0, v1) 0.24232918\n",
            "self.loss(score_0, v2) 0.24694657\n",
            "self.loss(score_2, v3) 0.044810325\n",
            "loss tensor(0.6424, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07093893\n",
            "self.loss(score_0, v1) 0.0685058\n",
            "self.loss(score_0, v2) 0.105456606\n",
            "self.loss(score_2, v3) 0.041715175\n",
            "loss tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09068546\n",
            "self.loss(score_0, v1) 0.14096367\n",
            "self.loss(score_0, v2) 0.16780195\n",
            "self.loss(score_2, v3) 0.056131266\n",
            "loss tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18091238\n",
            "self.loss(score_0, v1) 0.581514\n",
            "self.loss(score_0, v2) 0.4461848\n",
            "self.loss(score_2, v3) 0.05803021\n",
            "loss tensor(1.2957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.071143605\n",
            "self.loss(score_0, v1) 0.102231435\n",
            "self.loss(score_0, v2) 0.08320801\n",
            "self.loss(score_2, v3) 0.04503831\n",
            "loss tensor(0.3241, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13784492\n",
            "self.loss(score_0, v1) 0.23450279\n",
            "self.loss(score_0, v2) 0.39029175\n",
            "self.loss(score_2, v3) 0.21292487\n",
            "loss tensor(1.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10157605\n",
            "self.loss(score_0, v1) 0.10427447\n",
            "self.loss(score_0, v2) 0.101733424\n",
            "self.loss(score_2, v3) 0.05856306\n",
            "loss tensor(0.3954, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.412911\n",
            "self.loss(score_0, v1) 0.4006845\n",
            "self.loss(score_0, v2) 0.15774477\n",
            "self.loss(score_2, v3) 0.058568235\n",
            "loss tensor(1.0592, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09402067\n",
            "self.loss(score_0, v1) 0.14744261\n",
            "self.loss(score_0, v2) 0.1528491\n",
            "self.loss(score_2, v3) 0.052003402\n",
            "loss tensor(0.4723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13278979\n",
            "self.loss(score_0, v1) 0.18809135\n",
            "self.loss(score_0, v2) 0.12632583\n",
            "self.loss(score_2, v3) 0.055357333\n",
            "loss tensor(0.5302, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08185295\n",
            "self.loss(score_0, v1) 0.30987778\n",
            "self.loss(score_0, v2) 0.23939689\n",
            "self.loss(score_2, v3) 0.056320343\n",
            "loss tensor(0.7156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.089119\n",
            "self.loss(score_0, v1) 0.12359335\n",
            "self.loss(score_0, v2) 0.1050265\n",
            "self.loss(score_2, v3) 0.032613695\n",
            "loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07801948\n",
            "self.loss(score_0, v1) 0.09616557\n",
            "self.loss(score_0, v2) 0.07523092\n",
            "self.loss(score_2, v3) 0.04295969\n",
            "loss tensor(0.3139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060176786\n",
            "self.loss(score_0, v1) 0.23337534\n",
            "self.loss(score_0, v2) 0.15954216\n",
            "self.loss(score_2, v3) 0.024288533\n",
            "loss tensor(0.4895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12055969\n",
            "self.loss(score_0, v1) 0.26046997\n",
            "self.loss(score_0, v2) 0.15465656\n",
            "self.loss(score_2, v3) 0.05492298\n",
            "loss tensor(0.6181, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08415496\n",
            "self.loss(score_0, v1) 0.10156771\n",
            "self.loss(score_0, v2) 0.10061969\n",
            "self.loss(score_2, v3) 0.04645254\n",
            "loss tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.25439325\n",
            "self.loss(score_0, v1) 0.19660012\n",
            "self.loss(score_0, v2) 0.14138062\n",
            "self.loss(score_2, v3) 0.08578713\n",
            "loss tensor(0.7211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1306839\n",
            "self.loss(score_0, v1) 0.4036546\n",
            "self.loss(score_0, v2) 0.33735815\n",
            "self.loss(score_2, v3) 0.046051376\n",
            "loss tensor(0.9408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15788788\n",
            "self.loss(score_0, v1) 0.23615259\n",
            "self.loss(score_0, v2) 0.25114092\n",
            "self.loss(score_2, v3) 0.059648022\n",
            "loss tensor(0.7347, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08932375\n",
            "self.loss(score_0, v1) 0.16403937\n",
            "self.loss(score_0, v2) 0.19795212\n",
            "self.loss(score_2, v3) 0.05486846\n",
            "loss tensor(0.5336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07614256\n",
            "self.loss(score_0, v1) 0.08946893\n",
            "self.loss(score_0, v2) 0.13456629\n",
            "self.loss(score_2, v3) 0.04829778\n",
            "loss tensor(0.3726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1029164\n",
            "self.loss(score_0, v1) 0.1291714\n",
            "self.loss(score_0, v2) 0.08966701\n",
            "self.loss(score_2, v3) 0.040005956\n",
            "loss tensor(0.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.087783545\n",
            "self.loss(score_0, v1) 0.13881242\n",
            "self.loss(score_0, v2) 0.15824986\n",
            "self.loss(score_2, v3) 0.042494044\n",
            "loss tensor(0.4486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07235032\n",
            "self.loss(score_0, v1) 0.16690168\n",
            "self.loss(score_0, v2) 0.14048792\n",
            "self.loss(score_2, v3) 0.04085731\n",
            "loss tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.381724\n",
            "self.loss(score_0, v1) 0.8662082\n",
            "self.loss(score_0, v2) 0.47736254\n",
            "self.loss(score_2, v3) 0.03968325\n",
            "loss tensor(1.7848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10156445\n",
            "self.loss(score_0, v1) 0.17294115\n",
            "self.loss(score_0, v2) 0.13665831\n",
            "self.loss(score_2, v3) 0.051872097\n",
            "loss tensor(0.4890, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.083414584\n",
            "self.loss(score_0, v1) 0.48437133\n",
            "self.loss(score_0, v2) 0.46534225\n",
            "self.loss(score_2, v3) 0.08734875\n",
            "loss tensor(1.1642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06951833\n",
            "self.loss(score_0, v1) 0.0914143\n",
            "self.loss(score_0, v2) 0.10684418\n",
            "self.loss(score_2, v3) 0.040358942\n",
            "loss tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.064606175\n",
            "self.loss(score_0, v1) 0.07873359\n",
            "self.loss(score_0, v2) 0.089492306\n",
            "self.loss(score_2, v3) 0.036998283\n",
            "loss tensor(0.2883, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1008815\n",
            "self.loss(score_0, v1) 0.25036407\n",
            "self.loss(score_0, v2) 0.20962283\n",
            "self.loss(score_2, v3) 0.048634153\n",
            "loss tensor(0.6338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.084056534\n",
            "self.loss(score_0, v1) 0.11964091\n",
            "self.loss(score_0, v2) 0.0832191\n",
            "self.loss(score_2, v3) 0.04859573\n",
            "loss tensor(0.3598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.085005894\n",
            "self.loss(score_0, v1) 0.2118792\n",
            "self.loss(score_0, v2) 0.16892713\n",
            "self.loss(score_2, v3) 0.04501103\n",
            "loss tensor(0.5333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06258793\n",
            "self.loss(score_0, v1) 0.110257275\n",
            "self.loss(score_0, v2) 0.06985187\n",
            "self.loss(score_2, v3) 0.03328036\n",
            "loss tensor(0.2926, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11776842\n",
            "self.loss(score_0, v1) 0.29930565\n",
            "self.loss(score_0, v2) 0.2914008\n",
            "self.loss(score_2, v3) 0.03738582\n",
            "loss tensor(0.7646, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073052414\n",
            "self.loss(score_0, v1) 0.11375864\n",
            "self.loss(score_0, v2) 0.09056683\n",
            "self.loss(score_2, v3) 0.04807168\n",
            "loss tensor(0.3495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06753538\n",
            "self.loss(score_0, v1) 0.096241154\n",
            "self.loss(score_0, v2) 0.06839625\n",
            "self.loss(score_2, v3) 0.043008763\n",
            "loss tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08850256\n",
            "self.loss(score_0, v1) 0.13038164\n",
            "self.loss(score_0, v2) 0.1018699\n",
            "self.loss(score_2, v3) 0.04424081\n",
            "loss tensor(0.3871, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07410627\n",
            "self.loss(score_0, v1) 0.3543477\n",
            "self.loss(score_0, v2) 0.2844719\n",
            "self.loss(score_2, v3) 0.0368674\n",
            "loss tensor(0.7682, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08691987\n",
            "self.loss(score_0, v1) 0.13416038\n",
            "self.loss(score_0, v2) 0.13761409\n",
            "self.loss(score_2, v3) 0.05070394\n",
            "loss tensor(0.4348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08618257\n",
            "self.loss(score_0, v1) 0.38675457\n",
            "self.loss(score_0, v2) 0.3939856\n",
            "self.loss(score_2, v3) 0.2000026\n",
            "loss tensor(1.1669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09860307\n",
            "self.loss(score_0, v1) 0.1299683\n",
            "self.loss(score_0, v2) 0.12627085\n",
            "self.loss(score_2, v3) 0.037052482\n",
            "loss tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06274208\n",
            "self.loss(score_0, v1) 0.087602615\n",
            "self.loss(score_0, v2) 0.10706042\n",
            "self.loss(score_2, v3) 0.050416097\n",
            "loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06264248\n",
            "self.loss(score_0, v1) 0.18739527\n",
            "self.loss(score_0, v2) 0.19050555\n",
            "self.loss(score_2, v3) 0.044524815\n",
            "loss tensor(0.5073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14472197\n",
            "self.loss(score_0, v1) 0.19826211\n",
            "self.loss(score_0, v2) 0.1778623\n",
            "self.loss(score_2, v3) 0.039392006\n",
            "loss tensor(0.5799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11434833\n",
            "self.loss(score_0, v1) 0.13695706\n",
            "self.loss(score_0, v2) 0.13239764\n",
            "self.loss(score_2, v3) 0.050502487\n",
            "loss tensor(0.4595, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.101446584\n",
            "self.loss(score_0, v1) 0.17036077\n",
            "self.loss(score_0, v2) 0.13296142\n",
            "self.loss(score_2, v3) 0.05092171\n",
            "loss tensor(0.4812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08406226\n",
            "self.loss(score_0, v1) 0.20911793\n",
            "self.loss(score_0, v2) 0.32629693\n",
            "self.loss(score_2, v3) 0.0603479\n",
            "loss tensor(0.7100, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.091373734\n",
            "self.loss(score_0, v1) 0.114660464\n",
            "self.loss(score_0, v2) 0.10550528\n",
            "self.loss(score_2, v3) 0.039019007\n",
            "loss tensor(0.3701, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.35464108\n",
            "self.loss(score_0, v1) 0.33509484\n",
            "self.loss(score_0, v2) 0.096873686\n",
            "self.loss(score_2, v3) 0.04574951\n",
            "loss tensor(0.8552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09789315\n",
            "self.loss(score_0, v1) 0.24896714\n",
            "self.loss(score_0, v2) 0.20767905\n",
            "self.loss(score_2, v3) 0.053514924\n",
            "loss tensor(0.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07214095\n",
            "self.loss(score_0, v1) 0.092434675\n",
            "self.loss(score_0, v2) 0.07426309\n",
            "self.loss(score_2, v3) 0.042618483\n",
            "loss tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06766554\n",
            "self.loss(score_0, v1) 0.09972667\n",
            "self.loss(score_0, v2) 0.14523128\n",
            "self.loss(score_2, v3) 0.04191223\n",
            "loss tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10711565\n",
            "self.loss(score_0, v1) 0.29016575\n",
            "self.loss(score_0, v2) 0.36040318\n",
            "self.loss(score_2, v3) 0.06012262\n",
            "loss tensor(0.8479, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073852584\n",
            "self.loss(score_0, v1) 0.33020556\n",
            "self.loss(score_0, v2) 0.38983744\n",
            "self.loss(score_2, v3) 0.12266694\n",
            "loss tensor(0.9779, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22340623\n",
            "self.loss(score_0, v1) 0.3410256\n",
            "self.loss(score_0, v2) 0.21860774\n",
            "self.loss(score_2, v3) 0.074320786\n",
            "loss tensor(0.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12656154\n",
            "self.loss(score_0, v1) 0.15087211\n",
            "self.loss(score_0, v2) 0.116478525\n",
            "self.loss(score_2, v3) 0.03922712\n",
            "loss tensor(0.4528, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08821531\n",
            "self.loss(score_0, v1) 0.11645088\n",
            "self.loss(score_0, v2) 0.13035859\n",
            "self.loss(score_2, v3) 0.05343434\n",
            "loss tensor(0.4152, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05988492\n",
            "self.loss(score_0, v1) 0.071605004\n",
            "self.loss(score_0, v2) 0.070353575\n",
            "self.loss(score_2, v3) 0.036643036\n",
            "loss tensor(0.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0807972\n",
            "self.loss(score_0, v1) 0.18173014\n",
            "self.loss(score_0, v2) 0.22700955\n",
            "self.loss(score_2, v3) 0.0447652\n",
            "loss tensor(0.5567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16624096\n",
            "self.loss(score_0, v1) 0.5612627\n",
            "self.loss(score_0, v2) 0.3533183\n",
            "self.loss(score_2, v3) 0.054720916\n",
            "loss tensor(1.1629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08538906\n",
            "self.loss(score_0, v1) 0.13022763\n",
            "self.loss(score_0, v2) 0.097048774\n",
            "self.loss(score_2, v3) 0.04478509\n",
            "loss tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07932781\n",
            "self.loss(score_0, v1) 0.1308356\n",
            "self.loss(score_0, v2) 0.12935254\n",
            "self.loss(score_2, v3) 0.046277046\n",
            "loss tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0636254\n",
            "self.loss(score_0, v1) 0.40928236\n",
            "self.loss(score_0, v2) 1.1140109\n",
            "self.loss(score_2, v3) 0.8304617\n",
            "loss tensor(2.8326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.068621\n",
            "self.loss(score_0, v1) 0.102988884\n",
            "self.loss(score_0, v2) 0.10890803\n",
            "self.loss(score_2, v3) 0.055670943\n",
            "loss tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09198279\n",
            "self.loss(score_0, v1) 0.102185145\n",
            "self.loss(score_0, v2) 0.17516191\n",
            "self.loss(score_2, v3) 0.21427298\n",
            "loss tensor(0.6907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07889567\n",
            "self.loss(score_0, v1) 0.2538775\n",
            "self.loss(score_0, v2) 0.18850504\n",
            "self.loss(score_2, v3) 0.041545108\n",
            "loss tensor(0.5836, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.096042804\n",
            "self.loss(score_0, v1) 0.13666366\n",
            "self.loss(score_0, v2) 0.10589382\n",
            "self.loss(score_2, v3) 0.047462635\n",
            "loss tensor(0.4098, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10421078\n",
            "self.loss(score_0, v1) 0.17716604\n",
            "self.loss(score_0, v2) 0.17562583\n",
            "self.loss(score_2, v3) 0.05952052\n",
            "loss tensor(0.5463, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061245687\n",
            "self.loss(score_0, v1) 0.07591393\n",
            "self.loss(score_0, v2) 0.09696878\n",
            "self.loss(score_2, v3) 0.03991217\n",
            "loss tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09718639\n",
            "self.loss(score_0, v1) 0.23289473\n",
            "self.loss(score_0, v2) 0.20205836\n",
            "self.loss(score_2, v3) 0.049683567\n",
            "loss tensor(0.6067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0854619\n",
            "self.loss(score_0, v1) 0.115091816\n",
            "self.loss(score_0, v2) 0.08826179\n",
            "self.loss(score_2, v3) 0.044640247\n",
            "loss tensor(0.3558, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055637088\n",
            "self.loss(score_0, v1) 0.07650746\n",
            "self.loss(score_0, v2) 0.09377984\n",
            "self.loss(score_2, v3) 0.026496047\n",
            "loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05130052\n",
            "self.loss(score_0, v1) 0.094232686\n",
            "self.loss(score_0, v2) 0.053954754\n",
            "self.loss(score_2, v3) 0.025424246\n",
            "loss tensor(0.2376, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.42756972\n",
            "self.loss(score_0, v1) 0.3890943\n",
            "self.loss(score_0, v2) 0.20383294\n",
            "self.loss(score_2, v3) 0.12256898\n",
            "loss tensor(1.2044, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0581513\n",
            "self.loss(score_0, v1) 0.07983077\n",
            "self.loss(score_0, v2) 0.07185647\n",
            "self.loss(score_2, v3) 0.029069733\n",
            "loss tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.118722565\n",
            "self.loss(score_0, v1) 0.20323297\n",
            "self.loss(score_0, v2) 0.1301134\n",
            "self.loss(score_2, v3) 0.040778663\n",
            "loss tensor(0.5132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05128802\n",
            "self.loss(score_0, v1) 0.07131768\n",
            "self.loss(score_0, v2) 0.07045769\n",
            "self.loss(score_2, v3) 0.03240166\n",
            "loss tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06281591\n",
            "self.loss(score_0, v1) 0.091939606\n",
            "self.loss(score_0, v2) 0.14605112\n",
            "self.loss(score_2, v3) 0.04371611\n",
            "loss tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.102613695\n",
            "self.loss(score_0, v1) 0.16078387\n",
            "self.loss(score_0, v2) 0.16924591\n",
            "self.loss(score_2, v3) 0.05677533\n",
            "loss tensor(0.5178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09836243\n",
            "self.loss(score_0, v1) 0.15438329\n",
            "self.loss(score_0, v2) 0.19592588\n",
            "self.loss(score_2, v3) 0.04845458\n",
            "loss tensor(0.5214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09337279\n",
            "self.loss(score_0, v1) 0.1414479\n",
            "self.loss(score_0, v2) 0.15521708\n",
            "self.loss(score_2, v3) 0.060583316\n",
            "loss tensor(0.4809, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.108197056\n",
            "self.loss(score_0, v1) 0.09337118\n",
            "self.loss(score_0, v2) 0.09825179\n",
            "self.loss(score_2, v3) 0.041953493\n",
            "loss tensor(0.3628, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08121992\n",
            "self.loss(score_0, v1) 0.1042873\n",
            "self.loss(score_0, v2) 0.09136485\n",
            "self.loss(score_2, v3) 0.05483575\n",
            "loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073957115\n",
            "self.loss(score_0, v1) 0.106105104\n",
            "self.loss(score_0, v2) 0.20991972\n",
            "self.loss(score_2, v3) 0.20705529\n",
            "loss tensor(0.7006, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05489601\n",
            "self.loss(score_0, v1) 0.09615885\n",
            "self.loss(score_0, v2) 0.10663842\n",
            "self.loss(score_2, v3) 0.032182936\n",
            "loss tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.083120264\n",
            "self.loss(score_0, v1) 0.13311853\n",
            "self.loss(score_0, v2) 0.10547604\n",
            "self.loss(score_2, v3) 0.060956217\n",
            "loss tensor(0.4131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0722069\n",
            "self.loss(score_0, v1) 0.15186387\n",
            "self.loss(score_0, v2) 0.19786242\n",
            "self.loss(score_2, v3) 0.08970903\n",
            "loss tensor(0.5565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06494667\n",
            "self.loss(score_0, v1) 0.3801858\n",
            "self.loss(score_0, v2) 0.58324\n",
            "self.loss(score_2, v3) 0.19610007\n",
            "loss tensor(1.3225, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.103855364\n",
            "self.loss(score_0, v1) 0.16267422\n",
            "self.loss(score_0, v2) 0.12594241\n",
            "self.loss(score_2, v3) 0.08735409\n",
            "loss tensor(0.5235, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08741328\n",
            "self.loss(score_0, v1) 0.2781914\n",
            "self.loss(score_0, v2) 0.27932262\n",
            "self.loss(score_2, v3) 0.056983482\n",
            "loss tensor(0.7304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06912968\n",
            "self.loss(score_0, v1) 0.08740965\n",
            "self.loss(score_0, v2) 0.08855613\n",
            "self.loss(score_2, v3) 0.037563503\n",
            "loss tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07832871\n",
            "self.loss(score_0, v1) 0.1978256\n",
            "self.loss(score_0, v2) 0.244184\n",
            "self.loss(score_2, v3) 0.061101113\n",
            "loss tensor(0.6120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07291263\n",
            "self.loss(score_0, v1) 0.10722367\n",
            "self.loss(score_0, v2) 0.10053452\n",
            "self.loss(score_2, v3) 0.039400924\n",
            "loss tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.100335225\n",
            "self.loss(score_0, v1) 0.15112779\n",
            "self.loss(score_0, v2) 0.12611662\n",
            "self.loss(score_2, v3) 0.06074161\n",
            "loss tensor(0.4687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0719742\n",
            "self.loss(score_0, v1) 0.13833307\n",
            "self.loss(score_0, v2) 0.16546658\n",
            "self.loss(score_2, v3) 0.05065779\n",
            "loss tensor(0.4518, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09788382\n",
            "self.loss(score_0, v1) 0.12787344\n",
            "self.loss(score_0, v2) 0.09551074\n",
            "self.loss(score_2, v3) 0.046714555\n",
            "loss tensor(0.3913, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07643329\n",
            "self.loss(score_0, v1) 0.12427321\n",
            "self.loss(score_0, v2) 0.12429408\n",
            "self.loss(score_2, v3) 0.048274405\n",
            "loss tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.089812875\n",
            "self.loss(score_0, v1) 0.5553417\n",
            "self.loss(score_0, v2) 0.49477625\n",
            "self.loss(score_2, v3) 0.0630094\n",
            "loss tensor(1.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.076288074\n",
            "self.loss(score_0, v1) 0.109203294\n",
            "self.loss(score_0, v2) 0.120310366\n",
            "self.loss(score_2, v3) 0.043578267\n",
            "loss tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.070812\n",
            "self.loss(score_0, v1) 0.095961854\n",
            "self.loss(score_0, v2) 0.09680531\n",
            "self.loss(score_2, v3) 0.037197385\n",
            "loss tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10073895\n",
            "self.loss(score_0, v1) 0.30151647\n",
            "self.loss(score_0, v2) 0.24647582\n",
            "self.loss(score_2, v3) 0.05761496\n",
            "loss tensor(0.7352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12257929\n",
            "self.loss(score_0, v1) 0.15424947\n",
            "self.loss(score_0, v2) 0.085242294\n",
            "self.loss(score_2, v3) 0.052681424\n",
            "loss tensor(0.4411, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.112147965\n",
            "self.loss(score_0, v1) 0.12193024\n",
            "self.loss(score_0, v2) 0.12837662\n",
            "self.loss(score_2, v3) 0.04459886\n",
            "loss tensor(0.4294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.20684262\n",
            "self.loss(score_0, v1) 0.18500291\n",
            "self.loss(score_0, v2) 0.14402494\n",
            "self.loss(score_2, v3) 0.07750526\n",
            "loss tensor(0.6521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09728635\n",
            "self.loss(score_0, v1) 0.13892728\n",
            "self.loss(score_0, v2) 0.114752114\n",
            "self.loss(score_2, v3) 0.051017694\n",
            "loss tensor(0.4275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12985368\n",
            "self.loss(score_0, v1) 0.21709067\n",
            "self.loss(score_0, v2) 0.0906951\n",
            "self.loss(score_2, v3) 0.047269367\n",
            "loss tensor(0.5085, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09168059\n",
            "self.loss(score_0, v1) 0.30899286\n",
            "self.loss(score_0, v2) 0.23653221\n",
            "self.loss(score_2, v3) 0.0574571\n",
            "loss tensor(0.7234, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09787065\n",
            "self.loss(score_0, v1) 0.117278226\n",
            "self.loss(score_0, v2) 0.07817271\n",
            "self.loss(score_2, v3) 0.043384362\n",
            "loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.116253786\n",
            "self.loss(score_0, v1) 0.17020276\n",
            "self.loss(score_0, v2) 0.092719235\n",
            "self.loss(score_2, v3) 0.040804066\n",
            "loss tensor(0.4404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07347567\n",
            "self.loss(score_0, v1) 0.09916912\n",
            "self.loss(score_0, v2) 0.12637265\n",
            "self.loss(score_2, v3) 0.057569213\n",
            "loss tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09994542\n",
            "self.loss(score_0, v1) 0.3379816\n",
            "self.loss(score_0, v2) 0.3408557\n",
            "self.loss(score_2, v3) 0.038354263\n",
            "loss tensor(0.8363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05171276\n",
            "self.loss(score_0, v1) 0.09273718\n",
            "self.loss(score_0, v2) 0.10062705\n",
            "self.loss(score_2, v3) 0.03757739\n",
            "loss tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08372198\n",
            "self.loss(score_0, v1) 0.38802773\n",
            "self.loss(score_0, v2) 0.33426675\n",
            "self.loss(score_2, v3) 0.059118696\n",
            "loss tensor(0.8947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06041478\n",
            "self.loss(score_0, v1) 0.086080655\n",
            "self.loss(score_0, v2) 0.087434605\n",
            "self.loss(score_2, v3) 0.035258006\n",
            "loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.068071686\n",
            "self.loss(score_0, v1) 0.10971555\n",
            "self.loss(score_0, v2) 0.13051794\n",
            "self.loss(score_2, v3) 0.05267901\n",
            "loss tensor(0.3873, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.20430195\n",
            "self.loss(score_0, v1) 0.21200429\n",
            "self.loss(score_0, v2) 0.16683388\n",
            "self.loss(score_2, v3) 0.12916228\n",
            "loss tensor(0.7769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0602651\n",
            "self.loss(score_0, v1) 0.13687809\n",
            "self.loss(score_0, v2) 0.1613408\n",
            "self.loss(score_2, v3) 0.036992513\n",
            "loss tensor(0.4140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058438737\n",
            "self.loss(score_0, v1) 0.08167066\n",
            "self.loss(score_0, v2) 0.091767184\n",
            "self.loss(score_2, v3) 0.036586378\n",
            "loss tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09356273\n",
            "self.loss(score_0, v1) 0.1819523\n",
            "self.loss(score_0, v2) 0.16038045\n",
            "self.loss(score_2, v3) 0.053829137\n",
            "loss tensor(0.5166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11498299\n",
            "self.loss(score_0, v1) 0.62647766\n",
            "self.loss(score_0, v2) 0.5851334\n",
            "self.loss(score_2, v3) 0.04426761\n",
            "loss tensor(1.3930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.102830514\n",
            "self.loss(score_0, v1) 0.1275439\n",
            "self.loss(score_0, v2) 0.097310014\n",
            "self.loss(score_2, v3) 0.057286162\n",
            "loss tensor(0.4136, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.119044386\n",
            "self.loss(score_0, v1) 0.1643972\n",
            "self.loss(score_0, v2) 0.13954142\n",
            "self.loss(score_2, v3) 0.04751241\n",
            "loss tensor(0.4943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10095155\n",
            "self.loss(score_0, v1) 0.262871\n",
            "self.loss(score_0, v2) 0.2935936\n",
            "self.loss(score_2, v3) 0.12988943\n",
            "loss tensor(0.8523, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06597248\n",
            "self.loss(score_0, v1) 0.39192218\n",
            "self.loss(score_0, v2) 0.40719554\n",
            "self.loss(score_2, v3) 0.12005855\n",
            "loss tensor(1.0452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08227001\n",
            "self.loss(score_0, v1) 0.10639962\n",
            "self.loss(score_0, v2) 0.12254429\n",
            "self.loss(score_2, v3) 0.040631488\n",
            "loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03813335\n",
            "self.loss(score_0, v1) 0.06464417\n",
            "self.loss(score_0, v2) 0.122552134\n",
            "self.loss(score_2, v3) 0.022296328\n",
            "loss tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08478157\n",
            "self.loss(score_0, v1) 0.10553476\n",
            "self.loss(score_0, v2) 0.09171171\n",
            "self.loss(score_2, v3) 0.050424095\n",
            "loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.062307756\n",
            "self.loss(score_0, v1) 0.09456883\n",
            "self.loss(score_0, v2) 0.12574723\n",
            "self.loss(score_2, v3) 0.05613704\n",
            "loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0647798\n",
            "self.loss(score_0, v1) 0.07547578\n",
            "self.loss(score_0, v2) 0.067870215\n",
            "self.loss(score_2, v3) 0.041781407\n",
            "loss tensor(0.2708, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061889406\n",
            "self.loss(score_0, v1) 0.113961115\n",
            "self.loss(score_0, v2) 0.053997748\n",
            "self.loss(score_2, v3) 0.03033628\n",
            "loss tensor(0.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.087451085\n",
            "self.loss(score_0, v1) 0.110258\n",
            "self.loss(score_0, v2) 0.089602575\n",
            "self.loss(score_2, v3) 0.046896767\n",
            "loss tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14756581\n",
            "self.loss(score_0, v1) 0.16765857\n",
            "self.loss(score_0, v2) 0.09444679\n",
            "self.loss(score_2, v3) 0.052362084\n",
            "loss tensor(0.4882, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04867558\n",
            "self.loss(score_0, v1) 0.07129791\n",
            "self.loss(score_0, v2) 0.056425586\n",
            "self.loss(score_2, v3) 0.025691656\n",
            "loss tensor(0.2149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.079312\n",
            "self.loss(score_0, v1) 0.16099459\n",
            "self.loss(score_0, v2) 0.22790074\n",
            "self.loss(score_2, v3) 0.058570977\n",
            "loss tensor(0.5561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23752867\n",
            "self.loss(score_0, v1) 0.29357585\n",
            "self.loss(score_0, v2) 0.06897517\n",
            "self.loss(score_2, v3) 0.034232624\n",
            "loss tensor(0.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07076233\n",
            "self.loss(score_0, v1) 0.09596181\n",
            "self.loss(score_0, v2) 0.104266934\n",
            "self.loss(score_2, v3) 0.038697112\n",
            "loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07282012\n",
            "self.loss(score_0, v1) 0.09774118\n",
            "self.loss(score_0, v2) 0.09277161\n",
            "self.loss(score_2, v3) 0.05948575\n",
            "loss tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09719128\n",
            "self.loss(score_0, v1) 0.23291089\n",
            "self.loss(score_0, v2) 0.2560154\n",
            "self.loss(score_2, v3) 0.052575987\n",
            "loss tensor(0.6650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08052825\n",
            "self.loss(score_0, v1) 0.18171746\n",
            "self.loss(score_0, v2) 0.12228742\n",
            "self.loss(score_2, v3) 0.037965085\n",
            "loss tensor(0.4415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1160528\n",
            "self.loss(score_0, v1) 0.20271821\n",
            "self.loss(score_0, v2) 0.12674339\n",
            "self.loss(score_2, v3) 0.039359365\n",
            "loss tensor(0.5046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12820145\n",
            "self.loss(score_0, v1) 0.16858956\n",
            "self.loss(score_0, v2) 0.10235825\n",
            "self.loss(score_2, v3) 0.054879185\n",
            "loss tensor(0.4815, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04853223\n",
            "self.loss(score_0, v1) 0.14136505\n",
            "self.loss(score_0, v2) 0.20151533\n",
            "self.loss(score_2, v3) 0.024385959\n",
            "loss tensor(0.4280, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.095756605\n",
            "self.loss(score_0, v1) 0.10101558\n",
            "self.loss(score_0, v2) 0.07703704\n",
            "self.loss(score_2, v3) 0.039154563\n",
            "loss tensor(0.3325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06771662\n",
            "self.loss(score_0, v1) 0.1107055\n",
            "self.loss(score_0, v2) 0.15577781\n",
            "self.loss(score_2, v3) 0.04313923\n",
            "loss tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058960676\n",
            "self.loss(score_0, v1) 0.072692744\n",
            "self.loss(score_0, v2) 0.0671493\n",
            "self.loss(score_2, v3) 0.034874737\n",
            "loss tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23301509\n",
            "self.loss(score_0, v1) 0.25496092\n",
            "self.loss(score_0, v2) 0.09789349\n",
            "self.loss(score_2, v3) 0.046295233\n",
            "loss tensor(0.6553, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07305525\n",
            "self.loss(score_0, v1) 0.0701494\n",
            "self.loss(score_0, v2) 0.07078755\n",
            "self.loss(score_2, v3) 0.03952761\n",
            "loss tensor(0.2733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.072834365\n",
            "self.loss(score_0, v1) 0.17295603\n",
            "self.loss(score_0, v2) 0.18130137\n",
            "self.loss(score_2, v3) 0.05598835\n",
            "loss tensor(0.5111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09339487\n",
            "self.loss(score_0, v1) 0.24002954\n",
            "self.loss(score_0, v2) 0.6607518\n",
            "self.loss(score_2, v3) 0.6407521\n",
            "loss tensor(1.9553, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07201651\n",
            "self.loss(score_0, v1) 0.08334826\n",
            "self.loss(score_0, v2) 0.07552639\n",
            "self.loss(score_2, v3) 0.040217936\n",
            "loss tensor(0.2912, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23358631\n",
            "self.loss(score_0, v1) 0.30583635\n",
            "self.loss(score_0, v2) 0.20951083\n",
            "self.loss(score_2, v3) 0.04523215\n",
            "loss tensor(0.8168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09346776\n",
            "self.loss(score_0, v1) 0.25118518\n",
            "self.loss(score_0, v2) 0.23199138\n",
            "self.loss(score_2, v3) 0.037320256\n",
            "loss tensor(0.6326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.082986884\n",
            "self.loss(score_0, v1) 0.13473068\n",
            "self.loss(score_0, v2) 0.15879388\n",
            "self.loss(score_2, v3) 0.054589298\n",
            "loss tensor(0.4584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.102914564\n",
            "self.loss(score_0, v1) 0.10155477\n",
            "self.loss(score_0, v2) 0.059706304\n",
            "self.loss(score_2, v3) 0.032646555\n",
            "loss tensor(0.3131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08386447\n",
            "self.loss(score_0, v1) 0.1810879\n",
            "self.loss(score_0, v2) 0.17124616\n",
            "self.loss(score_2, v3) 0.041357175\n",
            "loss tensor(0.4982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19544034\n",
            "self.loss(score_0, v1) 0.23523049\n",
            "self.loss(score_0, v2) 0.10199534\n",
            "self.loss(score_2, v3) 0.042943113\n",
            "loss tensor(0.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.064386256\n",
            "self.loss(score_0, v1) 0.22187823\n",
            "self.loss(score_0, v2) 0.2084944\n",
            "self.loss(score_2, v3) 0.04341348\n",
            "loss tensor(0.5599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17692278\n",
            "self.loss(score_0, v1) 0.19458301\n",
            "self.loss(score_0, v2) 0.15195996\n",
            "self.loss(score_2, v3) 0.043389905\n",
            "loss tensor(0.5886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07074947\n",
            "self.loss(score_0, v1) 0.12844154\n",
            "self.loss(score_0, v2) 0.12571554\n",
            "self.loss(score_2, v3) 0.04008293\n",
            "loss tensor(0.3850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.095564775\n",
            "self.loss(score_0, v1) 0.11157887\n",
            "self.loss(score_0, v2) 0.08872356\n",
            "self.loss(score_2, v3) 0.047647998\n",
            "loss tensor(0.3673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09307023\n",
            "self.loss(score_0, v1) 0.14227524\n",
            "self.loss(score_0, v2) 0.16329993\n",
            "self.loss(score_2, v3) 0.04537954\n",
            "loss tensor(0.4667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.24174774\n",
            "self.loss(score_0, v1) 0.48064595\n",
            "self.loss(score_0, v2) 0.5065881\n",
            "self.loss(score_2, v3) 0.19250683\n",
            "loss tensor(1.5177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.063759245\n",
            "self.loss(score_0, v1) 0.10731925\n",
            "self.loss(score_0, v2) 0.09729726\n",
            "self.loss(score_2, v3) 0.04296445\n",
            "loss tensor(0.3328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18416223\n",
            "self.loss(score_0, v1) 0.25150368\n",
            "self.loss(score_0, v2) 0.18633893\n",
            "self.loss(score_2, v3) 0.038483106\n",
            "loss tensor(0.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08344698\n",
            "self.loss(score_0, v1) 0.095043756\n",
            "self.loss(score_0, v2) 0.087088585\n",
            "self.loss(score_2, v3) 0.05795192\n",
            "loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0642103\n",
            "self.loss(score_0, v1) 0.102492854\n",
            "self.loss(score_0, v2) 0.091142856\n",
            "self.loss(score_2, v3) 0.033663306\n",
            "loss tensor(0.3083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0698335\n",
            "self.loss(score_0, v1) 0.10429614\n",
            "self.loss(score_0, v2) 0.09292626\n",
            "self.loss(score_2, v3) 0.053163547\n",
            "loss tensor(0.3468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08836523\n",
            "self.loss(score_0, v1) 0.109205715\n",
            "self.loss(score_0, v2) 0.14626114\n",
            "self.loss(score_2, v3) 0.082793154\n",
            "loss tensor(0.4680, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06528548\n",
            "self.loss(score_0, v1) 0.07220834\n",
            "self.loss(score_0, v2) 0.08472996\n",
            "self.loss(score_2, v3) 0.039792616\n",
            "loss tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06870775\n",
            "self.loss(score_0, v1) 0.09279496\n",
            "self.loss(score_0, v2) 0.09311001\n",
            "self.loss(score_2, v3) 0.036416337\n",
            "loss tensor(0.3092, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0746443\n",
            "self.loss(score_0, v1) 0.75165176\n",
            "self.loss(score_0, v2) 0.75007457\n",
            "self.loss(score_2, v3) 0.054185513\n",
            "loss tensor(1.6576, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08397349\n",
            "self.loss(score_0, v1) 0.1565955\n",
            "self.loss(score_0, v2) 0.11869183\n",
            "self.loss(score_2, v3) 0.04266268\n",
            "loss tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0617786\n",
            "self.loss(score_0, v1) 0.08688326\n",
            "self.loss(score_0, v2) 0.08040272\n",
            "self.loss(score_2, v3) 0.043764733\n",
            "loss tensor(0.2947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08055412\n",
            "self.loss(score_0, v1) 0.11792608\n",
            "self.loss(score_0, v2) 0.12457814\n",
            "self.loss(score_2, v3) 0.04726389\n",
            "loss tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07559464\n",
            "self.loss(score_0, v1) 0.1413337\n",
            "self.loss(score_0, v2) 0.08570243\n",
            "self.loss(score_2, v3) 0.047846273\n",
            "loss tensor(0.3744, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.067545466\n",
            "self.loss(score_0, v1) 0.16523482\n",
            "self.loss(score_0, v2) 0.18634033\n",
            "self.loss(score_2, v3) 0.03843439\n",
            "loss tensor(0.4768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08412901\n",
            "self.loss(score_0, v1) 0.16391173\n",
            "self.loss(score_0, v2) 0.15938185\n",
            "self.loss(score_2, v3) 0.036210924\n",
            "loss tensor(0.4617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08697886\n",
            "self.loss(score_0, v1) 0.27957946\n",
            "self.loss(score_0, v2) 0.2747007\n",
            "self.loss(score_2, v3) 0.05007585\n",
            "loss tensor(0.7164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.093821086\n",
            "self.loss(score_0, v1) 0.36156577\n",
            "self.loss(score_0, v2) 0.27240455\n",
            "self.loss(score_2, v3) 0.06280905\n",
            "loss tensor(0.8220, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16874084\n",
            "self.loss(score_0, v1) 0.2990109\n",
            "self.loss(score_0, v2) 0.34018973\n",
            "self.loss(score_2, v3) 0.16086988\n",
            "loss tensor(1.0492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16345023\n",
            "self.loss(score_0, v1) 0.37608293\n",
            "self.loss(score_0, v2) 0.49106237\n",
            "self.loss(score_2, v3) 0.03864683\n",
            "loss tensor(1.0886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08618176\n",
            "self.loss(score_0, v1) 0.36024237\n",
            "self.loss(score_0, v2) 0.3319393\n",
            "self.loss(score_2, v3) 0.056010958\n",
            "loss tensor(0.8624, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.090427615\n",
            "self.loss(score_0, v1) 0.12531352\n",
            "self.loss(score_0, v2) 0.081842236\n",
            "self.loss(score_2, v3) 0.039444648\n",
            "loss tensor(0.3568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10271674\n",
            "self.loss(score_0, v1) 0.11981514\n",
            "self.loss(score_0, v2) 0.08848404\n",
            "self.loss(score_2, v3) 0.03713365\n",
            "loss tensor(0.3667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04449693\n",
            "self.loss(score_0, v1) 0.057699367\n",
            "self.loss(score_0, v2) 0.05936566\n",
            "self.loss(score_2, v3) 0.026839357\n",
            "loss tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0629961\n",
            "self.loss(score_0, v1) 0.1705084\n",
            "self.loss(score_0, v2) 0.24953896\n",
            "self.loss(score_2, v3) 0.035210565\n",
            "loss tensor(0.5359, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23002248\n",
            "self.loss(score_0, v1) 0.2873407\n",
            "self.loss(score_0, v2) 0.10201999\n",
            "self.loss(score_2, v3) 0.04721108\n",
            "loss tensor(0.6902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.070565775\n",
            "self.loss(score_0, v1) 0.20482695\n",
            "self.loss(score_0, v2) 0.20670816\n",
            "self.loss(score_2, v3) 0.054140758\n",
            "loss tensor(0.5633, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10697828\n",
            "self.loss(score_0, v1) 0.18363275\n",
            "self.loss(score_0, v2) 0.14571995\n",
            "self.loss(score_2, v3) 0.04029545\n",
            "loss tensor(0.4968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.028859282\n",
            "self.loss(score_0, v1) 0.08185199\n",
            "self.loss(score_0, v2) 0.10763003\n",
            "self.loss(score_2, v3) 0.045018017\n",
            "loss tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10460277\n",
            "self.loss(score_0, v1) 0.25342804\n",
            "self.loss(score_0, v2) 0.17184046\n",
            "self.loss(score_2, v3) 0.03722332\n",
            "loss tensor(0.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.083675735\n",
            "self.loss(score_0, v1) 0.10479037\n",
            "self.loss(score_0, v2) 0.087664485\n",
            "self.loss(score_2, v3) 0.04405021\n",
            "loss tensor(0.3422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.067862116\n",
            "self.loss(score_0, v1) 0.16571599\n",
            "self.loss(score_0, v2) 0.15948966\n",
            "self.loss(score_2, v3) 0.05071336\n",
            "loss tensor(0.4691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077096336\n",
            "self.loss(score_0, v1) 0.100688696\n",
            "self.loss(score_0, v2) 0.12343786\n",
            "self.loss(score_2, v3) 0.06121671\n",
            "loss tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055259503\n",
            "self.loss(score_0, v1) 0.17634726\n",
            "self.loss(score_0, v2) 0.10171815\n",
            "self.loss(score_2, v3) 0.034225613\n",
            "loss tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08387004\n",
            "self.loss(score_0, v1) 0.39519712\n",
            "self.loss(score_0, v2) 0.3395358\n",
            "self.loss(score_2, v3) 0.041420754\n",
            "loss tensor(0.8807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06614795\n",
            "self.loss(score_0, v1) 0.10884663\n",
            "self.loss(score_0, v2) 0.061942123\n",
            "self.loss(score_2, v3) 0.036363058\n",
            "loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056131355\n",
            "self.loss(score_0, v1) 0.07417301\n",
            "self.loss(score_0, v2) 0.07410823\n",
            "self.loss(score_2, v3) 0.02870265\n",
            "loss tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.107552946\n",
            "self.loss(score_0, v1) 0.08737723\n",
            "self.loss(score_0, v2) 0.0969849\n",
            "self.loss(score_2, v3) 0.0473128\n",
            "loss tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2157267\n",
            "self.loss(score_0, v1) 0.20588562\n",
            "self.loss(score_0, v2) 0.09589415\n",
            "self.loss(score_2, v3) 0.057795495\n",
            "loss tensor(0.6042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11950855\n",
            "self.loss(score_0, v1) 0.15842395\n",
            "self.loss(score_0, v2) 0.12262188\n",
            "self.loss(score_2, v3) 0.045146998\n",
            "loss tensor(0.4683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08877259\n",
            "self.loss(score_0, v1) 0.103158936\n",
            "self.loss(score_0, v2) 0.12001834\n",
            "self.loss(score_2, v3) 0.060512383\n",
            "loss tensor(0.4027, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07468985\n",
            "self.loss(score_0, v1) 0.12549445\n",
            "self.loss(score_0, v2) 0.12758751\n",
            "self.loss(score_2, v3) 0.044570338\n",
            "loss tensor(0.3946, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.054739635\n",
            "self.loss(score_0, v1) 0.075696\n",
            "self.loss(score_0, v2) 0.06645964\n",
            "self.loss(score_2, v3) 0.027302159\n",
            "loss tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09484902\n",
            "self.loss(score_0, v1) 0.46526274\n",
            "self.loss(score_0, v2) 0.46425354\n",
            "self.loss(score_2, v3) 0.06330504\n",
            "loss tensor(1.1193, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13217397\n",
            "self.loss(score_0, v1) 0.16635494\n",
            "self.loss(score_0, v2) 0.10259153\n",
            "self.loss(score_2, v3) 0.04395065\n",
            "loss tensor(0.4670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07499667\n",
            "self.loss(score_0, v1) 0.1106436\n",
            "self.loss(score_0, v2) 0.097261116\n",
            "self.loss(score_2, v3) 0.05591145\n",
            "loss tensor(0.3668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16298865\n",
            "self.loss(score_0, v1) 0.5423145\n",
            "self.loss(score_0, v2) 0.42742342\n",
            "self.loss(score_2, v3) 0.053010236\n",
            "loss tensor(1.2122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06818669\n",
            "self.loss(score_0, v1) 0.15596543\n",
            "self.loss(score_0, v2) 0.20545788\n",
            "self.loss(score_2, v3) 0.05005338\n",
            "loss tensor(0.5047, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14239863\n",
            "self.loss(score_0, v1) 0.20176846\n",
            "self.loss(score_0, v2) 0.21581829\n",
            "self.loss(score_2, v3) 0.052447677\n",
            "loss tensor(0.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08975125\n",
            "self.loss(score_0, v1) 0.124574155\n",
            "self.loss(score_0, v2) 0.12537512\n",
            "self.loss(score_2, v3) 0.041184194\n",
            "loss tensor(0.4015, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15015586\n",
            "self.loss(score_0, v1) 0.22722171\n",
            "self.loss(score_0, v2) 0.16028202\n",
            "self.loss(score_2, v3) 0.054808807\n",
            "loss tensor(0.6199, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10054221\n",
            "self.loss(score_0, v1) 0.1395115\n",
            "self.loss(score_0, v2) 0.1334001\n",
            "self.loss(score_2, v3) 0.039410982\n",
            "loss tensor(0.4326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06828521\n",
            "self.loss(score_0, v1) 0.10086819\n",
            "self.loss(score_0, v2) 0.10383527\n",
            "self.loss(score_2, v3) 0.041072212\n",
            "loss tensor(0.3346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22503863\n",
            "self.loss(score_0, v1) 0.17123325\n",
            "self.loss(score_0, v2) 0.13564451\n",
            "self.loss(score_2, v3) 0.04200175\n",
            "loss tensor(0.5949, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06832051\n",
            "self.loss(score_0, v1) 0.25867772\n",
            "self.loss(score_0, v2) 0.22824477\n",
            "self.loss(score_2, v3) 0.040088467\n",
            "loss tensor(0.6154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1041711\n",
            "self.loss(score_0, v1) 0.1068347\n",
            "self.loss(score_0, v2) 0.0796979\n",
            "self.loss(score_2, v3) 0.046627603\n",
            "loss tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09460603\n",
            "self.loss(score_0, v1) 0.14446938\n",
            "self.loss(score_0, v2) 0.10015172\n",
            "self.loss(score_2, v3) 0.04888196\n",
            "loss tensor(0.4126, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11594075\n",
            "self.loss(score_0, v1) 0.19696264\n",
            "self.loss(score_0, v2) 0.23501487\n",
            "self.loss(score_2, v3) 0.055817354\n",
            "loss tensor(0.6316, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1353279\n",
            "self.loss(score_0, v1) 0.2139833\n",
            "self.loss(score_0, v2) 0.16283895\n",
            "self.loss(score_2, v3) 0.049708918\n",
            "loss tensor(0.5867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15563154\n",
            "self.loss(score_0, v1) 0.15005016\n",
            "self.loss(score_0, v2) 0.07975898\n",
            "self.loss(score_2, v3) 0.03576641\n",
            "loss tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08587087\n",
            "self.loss(score_0, v1) 0.10208799\n",
            "self.loss(score_0, v2) 0.12331382\n",
            "self.loss(score_2, v3) 0.045101076\n",
            "loss tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06858555\n",
            "self.loss(score_0, v1) 0.08379465\n",
            "self.loss(score_0, v2) 0.08489973\n",
            "self.loss(score_2, v3) 0.04070842\n",
            "loss tensor(0.2983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05478782\n",
            "self.loss(score_0, v1) 0.07876292\n",
            "self.loss(score_0, v2) 0.10454343\n",
            "self.loss(score_2, v3) 0.035590384\n",
            "loss tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12433793\n",
            "self.loss(score_0, v1) 0.2770601\n",
            "self.loss(score_0, v2) 0.2964521\n",
            "self.loss(score_2, v3) 0.047649305\n",
            "loss tensor(0.7693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07863549\n",
            "self.loss(score_0, v1) 0.3292656\n",
            "self.loss(score_0, v2) 0.34948203\n",
            "self.loss(score_2, v3) 0.056270495\n",
            "loss tensor(0.8418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08298914\n",
            "self.loss(score_0, v1) 0.08318906\n",
            "self.loss(score_0, v2) 0.07735321\n",
            "self.loss(score_2, v3) 0.04006765\n",
            "loss tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07844749\n",
            "self.loss(score_0, v1) 0.22921188\n",
            "self.loss(score_0, v2) 0.27582037\n",
            "self.loss(score_2, v3) 0.035650276\n",
            "loss tensor(0.6370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1570645\n",
            "self.loss(score_0, v1) 0.17558771\n",
            "self.loss(score_0, v2) 0.148023\n",
            "self.loss(score_2, v3) 0.21070944\n",
            "loss tensor(0.7967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058827087\n",
            "self.loss(score_0, v1) 0.09524068\n",
            "self.loss(score_0, v2) 0.15965176\n",
            "self.loss(score_2, v3) 0.043896083\n",
            "loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18659395\n",
            "self.loss(score_0, v1) 0.12655075\n",
            "self.loss(score_0, v2) 0.10265337\n",
            "self.loss(score_2, v3) 0.05151639\n",
            "loss tensor(0.4931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11051997\n",
            "self.loss(score_0, v1) 0.12679937\n",
            "self.loss(score_0, v2) 0.085282594\n",
            "self.loss(score_2, v3) 0.045458477\n",
            "loss tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13879469\n",
            "self.loss(score_0, v1) 0.1683826\n",
            "self.loss(score_0, v2) 0.10758682\n",
            "self.loss(score_2, v3) 0.04268833\n",
            "loss tensor(0.4788, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0713619\n",
            "self.loss(score_0, v1) 0.06820229\n",
            "self.loss(score_0, v2) 0.05613527\n",
            "self.loss(score_2, v3) 0.02633076\n",
            "loss tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06981738\n",
            "self.loss(score_0, v1) 0.09996889\n",
            "self.loss(score_0, v2) 0.111696154\n",
            "self.loss(score_2, v3) 0.0442244\n",
            "loss tensor(0.3478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061994772\n",
            "self.loss(score_0, v1) 0.08436807\n",
            "self.loss(score_0, v2) 0.07226409\n",
            "self.loss(score_2, v3) 0.039380047\n",
            "loss tensor(0.2777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061284937\n",
            "self.loss(score_0, v1) 0.3598201\n",
            "self.loss(score_0, v2) 0.37574708\n",
            "self.loss(score_2, v3) 0.039736904\n",
            "loss tensor(0.8565, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06669482\n",
            "self.loss(score_0, v1) 0.08751284\n",
            "self.loss(score_0, v2) 0.10848562\n",
            "self.loss(score_2, v3) 0.04907911\n",
            "loss tensor(0.3363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15612595\n",
            "self.loss(score_0, v1) 0.18748087\n",
            "self.loss(score_0, v2) 0.087298065\n",
            "self.loss(score_2, v3) 0.040789075\n",
            "loss tensor(0.4921, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10555359\n",
            "self.loss(score_0, v1) 0.12058683\n",
            "self.loss(score_0, v2) 0.08714591\n",
            "self.loss(score_2, v3) 0.052166812\n",
            "loss tensor(0.3915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07783303\n",
            "self.loss(score_0, v1) 0.11277215\n",
            "self.loss(score_0, v2) 0.247707\n",
            "self.loss(score_2, v3) 0.2336598\n",
            "loss tensor(0.7888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07431401\n",
            "self.loss(score_0, v1) 0.118197046\n",
            "self.loss(score_0, v2) 0.10178795\n",
            "self.loss(score_2, v3) 0.050233014\n",
            "loss tensor(0.3696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06365577\n",
            "self.loss(score_0, v1) 0.08438789\n",
            "self.loss(score_0, v2) 0.07378444\n",
            "self.loss(score_2, v3) 0.04324254\n",
            "loss tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10799844\n",
            "self.loss(score_0, v1) 0.11566037\n",
            "self.loss(score_0, v2) 0.081571884\n",
            "self.loss(score_2, v3) 0.041289903\n",
            "loss tensor(0.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0753435\n",
            "self.loss(score_0, v1) 0.083838195\n",
            "self.loss(score_0, v2) 0.09353128\n",
            "self.loss(score_2, v3) 0.038291026\n",
            "loss tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06438917\n",
            "self.loss(score_0, v1) 0.17647819\n",
            "self.loss(score_0, v2) 0.19516927\n",
            "self.loss(score_2, v3) 0.053986423\n",
            "loss tensor(0.5170, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06737445\n",
            "self.loss(score_0, v1) 0.1269305\n",
            "self.loss(score_0, v2) 0.13363044\n",
            "self.loss(score_2, v3) 0.035974704\n",
            "loss tensor(0.3819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057471253\n",
            "self.loss(score_0, v1) 0.12050095\n",
            "self.loss(score_0, v2) 0.10347135\n",
            "self.loss(score_2, v3) 0.03156056\n",
            "loss tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09188459\n",
            "self.loss(score_0, v1) 0.28672728\n",
            "self.loss(score_0, v2) 0.2583226\n",
            "self.loss(score_2, v3) 0.04530688\n",
            "loss tensor(0.7049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14056467\n",
            "self.loss(score_0, v1) 0.20223479\n",
            "self.loss(score_0, v2) 0.12072183\n",
            "self.loss(score_2, v3) 0.05521851\n",
            "loss tensor(0.5463, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07298496\n",
            "self.loss(score_0, v1) 0.13195547\n",
            "self.loss(score_0, v2) 0.1832538\n",
            "self.loss(score_2, v3) 0.09702161\n",
            "loss tensor(0.5337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08963045\n",
            "self.loss(score_0, v1) 0.089258045\n",
            "self.loss(score_0, v2) 0.12662707\n",
            "self.loss(score_2, v3) 0.04536059\n",
            "loss tensor(0.3736, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09255049\n",
            "self.loss(score_0, v1) 0.11748165\n",
            "self.loss(score_0, v2) 0.07686376\n",
            "self.loss(score_2, v3) 0.039405517\n",
            "loss tensor(0.3460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09452568\n",
            "self.loss(score_0, v1) 0.16080293\n",
            "self.loss(score_0, v2) 0.16653612\n",
            "self.loss(score_2, v3) 0.040865522\n",
            "loss tensor(0.4832, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2545658\n",
            "self.loss(score_0, v1) 0.53498065\n",
            "self.loss(score_0, v2) 0.43663925\n",
            "self.loss(score_2, v3) 0.025198836\n",
            "loss tensor(1.2640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.123560615\n",
            "self.loss(score_0, v1) 0.13480283\n",
            "self.loss(score_0, v2) 0.07151532\n",
            "self.loss(score_2, v3) 0.03225673\n",
            "loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12448831\n",
            "self.loss(score_0, v1) 0.23059922\n",
            "self.loss(score_0, v2) 0.23664488\n",
            "self.loss(score_2, v3) 0.03923956\n",
            "loss tensor(0.6506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03973366\n",
            "self.loss(score_0, v1) 0.20629475\n",
            "self.loss(score_0, v2) 0.22202885\n",
            "self.loss(score_2, v3) 0.027272597\n",
            "loss tensor(0.5090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09452159\n",
            "self.loss(score_0, v1) 0.16210727\n",
            "self.loss(score_0, v2) 0.15337773\n",
            "self.loss(score_2, v3) 0.04394037\n",
            "loss tensor(0.4759, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07993625\n",
            "self.loss(score_0, v1) 0.11690871\n",
            "self.loss(score_0, v2) 0.12524396\n",
            "self.loss(score_2, v3) 0.04958851\n",
            "loss tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058390632\n",
            "self.loss(score_0, v1) 0.098106444\n",
            "self.loss(score_0, v2) 0.09567646\n",
            "self.loss(score_2, v3) 0.035335816\n",
            "loss tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07828702\n",
            "self.loss(score_0, v1) 0.11364915\n",
            "self.loss(score_0, v2) 0.09545654\n",
            "self.loss(score_2, v3) 0.04297299\n",
            "loss tensor(0.3519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08354049\n",
            "self.loss(score_0, v1) 0.13405241\n",
            "self.loss(score_0, v2) 0.16638826\n",
            "self.loss(score_2, v3) 0.0383886\n",
            "loss tensor(0.4416, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06569851\n",
            "self.loss(score_0, v1) 0.08814941\n",
            "self.loss(score_0, v2) 0.10799154\n",
            "self.loss(score_2, v3) 0.055177763\n",
            "loss tensor(0.3446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08530174\n",
            "self.loss(score_0, v1) 0.109665334\n",
            "self.loss(score_0, v2) 0.10726497\n",
            "self.loss(score_2, v3) 0.042474996\n",
            "loss tensor(0.3659, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06669643\n",
            "self.loss(score_0, v1) 0.08497791\n",
            "self.loss(score_0, v2) 0.12164402\n",
            "self.loss(score_2, v3) 0.05069706\n",
            "loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08980772\n",
            "self.loss(score_0, v1) 0.23285857\n",
            "self.loss(score_0, v2) 0.2301098\n",
            "self.loss(score_2, v3) 0.04966752\n",
            "loss tensor(0.6273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 0.5420117561889303, Train Accuracy : 0.9988422328139676\n",
            " Validation Accuracy : 6.599662821945807\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.05674258\n",
            "self.loss(score_0, v1) 0.15257224\n",
            "self.loss(score_0, v2) 0.28009367\n",
            "self.loss(score_2, v3) 0.071515836\n",
            "loss tensor(0.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052582864\n",
            "self.loss(score_0, v1) 0.091852844\n",
            "self.loss(score_0, v2) 0.17537855\n",
            "self.loss(score_2, v3) 0.09434049\n",
            "loss tensor(0.4613, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2408327\n",
            "self.loss(score_0, v1) 0.30187953\n",
            "self.loss(score_0, v2) 0.16619515\n",
            "self.loss(score_2, v3) 0.034092356\n",
            "loss tensor(0.7600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17264079\n",
            "self.loss(score_0, v1) 0.25667313\n",
            "self.loss(score_0, v2) 0.16378301\n",
            "self.loss(score_2, v3) 0.045960512\n",
            "loss tensor(0.6620, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.069043875\n",
            "self.loss(score_0, v1) 0.20793574\n",
            "self.loss(score_0, v2) 0.22242533\n",
            "self.loss(score_2, v3) 0.033239946\n",
            "loss tensor(0.5493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06243881\n",
            "self.loss(score_0, v1) 0.08089085\n",
            "self.loss(score_0, v2) 0.070941135\n",
            "self.loss(score_2, v3) 0.036955647\n",
            "loss tensor(0.2697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060401533\n",
            "self.loss(score_0, v1) 0.08008915\n",
            "self.loss(score_0, v2) 0.07263357\n",
            "self.loss(score_2, v3) 0.038226493\n",
            "loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.080475435\n",
            "self.loss(score_0, v1) 0.09262633\n",
            "self.loss(score_0, v2) 0.061532073\n",
            "self.loss(score_2, v3) 0.030711921\n",
            "loss tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07186029\n",
            "self.loss(score_0, v1) 0.09727629\n",
            "self.loss(score_0, v2) 0.10882919\n",
            "self.loss(score_2, v3) 0.042916052\n",
            "loss tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06476034\n",
            "self.loss(score_0, v1) 0.08440914\n",
            "self.loss(score_0, v2) 0.12325559\n",
            "self.loss(score_2, v3) 0.053353082\n",
            "loss tensor(0.3525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10631407\n",
            "self.loss(score_0, v1) 0.40022925\n",
            "self.loss(score_0, v2) 0.30092645\n",
            "self.loss(score_2, v3) 0.04290577\n",
            "loss tensor(0.8718, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08064381\n",
            "self.loss(score_0, v1) 0.11084518\n",
            "self.loss(score_0, v2) 0.10898531\n",
            "self.loss(score_2, v3) 0.03823052\n",
            "loss tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08649788\n",
            "self.loss(score_0, v1) 0.17671986\n",
            "self.loss(score_0, v2) 0.1671063\n",
            "self.loss(score_2, v3) 0.038706295\n",
            "loss tensor(0.4884, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11475964\n",
            "self.loss(score_0, v1) 0.15773849\n",
            "self.loss(score_0, v2) 0.1747754\n",
            "self.loss(score_2, v3) 0.040888287\n",
            "loss tensor(0.5086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06388812\n",
            "self.loss(score_0, v1) 0.092681296\n",
            "self.loss(score_0, v2) 0.10367595\n",
            "self.loss(score_2, v3) 0.035333827\n",
            "loss tensor(0.3132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21202132\n",
            "self.loss(score_0, v1) 0.19624686\n",
            "self.loss(score_0, v2) 0.09031603\n",
            "self.loss(score_2, v3) 0.055574775\n",
            "loss tensor(0.5819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08625106\n",
            "self.loss(score_0, v1) 0.11979996\n",
            "self.loss(score_0, v2) 0.091714896\n",
            "self.loss(score_2, v3) 0.043750234\n",
            "loss tensor(0.3634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07039573\n",
            "self.loss(score_0, v1) 0.11844968\n",
            "self.loss(score_0, v2) 0.10145867\n",
            "self.loss(score_2, v3) 0.04099822\n",
            "loss tensor(0.3518, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.34265918\n",
            "self.loss(score_0, v1) 0.35694122\n",
            "self.loss(score_0, v2) 0.25535375\n",
            "self.loss(score_2, v3) 0.052124523\n",
            "loss tensor(1.0331, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09510728\n",
            "self.loss(score_0, v1) 0.15131147\n",
            "self.loss(score_0, v2) 0.18781403\n",
            "self.loss(score_2, v3) 0.051901877\n",
            "loss tensor(0.5121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08623103\n",
            "self.loss(score_0, v1) 0.11806492\n",
            "self.loss(score_0, v2) 0.10351697\n",
            "self.loss(score_2, v3) 0.041917056\n",
            "loss tensor(0.3707, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1356959\n",
            "self.loss(score_0, v1) 0.14498635\n",
            "self.loss(score_0, v2) 0.08264995\n",
            "self.loss(score_2, v3) 0.04964326\n",
            "loss tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056856208\n",
            "self.loss(score_0, v1) 0.08523787\n",
            "self.loss(score_0, v2) 0.18005076\n",
            "self.loss(score_2, v3) 0.04501559\n",
            "loss tensor(0.3897, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05503094\n",
            "self.loss(score_0, v1) 0.07522776\n",
            "self.loss(score_0, v2) 0.088188276\n",
            "self.loss(score_2, v3) 0.032489467\n",
            "loss tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0654582\n",
            "self.loss(score_0, v1) 0.08148399\n",
            "self.loss(score_0, v2) 0.075618714\n",
            "self.loss(score_2, v3) 0.035817593\n",
            "loss tensor(0.2763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06804745\n",
            "self.loss(score_0, v1) 0.10479771\n",
            "self.loss(score_0, v2) 0.1076532\n",
            "self.loss(score_2, v3) 0.049079966\n",
            "loss tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.090857305\n",
            "self.loss(score_0, v1) 0.14067434\n",
            "self.loss(score_0, v2) 0.10503818\n",
            "self.loss(score_2, v3) 0.043606628\n",
            "loss tensor(0.4020, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06130344\n",
            "self.loss(score_0, v1) 0.094522476\n",
            "self.loss(score_0, v2) 0.09532847\n",
            "self.loss(score_2, v3) 0.048722863\n",
            "loss tensor(0.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09017552\n",
            "self.loss(score_0, v1) 0.22442809\n",
            "self.loss(score_0, v2) 0.22942494\n",
            "self.loss(score_2, v3) 0.056170646\n",
            "loss tensor(0.6283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06441555\n",
            "self.loss(score_0, v1) 0.08444885\n",
            "self.loss(score_0, v2) 0.10817121\n",
            "self.loss(score_2, v3) 0.04436988\n",
            "loss tensor(0.3236, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.081170775\n",
            "self.loss(score_0, v1) 0.32603955\n",
            "self.loss(score_0, v2) 0.24772522\n",
            "self.loss(score_2, v3) 0.039863855\n",
            "loss tensor(0.7147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07280102\n",
            "self.loss(score_0, v1) 0.090517804\n",
            "self.loss(score_0, v2) 0.066480435\n",
            "self.loss(score_2, v3) 0.042299755\n",
            "loss tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.41509163\n",
            "self.loss(score_0, v1) 0.5316923\n",
            "self.loss(score_0, v2) 0.6536082\n",
            "self.loss(score_2, v3) 0.92140794\n",
            "loss tensor(2.9825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0834537\n",
            "self.loss(score_0, v1) 0.084635854\n",
            "self.loss(score_0, v2) 0.079722576\n",
            "self.loss(score_2, v3) 0.044822328\n",
            "loss tensor(0.3150, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.066881076\n",
            "self.loss(score_0, v1) 0.10194166\n",
            "self.loss(score_0, v2) 0.119892605\n",
            "self.loss(score_2, v3) 0.046451032\n",
            "loss tensor(0.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06997605\n",
            "self.loss(score_0, v1) 0.11858257\n",
            "self.loss(score_0, v2) 0.09482487\n",
            "self.loss(score_2, v3) 0.04989308\n",
            "loss tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06488081\n",
            "self.loss(score_0, v1) 0.09374368\n",
            "self.loss(score_0, v2) 0.08607091\n",
            "self.loss(score_2, v3) 0.052881055\n",
            "loss tensor(0.3240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07044552\n",
            "self.loss(score_0, v1) 0.15820517\n",
            "self.loss(score_0, v2) 0.18276066\n",
            "self.loss(score_2, v3) 0.0496467\n",
            "loss tensor(0.4859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14665727\n",
            "self.loss(score_0, v1) 0.18127498\n",
            "self.loss(score_0, v2) 0.08453912\n",
            "self.loss(score_2, v3) 0.050250422\n",
            "loss tensor(0.4878, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07413083\n",
            "self.loss(score_0, v1) 0.1291622\n",
            "self.loss(score_0, v2) 0.21785834\n",
            "self.loss(score_2, v3) 0.18426307\n",
            "loss tensor(0.6975, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15469308\n",
            "self.loss(score_0, v1) 0.15882026\n",
            "self.loss(score_0, v2) 0.052306805\n",
            "self.loss(score_2, v3) 0.029722124\n",
            "loss tensor(0.4104, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2611157\n",
            "self.loss(score_0, v1) 0.54407036\n",
            "self.loss(score_0, v2) 0.36802724\n",
            "self.loss(score_2, v3) 0.036704767\n",
            "loss tensor(1.2283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07699615\n",
            "self.loss(score_0, v1) 0.106102884\n",
            "self.loss(score_0, v2) 0.100372285\n",
            "self.loss(score_2, v3) 0.055159144\n",
            "loss tensor(0.3662, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05543931\n",
            "self.loss(score_0, v1) 0.0788248\n",
            "self.loss(score_0, v2) 0.09392155\n",
            "self.loss(score_2, v3) 0.03942937\n",
            "loss tensor(0.2873, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07371512\n",
            "self.loss(score_0, v1) 0.08811891\n",
            "self.loss(score_0, v2) 0.110180415\n",
            "self.loss(score_2, v3) 0.045669924\n",
            "loss tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.068780676\n",
            "self.loss(score_0, v1) 0.10152689\n",
            "self.loss(score_0, v2) 0.090981714\n",
            "self.loss(score_2, v3) 0.037012365\n",
            "loss tensor(0.3168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061596707\n",
            "self.loss(score_0, v1) 0.09072429\n",
            "self.loss(score_0, v2) 0.079356\n",
            "self.loss(score_2, v3) 0.052983552\n",
            "loss tensor(0.3112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077593066\n",
            "self.loss(score_0, v1) 0.22682075\n",
            "self.loss(score_0, v2) 0.23183355\n",
            "self.loss(score_2, v3) 0.041226055\n",
            "loss tensor(0.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059651986\n",
            "self.loss(score_0, v1) 0.060537033\n",
            "self.loss(score_0, v2) 0.0878526\n",
            "self.loss(score_2, v3) 0.039822835\n",
            "loss tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07971306\n",
            "self.loss(score_0, v1) 0.12684363\n",
            "self.loss(score_0, v2) 0.15339833\n",
            "self.loss(score_2, v3) 0.0524704\n",
            "loss tensor(0.4387, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15817355\n",
            "self.loss(score_0, v1) 0.5238887\n",
            "self.loss(score_0, v2) 0.41264114\n",
            "self.loss(score_2, v3) 0.053821407\n",
            "loss tensor(1.1754, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06129338\n",
            "self.loss(score_0, v1) 0.09003275\n",
            "self.loss(score_0, v2) 0.074975826\n",
            "self.loss(score_2, v3) 0.04176647\n",
            "loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12474611\n",
            "self.loss(score_0, v1) 0.21195549\n",
            "self.loss(score_0, v2) 0.36718598\n",
            "self.loss(score_2, v3) 0.20632485\n",
            "loss tensor(1.0134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08883135\n",
            "self.loss(score_0, v1) 0.0922714\n",
            "self.loss(score_0, v2) 0.091457434\n",
            "self.loss(score_2, v3) 0.053564098\n",
            "loss tensor(0.3529, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.385507\n",
            "self.loss(score_0, v1) 0.385731\n",
            "self.loss(score_0, v2) 0.14235914\n",
            "self.loss(score_2, v3) 0.054614544\n",
            "loss tensor(0.9955, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08297174\n",
            "self.loss(score_0, v1) 0.13134448\n",
            "self.loss(score_0, v2) 0.13033515\n",
            "self.loss(score_2, v3) 0.047792424\n",
            "loss tensor(0.4163, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12251761\n",
            "self.loss(score_0, v1) 0.17038047\n",
            "self.loss(score_0, v2) 0.11366343\n",
            "self.loss(score_2, v3) 0.050200004\n",
            "loss tensor(0.4819, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07177624\n",
            "self.loss(score_0, v1) 0.2744877\n",
            "self.loss(score_0, v2) 0.22180343\n",
            "self.loss(score_2, v3) 0.05280123\n",
            "loss tensor(0.6473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.078951634\n",
            "self.loss(score_0, v1) 0.11429994\n",
            "self.loss(score_0, v2) 0.09814494\n",
            "self.loss(score_2, v3) 0.029415375\n",
            "loss tensor(0.3355, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06774571\n",
            "self.loss(score_0, v1) 0.08606135\n",
            "self.loss(score_0, v2) 0.068885915\n",
            "self.loss(score_2, v3) 0.038996592\n",
            "loss tensor(0.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051756714\n",
            "self.loss(score_0, v1) 0.21780255\n",
            "self.loss(score_0, v2) 0.15202895\n",
            "self.loss(score_2, v3) 0.021973975\n",
            "loss tensor(0.4545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10578408\n",
            "self.loss(score_0, v1) 0.23843703\n",
            "self.loss(score_0, v2) 0.14362851\n",
            "self.loss(score_2, v3) 0.049503967\n",
            "loss tensor(0.5621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.074064724\n",
            "self.loss(score_0, v1) 0.088962585\n",
            "self.loss(score_0, v2) 0.088586636\n",
            "self.loss(score_2, v3) 0.043377746\n",
            "loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23728071\n",
            "self.loss(score_0, v1) 0.18310961\n",
            "self.loss(score_0, v2) 0.13472296\n",
            "self.loss(score_2, v3) 0.081802025\n",
            "loss tensor(0.6778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.118663445\n",
            "self.loss(score_0, v1) 0.3794846\n",
            "self.loss(score_0, v2) 0.32000896\n",
            "self.loss(score_2, v3) 0.041697014\n",
            "loss tensor(0.8807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14713342\n",
            "self.loss(score_0, v1) 0.21554716\n",
            "self.loss(score_0, v2) 0.2314764\n",
            "self.loss(score_2, v3) 0.055147424\n",
            "loss tensor(0.6769, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08164042\n",
            "self.loss(score_0, v1) 0.14786568\n",
            "self.loss(score_0, v2) 0.17996395\n",
            "self.loss(score_2, v3) 0.05045557\n",
            "loss tensor(0.4852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06780008\n",
            "self.loss(score_0, v1) 0.08124129\n",
            "self.loss(score_0, v2) 0.11656616\n",
            "self.loss(score_2, v3) 0.044960015\n",
            "loss tensor(0.3330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09151908\n",
            "self.loss(score_0, v1) 0.11738631\n",
            "self.loss(score_0, v2) 0.08309375\n",
            "self.loss(score_2, v3) 0.036591135\n",
            "loss tensor(0.3469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07789744\n",
            "self.loss(score_0, v1) 0.12888429\n",
            "self.loss(score_0, v2) 0.15241554\n",
            "self.loss(score_2, v3) 0.038660184\n",
            "loss tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06548666\n",
            "self.loss(score_0, v1) 0.124421895\n",
            "self.loss(score_0, v2) 0.12561339\n",
            "self.loss(score_2, v3) 0.037420653\n",
            "loss tensor(0.3717, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.35166997\n",
            "self.loss(score_0, v1) 0.7938396\n",
            "self.loss(score_0, v2) 0.44194004\n",
            "self.loss(score_2, v3) 0.03575795\n",
            "loss tensor(1.6411, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09305697\n",
            "self.loss(score_0, v1) 0.15222763\n",
            "self.loss(score_0, v2) 0.12694219\n",
            "self.loss(score_2, v3) 0.04786991\n",
            "loss tensor(0.4440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07415652\n",
            "self.loss(score_0, v1) 0.4529051\n",
            "self.loss(score_0, v2) 0.43847615\n",
            "self.loss(score_2, v3) 0.07856283\n",
            "loss tensor(1.0834, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06091172\n",
            "self.loss(score_0, v1) 0.08093417\n",
            "self.loss(score_0, v2) 0.09668514\n",
            "self.loss(score_2, v3) 0.03670591\n",
            "loss tensor(0.2936, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05676505\n",
            "self.loss(score_0, v1) 0.068693966\n",
            "self.loss(score_0, v2) 0.07836643\n",
            "self.loss(score_2, v3) 0.033677123\n",
            "loss tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0892229\n",
            "self.loss(score_0, v1) 0.22141026\n",
            "self.loss(score_0, v2) 0.19338804\n",
            "self.loss(score_2, v3) 0.043729134\n",
            "loss tensor(0.5696, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073887154\n",
            "self.loss(score_0, v1) 0.108999915\n",
            "self.loss(score_0, v2) 0.07780585\n",
            "self.loss(score_2, v3) 0.044003624\n",
            "loss tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07556777\n",
            "self.loss(score_0, v1) 0.1906732\n",
            "self.loss(score_0, v2) 0.15123594\n",
            "self.loss(score_2, v3) 0.040524814\n",
            "loss tensor(0.4783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053970657\n",
            "self.loss(score_0, v1) 0.09814073\n",
            "self.loss(score_0, v2) 0.0637407\n",
            "self.loss(score_2, v3) 0.029745448\n",
            "loss tensor(0.2605, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11137887\n",
            "self.loss(score_0, v1) 0.2755843\n",
            "self.loss(score_0, v2) 0.274172\n",
            "self.loss(score_2, v3) 0.034294523\n",
            "loss tensor(0.7126, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06354974\n",
            "self.loss(score_0, v1) 0.10453598\n",
            "self.loss(score_0, v2) 0.082332335\n",
            "self.loss(score_2, v3) 0.043331135\n",
            "loss tensor(0.3154, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05886857\n",
            "self.loss(score_0, v1) 0.08338172\n",
            "self.loss(score_0, v2) 0.061899263\n",
            "self.loss(score_2, v3) 0.039151005\n",
            "loss tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.078028806\n",
            "self.loss(score_0, v1) 0.120470054\n",
            "self.loss(score_0, v2) 0.09254356\n",
            "self.loss(score_2, v3) 0.03961026\n",
            "loss tensor(0.3505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06548726\n",
            "self.loss(score_0, v1) 0.33606678\n",
            "self.loss(score_0, v2) 0.26823658\n",
            "self.loss(score_2, v3) 0.033487845\n",
            "loss tensor(0.7200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07733083\n",
            "self.loss(score_0, v1) 0.12090952\n",
            "self.loss(score_0, v2) 0.12644525\n",
            "self.loss(score_2, v3) 0.045795687\n",
            "loss tensor(0.3934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0758802\n",
            "self.loss(score_0, v1) 0.36099052\n",
            "self.loss(score_0, v2) 0.37785515\n",
            "self.loss(score_2, v3) 0.19249725\n",
            "loss tensor(1.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08601568\n",
            "self.loss(score_0, v1) 0.123176865\n",
            "self.loss(score_0, v2) 0.118117675\n",
            "self.loss(score_2, v3) 0.033986032\n",
            "loss tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05470416\n",
            "self.loss(score_0, v1) 0.07686227\n",
            "self.loss(score_0, v2) 0.096434064\n",
            "self.loss(score_2, v3) 0.04584093\n",
            "loss tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05464571\n",
            "self.loss(score_0, v1) 0.17311051\n",
            "self.loss(score_0, v2) 0.18083708\n",
            "self.loss(score_2, v3) 0.04070911\n",
            "loss tensor(0.4697, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13531281\n",
            "self.loss(score_0, v1) 0.17522837\n",
            "self.loss(score_0, v2) 0.16073486\n",
            "self.loss(score_2, v3) 0.03561683\n",
            "loss tensor(0.5247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10058422\n",
            "self.loss(score_0, v1) 0.12151529\n",
            "self.loss(score_0, v2) 0.11849812\n",
            "self.loss(score_2, v3) 0.04707132\n",
            "loss tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.093611114\n",
            "self.loss(score_0, v1) 0.1508118\n",
            "self.loss(score_0, v2) 0.12302589\n",
            "self.loss(score_2, v3) 0.046850916\n",
            "loss tensor(0.4377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0733131\n",
            "self.loss(score_0, v1) 0.18262056\n",
            "self.loss(score_0, v2) 0.30962303\n",
            "self.loss(score_2, v3) 0.053623177\n",
            "loss tensor(0.6460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.080897495\n",
            "self.loss(score_0, v1) 0.101077594\n",
            "self.loss(score_0, v2) 0.09740084\n",
            "self.loss(score_2, v3) 0.03549173\n",
            "loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.33151823\n",
            "self.loss(score_0, v1) 0.30398136\n",
            "self.loss(score_0, v2) 0.08888403\n",
            "self.loss(score_2, v3) 0.04076159\n",
            "loss tensor(0.7855, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09061478\n",
            "self.loss(score_0, v1) 0.22649176\n",
            "self.loss(score_0, v2) 0.19266984\n",
            "self.loss(score_2, v3) 0.04894994\n",
            "loss tensor(0.5832, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06293859\n",
            "self.loss(score_0, v1) 0.0813376\n",
            "self.loss(score_0, v2) 0.06690571\n",
            "self.loss(score_2, v3) 0.038677294\n",
            "loss tensor(0.2692, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05944655\n",
            "self.loss(score_0, v1) 0.08942282\n",
            "self.loss(score_0, v2) 0.13351314\n",
            "self.loss(score_2, v3) 0.038550694\n",
            "loss tensor(0.3402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.098269984\n",
            "self.loss(score_0, v1) 0.27786765\n",
            "self.loss(score_0, v2) 0.34361523\n",
            "self.loss(score_2, v3) 0.05634483\n",
            "loss tensor(0.8043, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.065181136\n",
            "self.loss(score_0, v1) 0.30474654\n",
            "self.loss(score_0, v2) 0.366713\n",
            "self.loss(score_2, v3) 0.117373824\n",
            "loss tensor(0.9127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.20531243\n",
            "self.loss(score_0, v1) 0.3089199\n",
            "self.loss(score_0, v2) 0.20504208\n",
            "self.loss(score_2, v3) 0.07058752\n",
            "loss tensor(0.8252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.116852984\n",
            "self.loss(score_0, v1) 0.1321128\n",
            "self.loss(score_0, v2) 0.10728089\n",
            "self.loss(score_2, v3) 0.035461444\n",
            "loss tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07821272\n",
            "self.loss(score_0, v1) 0.103670575\n",
            "self.loss(score_0, v2) 0.11808586\n",
            "self.loss(score_2, v3) 0.04860275\n",
            "loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05211153\n",
            "self.loss(score_0, v1) 0.062051944\n",
            "self.loss(score_0, v2) 0.06241129\n",
            "self.loss(score_2, v3) 0.033615727\n",
            "loss tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.071215354\n",
            "self.loss(score_0, v1) 0.16751269\n",
            "self.loss(score_0, v2) 0.21961188\n",
            "self.loss(score_2, v3) 0.04091466\n",
            "loss tensor(0.5197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15457934\n",
            "self.loss(score_0, v1) 0.5311701\n",
            "self.loss(score_0, v2) 0.33409625\n",
            "self.loss(score_2, v3) 0.049819343\n",
            "loss tensor(1.0946, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.076415606\n",
            "self.loss(score_0, v1) 0.11634591\n",
            "self.loss(score_0, v2) 0.08690391\n",
            "self.loss(score_2, v3) 0.040741052\n",
            "loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.071765766\n",
            "self.loss(score_0, v1) 0.11826528\n",
            "self.loss(score_0, v2) 0.1175191\n",
            "self.loss(score_2, v3) 0.042227406\n",
            "loss tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055825055\n",
            "self.loss(score_0, v1) 0.40130472\n",
            "self.loss(score_0, v2) 1.077287\n",
            "self.loss(score_2, v3) 0.7750229\n",
            "loss tensor(2.6970, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06304327\n",
            "self.loss(score_0, v1) 0.09012121\n",
            "self.loss(score_0, v2) 0.103090666\n",
            "self.loss(score_2, v3) 0.050679415\n",
            "loss tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.083275534\n",
            "self.loss(score_0, v1) 0.08960406\n",
            "self.loss(score_0, v2) 0.16936256\n",
            "self.loss(score_2, v3) 0.20687252\n",
            "loss tensor(0.6526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.069508255\n",
            "self.loss(score_0, v1) 0.23897897\n",
            "self.loss(score_0, v2) 0.17691988\n",
            "self.loss(score_2, v3) 0.038451966\n",
            "loss tensor(0.5431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08500125\n",
            "self.loss(score_0, v1) 0.123512715\n",
            "self.loss(score_0, v2) 0.097946234\n",
            "self.loss(score_2, v3) 0.043693107\n",
            "loss tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.093510866\n",
            "self.loss(score_0, v1) 0.15329021\n",
            "self.loss(score_0, v2) 0.15568554\n",
            "self.loss(score_2, v3) 0.05381605\n",
            "loss tensor(0.4832, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0538369\n",
            "self.loss(score_0, v1) 0.06654712\n",
            "self.loss(score_0, v2) 0.08628511\n",
            "self.loss(score_2, v3) 0.036559504\n",
            "loss tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08746872\n",
            "self.loss(score_0, v1) 0.19958286\n",
            "self.loss(score_0, v2) 0.18394695\n",
            "self.loss(score_2, v3) 0.044835802\n",
            "loss tensor(0.5383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07764645\n",
            "self.loss(score_0, v1) 0.097809\n",
            "self.loss(score_0, v2) 0.078955024\n",
            "self.loss(score_2, v3) 0.040480316\n",
            "loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049144156\n",
            "self.loss(score_0, v1) 0.06615842\n",
            "self.loss(score_0, v2) 0.07864939\n",
            "self.loss(score_2, v3) 0.024319535\n",
            "loss tensor(0.2304, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04599387\n",
            "self.loss(score_0, v1) 0.08260329\n",
            "self.loss(score_0, v2) 0.046450846\n",
            "self.loss(score_2, v3) 0.023000736\n",
            "loss tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.4000719\n",
            "self.loss(score_0, v1) 0.34287465\n",
            "self.loss(score_0, v2) 0.19403465\n",
            "self.loss(score_2, v3) 0.11468751\n",
            "loss tensor(1.1090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0525144\n",
            "self.loss(score_0, v1) 0.069806\n",
            "self.loss(score_0, v2) 0.06458441\n",
            "self.loss(score_2, v3) 0.026535219\n",
            "loss tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.108002536\n",
            "self.loss(score_0, v1) 0.18613812\n",
            "self.loss(score_0, v2) 0.12194426\n",
            "self.loss(score_2, v3) 0.03734701\n",
            "loss tensor(0.4721, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.045989092\n",
            "self.loss(score_0, v1) 0.062445432\n",
            "self.loss(score_0, v2) 0.06655022\n",
            "self.loss(score_2, v3) 0.029995497\n",
            "loss tensor(0.2200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.054096334\n",
            "self.loss(score_0, v1) 0.082268216\n",
            "self.loss(score_0, v2) 0.13291156\n",
            "self.loss(score_2, v3) 0.040655956\n",
            "loss tensor(0.3303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.092766844\n",
            "self.loss(score_0, v1) 0.14943027\n",
            "self.loss(score_0, v2) 0.15312226\n",
            "self.loss(score_2, v3) 0.053282402\n",
            "loss tensor(0.4752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08935928\n",
            "self.loss(score_0, v1) 0.14178048\n",
            "self.loss(score_0, v2) 0.18204127\n",
            "self.loss(score_2, v3) 0.043997567\n",
            "loss tensor(0.4792, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.084380865\n",
            "self.loss(score_0, v1) 0.12807664\n",
            "self.loss(score_0, v2) 0.14416805\n",
            "self.loss(score_2, v3) 0.054815654\n",
            "loss tensor(0.4388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09678065\n",
            "self.loss(score_0, v1) 0.085158564\n",
            "self.loss(score_0, v2) 0.08737363\n",
            "self.loss(score_2, v3) 0.037478216\n",
            "loss tensor(0.3255, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07116648\n",
            "self.loss(score_0, v1) 0.09207048\n",
            "self.loss(score_0, v2) 0.0817144\n",
            "self.loss(score_2, v3) 0.049339384\n",
            "loss tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06549352\n",
            "self.loss(score_0, v1) 0.091611624\n",
            "self.loss(score_0, v2) 0.20152044\n",
            "self.loss(score_2, v3) 0.20299166\n",
            "loss tensor(0.6631, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.048311483\n",
            "self.loss(score_0, v1) 0.087045394\n",
            "self.loss(score_0, v2) 0.09083253\n",
            "self.loss(score_2, v3) 0.02950937\n",
            "loss tensor(0.2705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073147014\n",
            "self.loss(score_0, v1) 0.12136179\n",
            "self.loss(score_0, v2) 0.095847294\n",
            "self.loss(score_2, v3) 0.056126375\n",
            "loss tensor(0.3745, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06313212\n",
            "self.loss(score_0, v1) 0.13906962\n",
            "self.loss(score_0, v2) 0.18492417\n",
            "self.loss(score_2, v3) 0.084212184\n",
            "loss tensor(0.5134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056506503\n",
            "self.loss(score_0, v1) 0.3618206\n",
            "self.loss(score_0, v2) 0.5638367\n",
            "self.loss(score_2, v3) 0.18691911\n",
            "loss tensor(1.2625, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09457964\n",
            "self.loss(score_0, v1) 0.15421146\n",
            "self.loss(score_0, v2) 0.114671275\n",
            "self.loss(score_2, v3) 0.08260156\n",
            "loss tensor(0.4874, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.077420436\n",
            "self.loss(score_0, v1) 0.2571757\n",
            "self.loss(score_0, v2) 0.2578898\n",
            "self.loss(score_2, v3) 0.052375168\n",
            "loss tensor(0.6710, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059723977\n",
            "self.loss(score_0, v1) 0.07666997\n",
            "self.loss(score_0, v2) 0.07846532\n",
            "self.loss(score_2, v3) 0.03387933\n",
            "loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0685451\n",
            "self.loss(score_0, v1) 0.18225794\n",
            "self.loss(score_0, v2) 0.22684178\n",
            "self.loss(score_2, v3) 0.057459455\n",
            "loss tensor(0.5638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0638877\n",
            "self.loss(score_0, v1) 0.09490916\n",
            "self.loss(score_0, v2) 0.09407898\n",
            "self.loss(score_2, v3) 0.036112722\n",
            "loss tensor(0.3070, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.090530366\n",
            "self.loss(score_0, v1) 0.1393089\n",
            "self.loss(score_0, v2) 0.11512969\n",
            "self.loss(score_2, v3) 0.056313045\n",
            "loss tensor(0.4294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06288618\n",
            "self.loss(score_0, v1) 0.12810443\n",
            "self.loss(score_0, v2) 0.1563771\n",
            "self.loss(score_2, v3) 0.04630371\n",
            "loss tensor(0.4168, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0869443\n",
            "self.loss(score_0, v1) 0.11434308\n",
            "self.loss(score_0, v2) 0.087123394\n",
            "self.loss(score_2, v3) 0.04208092\n",
            "loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06850743\n",
            "self.loss(score_0, v1) 0.1100997\n",
            "self.loss(score_0, v2) 0.11113782\n",
            "self.loss(score_2, v3) 0.044262204\n",
            "loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08006252\n",
            "self.loss(score_0, v1) 0.5344862\n",
            "self.loss(score_0, v2) 0.4665258\n",
            "self.loss(score_2, v3) 0.057573665\n",
            "loss tensor(1.1674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06684596\n",
            "self.loss(score_0, v1) 0.097103454\n",
            "self.loss(score_0, v2) 0.10608448\n",
            "self.loss(score_2, v3) 0.040391874\n",
            "loss tensor(0.3306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061876986\n",
            "self.loss(score_0, v1) 0.085146815\n",
            "self.loss(score_0, v2) 0.08685834\n",
            "self.loss(score_2, v3) 0.033517484\n",
            "loss tensor(0.2842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.089963734\n",
            "self.loss(score_0, v1) 0.27446902\n",
            "self.loss(score_0, v2) 0.22976308\n",
            "self.loss(score_2, v3) 0.052780017\n",
            "loss tensor(0.6734, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10873895\n",
            "self.loss(score_0, v1) 0.14087234\n",
            "self.loss(score_0, v2) 0.07614659\n",
            "self.loss(score_2, v3) 0.047889393\n",
            "loss tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.101445265\n",
            "self.loss(score_0, v1) 0.11212938\n",
            "self.loss(score_0, v2) 0.1180812\n",
            "self.loss(score_2, v3) 0.040371645\n",
            "loss tensor(0.3922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19937655\n",
            "self.loss(score_0, v1) 0.16802418\n",
            "self.loss(score_0, v2) 0.1343051\n",
            "self.loss(score_2, v3) 0.07344713\n",
            "loss tensor(0.6119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08805923\n",
            "self.loss(score_0, v1) 0.122344956\n",
            "self.loss(score_0, v2) 0.104817875\n",
            "self.loss(score_2, v3) 0.04615488\n",
            "loss tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11878053\n",
            "self.loss(score_0, v1) 0.19717921\n",
            "self.loss(score_0, v2) 0.08110886\n",
            "self.loss(score_2, v3) 0.04277876\n",
            "loss tensor(0.4612, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08109936\n",
            "self.loss(score_0, v1) 0.27968633\n",
            "self.loss(score_0, v2) 0.21689992\n",
            "self.loss(score_2, v3) 0.05269308\n",
            "loss tensor(0.6567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08854161\n",
            "self.loss(score_0, v1) 0.10508945\n",
            "self.loss(score_0, v2) 0.06979687\n",
            "self.loss(score_2, v3) 0.039256334\n",
            "loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10614012\n",
            "self.loss(score_0, v1) 0.15164466\n",
            "self.loss(score_0, v2) 0.08280779\n",
            "self.loss(score_2, v3) 0.0363098\n",
            "loss tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.063885145\n",
            "self.loss(score_0, v1) 0.08802763\n",
            "self.loss(score_0, v2) 0.115250774\n",
            "self.loss(score_2, v3) 0.05226613\n",
            "loss tensor(0.3456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.089194596\n",
            "self.loss(score_0, v1) 0.31343302\n",
            "self.loss(score_0, v2) 0.32256305\n",
            "self.loss(score_2, v3) 0.034742724\n",
            "loss tensor(0.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.046044484\n",
            "self.loss(score_0, v1) 0.08195527\n",
            "self.loss(score_0, v2) 0.09292202\n",
            "self.loss(score_2, v3) 0.033477068\n",
            "loss tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07377998\n",
            "self.loss(score_0, v1) 0.3613024\n",
            "self.loss(score_0, v2) 0.31680325\n",
            "self.loss(score_2, v3) 0.053248245\n",
            "loss tensor(0.8318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052866917\n",
            "self.loss(score_0, v1) 0.07394651\n",
            "self.loss(score_0, v2) 0.07879197\n",
            "self.loss(score_2, v3) 0.031964257\n",
            "loss tensor(0.2536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059774235\n",
            "self.loss(score_0, v1) 0.09737859\n",
            "self.loss(score_0, v2) 0.118726686\n",
            "self.loss(score_2, v3) 0.047644094\n",
            "loss tensor(0.3473, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19493815\n",
            "self.loss(score_0, v1) 0.19849542\n",
            "self.loss(score_0, v2) 0.15237334\n",
            "self.loss(score_2, v3) 0.12162224\n",
            "loss tensor(0.7282, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05285506\n",
            "self.loss(score_0, v1) 0.12690404\n",
            "self.loss(score_0, v2) 0.15033917\n",
            "self.loss(score_2, v3) 0.033938233\n",
            "loss tensor(0.3810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05147746\n",
            "self.loss(score_0, v1) 0.07128823\n",
            "self.loss(score_0, v2) 0.08439801\n",
            "self.loss(score_2, v3) 0.033169616\n",
            "loss tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08491258\n",
            "self.loss(score_0, v1) 0.15564887\n",
            "self.loss(score_0, v2) 0.14399926\n",
            "self.loss(score_2, v3) 0.05026945\n",
            "loss tensor(0.4600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10802073\n",
            "self.loss(score_0, v1) 0.5910595\n",
            "self.loss(score_0, v2) 0.56236696\n",
            "self.loss(score_2, v3) 0.040518165\n",
            "loss tensor(1.3222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09443417\n",
            "self.loss(score_0, v1) 0.11211825\n",
            "self.loss(score_0, v2) 0.08904105\n",
            "self.loss(score_2, v3) 0.051563654\n",
            "loss tensor(0.3729, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10987691\n",
            "self.loss(score_0, v1) 0.14762793\n",
            "self.loss(score_0, v2) 0.1305042\n",
            "self.loss(score_2, v3) 0.043038003\n",
            "loss tensor(0.4526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09027686\n",
            "self.loss(score_0, v1) 0.23002441\n",
            "self.loss(score_0, v2) 0.2707377\n",
            "self.loss(score_2, v3) 0.12407383\n",
            "loss tensor(0.7771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05842936\n",
            "self.loss(score_0, v1) 0.36750653\n",
            "self.loss(score_0, v2) 0.3869763\n",
            "self.loss(score_2, v3) 0.115014955\n",
            "loss tensor(0.9854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073767036\n",
            "self.loss(score_0, v1) 0.093700014\n",
            "self.loss(score_0, v2) 0.11018629\n",
            "self.loss(score_2, v3) 0.036389668\n",
            "loss tensor(0.3322, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.034063615\n",
            "self.loss(score_0, v1) 0.05590197\n",
            "self.loss(score_0, v2) 0.107229844\n",
            "self.loss(score_2, v3) 0.020318313\n",
            "loss tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07440496\n",
            "self.loss(score_0, v1) 0.09266377\n",
            "self.loss(score_0, v2) 0.08128019\n",
            "self.loss(score_2, v3) 0.04603746\n",
            "loss tensor(0.3174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.054625437\n",
            "self.loss(score_0, v1) 0.08419472\n",
            "self.loss(score_0, v2) 0.112046234\n",
            "self.loss(score_2, v3) 0.05004304\n",
            "loss tensor(0.3259, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057296272\n",
            "self.loss(score_0, v1) 0.06564801\n",
            "self.loss(score_0, v2) 0.060184997\n",
            "self.loss(score_2, v3) 0.037441146\n",
            "loss tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05425399\n",
            "self.loss(score_0, v1) 0.10104409\n",
            "self.loss(score_0, v2) 0.047770947\n",
            "self.loss(score_2, v3) 0.026996506\n",
            "loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07737007\n",
            "self.loss(score_0, v1) 0.09776144\n",
            "self.loss(score_0, v2) 0.079688504\n",
            "self.loss(score_2, v3) 0.042020094\n",
            "loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13555771\n",
            "self.loss(score_0, v1) 0.15449063\n",
            "self.loss(score_0, v2) 0.084449925\n",
            "self.loss(score_2, v3) 0.047214918\n",
            "loss tensor(0.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.042172827\n",
            "self.loss(score_0, v1) 0.062838\n",
            "self.loss(score_0, v2) 0.050244723\n",
            "self.loss(score_2, v3) 0.023102859\n",
            "loss tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07005538\n",
            "self.loss(score_0, v1) 0.14390586\n",
            "self.loss(score_0, v2) 0.20621397\n",
            "self.loss(score_2, v3) 0.054418277\n",
            "loss tensor(0.5018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22642326\n",
            "self.loss(score_0, v1) 0.28381115\n",
            "self.loss(score_0, v2) 0.061243728\n",
            "self.loss(score_2, v3) 0.029821435\n",
            "loss tensor(0.6162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06296614\n",
            "self.loss(score_0, v1) 0.08589122\n",
            "self.loss(score_0, v2) 0.09331366\n",
            "self.loss(score_2, v3) 0.034409348\n",
            "loss tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06393865\n",
            "self.loss(score_0, v1) 0.087212496\n",
            "self.loss(score_0, v2) 0.08342312\n",
            "self.loss(score_2, v3) 0.053463392\n",
            "loss tensor(0.3148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.085940376\n",
            "self.loss(score_0, v1) 0.21482496\n",
            "self.loss(score_0, v2) 0.24430896\n",
            "self.loss(score_2, v3) 0.047308903\n",
            "loss tensor(0.6160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07158578\n",
            "self.loss(score_0, v1) 0.16689582\n",
            "self.loss(score_0, v2) 0.116178334\n",
            "self.loss(score_2, v3) 0.034359198\n",
            "loss tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.106084295\n",
            "self.loss(score_0, v1) 0.18708691\n",
            "self.loss(score_0, v2) 0.11844244\n",
            "self.loss(score_2, v3) 0.035681784\n",
            "loss tensor(0.4651, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.115882434\n",
            "self.loss(score_0, v1) 0.15507357\n",
            "self.loss(score_0, v2) 0.09239991\n",
            "self.loss(score_2, v3) 0.0494319\n",
            "loss tensor(0.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04255981\n",
            "self.loss(score_0, v1) 0.12728332\n",
            "self.loss(score_0, v2) 0.18592636\n",
            "self.loss(score_2, v3) 0.022064334\n",
            "loss tensor(0.3889, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08586593\n",
            "self.loss(score_0, v1) 0.089412175\n",
            "self.loss(score_0, v2) 0.0675711\n",
            "self.loss(score_2, v3) 0.03481358\n",
            "loss tensor(0.2951, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06091988\n",
            "self.loss(score_0, v1) 0.0977875\n",
            "self.loss(score_0, v2) 0.13821602\n",
            "self.loss(score_2, v3) 0.039477557\n",
            "loss tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051915627\n",
            "self.loss(score_0, v1) 0.06485036\n",
            "self.loss(score_0, v2) 0.05978477\n",
            "self.loss(score_2, v3) 0.0315329\n",
            "loss tensor(0.2239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22511826\n",
            "self.loss(score_0, v1) 0.23626494\n",
            "self.loss(score_0, v2) 0.08710816\n",
            "self.loss(score_2, v3) 0.040972985\n",
            "loss tensor(0.6100, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06444735\n",
            "self.loss(score_0, v1) 0.061194938\n",
            "self.loss(score_0, v2) 0.06304892\n",
            "self.loss(score_2, v3) 0.035729043\n",
            "loss tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06434962\n",
            "self.loss(score_0, v1) 0.15581548\n",
            "self.loss(score_0, v2) 0.16789779\n",
            "self.loss(score_2, v3) 0.05036171\n",
            "loss tensor(0.4636, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08458232\n",
            "self.loss(score_0, v1) 0.2217007\n",
            "self.loss(score_0, v2) 0.61774963\n",
            "self.loss(score_2, v3) 0.5888774\n",
            "loss tensor(1.8073, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06312859\n",
            "self.loss(score_0, v1) 0.07395136\n",
            "self.loss(score_0, v2) 0.0674986\n",
            "self.loss(score_2, v3) 0.035969112\n",
            "loss tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2196898\n",
            "self.loss(score_0, v1) 0.2872826\n",
            "self.loss(score_0, v2) 0.19929142\n",
            "self.loss(score_2, v3) 0.040185887\n",
            "loss tensor(0.7665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.084791675\n",
            "self.loss(score_0, v1) 0.22714667\n",
            "self.loss(score_0, v2) 0.22181492\n",
            "self.loss(score_2, v3) 0.033327226\n",
            "loss tensor(0.5837, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07399161\n",
            "self.loss(score_0, v1) 0.12245112\n",
            "self.loss(score_0, v2) 0.14545631\n",
            "self.loss(score_2, v3) 0.050426662\n",
            "loss tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09316867\n",
            "self.loss(score_0, v1) 0.09119079\n",
            "self.loss(score_0, v2) 0.052290294\n",
            "self.loss(score_2, v3) 0.028793499\n",
            "loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07527792\n",
            "self.loss(score_0, v1) 0.17062734\n",
            "self.loss(score_0, v2) 0.16267125\n",
            "self.loss(score_2, v3) 0.03736831\n",
            "loss tensor(0.4646, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18191887\n",
            "self.loss(score_0, v1) 0.21583068\n",
            "self.loss(score_0, v2) 0.09231845\n",
            "self.loss(score_2, v3) 0.03872279\n",
            "loss tensor(0.5482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056225557\n",
            "self.loss(score_0, v1) 0.2000844\n",
            "self.loss(score_0, v2) 0.19037777\n",
            "self.loss(score_2, v3) 0.039112285\n",
            "loss tensor(0.5054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17025182\n",
            "self.loss(score_0, v1) 0.18212941\n",
            "self.loss(score_0, v2) 0.14278701\n",
            "self.loss(score_2, v3) 0.03990642\n",
            "loss tensor(0.5550, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06291189\n",
            "self.loss(score_0, v1) 0.11698333\n",
            "self.loss(score_0, v2) 0.11456433\n",
            "self.loss(score_2, v3) 0.036138073\n",
            "loss tensor(0.3487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08772304\n",
            "self.loss(score_0, v1) 0.094626896\n",
            "self.loss(score_0, v2) 0.080018155\n",
            "self.loss(score_2, v3) 0.042966384\n",
            "loss tensor(0.3268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08359709\n",
            "self.loss(score_0, v1) 0.12781121\n",
            "self.loss(score_0, v2) 0.1494372\n",
            "self.loss(score_2, v3) 0.041644186\n",
            "loss tensor(0.4233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2192007\n",
            "self.loss(score_0, v1) 0.44171947\n",
            "self.loss(score_0, v2) 0.48059553\n",
            "self.loss(score_2, v3) 0.18192734\n",
            "loss tensor(1.4144, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055854175\n",
            "self.loss(score_0, v1) 0.093868405\n",
            "self.loss(score_0, v2) 0.08772842\n",
            "self.loss(score_2, v3) 0.039911363\n",
            "loss tensor(0.2973, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17585075\n",
            "self.loss(score_0, v1) 0.2375483\n",
            "self.loss(score_0, v2) 0.17743737\n",
            "self.loss(score_2, v3) 0.035057984\n",
            "loss tensor(0.6434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07395366\n",
            "self.loss(score_0, v1) 0.08236838\n",
            "self.loss(score_0, v2) 0.07882449\n",
            "self.loss(score_2, v3) 0.05219584\n",
            "loss tensor(0.3134, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05706644\n",
            "self.loss(score_0, v1) 0.09392564\n",
            "self.loss(score_0, v2) 0.084177755\n",
            "self.loss(score_2, v3) 0.030289477\n",
            "loss tensor(0.2806, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06188717\n",
            "self.loss(score_0, v1) 0.09153464\n",
            "self.loss(score_0, v2) 0.08414253\n",
            "self.loss(score_2, v3) 0.047801048\n",
            "loss tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07935135\n",
            "self.loss(score_0, v1) 0.10043775\n",
            "self.loss(score_0, v2) 0.13776453\n",
            "self.loss(score_2, v3) 0.07804785\n",
            "loss tensor(0.4346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058345143\n",
            "self.loss(score_0, v1) 0.06378781\n",
            "self.loss(score_0, v2) 0.07585429\n",
            "self.loss(score_2, v3) 0.0359574\n",
            "loss tensor(0.2519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060312323\n",
            "self.loss(score_0, v1) 0.08315781\n",
            "self.loss(score_0, v2) 0.0837331\n",
            "self.loss(score_2, v3) 0.03255415\n",
            "loss tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06612948\n",
            "self.loss(score_0, v1) 0.6888305\n",
            "self.loss(score_0, v2) 0.71846914\n",
            "self.loss(score_2, v3) 0.051664602\n",
            "loss tensor(1.5509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07553162\n",
            "self.loss(score_0, v1) 0.1398752\n",
            "self.loss(score_0, v2) 0.106655754\n",
            "self.loss(score_2, v3) 0.038356375\n",
            "loss tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05437475\n",
            "self.loss(score_0, v1) 0.07767497\n",
            "self.loss(score_0, v2) 0.07204265\n",
            "self.loss(score_2, v3) 0.03882489\n",
            "loss tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07168249\n",
            "self.loss(score_0, v1) 0.108923376\n",
            "self.loss(score_0, v2) 0.11400419\n",
            "self.loss(score_2, v3) 0.042997595\n",
            "loss tensor(0.3591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0666057\n",
            "self.loss(score_0, v1) 0.12761545\n",
            "self.loss(score_0, v2) 0.07748001\n",
            "self.loss(score_2, v3) 0.043363355\n",
            "loss tensor(0.3367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059446715\n",
            "self.loss(score_0, v1) 0.15336545\n",
            "self.loss(score_0, v2) 0.17939682\n",
            "self.loss(score_2, v3) 0.03422619\n",
            "loss tensor(0.4435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07538991\n",
            "self.loss(score_0, v1) 0.15839669\n",
            "self.loss(score_0, v2) 0.15461415\n",
            "self.loss(score_2, v3) 0.032019664\n",
            "loss tensor(0.4364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07750154\n",
            "self.loss(score_0, v1) 0.25881502\n",
            "self.loss(score_0, v2) 0.25900888\n",
            "self.loss(score_2, v3) 0.04570884\n",
            "loss tensor(0.6639, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08372433\n",
            "self.loss(score_0, v1) 0.34704313\n",
            "self.loss(score_0, v2) 0.26307404\n",
            "self.loss(score_2, v3) 0.058562264\n",
            "loss tensor(0.7817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1515053\n",
            "self.loss(score_0, v1) 0.26915842\n",
            "self.loss(score_0, v2) 0.32182458\n",
            "self.loss(score_2, v3) 0.15379961\n",
            "loss tensor(0.9732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14529435\n",
            "self.loss(score_0, v1) 0.33592322\n",
            "self.loss(score_0, v2) 0.46908745\n",
            "self.loss(score_2, v3) 0.035792835\n",
            "loss tensor(1.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07723349\n",
            "self.loss(score_0, v1) 0.3351884\n",
            "self.loss(score_0, v2) 0.31487498\n",
            "self.loss(score_2, v3) 0.051673986\n",
            "loss tensor(0.8048, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0809358\n",
            "self.loss(score_0, v1) 0.11119083\n",
            "self.loss(score_0, v2) 0.07562541\n",
            "self.loss(score_2, v3) 0.035455868\n",
            "loss tensor(0.3209, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09684889\n",
            "self.loss(score_0, v1) 0.111921206\n",
            "self.loss(score_0, v2) 0.08214495\n",
            "self.loss(score_2, v3) 0.033246044\n",
            "loss tensor(0.3408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.039106585\n",
            "self.loss(score_0, v1) 0.052663755\n",
            "self.loss(score_0, v2) 0.055182762\n",
            "self.loss(score_2, v3) 0.024102848\n",
            "loss tensor(0.1831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05518917\n",
            "self.loss(score_0, v1) 0.1445681\n",
            "self.loss(score_0, v2) 0.22473721\n",
            "self.loss(score_2, v3) 0.03290563\n",
            "loss tensor(0.4739, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.20477703\n",
            "self.loss(score_0, v1) 0.2571439\n",
            "self.loss(score_0, v2) 0.09465219\n",
            "self.loss(score_2, v3) 0.042413276\n",
            "loss tensor(0.6202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06183427\n",
            "self.loss(score_0, v1) 0.1860631\n",
            "self.loss(score_0, v2) 0.19524997\n",
            "self.loss(score_2, v3) 0.048868343\n",
            "loss tensor(0.5164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09862723\n",
            "self.loss(score_0, v1) 0.1723329\n",
            "self.loss(score_0, v2) 0.12872829\n",
            "self.loss(score_2, v3) 0.037056584\n",
            "loss tensor(0.4553, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.024698157\n",
            "self.loss(score_0, v1) 0.079528846\n",
            "self.loss(score_0, v2) 0.10389757\n",
            "self.loss(score_2, v3) 0.03916653\n",
            "loss tensor(0.2669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09661809\n",
            "self.loss(score_0, v1) 0.23936407\n",
            "self.loss(score_0, v2) 0.1663243\n",
            "self.loss(score_2, v3) 0.03353756\n",
            "loss tensor(0.5526, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07539192\n",
            "self.loss(score_0, v1) 0.09361796\n",
            "self.loss(score_0, v2) 0.08181278\n",
            "self.loss(score_2, v3) 0.040782887\n",
            "loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06125921\n",
            "self.loss(score_0, v1) 0.14440234\n",
            "self.loss(score_0, v2) 0.14830504\n",
            "self.loss(score_2, v3) 0.045086965\n",
            "loss tensor(0.4216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06815922\n",
            "self.loss(score_0, v1) 0.089773595\n",
            "self.loss(score_0, v2) 0.11248124\n",
            "self.loss(score_2, v3) 0.0553565\n",
            "loss tensor(0.3534, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.048482183\n",
            "self.loss(score_0, v1) 0.16018331\n",
            "self.loss(score_0, v2) 0.096357554\n",
            "self.loss(score_2, v3) 0.030445818\n",
            "loss tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075383134\n",
            "self.loss(score_0, v1) 0.37142092\n",
            "self.loss(score_0, v2) 0.31939882\n",
            "self.loss(score_2, v3) 0.03732356\n",
            "loss tensor(0.8222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058188796\n",
            "self.loss(score_0, v1) 0.097026266\n",
            "self.loss(score_0, v2) 0.057240307\n",
            "self.loss(score_2, v3) 0.032895382\n",
            "loss tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04984503\n",
            "self.loss(score_0, v1) 0.06833227\n",
            "self.loss(score_0, v2) 0.06872548\n",
            "self.loss(score_2, v3) 0.025627095\n",
            "loss tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.097658746\n",
            "self.loss(score_0, v1) 0.081070416\n",
            "self.loss(score_0, v2) 0.087544195\n",
            "self.loss(score_2, v3) 0.043187845\n",
            "loss tensor(0.3311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1985325\n",
            "self.loss(score_0, v1) 0.1798188\n",
            "self.loss(score_0, v2) 0.09015985\n",
            "self.loss(score_2, v3) 0.052017536\n",
            "loss tensor(0.5465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11226118\n",
            "self.loss(score_0, v1) 0.14241941\n",
            "self.loss(score_0, v2) 0.116680555\n",
            "self.loss(score_2, v3) 0.041602805\n",
            "loss tensor(0.4338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07954739\n",
            "self.loss(score_0, v1) 0.091172546\n",
            "self.loss(score_0, v2) 0.10885018\n",
            "self.loss(score_2, v3) 0.05467214\n",
            "loss tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.067081966\n",
            "self.loss(score_0, v1) 0.11497208\n",
            "self.loss(score_0, v2) 0.11849977\n",
            "self.loss(score_2, v3) 0.041022833\n",
            "loss tensor(0.3621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049233433\n",
            "self.loss(score_0, v1) 0.0659984\n",
            "self.loss(score_0, v2) 0.059550103\n",
            "self.loss(score_2, v3) 0.024516815\n",
            "loss tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08638389\n",
            "self.loss(score_0, v1) 0.4391724\n",
            "self.loss(score_0, v2) 0.44060987\n",
            "self.loss(score_2, v3) 0.057531927\n",
            "loss tensor(1.0525, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11824494\n",
            "self.loss(score_0, v1) 0.15272956\n",
            "self.loss(score_0, v2) 0.094810635\n",
            "self.loss(score_2, v3) 0.039210387\n",
            "loss tensor(0.4246, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0672023\n",
            "self.loss(score_0, v1) 0.097503714\n",
            "self.loss(score_0, v2) 0.087722346\n",
            "self.loss(score_2, v3) 0.050691843\n",
            "loss tensor(0.3285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14462458\n",
            "self.loss(score_0, v1) 0.481698\n",
            "self.loss(score_0, v2) 0.39048713\n",
            "self.loss(score_2, v3) 0.048325922\n",
            "loss tensor(1.0893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060641415\n",
            "self.loss(score_0, v1) 0.13947794\n",
            "self.loss(score_0, v2) 0.1901475\n",
            "self.loss(score_2, v3) 0.04610328\n",
            "loss tensor(0.4594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1334202\n",
            "self.loss(score_0, v1) 0.18174292\n",
            "self.loss(score_0, v2) 0.1966291\n",
            "self.loss(score_2, v3) 0.0476717\n",
            "loss tensor(0.5833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08100246\n",
            "self.loss(score_0, v1) 0.11464396\n",
            "self.loss(score_0, v2) 0.114150934\n",
            "self.loss(score_2, v3) 0.037204042\n",
            "loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13979183\n",
            "self.loss(score_0, v1) 0.21111709\n",
            "self.loss(score_0, v2) 0.1512156\n",
            "self.loss(score_2, v3) 0.049411207\n",
            "loss tensor(0.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09139412\n",
            "self.loss(score_0, v1) 0.13140684\n",
            "self.loss(score_0, v2) 0.12592982\n",
            "self.loss(score_2, v3) 0.035332743\n",
            "loss tensor(0.4017, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06123717\n",
            "self.loss(score_0, v1) 0.09235881\n",
            "self.loss(score_0, v2) 0.0965206\n",
            "self.loss(score_2, v3) 0.037060384\n",
            "loss tensor(0.3057, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21634041\n",
            "self.loss(score_0, v1) 0.15714182\n",
            "self.loss(score_0, v2) 0.1292219\n",
            "self.loss(score_2, v3) 0.038374834\n",
            "loss tensor(0.5603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060418658\n",
            "self.loss(score_0, v1) 0.24427724\n",
            "self.loss(score_0, v2) 0.21545343\n",
            "self.loss(score_2, v3) 0.03641522\n",
            "loss tensor(0.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09167975\n",
            "self.loss(score_0, v1) 0.09581244\n",
            "self.loss(score_0, v2) 0.0719091\n",
            "self.loss(score_2, v3) 0.041866735\n",
            "loss tensor(0.3222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08625679\n",
            "self.loss(score_0, v1) 0.13240014\n",
            "self.loss(score_0, v2) 0.09112716\n",
            "self.loss(score_2, v3) 0.044011224\n",
            "loss tensor(0.3758, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10660852\n",
            "self.loss(score_0, v1) 0.17246749\n",
            "self.loss(score_0, v2) 0.22144903\n",
            "self.loss(score_2, v3) 0.050407227\n",
            "loss tensor(0.5761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12569244\n",
            "self.loss(score_0, v1) 0.19767828\n",
            "self.loss(score_0, v2) 0.15297034\n",
            "self.loss(score_2, v3) 0.0443133\n",
            "loss tensor(0.5428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14700924\n",
            "self.loss(score_0, v1) 0.13946268\n",
            "self.loss(score_0, v2) 0.07016829\n",
            "self.loss(score_2, v3) 0.031780608\n",
            "loss tensor(0.4043, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.076875076\n",
            "self.loss(score_0, v1) 0.091214515\n",
            "self.loss(score_0, v2) 0.10880566\n",
            "self.loss(score_2, v3) 0.0405057\n",
            "loss tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060275774\n",
            "self.loss(score_0, v1) 0.07521787\n",
            "self.loss(score_0, v2) 0.07659554\n",
            "self.loss(score_2, v3) 0.03696387\n",
            "loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.047764268\n",
            "self.loss(score_0, v1) 0.070182875\n",
            "self.loss(score_0, v2) 0.09496905\n",
            "self.loss(score_2, v3) 0.032535635\n",
            "loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11621276\n",
            "self.loss(score_0, v1) 0.25486675\n",
            "self.loss(score_0, v2) 0.27634034\n",
            "self.loss(score_2, v3) 0.04297467\n",
            "loss tensor(0.7119, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07023783\n",
            "self.loss(score_0, v1) 0.3024109\n",
            "self.loss(score_0, v2) 0.3294196\n",
            "self.loss(score_2, v3) 0.05090387\n",
            "loss tensor(0.7784, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07464806\n",
            "self.loss(score_0, v1) 0.07285679\n",
            "self.loss(score_0, v2) 0.06798414\n",
            "self.loss(score_2, v3) 0.035630036\n",
            "loss tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06999897\n",
            "self.loss(score_0, v1) 0.2143701\n",
            "self.loss(score_0, v2) 0.26444367\n",
            "self.loss(score_2, v3) 0.031904913\n",
            "loss tensor(0.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.146453\n",
            "self.loss(score_0, v1) 0.16342117\n",
            "self.loss(score_0, v2) 0.13722655\n",
            "self.loss(score_2, v3) 0.20516498\n",
            "loss tensor(0.7548, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051371448\n",
            "self.loss(score_0, v1) 0.08477331\n",
            "self.loss(score_0, v2) 0.14366694\n",
            "self.loss(score_2, v3) 0.040072814\n",
            "loss tensor(0.3399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17670529\n",
            "self.loss(score_0, v1) 0.115901075\n",
            "self.loss(score_0, v2) 0.092963465\n",
            "self.loss(score_2, v3) 0.04605095\n",
            "loss tensor(0.4546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10189047\n",
            "self.loss(score_0, v1) 0.11411877\n",
            "self.loss(score_0, v2) 0.07725282\n",
            "self.loss(score_2, v3) 0.040786695\n",
            "loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13332537\n",
            "self.loss(score_0, v1) 0.16147196\n",
            "self.loss(score_0, v2) 0.102284655\n",
            "self.loss(score_2, v3) 0.03788923\n",
            "loss tensor(0.4539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06328952\n",
            "self.loss(score_0, v1) 0.060759977\n",
            "self.loss(score_0, v2) 0.049714\n",
            "self.loss(score_2, v3) 0.023276614\n",
            "loss tensor(0.2087, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06218622\n",
            "self.loss(score_0, v1) 0.09043553\n",
            "self.loss(score_0, v2) 0.10244161\n",
            "self.loss(score_2, v3) 0.039922073\n",
            "loss tensor(0.3149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.054170977\n",
            "self.loss(score_0, v1) 0.07531089\n",
            "self.loss(score_0, v2) 0.06430989\n",
            "self.loss(score_2, v3) 0.0353943\n",
            "loss tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056121457\n",
            "self.loss(score_0, v1) 0.32247034\n",
            "self.loss(score_0, v2) 0.34609348\n",
            "self.loss(score_2, v3) 0.035856046\n",
            "loss tensor(0.7785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059004765\n",
            "self.loss(score_0, v1) 0.07902974\n",
            "self.loss(score_0, v2) 0.0983588\n",
            "self.loss(score_2, v3) 0.045484547\n",
            "loss tensor(0.3046, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1425466\n",
            "self.loss(score_0, v1) 0.17162031\n",
            "self.loss(score_0, v2) 0.07878491\n",
            "self.loss(score_2, v3) 0.036445484\n",
            "loss tensor(0.4476, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.095536344\n",
            "self.loss(score_0, v1) 0.107621334\n",
            "self.loss(score_0, v2) 0.07746908\n",
            "self.loss(score_2, v3) 0.046465635\n",
            "loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06957745\n",
            "self.loss(score_0, v1) 0.09988938\n",
            "self.loss(score_0, v2) 0.24091241\n",
            "self.loss(score_2, v3) 0.22883591\n",
            "loss tensor(0.7536, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06523515\n",
            "self.loss(score_0, v1) 0.106804155\n",
            "self.loss(score_0, v2) 0.092473805\n",
            "self.loss(score_2, v3) 0.045389496\n",
            "loss tensor(0.3326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056035213\n",
            "self.loss(score_0, v1) 0.07514879\n",
            "self.loss(score_0, v2) 0.06706976\n",
            "self.loss(score_2, v3) 0.03896807\n",
            "loss tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09804652\n",
            "self.loss(score_0, v1) 0.1043748\n",
            "self.loss(score_0, v2) 0.073099084\n",
            "self.loss(score_2, v3) 0.036784764\n",
            "loss tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06659262\n",
            "self.loss(score_0, v1) 0.07325114\n",
            "self.loss(score_0, v2) 0.084454015\n",
            "self.loss(score_2, v3) 0.034138013\n",
            "loss tensor(0.2755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056853343\n",
            "self.loss(score_0, v1) 0.160061\n",
            "self.loss(score_0, v2) 0.1810777\n",
            "self.loss(score_2, v3) 0.048716933\n",
            "loss tensor(0.4711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05985807\n",
            "self.loss(score_0, v1) 0.11630076\n",
            "self.loss(score_0, v2) 0.12398404\n",
            "self.loss(score_2, v3) 0.032202117\n",
            "loss tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05063962\n",
            "self.loss(score_0, v1) 0.10850911\n",
            "self.loss(score_0, v2) 0.095050074\n",
            "self.loss(score_2, v3) 0.028514873\n",
            "loss tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08283373\n",
            "self.loss(score_0, v1) 0.27368355\n",
            "self.loss(score_0, v2) 0.24796985\n",
            "self.loss(score_2, v3) 0.040723804\n",
            "loss tensor(0.6656, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12924415\n",
            "self.loss(score_0, v1) 0.18650635\n",
            "self.loss(score_0, v2) 0.10969311\n",
            "self.loss(score_2, v3) 0.050211716\n",
            "loss tensor(0.5008, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06517654\n",
            "self.loss(score_0, v1) 0.120129995\n",
            "self.loss(score_0, v2) 0.17126538\n",
            "self.loss(score_2, v3) 0.09037196\n",
            "loss tensor(0.4921, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.082797684\n",
            "self.loss(score_0, v1) 0.07638539\n",
            "self.loss(score_0, v2) 0.11283915\n",
            "self.loss(score_2, v3) 0.041076604\n",
            "loss tensor(0.3336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08408219\n",
            "self.loss(score_0, v1) 0.10582058\n",
            "self.loss(score_0, v2) 0.068395935\n",
            "self.loss(score_2, v3) 0.035036724\n",
            "loss tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08403445\n",
            "self.loss(score_0, v1) 0.1472028\n",
            "self.loss(score_0, v2) 0.15576886\n",
            "self.loss(score_2, v3) 0.037040673\n",
            "loss tensor(0.4426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2405032\n",
            "self.loss(score_0, v1) 0.51728123\n",
            "self.loss(score_0, v2) 0.43250886\n",
            "self.loss(score_2, v3) 0.02243465\n",
            "loss tensor(1.2239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11366922\n",
            "self.loss(score_0, v1) 0.1190681\n",
            "self.loss(score_0, v2) 0.06462824\n",
            "self.loss(score_2, v3) 0.028628312\n",
            "loss tensor(0.3403, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11601994\n",
            "self.loss(score_0, v1) 0.21444263\n",
            "self.loss(score_0, v2) 0.2233118\n",
            "self.loss(score_2, v3) 0.035262108\n",
            "loss tensor(0.6067, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03479038\n",
            "self.loss(score_0, v1) 0.20394954\n",
            "self.loss(score_0, v2) 0.21805136\n",
            "self.loss(score_2, v3) 0.024203105\n",
            "loss tensor(0.4931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0869892\n",
            "self.loss(score_0, v1) 0.14747922\n",
            "self.loss(score_0, v2) 0.14440908\n",
            "self.loss(score_2, v3) 0.039451607\n",
            "loss tensor(0.4381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07061933\n",
            "self.loss(score_0, v1) 0.10234541\n",
            "self.loss(score_0, v2) 0.10998283\n",
            "self.loss(score_2, v3) 0.045687344\n",
            "loss tensor(0.3515, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05273589\n",
            "self.loss(score_0, v1) 0.08549596\n",
            "self.loss(score_0, v2) 0.087046504\n",
            "self.loss(score_2, v3) 0.03163607\n",
            "loss tensor(0.2727, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06989216\n",
            "self.loss(score_0, v1) 0.10181694\n",
            "self.loss(score_0, v2) 0.0865406\n",
            "self.loss(score_2, v3) 0.03845992\n",
            "loss tensor(0.3159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075147785\n",
            "self.loss(score_0, v1) 0.12156329\n",
            "self.loss(score_0, v2) 0.15364943\n",
            "self.loss(score_2, v3) 0.034518793\n",
            "loss tensor(0.4021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058777377\n",
            "self.loss(score_0, v1) 0.0780996\n",
            "self.loss(score_0, v2) 0.09752257\n",
            "self.loss(score_2, v3) 0.04997094\n",
            "loss tensor(0.3094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.076533414\n",
            "self.loss(score_0, v1) 0.09989686\n",
            "self.loss(score_0, v2) 0.096935116\n",
            "self.loss(score_2, v3) 0.0383\n",
            "loss tensor(0.3308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059066515\n",
            "self.loss(score_0, v1) 0.076205164\n",
            "self.loss(score_0, v2) 0.11068765\n",
            "self.loss(score_2, v3) 0.04522781\n",
            "loss tensor(0.3138, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07985958\n",
            "self.loss(score_0, v1) 0.21504767\n",
            "self.loss(score_0, v2) 0.21650614\n",
            "self.loss(score_2, v3) 0.04510004\n",
            "loss tensor(0.5791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 0.4968840029019459, Train Accuracy : 0.9988629849435375\n",
            " Validation Accuracy : 6.59979548110974\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.05006309\n",
            "self.loss(score_0, v1) 0.13855608\n",
            "self.loss(score_0, v2) 0.25814763\n",
            "self.loss(score_2, v3) 0.06885594\n",
            "loss tensor(0.5501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.045497555\n",
            "self.loss(score_0, v1) 0.07992654\n",
            "self.loss(score_0, v2) 0.16821735\n",
            "self.loss(score_2, v3) 0.08945937\n",
            "loss tensor(0.4278, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22900373\n",
            "self.loss(score_0, v1) 0.28742218\n",
            "self.loss(score_0, v2) 0.1552105\n",
            "self.loss(score_2, v3) 0.03030863\n",
            "loss tensor(0.7171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16354954\n",
            "self.loss(score_0, v1) 0.23673902\n",
            "self.loss(score_0, v2) 0.1514683\n",
            "self.loss(score_2, v3) 0.040977698\n",
            "loss tensor(0.6132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06326116\n",
            "self.loss(score_0, v1) 0.19632423\n",
            "self.loss(score_0, v2) 0.20889212\n",
            "self.loss(score_2, v3) 0.02990904\n",
            "loss tensor(0.5133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055478998\n",
            "self.loss(score_0, v1) 0.069977336\n",
            "self.loss(score_0, v2) 0.061738305\n",
            "self.loss(score_2, v3) 0.03317234\n",
            "loss tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05368979\n",
            "self.loss(score_0, v1) 0.07135995\n",
            "self.loss(score_0, v2) 0.066817336\n",
            "self.loss(score_2, v3) 0.034341116\n",
            "loss tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07225344\n",
            "self.loss(score_0, v1) 0.081912294\n",
            "self.loss(score_0, v2) 0.054750115\n",
            "self.loss(score_2, v3) 0.027292712\n",
            "loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06373264\n",
            "self.loss(score_0, v1) 0.08660973\n",
            "self.loss(score_0, v2) 0.09822353\n",
            "self.loss(score_2, v3) 0.038446553\n",
            "loss tensor(0.3062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05711114\n",
            "self.loss(score_0, v1) 0.07519646\n",
            "self.loss(score_0, v2) 0.111283325\n",
            "self.loss(score_2, v3) 0.047642913\n",
            "loss tensor(0.3151, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.096805796\n",
            "self.loss(score_0, v1) 0.37606743\n",
            "self.loss(score_0, v2) 0.28657937\n",
            "self.loss(score_2, v3) 0.038128033\n",
            "loss tensor(0.8166, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07258152\n",
            "self.loss(score_0, v1) 0.09803659\n",
            "self.loss(score_0, v2) 0.096370414\n",
            "self.loss(score_2, v3) 0.03400826\n",
            "loss tensor(0.3180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07660167\n",
            "self.loss(score_0, v1) 0.16282347\n",
            "self.loss(score_0, v2) 0.15509053\n",
            "self.loss(score_2, v3) 0.035309777\n",
            "loss tensor(0.4475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10232507\n",
            "self.loss(score_0, v1) 0.14442874\n",
            "self.loss(score_0, v2) 0.16101678\n",
            "self.loss(score_2, v3) 0.03700097\n",
            "loss tensor(0.4633, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056449603\n",
            "self.loss(score_0, v1) 0.08285867\n",
            "self.loss(score_0, v2) 0.09331853\n",
            "self.loss(score_2, v3) 0.03144262\n",
            "loss tensor(0.2798, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19554906\n",
            "self.loss(score_0, v1) 0.17321204\n",
            "self.loss(score_0, v2) 0.082958505\n",
            "self.loss(score_2, v3) 0.049585264\n",
            "loss tensor(0.5261, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07750408\n",
            "self.loss(score_0, v1) 0.106507346\n",
            "self.loss(score_0, v2) 0.08395278\n",
            "self.loss(score_2, v3) 0.03962621\n",
            "loss tensor(0.3274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06219913\n",
            "self.loss(score_0, v1) 0.105465546\n",
            "self.loss(score_0, v2) 0.09089597\n",
            "self.loss(score_2, v3) 0.03693631\n",
            "loss tensor(0.3140, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.32136965\n",
            "self.loss(score_0, v1) 0.33141413\n",
            "self.loss(score_0, v2) 0.2439361\n",
            "self.loss(score_2, v3) 0.046699367\n",
            "loss tensor(0.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.087241314\n",
            "self.loss(score_0, v1) 0.13799074\n",
            "self.loss(score_0, v2) 0.1730939\n",
            "self.loss(score_2, v3) 0.048094623\n",
            "loss tensor(0.4705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07719549\n",
            "self.loss(score_0, v1) 0.10561958\n",
            "self.loss(score_0, v2) 0.093490906\n",
            "self.loss(score_2, v3) 0.037158683\n",
            "loss tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12476629\n",
            "self.loss(score_0, v1) 0.13188401\n",
            "self.loss(score_0, v2) 0.073587395\n",
            "self.loss(score_2, v3) 0.044439018\n",
            "loss tensor(0.3969, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0496628\n",
            "self.loss(score_0, v1) 0.0750432\n",
            "self.loss(score_0, v2) 0.16338284\n",
            "self.loss(score_2, v3) 0.041457165\n",
            "loss tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049347013\n",
            "self.loss(score_0, v1) 0.065627545\n",
            "self.loss(score_0, v2) 0.0791537\n",
            "self.loss(score_2, v3) 0.029030787\n",
            "loss tensor(0.2377, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058062598\n",
            "self.loss(score_0, v1) 0.0714937\n",
            "self.loss(score_0, v2) 0.066208236\n",
            "self.loss(score_2, v3) 0.031871412\n",
            "loss tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060181063\n",
            "self.loss(score_0, v1) 0.09360878\n",
            "self.loss(score_0, v2) 0.098061725\n",
            "self.loss(score_2, v3) 0.043814182\n",
            "loss tensor(0.3176, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08397388\n",
            "self.loss(score_0, v1) 0.12874094\n",
            "self.loss(score_0, v2) 0.093749836\n",
            "self.loss(score_2, v3) 0.039439455\n",
            "loss tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05349496\n",
            "self.loss(score_0, v1) 0.08278273\n",
            "self.loss(score_0, v2) 0.08473785\n",
            "self.loss(score_2, v3) 0.04353869\n",
            "loss tensor(0.2863, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.083342016\n",
            "self.loss(score_0, v1) 0.1980715\n",
            "self.loss(score_0, v2) 0.2108807\n",
            "self.loss(score_2, v3) 0.051199306\n",
            "loss tensor(0.5691, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05737964\n",
            "self.loss(score_0, v1) 0.07526071\n",
            "self.loss(score_0, v2) 0.098213084\n",
            "self.loss(score_2, v3) 0.040144198\n",
            "loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07350101\n",
            "self.loss(score_0, v1) 0.30578786\n",
            "self.loss(score_0, v2) 0.238526\n",
            "self.loss(score_2, v3) 0.035425317\n",
            "loss tensor(0.6710, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06467315\n",
            "self.loss(score_0, v1) 0.07995953\n",
            "self.loss(score_0, v2) 0.060202166\n",
            "self.loss(score_2, v3) 0.037741724\n",
            "loss tensor(0.2614, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.39806905\n",
            "self.loss(score_0, v1) 0.506399\n",
            "self.loss(score_0, v2) 0.624602\n",
            "self.loss(score_2, v3) 0.88816017\n",
            "loss tensor(2.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07372619\n",
            "self.loss(score_0, v1) 0.074771695\n",
            "self.loss(score_0, v2) 0.07186254\n",
            "self.loss(score_2, v3) 0.03992893\n",
            "loss tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059019204\n",
            "self.loss(score_0, v1) 0.09095287\n",
            "self.loss(score_0, v2) 0.10989438\n",
            "self.loss(score_2, v3) 0.04163587\n",
            "loss tensor(0.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06263661\n",
            "self.loss(score_0, v1) 0.10503367\n",
            "self.loss(score_0, v2) 0.084541224\n",
            "self.loss(score_2, v3) 0.04487823\n",
            "loss tensor(0.3195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057801496\n",
            "self.loss(score_0, v1) 0.081834964\n",
            "self.loss(score_0, v2) 0.07658547\n",
            "self.loss(score_2, v3) 0.047599405\n",
            "loss tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.062381465\n",
            "self.loss(score_0, v1) 0.14575455\n",
            "self.loss(score_0, v2) 0.17117812\n",
            "self.loss(score_2, v3) 0.04476426\n",
            "loss tensor(0.4465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13903733\n",
            "self.loss(score_0, v1) 0.16870083\n",
            "self.loss(score_0, v2) 0.07550922\n",
            "self.loss(score_2, v3) 0.04491898\n",
            "loss tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06720195\n",
            "self.loss(score_0, v1) 0.11582933\n",
            "self.loss(score_0, v2) 0.20303296\n",
            "self.loss(score_2, v3) 0.17703319\n",
            "loss tensor(0.6516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14593315\n",
            "self.loss(score_0, v1) 0.14460999\n",
            "self.loss(score_0, v2) 0.046263967\n",
            "self.loss(score_2, v3) 0.026532674\n",
            "loss tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.24513115\n",
            "self.loss(score_0, v1) 0.49493995\n",
            "self.loss(score_0, v2) 0.34736636\n",
            "self.loss(score_2, v3) 0.03270093\n",
            "loss tensor(1.1365, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06898473\n",
            "self.loss(score_0, v1) 0.089054175\n",
            "self.loss(score_0, v2) 0.090956144\n",
            "self.loss(score_2, v3) 0.05045816\n",
            "loss tensor(0.3247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049028963\n",
            "self.loss(score_0, v1) 0.070183136\n",
            "self.loss(score_0, v2) 0.08655069\n",
            "self.loss(score_2, v3) 0.035445627\n",
            "loss tensor(0.2589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06558456\n",
            "self.loss(score_0, v1) 0.07741616\n",
            "self.loss(score_0, v2) 0.10015092\n",
            "self.loss(score_2, v3) 0.041414797\n",
            "loss tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06087244\n",
            "self.loss(score_0, v1) 0.091136806\n",
            "self.loss(score_0, v2) 0.084143214\n",
            "self.loss(score_2, v3) 0.03317979\n",
            "loss tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.054563314\n",
            "self.loss(score_0, v1) 0.07964946\n",
            "self.loss(score_0, v2) 0.06984749\n",
            "self.loss(score_2, v3) 0.048201106\n",
            "loss tensor(0.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.071119614\n",
            "self.loss(score_0, v1) 0.20776387\n",
            "self.loss(score_0, v2) 0.21941286\n",
            "self.loss(score_2, v3) 0.03692944\n",
            "loss tensor(0.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051648848\n",
            "self.loss(score_0, v1) 0.053542208\n",
            "self.loss(score_0, v2) 0.07410407\n",
            "self.loss(score_2, v3) 0.036683846\n",
            "loss tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07142423\n",
            "self.loss(score_0, v1) 0.11487582\n",
            "self.loss(score_0, v2) 0.14012693\n",
            "self.loss(score_2, v3) 0.04795222\n",
            "loss tensor(0.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13788866\n",
            "self.loss(score_0, v1) 0.4563373\n",
            "self.loss(score_0, v2) 0.37156042\n",
            "self.loss(score_2, v3) 0.04942372\n",
            "loss tensor(1.0399, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053775806\n",
            "self.loss(score_0, v1) 0.07964206\n",
            "self.loss(score_0, v2) 0.06769625\n",
            "self.loss(score_2, v3) 0.037599638\n",
            "loss tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11423935\n",
            "self.loss(score_0, v1) 0.19184884\n",
            "self.loss(score_0, v2) 0.3480078\n",
            "self.loss(score_2, v3) 0.19864547\n",
            "loss tensor(0.9521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07934586\n",
            "self.loss(score_0, v1) 0.08267134\n",
            "self.loss(score_0, v2) 0.08234309\n",
            "self.loss(score_2, v3) 0.048040666\n",
            "loss tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.36457923\n",
            "self.loss(score_0, v1) 0.3685308\n",
            "self.loss(score_0, v2) 0.13036442\n",
            "self.loss(score_2, v3) 0.04889254\n",
            "loss tensor(0.9368, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07351567\n",
            "self.loss(score_0, v1) 0.119078554\n",
            "self.loss(score_0, v2) 0.11477545\n",
            "self.loss(score_2, v3) 0.04320001\n",
            "loss tensor(0.3722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.11317638\n",
            "self.loss(score_0, v1) 0.1563501\n",
            "self.loss(score_0, v2) 0.10238014\n",
            "self.loss(score_2, v3) 0.044818036\n",
            "loss tensor(0.4391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.064031586\n",
            "self.loss(score_0, v1) 0.25231478\n",
            "self.loss(score_0, v2) 0.20770447\n",
            "self.loss(score_2, v3) 0.04800656\n",
            "loss tensor(0.5961, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07182117\n",
            "self.loss(score_0, v1) 0.1051131\n",
            "self.loss(score_0, v2) 0.090973474\n",
            "self.loss(score_2, v3) 0.026226697\n",
            "loss tensor(0.3072, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0601635\n",
            "self.loss(score_0, v1) 0.07650893\n",
            "self.loss(score_0, v2) 0.062340092\n",
            "self.loss(score_2, v3) 0.03494263\n",
            "loss tensor(0.2514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04660357\n",
            "self.loss(score_0, v1) 0.20414312\n",
            "self.loss(score_0, v2) 0.14667954\n",
            "self.loss(score_2, v3) 0.01957146\n",
            "loss tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09538614\n",
            "self.loss(score_0, v1) 0.22069587\n",
            "self.loss(score_0, v2) 0.13256815\n",
            "self.loss(score_2, v3) 0.044005502\n",
            "loss tensor(0.5147, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06553139\n",
            "self.loss(score_0, v1) 0.07853724\n",
            "self.loss(score_0, v2) 0.07811973\n",
            "self.loss(score_2, v3) 0.039222255\n",
            "loss tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22352007\n",
            "self.loss(score_0, v1) 0.16978742\n",
            "self.loss(score_0, v2) 0.12790926\n",
            "self.loss(score_2, v3) 0.07700408\n",
            "loss tensor(0.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10898623\n",
            "self.loss(score_0, v1) 0.35474998\n",
            "self.loss(score_0, v2) 0.30202273\n",
            "self.loss(score_2, v3) 0.037220705\n",
            "loss tensor(0.8216, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13843308\n",
            "self.loss(score_0, v1) 0.1950409\n",
            "self.loss(score_0, v2) 0.213308\n",
            "self.loss(score_2, v3) 0.050278123\n",
            "loss tensor(0.6222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07566751\n",
            "self.loss(score_0, v1) 0.13764417\n",
            "self.loss(score_0, v2) 0.16696326\n",
            "self.loss(score_2, v3) 0.04549598\n",
            "loss tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061657768\n",
            "self.loss(score_0, v1) 0.07384757\n",
            "self.loss(score_0, v2) 0.100604706\n",
            "self.loss(score_2, v3) 0.04151623\n",
            "loss tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.083075896\n",
            "self.loss(score_0, v1) 0.10780025\n",
            "self.loss(score_0, v2) 0.07675243\n",
            "self.loss(score_2, v3) 0.03260604\n",
            "loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07024254\n",
            "self.loss(score_0, v1) 0.11957658\n",
            "self.loss(score_0, v2) 0.14513639\n",
            "self.loss(score_2, v3) 0.03449547\n",
            "loss tensor(0.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059236426\n",
            "self.loss(score_0, v1) 0.10372435\n",
            "self.loss(score_0, v2) 0.113736585\n",
            "self.loss(score_2, v3) 0.033740815\n",
            "loss tensor(0.3273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.32307133\n",
            "self.loss(score_0, v1) 0.7118641\n",
            "self.loss(score_0, v2) 0.40294284\n",
            "self.loss(score_2, v3) 0.0320503\n",
            "loss tensor(1.4860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08568641\n",
            "self.loss(score_0, v1) 0.13682994\n",
            "self.loss(score_0, v2) 0.119585656\n",
            "self.loss(score_2, v3) 0.043553315\n",
            "loss tensor(0.4074, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06698345\n",
            "self.loss(score_0, v1) 0.42260948\n",
            "self.loss(score_0, v2) 0.41648188\n",
            "self.loss(score_2, v3) 0.07138806\n",
            "loss tensor(1.0132, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053956337\n",
            "self.loss(score_0, v1) 0.072744735\n",
            "self.loss(score_0, v2) 0.08894574\n",
            "self.loss(score_2, v3) 0.032909743\n",
            "loss tensor(0.2650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050194383\n",
            "self.loss(score_0, v1) 0.060768794\n",
            "self.loss(score_0, v2) 0.069444835\n",
            "self.loss(score_2, v3) 0.030056436\n",
            "loss tensor(0.2255, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08119819\n",
            "self.loss(score_0, v1) 0.18656965\n",
            "self.loss(score_0, v2) 0.1739604\n",
            "self.loss(score_2, v3) 0.038957704\n",
            "loss tensor(0.5002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06616088\n",
            "self.loss(score_0, v1) 0.09767061\n",
            "self.loss(score_0, v2) 0.07288739\n",
            "self.loss(score_2, v3) 0.039289206\n",
            "loss tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06793037\n",
            "self.loss(score_0, v1) 0.17063583\n",
            "self.loss(score_0, v2) 0.13683715\n",
            "self.loss(score_2, v3) 0.035966285\n",
            "loss tensor(0.4294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04819758\n",
            "self.loss(score_0, v1) 0.08759514\n",
            "self.loss(score_0, v2) 0.057652224\n",
            "self.loss(score_2, v3) 0.026374012\n",
            "loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10607332\n",
            "self.loss(score_0, v1) 0.252876\n",
            "self.loss(score_0, v2) 0.25769818\n",
            "self.loss(score_2, v3) 0.030934587\n",
            "loss tensor(0.6630, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056441266\n",
            "self.loss(score_0, v1) 0.09424377\n",
            "self.loss(score_0, v2) 0.07475388\n",
            "self.loss(score_2, v3) 0.038475785\n",
            "loss tensor(0.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051791348\n",
            "self.loss(score_0, v1) 0.07327359\n",
            "self.loss(score_0, v2) 0.0557932\n",
            "self.loss(score_2, v3) 0.035147805\n",
            "loss tensor(0.2336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06997253\n",
            "self.loss(score_0, v1) 0.11049948\n",
            "self.loss(score_0, v2) 0.08415389\n",
            "self.loss(score_2, v3) 0.035060473\n",
            "loss tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058340244\n",
            "self.loss(score_0, v1) 0.31908095\n",
            "self.loss(score_0, v2) 0.252785\n",
            "self.loss(score_2, v3) 0.029782498\n",
            "loss tensor(0.6749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06898675\n",
            "self.loss(score_0, v1) 0.10934566\n",
            "self.loss(score_0, v2) 0.115500666\n",
            "self.loss(score_2, v3) 0.040746875\n",
            "loss tensor(0.3550, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06784762\n",
            "self.loss(score_0, v1) 0.3360411\n",
            "self.loss(score_0, v2) 0.3585227\n",
            "self.loss(score_2, v3) 0.18718217\n",
            "loss tensor(1.0432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07745104\n",
            "self.loss(score_0, v1) 0.113751225\n",
            "self.loss(score_0, v2) 0.11048388\n",
            "self.loss(score_2, v3) 0.030508885\n",
            "loss tensor(0.3474, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.048231486\n",
            "self.loss(score_0, v1) 0.06847091\n",
            "self.loss(score_0, v2) 0.08734553\n",
            "self.loss(score_2, v3) 0.041074794\n",
            "loss tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04815184\n",
            "self.loss(score_0, v1) 0.15828863\n",
            "self.loss(score_0, v2) 0.16986597\n",
            "self.loss(score_2, v3) 0.03648205\n",
            "loss tensor(0.4310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1267144\n",
            "self.loss(score_0, v1) 0.15635222\n",
            "self.loss(score_0, v2) 0.14881442\n",
            "self.loss(score_2, v3) 0.031813208\n",
            "loss tensor(0.4796, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08873512\n",
            "self.loss(score_0, v1) 0.10939691\n",
            "self.loss(score_0, v2) 0.10470287\n",
            "self.loss(score_2, v3) 0.04364725\n",
            "loss tensor(0.3683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08602457\n",
            "self.loss(score_0, v1) 0.13565125\n",
            "self.loss(score_0, v2) 0.1150469\n",
            "self.loss(score_2, v3) 0.04262252\n",
            "loss tensor(0.4007, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.064809024\n",
            "self.loss(score_0, v1) 0.1573689\n",
            "self.loss(score_0, v2) 0.29309806\n",
            "self.loss(score_2, v3) 0.047955588\n",
            "loss tensor(0.5872, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07203353\n",
            "self.loss(score_0, v1) 0.09024274\n",
            "self.loss(score_0, v2) 0.0894385\n",
            "self.loss(score_2, v3) 0.0318163\n",
            "loss tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.30707252\n",
            "self.loss(score_0, v1) 0.2758313\n",
            "self.loss(score_0, v2) 0.08047953\n",
            "self.loss(score_2, v3) 0.036200184\n",
            "loss tensor(0.7177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08341655\n",
            "self.loss(score_0, v1) 0.20758422\n",
            "self.loss(score_0, v2) 0.1784675\n",
            "self.loss(score_2, v3) 0.04411308\n",
            "loss tensor(0.5356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055363685\n",
            "self.loss(score_0, v1) 0.07204811\n",
            "self.loss(score_0, v2) 0.060213715\n",
            "self.loss(score_2, v3) 0.0347291\n",
            "loss tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05216532\n",
            "self.loss(score_0, v1) 0.07983571\n",
            "self.loss(score_0, v2) 0.12109808\n",
            "self.loss(score_2, v3) 0.034882843\n",
            "loss tensor(0.3054, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.091448456\n",
            "self.loss(score_0, v1) 0.26591647\n",
            "self.loss(score_0, v2) 0.32759959\n",
            "self.loss(score_2, v3) 0.052481677\n",
            "loss tensor(0.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057159565\n",
            "self.loss(score_0, v1) 0.28308743\n",
            "self.loss(score_0, v2) 0.34568334\n",
            "self.loss(score_2, v3) 0.11245658\n",
            "loss tensor(0.8546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1903913\n",
            "self.loss(score_0, v1) 0.28373528\n",
            "self.loss(score_0, v2) 0.19142987\n",
            "self.loss(score_2, v3) 0.066181324\n",
            "loss tensor(0.7648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.108572535\n",
            "self.loss(score_0, v1) 0.11849938\n",
            "self.loss(score_0, v2) 0.0991923\n",
            "self.loss(score_2, v3) 0.031699248\n",
            "loss tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06969122\n",
            "self.loss(score_0, v1) 0.09237163\n",
            "self.loss(score_0, v2) 0.106461346\n",
            "self.loss(score_2, v3) 0.04329185\n",
            "loss tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.045447525\n",
            "self.loss(score_0, v1) 0.05412148\n",
            "self.loss(score_0, v2) 0.055229165\n",
            "self.loss(score_2, v3) 0.030069353\n",
            "loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06284477\n",
            "self.loss(score_0, v1) 0.15490453\n",
            "self.loss(score_0, v2) 0.2112401\n",
            "self.loss(score_2, v3) 0.036646355\n",
            "loss tensor(0.4840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14454828\n",
            "self.loss(score_0, v1) 0.49812967\n",
            "self.loss(score_0, v2) 0.31414837\n",
            "self.loss(score_2, v3) 0.04479753\n",
            "loss tensor(1.0240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.068777665\n",
            "self.loss(score_0, v1) 0.10195315\n",
            "self.loss(score_0, v2) 0.0768303\n",
            "self.loss(score_2, v3) 0.036660727\n",
            "loss tensor(0.3026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0653787\n",
            "self.loss(score_0, v1) 0.10723433\n",
            "self.loss(score_0, v2) 0.10593596\n",
            "self.loss(score_2, v3) 0.038012814\n",
            "loss tensor(0.3356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049144946\n",
            "self.loss(score_0, v1) 0.38457853\n",
            "self.loss(score_0, v2) 1.0314155\n",
            "self.loss(score_2, v3) 0.7174414\n",
            "loss tensor(2.5413, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05693839\n",
            "self.loss(score_0, v1) 0.08246717\n",
            "self.loss(score_0, v2) 0.098474704\n",
            "self.loss(score_2, v3) 0.046446007\n",
            "loss tensor(0.3075, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07613096\n",
            "self.loss(score_0, v1) 0.07842669\n",
            "self.loss(score_0, v2) 0.16080129\n",
            "self.loss(score_2, v3) 0.19902308\n",
            "loss tensor(0.6139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061953627\n",
            "self.loss(score_0, v1) 0.22607987\n",
            "self.loss(score_0, v2) 0.16606148\n",
            "self.loss(score_2, v3) 0.035127558\n",
            "loss tensor(0.5068, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075755596\n",
            "self.loss(score_0, v1) 0.111531146\n",
            "self.loss(score_0, v2) 0.09032705\n",
            "self.loss(score_2, v3) 0.0396299\n",
            "loss tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08418678\n",
            "self.loss(score_0, v1) 0.136007\n",
            "self.loss(score_0, v2) 0.1406909\n",
            "self.loss(score_2, v3) 0.048562508\n",
            "loss tensor(0.4337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0470349\n",
            "self.loss(score_0, v1) 0.058595765\n",
            "self.loss(score_0, v2) 0.07605076\n",
            "self.loss(score_2, v3) 0.033178277\n",
            "loss tensor(0.2314, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07999079\n",
            "self.loss(score_0, v1) 0.16450778\n",
            "self.loss(score_0, v2) 0.16520014\n",
            "self.loss(score_2, v3) 0.04039968\n",
            "loss tensor(0.4703, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.070446566\n",
            "self.loss(score_0, v1) 0.084693536\n",
            "self.loss(score_0, v2) 0.0704154\n",
            "self.loss(score_2, v3) 0.036304045\n",
            "loss tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04377434\n",
            "self.loss(score_0, v1) 0.05756131\n",
            "self.loss(score_0, v2) 0.06755224\n",
            "self.loss(score_2, v3) 0.021790951\n",
            "loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.041467063\n",
            "self.loss(score_0, v1) 0.07251657\n",
            "self.loss(score_0, v2) 0.040593687\n",
            "self.loss(score_2, v3) 0.020673325\n",
            "loss tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.37216508\n",
            "self.loss(score_0, v1) 0.30282283\n",
            "self.loss(score_0, v2) 0.183881\n",
            "self.loss(score_2, v3) 0.10719867\n",
            "loss tensor(1.0197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04722787\n",
            "self.loss(score_0, v1) 0.061736766\n",
            "self.loss(score_0, v2) 0.058219146\n",
            "self.loss(score_2, v3) 0.023875557\n",
            "loss tensor(0.2030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09946169\n",
            "self.loss(score_0, v1) 0.16989417\n",
            "self.loss(score_0, v2) 0.11395766\n",
            "self.loss(score_2, v3) 0.033879068\n",
            "loss tensor(0.4341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.041182995\n",
            "self.loss(score_0, v1) 0.055387363\n",
            "self.loss(score_0, v2) 0.06280737\n",
            "self.loss(score_2, v3) 0.027189717\n",
            "loss tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.047189027\n",
            "self.loss(score_0, v1) 0.07349537\n",
            "self.loss(score_0, v2) 0.12232251\n",
            "self.loss(score_2, v3) 0.03725602\n",
            "loss tensor(0.2989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08493132\n",
            "self.loss(score_0, v1) 0.13772278\n",
            "self.loss(score_0, v2) 0.13890593\n",
            "self.loss(score_2, v3) 0.049021464\n",
            "loss tensor(0.4351, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08133515\n",
            "self.loss(score_0, v1) 0.13020438\n",
            "self.loss(score_0, v2) 0.16870387\n",
            "self.loss(score_2, v3) 0.039603285\n",
            "loss tensor(0.4396, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.075958125\n",
            "self.loss(score_0, v1) 0.1147015\n",
            "self.loss(score_0, v2) 0.13107845\n",
            "self.loss(score_2, v3) 0.04974991\n",
            "loss tensor(0.3964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.087081924\n",
            "self.loss(score_0, v1) 0.07655089\n",
            "self.loss(score_0, v2) 0.0770748\n",
            "self.loss(score_2, v3) 0.033579558\n",
            "loss tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06300959\n",
            "self.loss(score_0, v1) 0.08156166\n",
            "self.loss(score_0, v2) 0.072517104\n",
            "self.loss(score_2, v3) 0.044251896\n",
            "loss tensor(0.2835, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05830178\n",
            "self.loss(score_0, v1) 0.08030764\n",
            "self.loss(score_0, v2) 0.19292772\n",
            "self.loss(score_2, v3) 0.19683976\n",
            "loss tensor(0.6268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.043128684\n",
            "self.loss(score_0, v1) 0.0780077\n",
            "self.loss(score_0, v2) 0.07765221\n",
            "self.loss(score_2, v3) 0.026716515\n",
            "loss tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0645225\n",
            "self.loss(score_0, v1) 0.1103511\n",
            "self.loss(score_0, v2) 0.08727112\n",
            "self.loss(score_2, v3) 0.051104475\n",
            "loss tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05554272\n",
            "self.loss(score_0, v1) 0.12641251\n",
            "self.loss(score_0, v2) 0.17236015\n",
            "self.loss(score_2, v3) 0.07855898\n",
            "loss tensor(0.4722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049495973\n",
            "self.loss(score_0, v1) 0.3452573\n",
            "self.loss(score_0, v2) 0.54593873\n",
            "self.loss(score_2, v3) 0.17810667\n",
            "loss tensor(1.2079, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08627975\n",
            "self.loss(score_0, v1) 0.14282633\n",
            "self.loss(score_0, v2) 0.103172526\n",
            "self.loss(score_2, v3) 0.077403024\n",
            "loss tensor(0.4484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.069226444\n",
            "self.loss(score_0, v1) 0.23445156\n",
            "self.loss(score_0, v2) 0.23568963\n",
            "self.loss(score_2, v3) 0.047829606\n",
            "loss tensor(0.6111, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052057646\n",
            "self.loss(score_0, v1) 0.067006335\n",
            "self.loss(score_0, v2) 0.068907164\n",
            "self.loss(score_2, v3) 0.03027305\n",
            "loss tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06052801\n",
            "self.loss(score_0, v1) 0.16454834\n",
            "self.loss(score_0, v2) 0.20972708\n",
            "self.loss(score_2, v3) 0.053300485\n",
            "loss tensor(0.5148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05576417\n",
            "self.loss(score_0, v1) 0.08418074\n",
            "self.loss(score_0, v2) 0.08834047\n",
            "self.loss(score_2, v3) 0.032543756\n",
            "loss tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.082251415\n",
            "self.loss(score_0, v1) 0.12799521\n",
            "self.loss(score_0, v2) 0.10417337\n",
            "self.loss(score_2, v3) 0.051612444\n",
            "loss tensor(0.3918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055311512\n",
            "self.loss(score_0, v1) 0.11798602\n",
            "self.loss(score_0, v2) 0.14770685\n",
            "self.loss(score_2, v3) 0.041909665\n",
            "loss tensor(0.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07764651\n",
            "self.loss(score_0, v1) 0.10178312\n",
            "self.loss(score_0, v2) 0.07936046\n",
            "self.loss(score_2, v3) 0.03777884\n",
            "loss tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061696228\n",
            "self.loss(score_0, v1) 0.097690865\n",
            "self.loss(score_0, v2) 0.098826826\n",
            "self.loss(score_2, v3) 0.04012008\n",
            "loss tensor(0.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.071843766\n",
            "self.loss(score_0, v1) 0.50535405\n",
            "self.loss(score_0, v2) 0.43307802\n",
            "self.loss(score_2, v3) 0.052251726\n",
            "loss tensor(1.0887, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058766622\n",
            "self.loss(score_0, v1) 0.08642652\n",
            "self.loss(score_0, v2) 0.09437291\n",
            "self.loss(score_2, v3) 0.03669845\n",
            "loss tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.054406412\n",
            "self.loss(score_0, v1) 0.07510396\n",
            "self.loss(score_0, v2) 0.07742186\n",
            "self.loss(score_2, v3) 0.030093022\n",
            "loss tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0808964\n",
            "self.loss(score_0, v1) 0.24872467\n",
            "self.loss(score_0, v2) 0.21362934\n",
            "self.loss(score_2, v3) 0.04782742\n",
            "loss tensor(0.6150, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09524663\n",
            "self.loss(score_0, v1) 0.12719384\n",
            "self.loss(score_0, v2) 0.06812046\n",
            "self.loss(score_2, v3) 0.043035816\n",
            "loss tensor(0.3551, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09148648\n",
            "self.loss(score_0, v1) 0.10305542\n",
            "self.loss(score_0, v2) 0.10880223\n",
            "self.loss(score_2, v3) 0.036376726\n",
            "loss tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.19269909\n",
            "self.loss(score_0, v1) 0.15125504\n",
            "self.loss(score_0, v2) 0.12335259\n",
            "self.loss(score_2, v3) 0.06935913\n",
            "loss tensor(0.5713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07942982\n",
            "self.loss(score_0, v1) 0.108150996\n",
            "self.loss(score_0, v2) 0.095139876\n",
            "self.loss(score_2, v3) 0.041622754\n",
            "loss tensor(0.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10955409\n",
            "self.loss(score_0, v1) 0.17891994\n",
            "self.loss(score_0, v2) 0.07185127\n",
            "self.loss(score_2, v3) 0.038574327\n",
            "loss tensor(0.4182, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.072268546\n",
            "self.loss(score_0, v1) 0.25106514\n",
            "self.loss(score_0, v2) 0.2009931\n",
            "self.loss(score_2, v3) 0.048032206\n",
            "loss tensor(0.5964, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.080153964\n",
            "self.loss(score_0, v1) 0.09391065\n",
            "self.loss(score_0, v2) 0.062222574\n",
            "self.loss(score_2, v3) 0.035121042\n",
            "loss tensor(0.2890, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09696681\n",
            "self.loss(score_0, v1) 0.13528599\n",
            "self.loss(score_0, v2) 0.073542625\n",
            "self.loss(score_2, v3) 0.032428373\n",
            "loss tensor(0.3544, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05591982\n",
            "self.loss(score_0, v1) 0.07798094\n",
            "self.loss(score_0, v2) 0.10498265\n",
            "self.loss(score_2, v3) 0.047120184\n",
            "loss tensor(0.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07959224\n",
            "self.loss(score_0, v1) 0.28703842\n",
            "self.loss(score_0, v2) 0.3057273\n",
            "self.loss(score_2, v3) 0.031152517\n",
            "loss tensor(0.7191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.041238464\n",
            "self.loss(score_0, v1) 0.07191244\n",
            "self.loss(score_0, v2) 0.085578166\n",
            "self.loss(score_2, v3) 0.029537639\n",
            "loss tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06542489\n",
            "self.loss(score_0, v1) 0.33539137\n",
            "self.loss(score_0, v2) 0.3000449\n",
            "self.loss(score_2, v3) 0.047708966\n",
            "loss tensor(0.7724, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.046506766\n",
            "self.loss(score_0, v1) 0.06351794\n",
            "self.loss(score_0, v2) 0.07078067\n",
            "self.loss(score_2, v3) 0.02877951\n",
            "loss tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052452706\n",
            "self.loss(score_0, v1) 0.086959876\n",
            "self.loss(score_0, v2) 0.108555995\n",
            "self.loss(score_2, v3) 0.042843647\n",
            "loss tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18578787\n",
            "self.loss(score_0, v1) 0.18529715\n",
            "self.loss(score_0, v2) 0.13957627\n",
            "self.loss(score_2, v3) 0.11403002\n",
            "loss tensor(0.6817, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04636778\n",
            "self.loss(score_0, v1) 0.11765266\n",
            "self.loss(score_0, v2) 0.13928957\n",
            "self.loss(score_2, v3) 0.03072768\n",
            "loss tensor(0.3494, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04556589\n",
            "self.loss(score_0, v1) 0.062022828\n",
            "self.loss(score_0, v2) 0.07714209\n",
            "self.loss(score_2, v3) 0.029883372\n",
            "loss tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.076856844\n",
            "self.loss(score_0, v1) 0.13628995\n",
            "self.loss(score_0, v2) 0.12841526\n",
            "self.loss(score_2, v3) 0.046199054\n",
            "loss tensor(0.4109, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10069821\n",
            "self.loss(score_0, v1) 0.5541834\n",
            "self.loss(score_0, v2) 0.53695714\n",
            "self.loss(score_2, v3) 0.036898375\n",
            "loss tensor(1.2472, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08745024\n",
            "self.loss(score_0, v1) 0.09817438\n",
            "self.loss(score_0, v2) 0.08031987\n",
            "self.loss(score_2, v3) 0.046170548\n",
            "loss tensor(0.3352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10140656\n",
            "self.loss(score_0, v1) 0.13303061\n",
            "self.loss(score_0, v2) 0.12250004\n",
            "self.loss(score_2, v3) 0.038652327\n",
            "loss tensor(0.4149, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08118921\n",
            "self.loss(score_0, v1) 0.20252213\n",
            "self.loss(score_0, v2) 0.25057057\n",
            "self.loss(score_2, v3) 0.11890522\n",
            "loss tensor(0.7126, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051813077\n",
            "self.loss(score_0, v1) 0.33696148\n",
            "self.loss(score_0, v2) 0.36124977\n",
            "self.loss(score_2, v3) 0.11018693\n",
            "loss tensor(0.9153, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06608121\n",
            "self.loss(score_0, v1) 0.08258576\n",
            "self.loss(score_0, v2) 0.09850656\n",
            "self.loss(score_2, v3) 0.032481376\n",
            "loss tensor(0.2959, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.030391622\n",
            "self.loss(score_0, v1) 0.048917722\n",
            "self.loss(score_0, v2) 0.09502779\n",
            "self.loss(score_2, v3) 0.01818864\n",
            "loss tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.065575376\n",
            "self.loss(score_0, v1) 0.08143738\n",
            "self.loss(score_0, v2) 0.071938284\n",
            "self.loss(score_2, v3) 0.041549724\n",
            "loss tensor(0.2813, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.047908925\n",
            "self.loss(score_0, v1) 0.07457465\n",
            "self.loss(score_0, v2) 0.100928545\n",
            "self.loss(score_2, v3) 0.044592254\n",
            "loss tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050539218\n",
            "self.loss(score_0, v1) 0.057291877\n",
            "self.loss(score_0, v2) 0.05339542\n",
            "self.loss(score_2, v3) 0.033337127\n",
            "loss tensor(0.2112, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04778443\n",
            "self.loss(score_0, v1) 0.0876996\n",
            "self.loss(score_0, v2) 0.04198099\n",
            "self.loss(score_2, v3) 0.02388328\n",
            "loss tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06886792\n",
            "self.loss(score_0, v1) 0.086712256\n",
            "self.loss(score_0, v2) 0.07076922\n",
            "self.loss(score_2, v3) 0.037419148\n",
            "loss tensor(0.2825, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.123312384\n",
            "self.loss(score_0, v1) 0.14024544\n",
            "self.loss(score_0, v2) 0.07531955\n",
            "self.loss(score_2, v3) 0.042234883\n",
            "loss tensor(0.4022, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.036717556\n",
            "self.loss(score_0, v1) 0.05571924\n",
            "self.loss(score_0, v2) 0.044590514\n",
            "self.loss(score_2, v3) 0.020512812\n",
            "loss tensor(0.1678, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.061972756\n",
            "self.loss(score_0, v1) 0.12867899\n",
            "self.loss(score_0, v2) 0.18880256\n",
            "self.loss(score_2, v3) 0.049997136\n",
            "loss tensor(0.4545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21613227\n",
            "self.loss(score_0, v1) 0.27435756\n",
            "self.loss(score_0, v2) 0.05396196\n",
            "self.loss(score_2, v3) 0.026150197\n",
            "loss tensor(0.5837, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056084156\n",
            "self.loss(score_0, v1) 0.075804085\n",
            "self.loss(score_0, v2) 0.08250931\n",
            "self.loss(score_2, v3) 0.030605292\n",
            "loss tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05619115\n",
            "self.loss(score_0, v1) 0.07723961\n",
            "self.loss(score_0, v2) 0.074432045\n",
            "self.loss(score_2, v3) 0.04779066\n",
            "loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07700461\n",
            "self.loss(score_0, v1) 0.193672\n",
            "self.loss(score_0, v2) 0.23035699\n",
            "self.loss(score_2, v3) 0.04245146\n",
            "loss tensor(0.5647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.063711636\n",
            "self.loss(score_0, v1) 0.15307261\n",
            "self.loss(score_0, v2) 0.11018784\n",
            "self.loss(score_2, v3) 0.030727902\n",
            "loss tensor(0.3731, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09747175\n",
            "self.loss(score_0, v1) 0.17149597\n",
            "self.loss(score_0, v2) 0.11030169\n",
            "self.loss(score_2, v3) 0.03214185\n",
            "loss tensor(0.4275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10431364\n",
            "self.loss(score_0, v1) 0.14084741\n",
            "self.loss(score_0, v2) 0.08275263\n",
            "self.loss(score_2, v3) 0.044238925\n",
            "loss tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.037583686\n",
            "self.loss(score_0, v1) 0.11407516\n",
            "self.loss(score_0, v2) 0.17168957\n",
            "self.loss(score_2, v3) 0.019759003\n",
            "loss tensor(0.3530, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07743862\n",
            "self.loss(score_0, v1) 0.0791862\n",
            "self.loss(score_0, v2) 0.058719035\n",
            "self.loss(score_2, v3) 0.030890966\n",
            "loss tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055167846\n",
            "self.loss(score_0, v1) 0.08613933\n",
            "self.loss(score_0, v2) 0.12259412\n",
            "self.loss(score_2, v3) 0.035998363\n",
            "loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.046222184\n",
            "self.loss(score_0, v1) 0.058209307\n",
            "self.loss(score_0, v2) 0.05285584\n",
            "self.loss(score_2, v3) 0.028379036\n",
            "loss tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.21611248\n",
            "self.loss(score_0, v1) 0.2147063\n",
            "self.loss(score_0, v2) 0.07683509\n",
            "self.loss(score_2, v3) 0.036305387\n",
            "loss tensor(0.5621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056869853\n",
            "self.loss(score_0, v1) 0.05332802\n",
            "self.loss(score_0, v2) 0.055937\n",
            "self.loss(score_2, v3) 0.03206642\n",
            "loss tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057000212\n",
            "self.loss(score_0, v1) 0.13922957\n",
            "self.loss(score_0, v2) 0.15388165\n",
            "self.loss(score_2, v3) 0.045130026\n",
            "loss tensor(0.4178, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07678705\n",
            "self.loss(score_0, v1) 0.20691612\n",
            "self.loss(score_0, v2) 0.5750857\n",
            "self.loss(score_2, v3) 0.53602403\n",
            "loss tensor(1.6628, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055523627\n",
            "self.loss(score_0, v1) 0.06550751\n",
            "self.loss(score_0, v2) 0.060297146\n",
            "self.loss(score_2, v3) 0.03196343\n",
            "loss tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.205934\n",
            "self.loss(score_0, v1) 0.26774588\n",
            "self.loss(score_0, v2) 0.18885769\n",
            "self.loss(score_2, v3) 0.03567189\n",
            "loss tensor(0.7160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07726268\n",
            "self.loss(score_0, v1) 0.20658343\n",
            "self.loss(score_0, v2) 0.21211545\n",
            "self.loss(score_2, v3) 0.029453333\n",
            "loss tensor(0.5401, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06606075\n",
            "self.loss(score_0, v1) 0.11099255\n",
            "self.loss(score_0, v2) 0.13195483\n",
            "self.loss(score_2, v3) 0.04629915\n",
            "loss tensor(0.3785, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08470602\n",
            "self.loss(score_0, v1) 0.081588954\n",
            "self.loss(score_0, v2) 0.04544005\n",
            "self.loss(score_2, v3) 0.025282938\n",
            "loss tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06768075\n",
            "self.loss(score_0, v1) 0.161559\n",
            "self.loss(score_0, v2) 0.15444553\n",
            "self.loss(score_2, v3) 0.033480372\n",
            "loss tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16963494\n",
            "self.loss(score_0, v1) 0.19778611\n",
            "self.loss(score_0, v2) 0.08286932\n",
            "self.loss(score_2, v3) 0.03462374\n",
            "loss tensor(0.5022, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0491019\n",
            "self.loss(score_0, v1) 0.17948768\n",
            "self.loss(score_0, v2) 0.17278156\n",
            "self.loss(score_2, v3) 0.03504145\n",
            "loss tensor(0.4539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16280875\n",
            "self.loss(score_0, v1) 0.17013173\n",
            "self.loss(score_0, v2) 0.1350316\n",
            "self.loss(score_2, v3) 0.036358718\n",
            "loss tensor(0.5225, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055974532\n",
            "self.loss(score_0, v1) 0.10508368\n",
            "self.loss(score_0, v2) 0.102672964\n",
            "self.loss(score_2, v3) 0.03241165\n",
            "loss tensor(0.3123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.079991855\n",
            "self.loss(score_0, v1) 0.08194498\n",
            "self.loss(score_0, v2) 0.07089731\n",
            "self.loss(score_2, v3) 0.038609732\n",
            "loss tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07492\n",
            "self.loss(score_0, v1) 0.11475553\n",
            "self.loss(score_0, v2) 0.13690297\n",
            "self.loss(score_2, v3) 0.03806843\n",
            "loss tensor(0.3837, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1996484\n",
            "self.loss(score_0, v1) 0.39838675\n",
            "self.loss(score_0, v2) 0.4493996\n",
            "self.loss(score_2, v3) 0.17135723\n",
            "loss tensor(1.3045, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.049314488\n",
            "self.loss(score_0, v1) 0.082006074\n",
            "self.loss(score_0, v2) 0.07940362\n",
            "self.loss(score_2, v3) 0.03606527\n",
            "loss tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1682869\n",
            "self.loss(score_0, v1) 0.22467789\n",
            "self.loss(score_0, v2) 0.16912113\n",
            "self.loss(score_2, v3) 0.031611018\n",
            "loss tensor(0.6095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06580533\n",
            "self.loss(score_0, v1) 0.071197405\n",
            "self.loss(score_0, v2) 0.0706854\n",
            "self.loss(score_2, v3) 0.046877313\n",
            "loss tensor(0.2780, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05086587\n",
            "self.loss(score_0, v1) 0.086988054\n",
            "self.loss(score_0, v2) 0.077646784\n",
            "self.loss(score_2, v3) 0.027081888\n",
            "loss tensor(0.2561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.054845024\n",
            "self.loss(score_0, v1) 0.08048992\n",
            "self.loss(score_0, v2) 0.07572272\n",
            "self.loss(score_2, v3) 0.042742968\n",
            "loss tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07130745\n",
            "self.loss(score_0, v1) 0.09225444\n",
            "self.loss(score_0, v2) 0.13007608\n",
            "self.loss(score_2, v3) 0.07325881\n",
            "loss tensor(0.4035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051739767\n",
            "self.loss(score_0, v1) 0.056567907\n",
            "self.loss(score_0, v2) 0.0679744\n",
            "self.loss(score_2, v3) 0.03221303\n",
            "loss tensor(0.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053168375\n",
            "self.loss(score_0, v1) 0.07441053\n",
            "self.loss(score_0, v2) 0.075048536\n",
            "self.loss(score_2, v3) 0.029003793\n",
            "loss tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.059463967\n",
            "self.loss(score_0, v1) 0.6216375\n",
            "self.loss(score_0, v2) 0.68250394\n",
            "self.loss(score_2, v3) 0.04870832\n",
            "loss tensor(1.4367, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06793286\n",
            "self.loss(score_0, v1) 0.12513089\n",
            "self.loss(score_0, v2) 0.096423365\n",
            "self.loss(score_2, v3) 0.034452505\n",
            "loss tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.048162792\n",
            "self.loss(score_0, v1) 0.06950504\n",
            "self.loss(score_0, v2) 0.063587464\n",
            "self.loss(score_2, v3) 0.03447473\n",
            "loss tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.064124726\n",
            "self.loss(score_0, v1) 0.10109973\n",
            "self.loss(score_0, v2) 0.10529618\n",
            "self.loss(score_2, v3) 0.039004557\n",
            "loss tensor(0.3290, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058836028\n",
            "self.loss(score_0, v1) 0.11517765\n",
            "self.loss(score_0, v2) 0.06973778\n",
            "self.loss(score_2, v3) 0.03901032\n",
            "loss tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052534055\n",
            "self.loss(score_0, v1) 0.14113921\n",
            "self.loss(score_0, v2) 0.17180455\n",
            "self.loss(score_2, v3) 0.0303333\n",
            "loss tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06755508\n",
            "self.loss(score_0, v1) 0.15174423\n",
            "self.loss(score_0, v2) 0.14777821\n",
            "self.loss(score_2, v3) 0.028199555\n",
            "loss tensor(0.4094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.069204174\n",
            "self.loss(score_0, v1) 0.23779678\n",
            "self.loss(score_0, v2) 0.24385838\n",
            "self.loss(score_2, v3) 0.041429482\n",
            "loss tensor(0.6130, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07469536\n",
            "self.loss(score_0, v1) 0.32838774\n",
            "self.loss(score_0, v2) 0.25054795\n",
            "self.loss(score_2, v3) 0.05357354\n",
            "loss tensor(0.7340, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13419983\n",
            "self.loss(score_0, v1) 0.2365231\n",
            "self.loss(score_0, v2) 0.30278435\n",
            "self.loss(score_2, v3) 0.14745072\n",
            "loss tensor(0.8947, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12870322\n",
            "self.loss(score_0, v1) 0.2923446\n",
            "self.loss(score_0, v2) 0.4435952\n",
            "self.loss(score_2, v3) 0.03283442\n",
            "loss tensor(0.9139, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06941919\n",
            "self.loss(score_0, v1) 0.304052\n",
            "self.loss(score_0, v2) 0.29199263\n",
            "self.loss(score_2, v3) 0.047057\n",
            "loss tensor(0.7360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.072632514\n",
            "self.loss(score_0, v1) 0.09963373\n",
            "self.loss(score_0, v2) 0.07019259\n",
            "self.loss(score_2, v3) 0.03174291\n",
            "loss tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09137494\n",
            "self.loss(score_0, v1) 0.10637381\n",
            "self.loss(score_0, v2) 0.07776718\n",
            "self.loss(score_2, v3) 0.029640311\n",
            "loss tensor(0.3200, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.03426673\n",
            "self.loss(score_0, v1) 0.048658058\n",
            "self.loss(score_0, v2) 0.05212302\n",
            "self.loss(score_2, v3) 0.021555712\n",
            "loss tensor(0.1674, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04846922\n",
            "self.loss(score_0, v1) 0.11862842\n",
            "self.loss(score_0, v2) 0.19928625\n",
            "self.loss(score_2, v3) 0.03077348\n",
            "loss tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18014865\n",
            "self.loss(score_0, v1) 0.22835347\n",
            "self.loss(score_0, v2) 0.08861172\n",
            "self.loss(score_2, v3) 0.038133617\n",
            "loss tensor(0.5543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05458212\n",
            "self.loss(score_0, v1) 0.16818753\n",
            "self.loss(score_0, v2) 0.1846721\n",
            "self.loss(score_2, v3) 0.044090897\n",
            "loss tensor(0.4736, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.09072138\n",
            "self.loss(score_0, v1) 0.16161618\n",
            "self.loss(score_0, v2) 0.115349114\n",
            "self.loss(score_2, v3) 0.033809595\n",
            "loss tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.021388557\n",
            "self.loss(score_0, v1) 0.07719403\n",
            "self.loss(score_0, v2) 0.10035979\n",
            "self.loss(score_2, v3) 0.033942133\n",
            "loss tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08938332\n",
            "self.loss(score_0, v1) 0.22441268\n",
            "self.loss(score_0, v2) 0.15932998\n",
            "self.loss(score_2, v3) 0.030247929\n",
            "loss tensor(0.5185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06765357\n",
            "self.loss(score_0, v1) 0.08447523\n",
            "self.loss(score_0, v2) 0.07672702\n",
            "self.loss(score_2, v3) 0.037989825\n",
            "loss tensor(0.2858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0560396\n",
            "self.loss(score_0, v1) 0.12364225\n",
            "self.loss(score_0, v2) 0.13794217\n",
            "self.loss(score_2, v3) 0.040051814\n",
            "loss tensor(0.3777, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060108934\n",
            "self.loss(score_0, v1) 0.07935578\n",
            "self.loss(score_0, v2) 0.10224637\n",
            "self.loss(score_2, v3) 0.049866438\n",
            "loss tensor(0.3165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.042696387\n",
            "self.loss(score_0, v1) 0.14362149\n",
            "self.loss(score_0, v2) 0.09099246\n",
            "self.loss(score_2, v3) 0.027030585\n",
            "loss tensor(0.3179, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06806019\n",
            "self.loss(score_0, v1) 0.34387606\n",
            "self.loss(score_0, v2) 0.2975061\n",
            "self.loss(score_2, v3) 0.033573933\n",
            "loss tensor(0.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.051399495\n",
            "self.loss(score_0, v1) 0.08590161\n",
            "self.loss(score_0, v2) 0.052746307\n",
            "self.loss(score_2, v3) 0.02967971\n",
            "loss tensor(0.2346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.044317383\n",
            "self.loss(score_0, v1) 0.063362\n",
            "self.loss(score_0, v2) 0.06349803\n",
            "self.loss(score_2, v3) 0.022716906\n",
            "loss tensor(0.2053, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.088733844\n",
            "self.loss(score_0, v1) 0.07488785\n",
            "self.loss(score_0, v2) 0.079214044\n",
            "self.loss(score_2, v3) 0.039216477\n",
            "loss tensor(0.3017, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18282878\n",
            "self.loss(score_0, v1) 0.15887868\n",
            "self.loss(score_0, v2) 0.08489096\n",
            "self.loss(score_2, v3) 0.046743147\n",
            "loss tensor(0.4967, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1057692\n",
            "self.loss(score_0, v1) 0.12847522\n",
            "self.loss(score_0, v2) 0.1109861\n",
            "self.loss(score_2, v3) 0.03845314\n",
            "loss tensor(0.4029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07117543\n",
            "self.loss(score_0, v1) 0.080042094\n",
            "self.loss(score_0, v2) 0.09779962\n",
            "self.loss(score_2, v3) 0.049379855\n",
            "loss tensor(0.3231, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060802303\n",
            "self.loss(score_0, v1) 0.10477223\n",
            "self.loss(score_0, v2) 0.10960145\n",
            "self.loss(score_2, v3) 0.037357606\n",
            "loss tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.044208307\n",
            "self.loss(score_0, v1) 0.05744835\n",
            "self.loss(score_0, v2) 0.053004112\n",
            "self.loss(score_2, v3) 0.021936929\n",
            "loss tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07874163\n",
            "self.loss(score_0, v1) 0.4084987\n",
            "self.loss(score_0, v2) 0.41507277\n",
            "self.loss(score_2, v3) 0.052025147\n",
            "loss tensor(0.9804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10559877\n",
            "self.loss(score_0, v1) 0.13796592\n",
            "self.loss(score_0, v2) 0.08676731\n",
            "self.loss(score_2, v3) 0.03487001\n",
            "loss tensor(0.3826, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.060208574\n",
            "self.loss(score_0, v1) 0.085847564\n",
            "self.loss(score_0, v2) 0.07866856\n",
            "self.loss(score_2, v3) 0.045805678\n",
            "loss tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12707701\n",
            "self.loss(score_0, v1) 0.40784258\n",
            "self.loss(score_0, v2) 0.34403753\n",
            "self.loss(score_2, v3) 0.044625055\n",
            "loss tensor(0.9459, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053860735\n",
            "self.loss(score_0, v1) 0.12344827\n",
            "self.loss(score_0, v2) 0.17407286\n",
            "self.loss(score_2, v3) 0.04243313\n",
            "loss tensor(0.4150, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12529135\n",
            "self.loss(score_0, v1) 0.16109595\n",
            "self.loss(score_0, v2) 0.176034\n",
            "self.loss(score_2, v3) 0.043260712\n",
            "loss tensor(0.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.073278464\n",
            "self.loss(score_0, v1) 0.104670875\n",
            "self.loss(score_0, v2) 0.102087624\n",
            "self.loss(score_2, v3) 0.033615652\n",
            "loss tensor(0.3305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13050127\n",
            "self.loss(score_0, v1) 0.1964991\n",
            "self.loss(score_0, v2) 0.1417689\n",
            "self.loss(score_2, v3) 0.04453694\n",
            "loss tensor(0.5356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08301584\n",
            "self.loss(score_0, v1) 0.12422958\n",
            "self.loss(score_0, v2) 0.11847286\n",
            "self.loss(score_2, v3) 0.03164378\n",
            "loss tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055153202\n",
            "self.loss(score_0, v1) 0.08476301\n",
            "self.loss(score_0, v2) 0.089466855\n",
            "self.loss(score_2, v3) 0.033407662\n",
            "loss tensor(0.2795, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2061091\n",
            "self.loss(score_0, v1) 0.14394234\n",
            "self.loss(score_0, v2) 0.122252494\n",
            "self.loss(score_2, v3) 0.03493964\n",
            "loss tensor(0.5247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053494185\n",
            "self.loss(score_0, v1) 0.23162575\n",
            "self.loss(score_0, v2) 0.20371413\n",
            "self.loss(score_2, v3) 0.03296324\n",
            "loss tensor(0.5383, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08089127\n",
            "self.loss(score_0, v1) 0.08526336\n",
            "self.loss(score_0, v2) 0.06411348\n",
            "self.loss(score_2, v3) 0.037391566\n",
            "loss tensor(0.2864, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07865694\n",
            "self.loss(score_0, v1) 0.120327905\n",
            "self.loss(score_0, v2) 0.08207526\n",
            "self.loss(score_2, v3) 0.039559674\n",
            "loss tensor(0.3404, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.098236285\n",
            "self.loss(score_0, v1) 0.14495628\n",
            "self.loss(score_0, v2) 0.20746309\n",
            "self.loss(score_2, v3) 0.045614686\n",
            "loss tensor(0.5191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1164085\n",
            "self.loss(score_0, v1) 0.17986889\n",
            "self.loss(score_0, v2) 0.14280908\n",
            "self.loss(score_2, v3) 0.039508358\n",
            "loss tensor(0.4983, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13790561\n",
            "self.loss(score_0, v1) 0.12754923\n",
            "self.loss(score_0, v2) 0.06101848\n",
            "self.loss(score_2, v3) 0.02821735\n",
            "loss tensor(0.3688, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0687995\n",
            "self.loss(score_0, v1) 0.08179572\n",
            "self.loss(score_0, v2) 0.09498513\n",
            "self.loss(score_2, v3) 0.036313746\n",
            "loss tensor(0.3001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053074807\n",
            "self.loss(score_0, v1) 0.06695766\n",
            "self.loss(score_0, v2) 0.06867264\n",
            "self.loss(score_2, v3) 0.033505403\n",
            "loss tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.041557524\n",
            "self.loss(score_0, v1) 0.06214557\n",
            "self.loss(score_0, v2) 0.08645213\n",
            "self.loss(score_2, v3) 0.029558778\n",
            "loss tensor(0.2345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.108708434\n",
            "self.loss(score_0, v1) 0.22954889\n",
            "self.loss(score_0, v2) 0.25525475\n",
            "self.loss(score_2, v3) 0.038654413\n",
            "loss tensor(0.6515, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06303689\n",
            "self.loss(score_0, v1) 0.2719653\n",
            "self.loss(score_0, v2) 0.30752537\n",
            "self.loss(score_2, v3) 0.045946665\n",
            "loss tensor(0.7114, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0670978\n",
            "self.loss(score_0, v1) 0.063303165\n",
            "self.loss(score_0, v2) 0.058995068\n",
            "self.loss(score_2, v3) 0.03167667\n",
            "loss tensor(0.2369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.062279318\n",
            "self.loss(score_0, v1) 0.19826676\n",
            "self.loss(score_0, v2) 0.25106245\n",
            "self.loss(score_2, v3) 0.028480662\n",
            "loss tensor(0.5543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13395858\n",
            "self.loss(score_0, v1) 0.15045263\n",
            "self.loss(score_0, v2) 0.12629175\n",
            "self.loss(score_2, v3) 0.19958049\n",
            "loss tensor(0.7101, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04483111\n",
            "self.loss(score_0, v1) 0.074225724\n",
            "self.loss(score_0, v2) 0.1290189\n",
            "self.loss(score_2, v3) 0.03657557\n",
            "loss tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16731736\n",
            "self.loss(score_0, v1) 0.10577384\n",
            "self.loss(score_0, v2) 0.08349259\n",
            "self.loss(score_2, v3) 0.04093925\n",
            "loss tensor(0.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.093764886\n",
            "self.loss(score_0, v1) 0.10210799\n",
            "self.loss(score_0, v2) 0.069450326\n",
            "self.loss(score_2, v3) 0.03660184\n",
            "loss tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12763877\n",
            "self.loss(score_0, v1) 0.15589905\n",
            "self.loss(score_0, v2) 0.097310826\n",
            "self.loss(score_2, v3) 0.033490505\n",
            "loss tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.056208007\n",
            "self.loss(score_0, v1) 0.05411028\n",
            "self.loss(score_0, v2) 0.043686856\n",
            "self.loss(score_2, v3) 0.02052389\n",
            "loss tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.055362754\n",
            "self.loss(score_0, v1) 0.08119928\n",
            "self.loss(score_0, v2) 0.092367455\n",
            "self.loss(score_2, v3) 0.035983764\n",
            "loss tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.047384918\n",
            "self.loss(score_0, v1) 0.06722427\n",
            "self.loss(score_0, v2) 0.056854587\n",
            "self.loss(score_2, v3) 0.031629268\n",
            "loss tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05174852\n",
            "self.loss(score_0, v1) 0.28289905\n",
            "self.loss(score_0, v2) 0.31448913\n",
            "self.loss(score_2, v3) 0.032469828\n",
            "loss tensor(0.6978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052043214\n",
            "self.loss(score_0, v1) 0.07124598\n",
            "self.loss(score_0, v2) 0.08901142\n",
            "self.loss(score_2, v3) 0.041700054\n",
            "loss tensor(0.2749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12872054\n",
            "self.loss(score_0, v1) 0.15584832\n",
            "self.loss(score_0, v2) 0.07103346\n",
            "self.loss(score_2, v3) 0.032400902\n",
            "loss tensor(0.4042, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08587864\n",
            "self.loss(score_0, v1) 0.09595466\n",
            "self.loss(score_0, v2) 0.06817107\n",
            "self.loss(score_2, v3) 0.04133095\n",
            "loss tensor(0.3120, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06234334\n",
            "self.loss(score_0, v1) 0.0881254\n",
            "self.loss(score_0, v2) 0.23129389\n",
            "self.loss(score_2, v3) 0.22176671\n",
            "loss tensor(0.7144, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.057112884\n",
            "self.loss(score_0, v1) 0.09604387\n",
            "self.loss(score_0, v2) 0.083282195\n",
            "self.loss(score_2, v3) 0.04088135\n",
            "loss tensor(0.2978, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.04939219\n",
            "self.loss(score_0, v1) 0.06663522\n",
            "self.loss(score_0, v2) 0.060530387\n",
            "self.loss(score_2, v3) 0.0350249\n",
            "loss tensor(0.2291, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.08887433\n",
            "self.loss(score_0, v1) 0.094158314\n",
            "self.loss(score_0, v2) 0.06490281\n",
            "self.loss(score_2, v3) 0.032688\n",
            "loss tensor(0.2970, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058795124\n",
            "self.loss(score_0, v1) 0.06384771\n",
            "self.loss(score_0, v2) 0.076246195\n",
            "self.loss(score_2, v3) 0.0304012\n",
            "loss tensor(0.2445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.050213788\n",
            "self.loss(score_0, v1) 0.14162014\n",
            "self.loss(score_0, v2) 0.16555311\n",
            "self.loss(score_2, v3) 0.043600928\n",
            "loss tensor(0.4228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.053080663\n",
            "self.loss(score_0, v1) 0.10613177\n",
            "self.loss(score_0, v2) 0.11445949\n",
            "self.loss(score_2, v3) 0.028686307\n",
            "loss tensor(0.3167, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.044599615\n",
            "self.loss(score_0, v1) 0.09781273\n",
            "self.loss(score_0, v2) 0.08678991\n",
            "self.loss(score_2, v3) 0.025553023\n",
            "loss tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07482146\n",
            "self.loss(score_0, v1) 0.2546878\n",
            "self.loss(score_0, v2) 0.23330048\n",
            "self.loss(score_2, v3) 0.03643071\n",
            "loss tensor(0.6175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.117059946\n",
            "self.loss(score_0, v1) 0.16996792\n",
            "self.loss(score_0, v2) 0.09911655\n",
            "self.loss(score_2, v3) 0.04560852\n",
            "loss tensor(0.4546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.058332324\n",
            "self.loss(score_0, v1) 0.10945962\n",
            "self.loss(score_0, v2) 0.15904482\n",
            "self.loss(score_2, v3) 0.083372936\n",
            "loss tensor(0.4519, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07665753\n",
            "self.loss(score_0, v1) 0.065205246\n",
            "self.loss(score_0, v2) 0.09977874\n",
            "self.loss(score_2, v3) 0.03700326\n",
            "loss tensor(0.2971, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.0764912\n",
            "self.loss(score_0, v1) 0.094585836\n",
            "self.loss(score_0, v2) 0.06014888\n",
            "self.loss(score_2, v3) 0.031096667\n",
            "loss tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07451909\n",
            "self.loss(score_0, v1) 0.13477151\n",
            "self.loss(score_0, v2) 0.14559944\n",
            "self.loss(score_2, v3) 0.033253264\n",
            "loss tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22362421\n",
            "self.loss(score_0, v1) 0.4887377\n",
            "self.loss(score_0, v2) 0.42146152\n",
            "self.loss(score_2, v3) 0.019956574\n",
            "loss tensor(1.1638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10337082\n",
            "self.loss(score_0, v1) 0.10357638\n",
            "self.loss(score_0, v2) 0.058228746\n",
            "self.loss(score_2, v3) 0.02527767\n",
            "loss tensor(0.3031, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.10813203\n",
            "self.loss(score_0, v1) 0.19694965\n",
            "self.loss(score_0, v2) 0.20819578\n",
            "self.loss(score_2, v3) 0.031573184\n",
            "loss tensor(0.5606, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.030365448\n",
            "self.loss(score_0, v1) 0.19770639\n",
            "self.loss(score_0, v2) 0.21200466\n",
            "self.loss(score_2, v3) 0.02145232\n",
            "loss tensor(0.4723, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.07984511\n",
            "self.loss(score_0, v1) 0.1311135\n",
            "self.loss(score_0, v2) 0.13495536\n",
            "self.loss(score_2, v3) 0.035353024\n",
            "loss tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06259073\n",
            "self.loss(score_0, v1) 0.08925325\n",
            "self.loss(score_0, v2) 0.09557651\n",
            "self.loss(score_2, v3) 0.04195105\n",
            "loss tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.047386456\n",
            "self.loss(score_0, v1) 0.074275315\n",
            "self.loss(score_0, v2) 0.078917734\n",
            "self.loss(score_2, v3) 0.028208992\n",
            "loss tensor(0.2429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06262512\n",
            "self.loss(score_0, v1) 0.09117234\n",
            "self.loss(score_0, v2) 0.0778787\n",
            "self.loss(score_2, v3) 0.0342695\n",
            "loss tensor(0.2831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.067530215\n",
            "self.loss(score_0, v1) 0.109964006\n",
            "self.loss(score_0, v2) 0.14118814\n",
            "self.loss(score_2, v3) 0.030872678\n",
            "loss tensor(0.3650, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.052799482\n",
            "self.loss(score_0, v1) 0.06916031\n",
            "self.loss(score_0, v2) 0.087341644\n",
            "self.loss(score_2, v3) 0.044982404\n",
            "loss tensor(0.2768, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.06885513\n",
            "self.loss(score_0, v1) 0.090913884\n",
            "self.loss(score_0, v2) 0.086699106\n",
            "self.loss(score_2, v3) 0.034512144\n",
            "loss tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.05231038\n",
            "self.loss(score_0, v1) 0.068186454\n",
            "self.loss(score_0, v2) 0.10025493\n",
            "self.loss(score_2, v3) 0.04016408\n",
            "loss tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.071174115\n",
            "self.loss(score_0, v1) 0.19670759\n",
            "self.loss(score_0, v2) 0.20248166\n",
            "self.loss(score_2, v3) 0.04076235\n",
            "loss tensor(0.5315, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 0.4545936173504325, Train Accuracy : 0.9988746706443661\n",
            " Validation Accuracy : 6.599864973561443\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_0,'-o')\n",
        "plt.plot(loss_1,'-o')\n",
        "plt.plot(loss_2,'-o')\n",
        "plt.plot(loss_3,'-o')\n",
        "plt.xlabel('sample')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['loss 0','loss 1','loss 2','loss 3'])\n",
        "plt.title('loss vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UPfmfthBjSZw",
        "outputId": "2562876b-e182-4f42-8cde-e68d8546b133"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy evalutaion F-scores"
      ],
      "metadata": {
        "id": "sJbWsH72N2Mb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. create folder with part object of all pieces \n",
        "2. load a piece from dataloader with true labels, the mixed piece and the part object \n",
        "3. create notearray from part object\n",
        "4. take 1 note from notearrray - input -> find corresponding frame by looking at time and pitch\n",
        "\n",
        "\n",
        "Output: pianoroll\n",
        "\n",
        "1 note in notearray could be mulitple bins\n",
        "\n",
        "take 1 note from notearrray - input -> find corresponding frame by looking at time and pitch\n",
        "\n",
        "note start at same time with different pitch -> different notes\n",
        "\n",
        "for each note array find corresponding matrix -> \n",
        "\n",
        "\n",
        "if note is only composed by 1 bin: save indx of vocie -> save it to note array\n",
        "\n",
        "if more than 1: look what are idx that compose this note -> majority note -> save it for the note array (if its 50/50 take it random -> count how often this happens) \n",
        "\n",
        "\n",
        "with idx : in note_array find which note corresponds to what voice"
      ],
      "metadata": {
        "id": "CFClch37N6nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MusicDataset_new(PATH_TO_DATA) #MusicDataset(PATH_TO_DATA)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "\n",
        "val_dataloader "
      ],
      "metadata": {
        "id": "afYHFVNMlMnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef85f92-6ab4-4255-b607-11b16aaf436f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7feba7475cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## makes cell output nothing\n",
        "%%capture  \n",
        "output_dim = 88\n",
        "model = MusicNetwork(network_type, output_dim, hidden_dim, rnn_depth, cell_type)  \n",
        "checkpoint = torch.load(\"./AI-MA_project/model_temp_epoch5.pkl\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "4TAhTQcpmx8m"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create dic with key:filename, val: part_obj  for fugues"
      ],
      "metadata": {
        "id": "5RVmMv6Q9CJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if PATH_TO_DATA == \"AI-MA_project/bach_pr_fugues\":\n",
        "    path_parts = \"AI-MA_project/bach_fugues\"\n",
        "    part_dic = {}\n",
        "\n",
        "    #### create a list with all filenames in the right order ####\n",
        "    file_names_part = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.mid'): continue\n",
        "        file_names_part.append(filename[3:7])\n",
        "    #print(file_names_part)\n",
        "\n",
        "    #### create a list with all part objects in the right order ####\n",
        "    part_list = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.mid'): continue\n",
        "        fullname = os.path.join(path_parts, filename)\n",
        "        part = partitura.load_score_midi(fullname)\n",
        "        part_list.append(part)\n",
        "    #print(part_list)\n",
        "\n",
        "    #### create a dict with keys:filenames , values: part object ####\n",
        "    for i in range(len(file_names_part)):\n",
        "        part_dic[file_names_part[i]] = part_list[i]\n",
        "    \n",
        "    print(part_dic.keys(),part_dic.values())"
      ],
      "metadata": {
        "id": "_XYM_KWu2qkX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create dic with key:filename, val: part_obj  for chorales"
      ],
      "metadata": {
        "id": "6D9oTp_lNQbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if PATH_TO_DATA == \"AI-MA_project/pianoroll_88\":\n",
        "    path_parts = \"AI-MA_project/chorales_converted\"\n",
        "    part_dic = {}\n",
        "\n",
        "    #### create a list with all filenames in the right order ####\n",
        "    file_names_part = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.xml'): continue\n",
        "        file_names_part.append(filename[4:7])\n",
        "    #print(file_names_part)\n",
        "\n",
        "    #### create a list with all part objects in the right order ####\n",
        "    part_list = []\n",
        "    for filename in sorted(os.listdir(path_parts)):\n",
        "        if not filename.endswith('.xml'): continue\n",
        "        fullname = os.path.join(path_parts, filename)\n",
        "        part = partitura.load_musicxml(fullname)\n",
        "        part_list.append(part)\n",
        "    #print(part_list)\n",
        "\n",
        "    #### create a dict with keys:filenames , values: part object ####\n",
        "    for i in range(len(file_names_part)):\n",
        "        part_dic[file_names_part[i]] = part_list[i]\n",
        "    \n",
        "    print(\"part_dic.keys()\",part_dic.keys())\n",
        "    print(\"part_dic.values()\",part_dic.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4q58c16NjbE",
        "outputId": "05da6345-643f-417a-9fef-3d3a71e22662"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part_dic.keys() dict_keys(['001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '042', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', '054', '055', '056', '057', '058', '059', '060', '061', '062', '063', '064', '065', '066', '067', '068', '069', '070', '071', '072', '073', '074', '075', '076', '077', '078', '079', '080', '081', '082', '083', '084', '085', '086', '087', '088', '089', '090', '091', '092', '093', '094', '095', '096', '097', '098', '099', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371'])\n",
            "part_dic.values() dict_values([[<partitura.score.Part object at 0x7feba028f210>, <partitura.score.Part object at 0x7feba028f290>, <partitura.score.Part object at 0x7feba028f310>, <partitura.score.Part object at 0x7feba028f390>], [<partitura.score.Part object at 0x7feba01e2110>, <partitura.score.Part object at 0x7feba01a2950>, <partitura.score.Part object at 0x7feba01a29d0>, <partitura.score.Part object at 0x7feba01a2a50>], [<partitura.score.Part object at 0x7feba00847d0>, <partitura.score.Part object at 0x7feba004c550>, <partitura.score.Part object at 0x7feba004c5d0>, <partitura.score.Part object at 0x7feba004c650>], [<partitura.score.Part object at 0x7fea95f6b3d0>, <partitura.score.Part object at 0x7fea95f23a10>, <partitura.score.Part object at 0x7fea95f23a90>, <partitura.score.Part object at 0x7fea95f23b10>], [<partitura.score.Part object at 0x7fea95e612d0>, <partitura.score.Part object at 0x7fea95e1a510>, <partitura.score.Part object at 0x7fea95e1a590>, <partitura.score.Part object at 0x7fea95e1a610>], [<partitura.score.Part object at 0x7fea95ca9c90>, <partitura.score.Part object at 0x7fea95ca9f50>, <partitura.score.Part object at 0x7fea95ca9fd0>, <partitura.score.Part object at 0x7fea95c5e090>], [<partitura.score.Part object at 0x7fea95bc9810>, <partitura.score.Part object at 0x7fea95bf2810>, <partitura.score.Part object at 0x7fea95bf2890>, <partitura.score.Part object at 0x7fea95bf2910>], [<partitura.score.Part object at 0x7feba7513790>, <partitura.score.Part object at 0x7feba750df90>, <partitura.score.Part object at 0x7feba7e11c50>, <partitura.score.Part object at 0x7fec77d69d50>], [<partitura.score.Part object at 0x7feba759fc10>, <partitura.score.Part object at 0x7feba7561f90>, <partitura.score.Part object at 0x7feba7561e10>, <partitura.score.Part object at 0x7feba7550550>], [<partitura.score.Part object at 0x7feba9608590>, <partitura.score.Part object at 0x7fea9587e050>, <partitura.score.Part object at 0x7fea9587e310>, <partitura.score.Part object at 0x7fea9587e390>], [<partitura.score.Part object at 0x7fea957b1790>, <partitura.score.Part object at 0x7fea95767a10>, <partitura.score.Part object at 0x7fea95767a90>, <partitura.score.Part object at 0x7fea95767b10>], [<partitura.score.Part object at 0x7fea95581410>, <partitura.score.Part object at 0x7fea95575890>, <partitura.score.Part object at 0x7fea95575910>, <partitura.score.Part object at 0x7fea95575990>], [<partitura.score.Part object at 0x7fea954b0650>, <partitura.score.Part object at 0x7fea95459e90>, <partitura.score.Part object at 0x7fea95459f10>, <partitura.score.Part object at 0x7fea95459f90>], [<partitura.score.Part object at 0x7fea9536eb50>, <partitura.score.Part object at 0x7fea952c9cd0>, <partitura.score.Part object at 0x7fea952c9d50>, <partitura.score.Part object at 0x7fea952c9dd0>], [<partitura.score.Part object at 0x7fea951c4390>, <partitura.score.Part object at 0x7fea9518d290>, <partitura.score.Part object at 0x7fea9518d310>, <partitura.score.Part object at 0x7fea9518d390>], [<partitura.score.Part object at 0x7fea950f6a10>, <partitura.score.Part object at 0x7fea950bf510>, <partitura.score.Part object at 0x7fea950bf590>, <partitura.score.Part object at 0x7fea950bf610>], [<partitura.score.Part object at 0x7fea94f53dd0>, <partitura.score.Part object at 0x7fea94f32d90>, <partitura.score.Part object at 0x7fea94f32dd0>, <partitura.score.Part object at 0x7fea94f32e50>], [<partitura.score.Part object at 0x7fea94e7c210>, <partitura.score.Part object at 0x7fea94e35110>, <partitura.score.Part object at 0x7fea94e35190>, <partitura.score.Part object at 0x7fea94e35210>], [<partitura.score.Part object at 0x7fea94d724d0>, <partitura.score.Part object at 0x7fea94d309d0>, <partitura.score.Part object at 0x7fea94d30a50>, <partitura.score.Part object at 0x7fea94d30ad0>], [<partitura.score.Part object at 0x7fea94c70290>, <partitura.score.Part object at 0x7fea94c1ec50>, <partitura.score.Part object at 0x7fea94c1ecd0>, <partitura.score.Part object at 0x7fea94c1ed50>], [<partitura.score.Part object at 0x7fea94b06190>, <partitura.score.Part object at 0x7fea94ac6dd0>, <partitura.score.Part object at 0x7fea94ac6e50>, <partitura.score.Part object at 0x7fea94ac6ed0>], [<partitura.score.Part object at 0x7fea94a07990>, <partitura.score.Part object at 0x7fea949c0990>, <partitura.score.Part object at 0x7fea949c0a10>, <partitura.score.Part object at 0x7fea949c0a90>], [<partitura.score.Part object at 0x7fea9492ebd0>, <partitura.score.Part object at 0x7fea94884190>, <partitura.score.Part object at 0x7fea94884210>, <partitura.score.Part object at 0x7fea94884290>], [<partitura.score.Part object at 0x7fea94884250>, <partitura.score.Part object at 0x7fea947d6990>, <partitura.score.Part object at 0x7fea94790b90>, <partitura.score.Part object at 0x7fea94790c10>], [<partitura.score.Part object at 0x7fea946f0190>, <partitura.score.Part object at 0x7fea946ab690>, <partitura.score.Part object at 0x7fea946ab710>, <partitura.score.Part object at 0x7fea946ab790>], [<partitura.score.Part object at 0x7fea945fd510>, <partitura.score.Part object at 0x7fea945b8990>, <partitura.score.Part object at 0x7fea945b8a10>, <partitura.score.Part object at 0x7fea945b8a90>], [<partitura.score.Part object at 0x7fea944f9110>, <partitura.score.Part object at 0x7fea944af150>, <partitura.score.Part object at 0x7fea944af1d0>, <partitura.score.Part object at 0x7fea944af250>], [<partitura.score.Part object at 0x7fea943e5a90>, <partitura.score.Part object at 0x7fea94399ed0>, <partitura.score.Part object at 0x7fea94399f50>, <partitura.score.Part object at 0x7fea94399fd0>], [<partitura.score.Part object at 0x7fea9433a6d0>, <partitura.score.Part object at 0x7fea942e3890>, <partitura.score.Part object at 0x7fea942e3d50>, <partitura.score.Part object at 0x7fea942e3dd0>], [<partitura.score.Part object at 0x7fea941d7050>, <partitura.score.Part object at 0x7fea941f6710>, <partitura.score.Part object at 0x7fea941f6790>, <partitura.score.Part object at 0x7fea941f6810>], [<partitura.score.Part object at 0x7fea940cdad0>, <partitura.score.Part object at 0x7fea9408bf90>, <partitura.score.Part object at 0x7fea940af050>, <partitura.score.Part object at 0x7fea940af0d0>], [<partitura.score.Part object at 0x7fea93fdd650>, <partitura.score.Part object at 0x7fea93f95f90>, <partitura.score.Part object at 0x7fea93fb9050>, <partitura.score.Part object at 0x7fea93fb90d0>], [<partitura.score.Part object at 0x7fea93eeca90>, <partitura.score.Part object at 0x7fea93ea3d90>, <partitura.score.Part object at 0x7fea93ea3e10>, <partitura.score.Part object at 0x7fea93ea3e90>], [<partitura.score.Part object at 0x7fea93de5750>, <partitura.score.Part object at 0x7fea93d9d250>, <partitura.score.Part object at 0x7fea93d9d2d0>, <partitura.score.Part object at 0x7fea93d9d350>], [<partitura.score.Part object at 0x7fea93cadc10>, <partitura.score.Part object at 0x7fea93c7e990>, <partitura.score.Part object at 0x7fea93c7ea10>, <partitura.score.Part object at 0x7fea93c7ea90>], [<partitura.score.Part object at 0x7fea93bb5510>, <partitura.score.Part object at 0x7fea93b60990>, <partitura.score.Part object at 0x7fea93b7e090>, <partitura.score.Part object at 0x7fea93b7e110>], [<partitura.score.Part object at 0x7fea94838510>, <partitura.score.Part object at 0x7fea93a16190>, <partitura.score.Part object at 0x7fea93a16210>, <partitura.score.Part object at 0x7fea93a16290>], [<partitura.score.Part object at 0x7fea9397ea50>, <partitura.score.Part object at 0x7fea938c9510>, <partitura.score.Part object at 0x7fea938c9590>, <partitura.score.Part object at 0x7fea938c9610>], [<partitura.score.Part object at 0x7fea93801c90>, <partitura.score.Part object at 0x7fea93837490>, <partitura.score.Part object at 0x7fea93837510>, <partitura.score.Part object at 0x7fea93837590>], [<partitura.score.Part object at 0x7fea93719a10>, <partitura.score.Part object at 0x7fea936d4cd0>, <partitura.score.Part object at 0x7fea936d4d50>, <partitura.score.Part object at 0x7fea936d4dd0>], [<partitura.score.Part object at 0x7fea93666dd0>, <partitura.score.Part object at 0x7fea936195d0>, <partitura.score.Part object at 0x7fea93619650>, <partitura.score.Part object at 0x7fea936196d0>], [<partitura.score.Part object at 0x7fea93508cd0>, <partitura.score.Part object at 0x7fea934d3990>, <partitura.score.Part object at 0x7fea934d3a10>, <partitura.score.Part object at 0x7fea934d3a90>], [<partitura.score.Part object at 0x7fea934664d0>, <partitura.score.Part object at 0x7fea9340bb50>, <partitura.score.Part object at 0x7fea9340bbd0>, <partitura.score.Part object at 0x7fea9340bc50>], [<partitura.score.Part object at 0x7fea9336df10>, <partitura.score.Part object at 0x7fea932c4850>, <partitura.score.Part object at 0x7fea932c48d0>, <partitura.score.Part object at 0x7fea932c4950>], [<partitura.score.Part object at 0x7fea93271910>, <partitura.score.Part object at 0x7fea93226090>, <partitura.score.Part object at 0x7fea93226110>, <partitura.score.Part object at 0x7fea93226190>], [<partitura.score.Part object at 0x7fea9313c050>, <partitura.score.Part object at 0x7fea930834d0>, <partitura.score.Part object at 0x7fea93083550>, <partitura.score.Part object at 0x7fea930835d0>], [<partitura.score.Part object at 0x7fea92fc25d0>, <partitura.score.Part object at 0x7fea92f8c050>, <partitura.score.Part object at 0x7fea92f8c0d0>, <partitura.score.Part object at 0x7fea92f8c150>], [<partitura.score.Part object at 0x7fea93083590>, <partitura.score.Part object at 0x7fea92e82ad0>, <partitura.score.Part object at 0x7fea92e82a90>, <partitura.score.Part object at 0x7fea92e82b10>], [<partitura.score.Part object at 0x7fea92f8c110>, <partitura.score.Part object at 0x7fea92dfa3d0>, <partitura.score.Part object at 0x7fea92dfa410>, <partitura.score.Part object at 0x7fea92dfa490>], [<partitura.score.Part object at 0x7fea92cdd9d0>, <partitura.score.Part object at 0x7fea92c9afd0>, <partitura.score.Part object at 0x7fea92cbd090>, <partitura.score.Part object at 0x7fea92cbd110>], [<partitura.score.Part object at 0x7fea92beedd0>, <partitura.score.Part object at 0x7fea92bb4a10>, <partitura.score.Part object at 0x7fea92bb4a90>, <partitura.score.Part object at 0x7fea92bb4b10>], [<partitura.score.Part object at 0x7fea92afde90>, <partitura.score.Part object at 0x7fea92ab6fd0>, <partitura.score.Part object at 0x7fea92a56090>, <partitura.score.Part object at 0x7fea92a56110>], [<partitura.score.Part object at 0x7fea92946dd0>, <partitura.score.Part object at 0x7fea92922750>, <partitura.score.Part object at 0x7fea929227d0>, <partitura.score.Part object at 0x7fea92922850>], [<partitura.score.Part object at 0x7fea9284f750>, <partitura.score.Part object at 0x7fea92803490>, <partitura.score.Part object at 0x7fea92803510>, <partitura.score.Part object at 0x7fea92803590>], [<partitura.score.Part object at 0x7fea927a5ad0>, <partitura.score.Part object at 0x7fea9275bcd0>, <partitura.score.Part object at 0x7fea9275bd50>, <partitura.score.Part object at 0x7fea9275bdd0>], [<partitura.score.Part object at 0x7fea9269ab10>, <partitura.score.Part object at 0x7fea92653990>, <partitura.score.Part object at 0x7fea92653a10>, <partitura.score.Part object at 0x7fea92653a90>], [<partitura.score.Part object at 0x7fea92561110>, <partitura.score.Part object at 0x7fea9252e4d0>, <partitura.score.Part object at 0x7fea9252e510>, <partitura.score.Part object at 0x7fea9252e590>], [<partitura.score.Part object at 0x7fea924494d0>, <partitura.score.Part object at 0x7fea92472950>, <partitura.score.Part object at 0x7fea924729d0>, <partitura.score.Part object at 0x7fea92472a50>], [<partitura.score.Part object at 0x7fea92338c90>, <partitura.score.Part object at 0x7fea922aae10>, <partitura.score.Part object at 0x7fea922aae90>, <partitura.score.Part object at 0x7fea922aaf10>], [<partitura.score.Part object at 0x7fea92922810>, <partitura.score.Part object at 0x7fea92239cd0>, <partitura.score.Part object at 0x7fea921ba850>, <partitura.score.Part object at 0x7fea921baa50>], [<partitura.score.Part object at 0x7fea920edb90>, <partitura.score.Part object at 0x7fea920b1150>, <partitura.score.Part object at 0x7fea920b11d0>, <partitura.score.Part object at 0x7fea920b1250>], [<partitura.score.Part object at 0x7fea91fb6ed0>, <partitura.score.Part object at 0x7fea91f12090>, <partitura.score.Part object at 0x7fea91f12110>, <partitura.score.Part object at 0x7fea91f12190>], [<partitura.score.Part object at 0x7fea91eafe10>, <partitura.score.Part object at 0x7fea91e64890>, <partitura.score.Part object at 0x7fea91e64910>, <partitura.score.Part object at 0x7fea91e64990>], [<partitura.score.Part object at 0x7fea91da0c50>, <partitura.score.Part object at 0x7fea91d67690>, <partitura.score.Part object at 0x7fea91d67710>, <partitura.score.Part object at 0x7fea91d67790>], [<partitura.score.Part object at 0x7fea91c4e6d0>, <partitura.score.Part object at 0x7fea91c09c90>, <partitura.score.Part object at 0x7fea91c09d10>, <partitura.score.Part object at 0x7fea91c09d90>], [<partitura.score.Part object at 0x7fea91b4dfd0>, <partitura.score.Part object at 0x7fea91b07f50>, <partitura.score.Part object at 0x7fea91b07fd0>, <partitura.score.Part object at 0x7fea91b26090>], [<partitura.score.Part object at 0x7fea91a12590>, <partitura.score.Part object at 0x7fea919dee90>, <partitura.score.Part object at 0x7fea919def10>, <partitura.score.Part object at 0x7fea919def90>], [<partitura.score.Part object at 0x7fea918c6410>, <partitura.score.Part object at 0x7fea91884bd0>, <partitura.score.Part object at 0x7fea91884c50>, <partitura.score.Part object at 0x7fea91884cd0>], [<partitura.score.Part object at 0x7fea917c5510>, <partitura.score.Part object at 0x7fea917f7f50>, <partitura.score.Part object at 0x7fea917f7fd0>, <partitura.score.Part object at 0x7fea91794090>], [<partitura.score.Part object at 0x7fea916185d0>, <partitura.score.Part object at 0x7fea9159c690>, <partitura.score.Part object at 0x7fea9159c710>, <partitura.score.Part object at 0x7fea9159c790>], [<partitura.score.Part object at 0x7fea91403890>, <partitura.score.Part object at 0x7fea913eac10>, <partitura.score.Part object at 0x7fea913eac90>, <partitura.score.Part object at 0x7fea913ead10>], [<partitura.score.Part object at 0x7fea912f4450>, <partitura.score.Part object at 0x7fea91241e10>, <partitura.score.Part object at 0x7fea91241e90>, <partitura.score.Part object at 0x7fea91241f10>], [<partitura.score.Part object at 0x7fea911effd0>, <partitura.score.Part object at 0x7fea911a5b50>, <partitura.score.Part object at 0x7fea911a5bd0>, <partitura.score.Part object at 0x7fea911a5c50>], [<partitura.score.Part object at 0x7fea910f1ad0>, <partitura.score.Part object at 0x7fea910aee50>, <partitura.score.Part object at 0x7fea910aeed0>, <partitura.score.Part object at 0x7fea910aef50>], [<partitura.score.Part object at 0x7fea90fedf10>, <partitura.score.Part object at 0x7fea90fb3250>, <partitura.score.Part object at 0x7fea90fb32d0>, <partitura.score.Part object at 0x7fea90fb3350>], [<partitura.score.Part object at 0x7fea90ef50d0>, <partitura.score.Part object at 0x7fea90ea3ed0>, <partitura.score.Part object at 0x7fea90ea3f50>, <partitura.score.Part object at 0x7fea90ea3fd0>], [<partitura.score.Part object at 0x7fea90d8e850>, <partitura.score.Part object at 0x7fea90d59190>, <partitura.score.Part object at 0x7fea90d59210>, <partitura.score.Part object at 0x7fea90d59290>], [<partitura.score.Part object at 0x7fea90cbf810>, <partitura.score.Part object at 0x7fea90c0d210>, <partitura.score.Part object at 0x7fea90c0d290>, <partitura.score.Part object at 0x7fea90c0d310>], [<partitura.score.Part object at 0x7fea90b47e50>, <partitura.score.Part object at 0x7fea90b7ff90>, <partitura.score.Part object at 0x7fea90b21050>, <partitura.score.Part object at 0x7fea90b210d0>], [<partitura.score.Part object at 0x7fea90a6a250>, <partitura.score.Part object at 0x7fea90a33150>, <partitura.score.Part object at 0x7fea90a331d0>, <partitura.score.Part object at 0x7fea90a33250>], [<partitura.score.Part object at 0x7fea9097b790>, <partitura.score.Part object at 0x7fea909327d0>, <partitura.score.Part object at 0x7fea90932850>, <partitura.score.Part object at 0x7fea909328d0>], [<partitura.score.Part object at 0x7fea90821610>, <partitura.score.Part object at 0x7fea907e8a10>, <partitura.score.Part object at 0x7fea907e8a50>, <partitura.score.Part object at 0x7fea907e8ad0>], [<partitura.score.Part object at 0x7fea906e5d10>, <partitura.score.Part object at 0x7fea906be5d0>, <partitura.score.Part object at 0x7fea906be650>, <partitura.score.Part object at 0x7fea906be6d0>], [<partitura.score.Part object at 0x7fea905b8410>, <partitura.score.Part object at 0x7fea90504b90>, <partitura.score.Part object at 0x7fea90504c10>, <partitura.score.Part object at 0x7fea90504c90>], [<partitura.score.Part object at 0x7fea9041d610>, <partitura.score.Part object at 0x7fea903ee8d0>, <partitura.score.Part object at 0x7fea903ee950>, <partitura.score.Part object at 0x7fea903ee9d0>], [<partitura.score.Part object at 0x7fea902eaa10>, <partitura.score.Part object at 0x7fea902b6d90>, <partitura.score.Part object at 0x7fea902b6e10>, <partitura.score.Part object at 0x7fea902b6e90>], [<partitura.score.Part object at 0x7fea901af890>, <partitura.score.Part object at 0x7fea90179650>, <partitura.score.Part object at 0x7fea901796d0>, <partitura.score.Part object at 0x7fea90179750>], [<partitura.score.Part object at 0x7fea9004ff50>, <partitura.score.Part object at 0x7fea90019a90>, <partitura.score.Part object at 0x7fea90019b10>, <partitura.score.Part object at 0x7fea90019b90>], [<partitura.score.Part object at 0x7fea8ff70310>, <partitura.score.Part object at 0x7fea8ff2d590>, <partitura.score.Part object at 0x7fea8ff2d650>, <partitura.score.Part object at 0x7fea8ff2d610>], [<partitura.score.Part object at 0x7fea8fe66ad0>, <partitura.score.Part object at 0x7fea8fe2d250>, <partitura.score.Part object at 0x7fea8fe2d290>, <partitura.score.Part object at 0x7fea8fe2d310>], [<partitura.score.Part object at 0x7fea8fd45c50>, <partitura.score.Part object at 0x7fea8fd77e10>, <partitura.score.Part object at 0x7fea8fd77e90>, <partitura.score.Part object at 0x7fea8fd77f10>], [<partitura.score.Part object at 0x7fea8fba4450>, <partitura.score.Part object at 0x7fea8fb28e90>, <partitura.score.Part object at 0x7fea8fb28f10>, <partitura.score.Part object at 0x7fea8fb28f90>], [<partitura.score.Part object at 0x7fea8fa1bd10>, <partitura.score.Part object at 0x7fea8f9d8f90>, <partitura.score.Part object at 0x7fea8f9fa050>, <partitura.score.Part object at 0x7fea8f9fa0d0>], [<partitura.score.Part object at 0x7fea8f976d50>, <partitura.score.Part object at 0x7fea8f92d7d0>, <partitura.score.Part object at 0x7fea8f92d850>, <partitura.score.Part object at 0x7fea8f92d8d0>], [<partitura.score.Part object at 0x7fea8f85b850>, <partitura.score.Part object at 0x7fea8f813a50>, <partitura.score.Part object at 0x7fea8f813ad0>, <partitura.score.Part object at 0x7fea8f813b50>], [<partitura.score.Part object at 0x7fea8f7616d0>, <partitura.score.Part object at 0x7fea8f71ed50>, <partitura.score.Part object at 0x7fea8f71edd0>, <partitura.score.Part object at 0x7fea8f71ee50>], [<partitura.score.Part object at 0x7fea8f6007d0>, <partitura.score.Part object at 0x7fea8f63ba90>, <partitura.score.Part object at 0x7fea8f63bb10>, <partitura.score.Part object at 0x7fea8f63bb90>], [<partitura.score.Part object at 0x7fea8f529750>, <partitura.score.Part object at 0x7fea8f4f5a50>, <partitura.score.Part object at 0x7fea8f4f5ad0>, <partitura.score.Part object at 0x7fea8f4f5b50>], [<partitura.score.Part object at 0x7fea8f43de10>, <partitura.score.Part object at 0x7fea8f399050>, <partitura.score.Part object at 0x7fea8f3990d0>, <partitura.score.Part object at 0x7fea8f399150>], [<partitura.score.Part object at 0x7fea8f2c2410>, <partitura.score.Part object at 0x7fea8f2fc710>, <partitura.score.Part object at 0x7fea8f2fc790>, <partitura.score.Part object at 0x7fea8f2fc810>], [<partitura.score.Part object at 0x7fea8f1e1b90>, <partitura.score.Part object at 0x7fea8f1acb10>, <partitura.score.Part object at 0x7fea8f1acb90>, <partitura.score.Part object at 0x7fea8f1acc10>], [<partitura.score.Part object at 0x7fea8f0e5d50>, <partitura.score.Part object at 0x7fea8f09a990>, <partitura.score.Part object at 0x7fea8f09aa10>, <partitura.score.Part object at 0x7fea8f09aa90>], [<partitura.score.Part object at 0x7fea8efd7c50>, <partitura.score.Part object at 0x7fea8ef9c890>, <partitura.score.Part object at 0x7fea8ef9c910>, <partitura.score.Part object at 0x7fea8ef9c990>], [<partitura.score.Part object at 0x7fea8ee88090>, <partitura.score.Part object at 0x7fea8eea4710>, <partitura.score.Part object at 0x7fea8eea4790>, <partitura.score.Part object at 0x7fea8eea4810>], [<partitura.score.Part object at 0x7fea8edc5e90>, <partitura.score.Part object at 0x7fea8edfca50>, <partitura.score.Part object at 0x7fea8edfcad0>, <partitura.score.Part object at 0x7fea8edfcb50>], [<partitura.score.Part object at 0x7fea8ed370d0>, <partitura.score.Part object at 0x7fea8ecf0210>, <partitura.score.Part object at 0x7fea8ecf0290>, <partitura.score.Part object at 0x7fea8ecf0310>], [<partitura.score.Part object at 0x7fea8ebc3ed0>, <partitura.score.Part object at 0x7fea8eb98290>, <partitura.score.Part object at 0x7fea8eb98310>, <partitura.score.Part object at 0x7fea8eb98390>], [<partitura.score.Part object at 0x7fea8ea6f850>, <partitura.score.Part object at 0x7fea8e9dfa50>, <partitura.score.Part object at 0x7fea8e9dfad0>, <partitura.score.Part object at 0x7fea8e9dfb50>], [<partitura.score.Part object at 0x7fea8e9226d0>, <partitura.score.Part object at 0x7fea8e8d8ad0>, <partitura.score.Part object at 0x7fea8e8d8b50>, <partitura.score.Part object at 0x7fea8e8d8bd0>], [<partitura.score.Part object at 0x7fea8e7e86d0>, <partitura.score.Part object at 0x7fea8e743650>, <partitura.score.Part object at 0x7fea8e7436d0>, <partitura.score.Part object at 0x7fea8e743750>], [<partitura.score.Part object at 0x7fea8e69fd50>, <partitura.score.Part object at 0x7fea8e66aa90>, <partitura.score.Part object at 0x7fea8e66ab10>, <partitura.score.Part object at 0x7fea8e66ab90>], [<partitura.score.Part object at 0x7fea8e546b50>, <partitura.score.Part object at 0x7fea8e5091d0>, <partitura.score.Part object at 0x7fea8e509250>, <partitura.score.Part object at 0x7fea8e5092d0>], [<partitura.score.Part object at 0x7fea8e4a1a50>, <partitura.score.Part object at 0x7fea8e4543d0>, <partitura.score.Part object at 0x7fea8e454450>, <partitura.score.Part object at 0x7fea8e4544d0>], [<partitura.score.Part object at 0x7fea8e3b6d50>, <partitura.score.Part object at 0x7fea8e308450>, <partitura.score.Part object at 0x7fea8e308490>, <partitura.score.Part object at 0x7fea8e308510>], [<partitura.score.Part object at 0x7fea8e25f510>, <partitura.score.Part object at 0x7fea8e21c710>, <partitura.score.Part object at 0x7fea8e21c790>, <partitura.score.Part object at 0x7fea8e21c810>], [<partitura.score.Part object at 0x7fea8e17ea50>, <partitura.score.Part object at 0x7fea8e0c7490>, <partitura.score.Part object at 0x7fea8e0c7510>, <partitura.score.Part object at 0x7fea8e0c7590>], [<partitura.score.Part object at 0x7fea8df693d0>, <partitura.score.Part object at 0x7fea8dee2a90>, <partitura.score.Part object at 0x7fea8dee2b10>, <partitura.score.Part object at 0x7fea8dee2b90>], [<partitura.score.Part object at 0x7fea8dddc290>, <partitura.score.Part object at 0x7fea8dd9a790>, <partitura.score.Part object at 0x7fea8dd9a810>, <partitura.score.Part object at 0x7fea8dd9a890>], [<partitura.score.Part object at 0x7fea8dcdec90>, <partitura.score.Part object at 0x7fea8dca4690>, <partitura.score.Part object at 0x7fea8dca4710>, <partitura.score.Part object at 0x7fea8dca4790>], [<partitura.score.Part object at 0x7fea8db6bf10>, <partitura.score.Part object at 0x7fea8dad9b10>, <partitura.score.Part object at 0x7fea8dad9b90>, <partitura.score.Part object at 0x7fea8dad9c10>], [<partitura.score.Part object at 0x7fea8deaf190>, <partitura.score.Part object at 0x7fea8d9a3750>, <partitura.score.Part object at 0x7fea8d9a37d0>, <partitura.score.Part object at 0x7fea8d9a3850>], [<partitura.score.Part object at 0x7fea8d8463d0>, <partitura.score.Part object at 0x7fea8d823390>, <partitura.score.Part object at 0x7fea8d823410>, <partitura.score.Part object at 0x7fea8d823490>], [<partitura.score.Part object at 0x7fea8d734e90>, <partitura.score.Part object at 0x7fea8d691ad0>, <partitura.score.Part object at 0x7fea8d691b50>, <partitura.score.Part object at 0x7fea8d691bd0>], [<partitura.score.Part object at 0x7fea8d58a150>, <partitura.score.Part object at 0x7fea8d553090>, <partitura.score.Part object at 0x7fea8d553110>, <partitura.score.Part object at 0x7fea8d553190>], [<partitura.score.Part object at 0x7fea8d44c750>, <partitura.score.Part object at 0x7fea8d410b10>, <partitura.score.Part object at 0x7fea8d410b90>, <partitura.score.Part object at 0x7fea8d410c10>], [<partitura.score.Part object at 0x7fea8d354d90>, <partitura.score.Part object at 0x7fea8d318310>, <partitura.score.Part object at 0x7fea8d318390>, <partitura.score.Part object at 0x7fea8d318410>], [<partitura.score.Part object at 0x7fea8d278710>, <partitura.score.Part object at 0x7fea8d1c3690>, <partitura.score.Part object at 0x7fea8d1c3710>, <partitura.score.Part object at 0x7fea8d1c3790>], [<partitura.score.Part object at 0x7fea8d100dd0>, <partitura.score.Part object at 0x7fea8d137b10>, <partitura.score.Part object at 0x7fea8d137b90>, <partitura.score.Part object at 0x7fea8d137c10>], [<partitura.score.Part object at 0x7fea8d014d90>, <partitura.score.Part object at 0x7fea8cfe0790>, <partitura.score.Part object at 0x7fea8cfe0810>, <partitura.score.Part object at 0x7fea8cfe0890>], [<partitura.score.Part object at 0x7fea8cf26850>, <partitura.score.Part object at 0x7fea8cedcb50>, <partitura.score.Part object at 0x7fea8cedcbd0>, <partitura.score.Part object at 0x7fea8cedcc50>], [<partitura.score.Part object at 0x7fea8ce41a50>, <partitura.score.Part object at 0x7fea8ce60250>, <partitura.score.Part object at 0x7fea8ce602d0>, <partitura.score.Part object at 0x7fea8ce60350>], [<partitura.score.Part object at 0x7fea8cdf7810>, <partitura.score.Part object at 0x7fea8cda2e50>, <partitura.score.Part object at 0x7fea8cda2ed0>, <partitura.score.Part object at 0x7fea8cda2f50>], [<partitura.score.Part object at 0x7fea8caa9850>, <partitura.score.Part object at 0x7fea8c98b090>, <partitura.score.Part object at 0x7fea8c98b110>, <partitura.score.Part object at 0x7fea8c98b190>], [<partitura.score.Part object at 0x7fea8c706790>, <partitura.score.Part object at 0x7fea8c6ade90>, <partitura.score.Part object at 0x7fea8c6adf10>, <partitura.score.Part object at 0x7fea8c6adf90>], [<partitura.score.Part object at 0x7fea8c5b6510>, <partitura.score.Part object at 0x7fea8c576b10>, <partitura.score.Part object at 0x7fea8c576b90>, <partitura.score.Part object at 0x7fea8c576c10>], [<partitura.score.Part object at 0x7fea8c411790>, <partitura.score.Part object at 0x7fea8c3e7f90>, <partitura.score.Part object at 0x7fea8c393050>, <partitura.score.Part object at 0x7fea8c3930d0>], [<partitura.score.Part object at 0x7fea8c312d50>, <partitura.score.Part object at 0x7fea8c2c64d0>, <partitura.score.Part object at 0x7fea8c2c6550>, <partitura.score.Part object at 0x7fea8c2c65d0>], [<partitura.score.Part object at 0x7fea8c1879d0>, <partitura.score.Part object at 0x7fea8c16d710>, <partitura.score.Part object at 0x7fea8c16d790>, <partitura.score.Part object at 0x7fea8c16d810>], [<partitura.score.Part object at 0x7fea8c0b9810>, <partitura.score.Part object at 0x7fea8c0745d0>, <partitura.score.Part object at 0x7fea8c074650>, <partitura.score.Part object at 0x7fea8c0746d0>], [<partitura.score.Part object at 0x7fea8bf40250>, <partitura.score.Part object at 0x7fea8bf7b9d0>, <partitura.score.Part object at 0x7fea8bf7ba50>, <partitura.score.Part object at 0x7fea8bf7bad0>], [<partitura.score.Part object at 0x7fea8be54910>, <partitura.score.Part object at 0x7fea8be0c8d0>, <partitura.score.Part object at 0x7fea8be0c950>, <partitura.score.Part object at 0x7fea8be0c9d0>], [<partitura.score.Part object at 0x7fea8bdbcdd0>, <partitura.score.Part object at 0x7fea8bd75a50>, <partitura.score.Part object at 0x7fea8bd75ad0>, <partitura.score.Part object at 0x7fea8bd75b50>], [<partitura.score.Part object at 0x7fea8bc64990>, <partitura.score.Part object at 0x7fea8bc2fa10>, <partitura.score.Part object at 0x7fea8bc2fa90>, <partitura.score.Part object at 0x7fea8bc2fb10>], [<partitura.score.Part object at 0x7fea8baf4410>, <partitura.score.Part object at 0x7fea8ba53310>, <partitura.score.Part object at 0x7fea8ba53350>, <partitura.score.Part object at 0x7fea8ba533d0>], [<partitura.score.Part object at 0x7fea8b9b6c90>, <partitura.score.Part object at 0x7fea8b97f510>, <partitura.score.Part object at 0x7fea8b97f590>, <partitura.score.Part object at 0x7fea8b97f610>], [<partitura.score.Part object at 0x7fea8b87e890>, <partitura.score.Part object at 0x7fea8b87e990>, <partitura.score.Part object at 0x7fea8b87e850>, <partitura.score.Part object at 0x7fea8b87eb10>], [<partitura.score.Part object at 0x7fea8b7b6710>, <partitura.score.Part object at 0x7fea8b76c4d0>, <partitura.score.Part object at 0x7fea8b76c550>, <partitura.score.Part object at 0x7fea8b76c5d0>], [<partitura.score.Part object at 0x7fea8b64e190>, <partitura.score.Part object at 0x7fea8b60da10>, <partitura.score.Part object at 0x7fea8b60da90>, <partitura.score.Part object at 0x7fea8b60db10>], [<partitura.score.Part object at 0x7fea8b5b2e50>, <partitura.score.Part object at 0x7fea8b567c50>, <partitura.score.Part object at 0x7fea8b567cd0>, <partitura.score.Part object at 0x7fea8b567d50>], [<partitura.score.Part object at 0x7fea8b4f21d0>, <partitura.score.Part object at 0x7fea8b497b10>, <partitura.score.Part object at 0x7fea8b497b90>, <partitura.score.Part object at 0x7fea8b497c10>], [<partitura.score.Part object at 0x7fea8b3d5050>, <partitura.score.Part object at 0x7fea8b3eb350>, <partitura.score.Part object at 0x7fea8b3eb3d0>, <partitura.score.Part object at 0x7fea8b3eb450>], [<partitura.score.Part object at 0x7fea8b2d81d0>, <partitura.score.Part object at 0x7fea8b2988d0>, <partitura.score.Part object at 0x7fea8b298950>, <partitura.score.Part object at 0x7fea8b2989d0>], [<partitura.score.Part object at 0x7fea8b1d4890>, <partitura.score.Part object at 0x7fea8b18ee10>, <partitura.score.Part object at 0x7fea8b18ee90>, <partitura.score.Part object at 0x7fea8b18ef10>], [<partitura.score.Part object at 0x7fea8b12b9d0>, <partitura.score.Part object at 0x7fea8b0d9f10>, <partitura.score.Part object at 0x7fea8b0d9f90>, <partitura.score.Part object at 0x7fea8b0f5050>], [<partitura.score.Part object at 0x7fea8afd0710>, <partitura.score.Part object at 0x7fea8af92ed0>, <partitura.score.Part object at 0x7fea8af92f50>, <partitura.score.Part object at 0x7fea8af92fd0>], [<partitura.score.Part object at 0x7fea8aec44d0>, <partitura.score.Part object at 0x7fea8aeeef10>, <partitura.score.Part object at 0x7fea8aeeef90>, <partitura.score.Part object at 0x7fea8ae8c050>], [<partitura.score.Part object at 0x7fea8ae18810>, <partitura.score.Part object at 0x7fea8adc5f50>, <partitura.score.Part object at 0x7fea8adc5fd0>, <partitura.score.Part object at 0x7fea8ade3090>], [<partitura.score.Part object at 0x7fea8ace2910>, <partitura.score.Part object at 0x7fea8acba410>, <partitura.score.Part object at 0x7fea8acba490>, <partitura.score.Part object at 0x7fea8acba510>], [<partitura.score.Part object at 0x7fea8abe86d0>, <partitura.score.Part object at 0x7fea8ab96e10>, <partitura.score.Part object at 0x7fea8ab96e90>, <partitura.score.Part object at 0x7fea8ab96f10>], [<partitura.score.Part object at 0x7fea8aac4f50>, <partitura.score.Part object at 0x7fea8aafba50>, <partitura.score.Part object at 0x7fea8aafbad0>, <partitura.score.Part object at 0x7fea8aafbb50>], [<partitura.score.Part object at 0x7fea8a9e5f50>, <partitura.score.Part object at 0x7fea8a9e5fd0>, <partitura.score.Part object at 0x7fea8b24e590>, <partitura.score.Part object at 0x7fea8ab96ed0>], [<partitura.score.Part object at 0x7fea8a8d4e10>, <partitura.score.Part object at 0x7fea8a8a1a50>, <partitura.score.Part object at 0x7fea8a8a1ad0>, <partitura.score.Part object at 0x7fea8a8a1b50>], [<partitura.score.Part object at 0x7fea8a7f9b90>, <partitura.score.Part object at 0x7fea8a7b3550>, <partitura.score.Part object at 0x7fea8a7b35d0>, <partitura.score.Part object at 0x7fea8a7b3650>], [<partitura.score.Part object at 0x7fea8a6f7c90>, <partitura.score.Part object at 0x7fea8a6ad410>, <partitura.score.Part object at 0x7fea8a6ad490>, <partitura.score.Part object at 0x7fea8a6ad510>], [<partitura.score.Part object at 0x7fea8a5f9e90>, <partitura.score.Part object at 0x7fea8a544250>, <partitura.score.Part object at 0x7fea8a5442d0>, <partitura.score.Part object at 0x7fea8a544350>], [<partitura.score.Part object at 0x7fea8a4b4250>, <partitura.score.Part object at 0x7fea8a4759d0>, <partitura.score.Part object at 0x7fea8a475a50>, <partitura.score.Part object at 0x7fea8a475ad0>], [<partitura.score.Part object at 0x7fea8a368b10>, <partitura.score.Part object at 0x7fea8a337a90>, <partitura.score.Part object at 0x7fea8a337b10>, <partitura.score.Part object at 0x7fea8a337b90>], [<partitura.score.Part object at 0x7fea8a2192d0>, <partitura.score.Part object at 0x7fea8a2195d0>, <partitura.score.Part object at 0x7fea8a2194d0>, <partitura.score.Part object at 0x7fea8a219690>], [<partitura.score.Part object at 0x7fea8a126b90>, <partitura.score.Part object at 0x7fea8a0f4810>, <partitura.score.Part object at 0x7fea8a0f4890>, <partitura.score.Part object at 0x7fea8a0f4910>], [<partitura.score.Part object at 0x7fea8a00eed0>, <partitura.score.Part object at 0x7fea89fc00d0>, <partitura.score.Part object at 0x7fea89fc0590>, <partitura.score.Part object at 0x7fea89fc0610>], [<partitura.score.Part object at 0x7fea89f16090>, <partitura.score.Part object at 0x7fea89f373d0>, <partitura.score.Part object at 0x7fea89f37450>, <partitura.score.Part object at 0x7fea89f374d0>], [<partitura.score.Part object at 0x7fea89e1a3d0>, <partitura.score.Part object at 0x7fea89dd7e10>, <partitura.score.Part object at 0x7fea89dd7e90>, <partitura.score.Part object at 0x7fea89dd7f10>], [<partitura.score.Part object at 0x7fea89d19850>, <partitura.score.Part object at 0x7fea89cd28d0>, <partitura.score.Part object at 0x7fea89cd2950>, <partitura.score.Part object at 0x7fea89cd29d0>], [<partitura.score.Part object at 0x7fea89c06cd0>, <partitura.score.Part object at 0x7fea89bc0950>, <partitura.score.Part object at 0x7fea89bc09d0>, <partitura.score.Part object at 0x7fea89bc0a50>], [<partitura.score.Part object at 0x7fea89b5db50>, <partitura.score.Part object at 0x7fea89b09f50>, <partitura.score.Part object at 0x7fea89b09fd0>, <partitura.score.Part object at 0x7fea89b24090>], [<partitura.score.Part object at 0x7fea89a51b90>, <partitura.score.Part object at 0x7fea89a0da10>, <partitura.score.Part object at 0x7fea89a0da90>, <partitura.score.Part object at 0x7fea89a0db10>], [<partitura.score.Part object at 0x7fea899aec50>, <partitura.score.Part object at 0x7fea89964950>, <partitura.score.Part object at 0x7fea899649d0>, <partitura.score.Part object at 0x7fea89964a50>], [<partitura.score.Part object at 0x7fea89883950>, <partitura.score.Part object at 0x7fea898b6690>, <partitura.score.Part object at 0x7fea898b6710>, <partitura.score.Part object at 0x7fea898b6790>], [<partitura.score.Part object at 0x7fea89749ed0>, <partitura.score.Part object at 0x7fea89725a10>, <partitura.score.Part object at 0x7fea89725a90>, <partitura.score.Part object at 0x7fea89725b10>], [<partitura.score.Part object at 0x7fea89725ad0>, <partitura.score.Part object at 0x7fea898b6750>, <partitura.score.Part object at 0x7fea8967c690>, <partitura.score.Part object at 0x7fea8967c750>], [<partitura.score.Part object at 0x7fea895bcbd0>, <partitura.score.Part object at 0x7fea89502590>, <partitura.score.Part object at 0x7fea89502610>, <partitura.score.Part object at 0x7fea89502690>], [<partitura.score.Part object at 0x7fea89458950>, <partitura.score.Part object at 0x7fea8941d3d0>, <partitura.score.Part object at 0x7fea8941d450>, <partitura.score.Part object at 0x7fea8941d4d0>], [<partitura.score.Part object at 0x7fea89373890>, <partitura.score.Part object at 0x7fea893328d0>, <partitura.score.Part object at 0x7fea89332950>, <partitura.score.Part object at 0x7fea893329d0>], [<partitura.score.Part object at 0x7fea89201910>, <partitura.score.Part object at 0x7fea891c5410>, <partitura.score.Part object at 0x7fea891c5490>, <partitura.score.Part object at 0x7fea891c5510>], [<partitura.score.Part object at 0x7fea891709d0>, <partitura.score.Part object at 0x7fea89124150>, <partitura.score.Part object at 0x7fea891241d0>, <partitura.score.Part object at 0x7fea89124250>], [<partitura.score.Part object at 0x7fea890716d0>, <partitura.score.Part object at 0x7fea8902f650>, <partitura.score.Part object at 0x7fea8902f6d0>, <partitura.score.Part object at 0x7fea8902f750>], [<partitura.score.Part object at 0x7fea88f4f510>, <partitura.score.Part object at 0x7fea88f7ba50>, <partitura.score.Part object at 0x7fea88f7bad0>, <partitura.score.Part object at 0x7fea88f7bb50>], [<partitura.score.Part object at 0x7fea88ea7790>, <partitura.score.Part object at 0x7fea88e4ff90>, <partitura.score.Part object at 0x7fea88e6e050>, <partitura.score.Part object at 0x7fea88e6e0d0>], [<partitura.score.Part object at 0x7fea88dfb790>, <partitura.score.Part object at 0x7fea88da8cd0>, <partitura.score.Part object at 0x7fea88da8d50>, <partitura.score.Part object at 0x7fea88da8dd0>], [<partitura.score.Part object at 0x7fea88c9d050>, <partitura.score.Part object at 0x7fea88cb0b50>, <partitura.score.Part object at 0x7fea88cb0bd0>, <partitura.score.Part object at 0x7fea88cb0c50>], [<partitura.score.Part object at 0x7fea88be6310>, <partitura.score.Part object at 0x7fea88b9e310>, <partitura.score.Part object at 0x7fea88b9e390>, <partitura.score.Part object at 0x7fea88b9e410>], [<partitura.score.Part object at 0x7fea88b3d950>, <partitura.score.Part object at 0x7fea88af4250>, <partitura.score.Part object at 0x7fea88af42d0>, <partitura.score.Part object at 0x7fea88af4350>], [<partitura.score.Part object at 0x7fea88a08ed0>, <partitura.score.Part object at 0x7fea88a3ca50>, <partitura.score.Part object at 0x7fea88a3cad0>, <partitura.score.Part object at 0x7fea88a3cb50>], [<partitura.score.Part object at 0x7fea8896cd90>, <partitura.score.Part object at 0x7fea8892e210>, <partitura.score.Part object at 0x7fea8892e290>, <partitura.score.Part object at 0x7fea8892e310>], [<partitura.score.Part object at 0x7fea888128d0>, <partitura.score.Part object at 0x7fea887db590>, <partitura.score.Part object at 0x7fea887db610>, <partitura.score.Part object at 0x7fea887db690>], [<partitura.score.Part object at 0x7fea886ce410>, <partitura.score.Part object at 0x7fea88691d10>, <partitura.score.Part object at 0x7fea88691d90>, <partitura.score.Part object at 0x7fea88691e10>], [<partitura.score.Part object at 0x7fea884b0d10>, <partitura.score.Part object at 0x7fea883e12d0>, <partitura.score.Part object at 0x7fea883e1350>, <partitura.score.Part object at 0x7fea883e13d0>], [<partitura.score.Part object at 0x7fea882b20d0>, <partitura.score.Part object at 0x7fea8820ac90>, <partitura.score.Part object at 0x7fea8820ad10>, <partitura.score.Part object at 0x7fea8820ad90>], [<partitura.score.Part object at 0x7fea8810f750>, <partitura.score.Part object at 0x7fea880d5a50>, <partitura.score.Part object at 0x7fea880d5ad0>, <partitura.score.Part object at 0x7fea880d5b50>], [<partitura.score.Part object at 0x7fea87fd7e10>, <partitura.score.Part object at 0x7fea87fa3950>, <partitura.score.Part object at 0x7fea87fa39d0>, <partitura.score.Part object at 0x7fea87fa3a50>], [<partitura.score.Part object at 0x7fea87e76d10>, <partitura.score.Part object at 0x7fea87ddefd0>, <partitura.score.Part object at 0x7fea87d8f090>, <partitura.score.Part object at 0x7fea87d8f110>], [<partitura.score.Part object at 0x7fea88c9da50>, <partitura.score.Part object at 0x7fea87bdfe10>, <partitura.score.Part object at 0x7fea87bdfe90>, <partitura.score.Part object at 0x7fea87bdff10>], [<partitura.score.Part object at 0x7fea87aeb6d0>, <partitura.score.Part object at 0x7fea87aaa9d0>, <partitura.score.Part object at 0x7fea87aaaa50>, <partitura.score.Part object at 0x7fea87aaaad0>], [<partitura.score.Part object at 0x7fea87a3bf10>, <partitura.score.Part object at 0x7fea879ed7d0>, <partitura.score.Part object at 0x7fea879ed850>, <partitura.score.Part object at 0x7fea879ed8d0>], [<partitura.score.Part object at 0x7fea8767b9d0>, <partitura.score.Part object at 0x7fea8752f150>, <partitura.score.Part object at 0x7fea8752f190>, <partitura.score.Part object at 0x7fea8752f210>], [<partitura.score.Part object at 0x7fea873ec9d0>, <partitura.score.Part object at 0x7fea87346210>, <partitura.score.Part object at 0x7fea87346290>, <partitura.score.Part object at 0x7fea87346310>], [<partitura.score.Part object at 0x7fea87293890>, <partitura.score.Part object at 0x7fea87243f90>, <partitura.score.Part object at 0x7fea8725f050>, <partitura.score.Part object at 0x7fea8725f0d0>], [<partitura.score.Part object at 0x7fea871aded0>, <partitura.score.Part object at 0x7fea87179b50>, <partitura.score.Part object at 0x7fea87179bd0>, <partitura.score.Part object at 0x7fea87179c50>], [<partitura.score.Part object at 0x7fea87052650>, <partitura.score.Part object at 0x7fea87017910>, <partitura.score.Part object at 0x7fea87017990>, <partitura.score.Part object at 0x7fea87017a10>], [<partitura.score.Part object at 0x7fea86f11750>, <partitura.score.Part object at 0x7fea86ed1f90>, <partitura.score.Part object at 0x7fea86ef6050>, <partitura.score.Part object at 0x7fea86ef60d0>], [<partitura.score.Part object at 0x7fea86df0350>, <partitura.score.Part object at 0x7fea86d43710>, <partitura.score.Part object at 0x7fea86d43790>, <partitura.score.Part object at 0x7fea86d43810>], [<partitura.score.Part object at 0x7fea86cb0fd0>, <partitura.score.Part object at 0x7fea86c7c490>, <partitura.score.Part object at 0x7fea86c7c510>, <partitura.score.Part object at 0x7fea86c7c590>], [<partitura.score.Part object at 0x7fea86bb1a50>, <partitura.score.Part object at 0x7fea86b69a10>, <partitura.score.Part object at 0x7fea86b69a90>, <partitura.score.Part object at 0x7fea86b69b10>], [<partitura.score.Part object at 0x7fea869abe50>, <partitura.score.Part object at 0x7fea8693b6d0>, <partitura.score.Part object at 0x7fea8693b750>, <partitura.score.Part object at 0x7fea8693b7d0>], [<partitura.score.Part object at 0x7fea86702cd0>, <partitura.score.Part object at 0x7fea86696410>, <partitura.score.Part object at 0x7fea86696490>, <partitura.score.Part object at 0x7fea86696510>], [<partitura.score.Part object at 0x7fea86554350>, <partitura.score.Part object at 0x7fea8652de90>, <partitura.score.Part object at 0x7fea8652df10>, <partitura.score.Part object at 0x7fea8652df90>], [<partitura.score.Part object at 0x7fea86458390>, <partitura.score.Part object at 0x7fea8647dd90>, <partitura.score.Part object at 0x7fea8647de10>, <partitura.score.Part object at 0x7fea8647de90>], [<partitura.score.Part object at 0x7fea86309690>, <partitura.score.Part object at 0x7fea862d93d0>, <partitura.score.Part object at 0x7fea862d9450>, <partitura.score.Part object at 0x7fea862d94d0>], [<partitura.score.Part object at 0x7fea8622e3d0>, <partitura.score.Part object at 0x7fea861e1e90>, <partitura.score.Part object at 0x7fea861e1f10>, <partitura.score.Part object at 0x7fea861e1f90>], [<partitura.score.Part object at 0x7fea86060e50>, <partitura.score.Part object at 0x7fea85fd2210>, <partitura.score.Part object at 0x7fea85fd2290>, <partitura.score.Part object at 0x7fea85fd2310>], [<partitura.score.Part object at 0x7fea85f307d0>, <partitura.score.Part object at 0x7fea85eec510>, <partitura.score.Part object at 0x7fea85eec590>, <partitura.score.Part object at 0x7fea85eec610>], [<partitura.score.Part object at 0x7fea85fd22d0>, <partitura.score.Part object at 0x7fea85e2ffd0>, <partitura.score.Part object at 0x7fea85df6390>, <partitura.score.Part object at 0x7fea85df6410>], [<partitura.score.Part object at 0x7fea868167d0>, <partitura.score.Part object at 0x7fea85c4c390>, <partitura.score.Part object at 0x7fea85c4c410>, <partitura.score.Part object at 0x7fea85c4c490>], [<partitura.score.Part object at 0x7fea85be6d10>, <partitura.score.Part object at 0x7fea85b9c590>, <partitura.score.Part object at 0x7fea85b9c610>, <partitura.score.Part object at 0x7fea85b9c690>], [<partitura.score.Part object at 0x7fea85aea850>, <partitura.score.Part object at 0x7fea85aa5890>, <partitura.score.Part object at 0x7fea85aa5910>, <partitura.score.Part object at 0x7fea85aa5990>], [<partitura.score.Part object at 0x7fea85983690>, <partitura.score.Part object at 0x7fea859415d0>, <partitura.score.Part object at 0x7fea85941650>, <partitura.score.Part object at 0x7fea859416d0>], [<partitura.score.Part object at 0x7fea858136d0>, <partitura.score.Part object at 0x7fea857f0c10>, <partitura.score.Part object at 0x7fea857f0c90>, <partitura.score.Part object at 0x7fea857f0d10>], [<partitura.score.Part object at 0x7fea85778150>, <partitura.score.Part object at 0x7fea85710910>, <partitura.score.Part object at 0x7fea85710cd0>, <partitura.score.Part object at 0x7fea85710d50>], [<partitura.score.Part object at 0x7fea855e4610>, <partitura.score.Part object at 0x7fea8554e610>, <partitura.score.Part object at 0x7fea8554e690>, <partitura.score.Part object at 0x7fea8554e710>], [<partitura.score.Part object at 0x7fea854ad2d0>, <partitura.score.Part object at 0x7fea85468510>, <partitura.score.Part object at 0x7fea85468590>, <partitura.score.Part object at 0x7fea85468610>], [<partitura.score.Part object at 0x7fea8537cb50>, <partitura.score.Part object at 0x7fea8537cc10>, <partitura.score.Part object at 0x7fea8537cb90>, <partitura.score.Part object at 0x7fea8537cc90>], [<partitura.score.Part object at 0x7fea85246950>, <partitura.score.Part object at 0x7fea85202e90>, <partitura.score.Part object at 0x7fea85202f10>, <partitura.score.Part object at 0x7fea85202f90>], [<partitura.score.Part object at 0x7fea85152710>, <partitura.score.Part object at 0x7fea8510bb90>, <partitura.score.Part object at 0x7fea8510bc10>, <partitura.score.Part object at 0x7fea8510bc90>], [<partitura.score.Part object at 0x7fea84feedd0>, <partitura.score.Part object at 0x7fea84f675d0>, <partitura.score.Part object at 0x7fea84f67650>, <partitura.score.Part object at 0x7fea84f676d0>], [<partitura.score.Part object at 0x7fea84e1f890>, <partitura.score.Part object at 0x7fea84df4c50>, <partitura.score.Part object at 0x7fea84df4cd0>, <partitura.score.Part object at 0x7fea84df4d50>], [<partitura.score.Part object at 0x7fea84d1e410>, <partitura.score.Part object at 0x7fea84cc7f50>, <partitura.score.Part object at 0x7fea84cc7fd0>, <partitura.score.Part object at 0x7fea84ce5090>], [<partitura.score.Part object at 0x7fea84be2d50>, <partitura.score.Part object at 0x7fea84b41610>, <partitura.score.Part object at 0x7fea84b41690>, <partitura.score.Part object at 0x7fea84b41710>], [<partitura.score.Part object at 0x7fea84afb2d0>, <partitura.score.Part object at 0x7fea84aaad50>, <partitura.score.Part object at 0x7fea84aaadd0>, <partitura.score.Part object at 0x7fea84aaae50>], [<partitura.score.Part object at 0x7fea849a7f90>, <partitura.score.Part object at 0x7fea84978450>, <partitura.score.Part object at 0x7fea849784d0>, <partitura.score.Part object at 0x7fea84978550>], [<partitura.score.Part object at 0x7fea8488c510>, <partitura.score.Part object at 0x7fea848b4710>, <partitura.score.Part object at 0x7fea848b4790>, <partitura.score.Part object at 0x7fea848b4810>], [<partitura.score.Part object at 0x7fea846ae450>, <partitura.score.Part object at 0x7fea845ca9d0>, <partitura.score.Part object at 0x7fea845caa50>, <partitura.score.Part object at 0x7fea845caad0>], [<partitura.score.Part object at 0x7fea844c9750>, <partitura.score.Part object at 0x7fea84488710>, <partitura.score.Part object at 0x7fea84488790>, <partitura.score.Part object at 0x7fea84488810>], [<partitura.score.Part object at 0x7fea843e7f10>, <partitura.score.Part object at 0x7fea843b6390>, <partitura.score.Part object at 0x7fea843b6410>, <partitura.score.Part object at 0x7fea843b6490>], [<partitura.score.Part object at 0x7fea842bfd90>, <partitura.score.Part object at 0x7fea84218b50>, <partitura.score.Part object at 0x7fea84218bd0>, <partitura.score.Part object at 0x7fea84218c50>], [<partitura.score.Part object at 0x7fea84167190>, <partitura.score.Part object at 0x7fea84111bd0>, <partitura.score.Part object at 0x7fea84111c50>, <partitura.score.Part object at 0x7fea84111cd0>], [<partitura.score.Part object at 0x7fea84012dd0>, <partitura.score.Part object at 0x7fea83fdd3d0>, <partitura.score.Part object at 0x7fea83fdd450>, <partitura.score.Part object at 0x7fea83fdd4d0>], [<partitura.score.Part object at 0x7fea83f101d0>, <partitura.score.Part object at 0x7fea83edd050>, <partitura.score.Part object at 0x7fea83edd0d0>, <partitura.score.Part object at 0x7fea83edd150>], [<partitura.score.Part object at 0x7fea83e0a7d0>, <partitura.score.Part object at 0x7fea83dc1d90>, <partitura.score.Part object at 0x7fea83dc1e10>, <partitura.score.Part object at 0x7fea83dc1e90>], [<partitura.score.Part object at 0x7fea83d39090>, <partitura.score.Part object at 0x7fea83cd96d0>, <partitura.score.Part object at 0x7fea83cd9750>, <partitura.score.Part object at 0x7fea83cd97d0>], [<partitura.score.Part object at 0x7fea83c3cd10>, <partitura.score.Part object at 0x7fea83b88b50>, <partitura.score.Part object at 0x7fea83b88bd0>, <partitura.score.Part object at 0x7fea83b88c50>], [<partitura.score.Part object at 0x7fea83acb3d0>, <partitura.score.Part object at 0x7fea83a8ea50>, <partitura.score.Part object at 0x7fea83a8ead0>, <partitura.score.Part object at 0x7fea83a8eb50>], [<partitura.score.Part object at 0x7fea8393f550>, <partitura.score.Part object at 0x7fea83849650>, <partitura.score.Part object at 0x7fea838496d0>, <partitura.score.Part object at 0x7fea83849750>], [<partitura.score.Part object at 0x7fea83757c10>, <partitura.score.Part object at 0x7fea8372f650>, <partitura.score.Part object at 0x7fea8372f6d0>, <partitura.score.Part object at 0x7fea8372f750>], [<partitura.score.Part object at 0x7fea8360d990>, <partitura.score.Part object at 0x7fea835d5290>, <partitura.score.Part object at 0x7fea835d5310>, <partitura.score.Part object at 0x7fea835d5390>], [<partitura.score.Part object at 0x7fea834cd7d0>, <partitura.score.Part object at 0x7fea83497450>, <partitura.score.Part object at 0x7fea834974d0>, <partitura.score.Part object at 0x7fea83497550>], [<partitura.score.Part object at 0x7fea833fd2d0>, <partitura.score.Part object at 0x7fea833b8890>, <partitura.score.Part object at 0x7fea833b8910>, <partitura.score.Part object at 0x7fea833b8990>], [<partitura.score.Part object at 0x7fea832d9650>, <partitura.score.Part object at 0x7fea832900d0>, <partitura.score.Part object at 0x7fea83290150>, <partitura.score.Part object at 0x7fea832901d0>], [<partitura.score.Part object at 0x7fea83192990>, <partitura.score.Part object at 0x7fea831649d0>, <partitura.score.Part object at 0x7fea83164a50>, <partitura.score.Part object at 0x7fea83164ad0>], [<partitura.score.Part object at 0x7fea8a337b50>, <partitura.score.Part object at 0x7fea82f0b610>, <partitura.score.Part object at 0x7fea82f0b3d0>, <partitura.score.Part object at 0x7fea82f9a150>], [<partitura.score.Part object at 0x7fea82e09c50>, <partitura.score.Part object at 0x7fea82dc1f90>, <partitura.score.Part object at 0x7fea82de4050>, <partitura.score.Part object at 0x7fea82de40d0>], [<partitura.score.Part object at 0x7fea82d0f7d0>, <partitura.score.Part object at 0x7fea82cc9e90>, <partitura.score.Part object at 0x7fea82cc9f10>, <partitura.score.Part object at 0x7fea82cc9f90>], [<partitura.score.Part object at 0x7fea82c0bad0>, <partitura.score.Part object at 0x7fea82bc2e50>, <partitura.score.Part object at 0x7fea82bc2ed0>, <partitura.score.Part object at 0x7fea82bc2f50>], [<partitura.score.Part object at 0x7fea82b03e50>, <partitura.score.Part object at 0x7fea82b3af10>, <partitura.score.Part object at 0x7fea82b3af90>, <partitura.score.Part object at 0x7fea82adc050>], [<partitura.score.Part object at 0x7fea82a0bcd0>, <partitura.score.Part object at 0x7fea829d1d50>, <partitura.score.Part object at 0x7fea829d1dd0>, <partitura.score.Part object at 0x7fea829d1e50>], [<partitura.score.Part object at 0x7fea828db950>, <partitura.score.Part object at 0x7fea8289f6d0>, <partitura.score.Part object at 0x7fea8289f750>, <partitura.score.Part object at 0x7fea8289f7d0>], [<partitura.score.Part object at 0x7fea827e6e10>, <partitura.score.Part object at 0x7fea827aa1d0>, <partitura.score.Part object at 0x7fea827aa250>, <partitura.score.Part object at 0x7fea827aa2d0>], [<partitura.score.Part object at 0x7fea8268e410>, <partitura.score.Part object at 0x7fea8264dc10>, <partitura.score.Part object at 0x7fea8264dc90>, <partitura.score.Part object at 0x7fea8264dd10>], [<partitura.score.Part object at 0x7fea82520d50>, <partitura.score.Part object at 0x7fea8248efd0>, <partitura.score.Part object at 0x7fea82446090>, <partitura.score.Part object at 0x7fea82446110>], [<partitura.score.Part object at 0x7fea82394750>, <partitura.score.Part object at 0x7fea8234ff50>, <partitura.score.Part object at 0x7fea8234ffd0>, <partitura.score.Part object at 0x7fea82376090>], [<partitura.score.Part object at 0x7fea822b1ad0>, <partitura.score.Part object at 0x7fea82272d90>, <partitura.score.Part object at 0x7fea82272e10>, <partitura.score.Part object at 0x7fea82272e90>], [<partitura.score.Part object at 0x7fea82167a90>, <partitura.score.Part object at 0x7fea820c0550>, <partitura.score.Part object at 0x7fea820c05d0>, <partitura.score.Part object at 0x7fea820c0650>], [<partitura.score.Part object at 0x7fea81fcaa90>, <partitura.score.Part object at 0x7fea81fa7690>, <partitura.score.Part object at 0x7fea81fa7710>, <partitura.score.Part object at 0x7fea81fa7790>], [<partitura.score.Part object at 0x7fea81ea15d0>, <partitura.score.Part object at 0x7fea81e6c350>, <partitura.score.Part object at 0x7fea81e6c3d0>, <partitura.score.Part object at 0x7fea81e6c450>], [<partitura.score.Part object at 0x7fea81d425d0>, <partitura.score.Part object at 0x7fea81d7f650>, <partitura.score.Part object at 0x7fea81d7f6d0>, <partitura.score.Part object at 0x7fea81d7f750>], [<partitura.score.Part object at 0x7fea81cbd710>, <partitura.score.Part object at 0x7fea81c79f10>, <partitura.score.Part object at 0x7fea81c79f90>, <partitura.score.Part object at 0x7fea81c1f050>], [<partitura.score.Part object at 0x7fea81bbc690>, <partitura.score.Part object at 0x7fea81b747d0>, <partitura.score.Part object at 0x7fea81b74850>, <partitura.score.Part object at 0x7fea81b748d0>], [<partitura.score.Part object at 0x7fea819deb10>, <partitura.score.Part object at 0x7fea81951f90>, <partitura.score.Part object at 0x7fea8190a050>, <partitura.score.Part object at 0x7fea8190a0d0>], [<partitura.score.Part object at 0x7fea81847a50>, <partitura.score.Part object at 0x7fea81810210>, <partitura.score.Part object at 0x7fea81810290>, <partitura.score.Part object at 0x7fea81810310>], [<partitura.score.Part object at 0x7fea817b55d0>, <partitura.score.Part object at 0x7fea8175efd0>, <partitura.score.Part object at 0x7fea8177d090>, <partitura.score.Part object at 0x7fea8177d110>], [<partitura.score.Part object at 0x7fea8163a990>, <partitura.score.Part object at 0x7fea815abcd0>, <partitura.score.Part object at 0x7fea815abd50>, <partitura.score.Part object at 0x7fea815abdd0>], [<partitura.score.Part object at 0x7fea81483d90>, <partitura.score.Part object at 0x7fea814bcd90>, <partitura.score.Part object at 0x7fea814bce10>, <partitura.score.Part object at 0x7fea814bce90>], [<partitura.score.Part object at 0x7fea81395110>, <partitura.score.Part object at 0x7fea813539d0>, <partitura.score.Part object at 0x7fea81353a50>, <partitura.score.Part object at 0x7fea81353ad0>], [<partitura.score.Part object at 0x7fea8120ded0>, <partitura.score.Part object at 0x7fea811d9d90>, <partitura.score.Part object at 0x7fea811d9e10>, <partitura.score.Part object at 0x7fea811d9e90>], [<partitura.score.Part object at 0x7fea810c5810>, <partitura.score.Part object at 0x7fea810ab050>, <partitura.score.Part object at 0x7fea810ab0d0>, <partitura.score.Part object at 0x7fea810ab150>], [<partitura.score.Part object at 0x7fea80fd86d0>, <partitura.score.Part object at 0x7fea80f92c10>, <partitura.score.Part object at 0x7fea80f92c90>, <partitura.score.Part object at 0x7fea80f92d10>], [<partitura.score.Part object at 0x7fea80ee5c10>, <partitura.score.Part object at 0x7fea80e9ff10>, <partitura.score.Part object at 0x7fea80e9ff90>, <partitura.score.Part object at 0x7fea80e40050>], [<partitura.score.Part object at 0x7fea81c79fd0>, <partitura.score.Part object at 0x7fea80e0b190>, <partitura.score.Part object at 0x7fea80e0b290>, <partitura.score.Part object at 0x7fea80df6050>], [<partitura.score.Part object at 0x7fea80d25910>, <partitura.score.Part object at 0x7fea80ce0a50>, <partitura.score.Part object at 0x7fea80ce0ad0>, <partitura.score.Part object at 0x7fea80ce0b50>], [<partitura.score.Part object at 0x7fea80c32990>, <partitura.score.Part object at 0x7fea80bf7590>, <partitura.score.Part object at 0x7fea80bf7610>, <partitura.score.Part object at 0x7fea80bf7690>], [<partitura.score.Part object at 0x7fea80acb650>, <partitura.score.Part object at 0x7fea80a8ac90>, <partitura.score.Part object at 0x7fea80a8ad10>, <partitura.score.Part object at 0x7fea80a8ad90>], [<partitura.score.Part object at 0x7fea809ebe50>, <partitura.score.Part object at 0x7fea809bf250>, <partitura.score.Part object at 0x7fea809bf2d0>, <partitura.score.Part object at 0x7fea809bf350>], [<partitura.score.Part object at 0x7fea8088b910>, <partitura.score.Part object at 0x7fea80851250>, <partitura.score.Part object at 0x7fea808512d0>, <partitura.score.Part object at 0x7fea80851350>], [<partitura.score.Part object at 0x7fea80786150>, <partitura.score.Part object at 0x7fea807b1d90>, <partitura.score.Part object at 0x7fea807b1e10>, <partitura.score.Part object at 0x7fea807b1e90>], [<partitura.score.Part object at 0x7fea806fed10>, <partitura.score.Part object at 0x7fea806440d0>, <partitura.score.Part object at 0x7fea80644150>, <partitura.score.Part object at 0x7fea806441d0>], [<partitura.score.Part object at 0x7fea8058a5d0>, <partitura.score.Part object at 0x7fea8058a690>, <partitura.score.Part object at 0x7fea8058a610>, <partitura.score.Part object at 0x7fea8058a710>], [<partitura.score.Part object at 0x7fea80444ed0>, <partitura.score.Part object at 0x7fea8043c6d0>, <partitura.score.Part object at 0x7fea8043c750>, <partitura.score.Part object at 0x7fea8043c7d0>], [<partitura.score.Part object at 0x7fea802d6e50>, <partitura.score.Part object at 0x7fea802ae710>, <partitura.score.Part object at 0x7fea802ae790>, <partitura.score.Part object at 0x7fea802ae810>], [<partitura.score.Part object at 0x7fea80196210>, <partitura.score.Part object at 0x7fea80152a50>, <partitura.score.Part object at 0x7fea80152ad0>, <partitura.score.Part object at 0x7fea80152b50>], [<partitura.score.Part object at 0x7fea80047bd0>, <partitura.score.Part object at 0x7fea80010e10>, <partitura.score.Part object at 0x7fea80010e90>, <partitura.score.Part object at 0x7fea80010f10>], [<partitura.score.Part object at 0x7fea7ff4ad50>, <partitura.score.Part object at 0x7fea7ff02e90>, <partitura.score.Part object at 0x7fea7ff02f10>, <partitura.score.Part object at 0x7fea7ff02f90>], [<partitura.score.Part object at 0x7fea7fe54b50>, <partitura.score.Part object at 0x7fea7fe190d0>, <partitura.score.Part object at 0x7fea7fe19150>, <partitura.score.Part object at 0x7fea7fe191d0>], [<partitura.score.Part object at 0x7fea7fd0cb50>, <partitura.score.Part object at 0x7fea7fccfe50>, <partitura.score.Part object at 0x7fea7fccfed0>, <partitura.score.Part object at 0x7fea7fccff50>], [<partitura.score.Part object at 0x7fea7fc0e090>, <partitura.score.Part object at 0x7fea7fc23a90>, <partitura.score.Part object at 0x7fea7fc23b10>, <partitura.score.Part object at 0x7fea7fc23b90>], [<partitura.score.Part object at 0x7fea7fb6b190>, <partitura.score.Part object at 0x7fea7fb27090>, <partitura.score.Part object at 0x7fea7fb27110>, <partitura.score.Part object at 0x7fea7fb27190>], [<partitura.score.Part object at 0x7fea7fa0b8d0>, <partitura.score.Part object at 0x7fea7f9d6390>, <partitura.score.Part object at 0x7fea7f9d6410>, <partitura.score.Part object at 0x7fea7f9d6490>], [<partitura.score.Part object at 0x7fea7f8a9750>, <partitura.score.Part object at 0x7fea7f812a10>, <partitura.score.Part object at 0x7fea7f812a90>, <partitura.score.Part object at 0x7fea7f812b10>], [<partitura.score.Part object at 0x7fea7f6ce810>, <partitura.score.Part object at 0x7fea7f6af410>, <partitura.score.Part object at 0x7fea7f6af490>, <partitura.score.Part object at 0x7fea7f6af510>], [<partitura.score.Part object at 0x7fea7f5e19d0>, <partitura.score.Part object at 0x7fea7f596450>, <partitura.score.Part object at 0x7fea7f5964d0>, <partitura.score.Part object at 0x7fea7f596550>], [<partitura.score.Part object at 0x7fea7f442610>, <partitura.score.Part object at 0x7fea7f421e50>, <partitura.score.Part object at 0x7fea7f421ed0>, <partitura.score.Part object at 0x7fea7f421f50>], [<partitura.score.Part object at 0x7fea7f353e10>, <partitura.score.Part object at 0x7fea7f308790>, <partitura.score.Part object at 0x7fea7f308810>, <partitura.score.Part object at 0x7fea7f308890>], [<partitura.score.Part object at 0x7fea7f254390>, <partitura.score.Part object at 0x7fea7f20d590>, <partitura.score.Part object at 0x7fea7f20d610>, <partitura.score.Part object at 0x7fea7f20d690>], [<partitura.score.Part object at 0x7fea7f113810>, <partitura.score.Part object at 0x7fea7f0dfe90>, <partitura.score.Part object at 0x7fea7f0dff10>, <partitura.score.Part object at 0x7fea7f0dff90>], [<partitura.score.Part object at 0x7fea7f035bd0>, <partitura.score.Part object at 0x7fea7effd250>, <partitura.score.Part object at 0x7fea7effd2d0>, <partitura.score.Part object at 0x7fea7effd350>], [<partitura.score.Part object at 0x7fea7eed1350>, <partitura.score.Part object at 0x7fea7ee96190>, <partitura.score.Part object at 0x7fea7ee96210>, <partitura.score.Part object at 0x7fea7ee96290>], [<partitura.score.Part object at 0x7fea7eddd450>, <partitura.score.Part object at 0x7fea7ed96d50>, <partitura.score.Part object at 0x7fea7ed96dd0>, <partitura.score.Part object at 0x7fea7ed96e50>], [<partitura.score.Part object at 0x7fea7ecef050>, <partitura.score.Part object at 0x7fea7ec85b10>, <partitura.score.Part object at 0x7fea7ec85b90>, <partitura.score.Part object at 0x7fea7ec85c10>], [<partitura.score.Part object at 0x7fea7ebc1f10>, <partitura.score.Part object at 0x7fea7eb87710>, <partitura.score.Part object at 0x7fea7eb87790>, <partitura.score.Part object at 0x7fea7eb87810>], [<partitura.score.Part object at 0x7fea7eaed110>, <partitura.score.Part object at 0x7fea7eaab950>, <partitura.score.Part object at 0x7fea7eaab9d0>, <partitura.score.Part object at 0x7fea7eaaba50>], [<partitura.score.Part object at 0x7fea7e950a10>, <partitura.score.Part object at 0x7fea7e924dd0>, <partitura.score.Part object at 0x7fea7e924e50>, <partitura.score.Part object at 0x7fea7e924ed0>], [<partitura.score.Part object at 0x7fea7e89ffd0>, <partitura.score.Part object at 0x7fea7e841c10>, <partitura.score.Part object at 0x7fea7e841c50>, <partitura.score.Part object at 0x7fea7e841cd0>], [<partitura.score.Part object at 0x7fea7e7865d0>, <partitura.score.Part object at 0x7fea7e7417d0>, <partitura.score.Part object at 0x7fea7e741850>, <partitura.score.Part object at 0x7fea7e7418d0>], [<partitura.score.Part object at 0x7fea7e648e90>, <partitura.score.Part object at 0x7fea7e620610>, <partitura.score.Part object at 0x7fea7e620690>, <partitura.score.Part object at 0x7fea7e620710>], [<partitura.score.Part object at 0x7fea7e4cb050>, <partitura.score.Part object at 0x7fea7e4eaad0>, <partitura.score.Part object at 0x7fea7e4eab50>, <partitura.score.Part object at 0x7fea7e4eabd0>], [<partitura.score.Part object at 0x7fea7e43b210>, <partitura.score.Part object at 0x7fea7e3f30d0>, <partitura.score.Part object at 0x7fea7e3f3150>, <partitura.score.Part object at 0x7fea7e3f31d0>], [<partitura.score.Part object at 0x7fea7e332390>, <partitura.score.Part object at 0x7fea7e2efb90>, <partitura.score.Part object at 0x7fea7e2efc10>, <partitura.score.Part object at 0x7fea7e2efc90>], [<partitura.score.Part object at 0x7fea7e23e150>, <partitura.score.Part object at 0x7fea7e1f9590>, <partitura.score.Part object at 0x7fea7e1f9610>, <partitura.score.Part object at 0x7fea7e1f9690>], [<partitura.score.Part object at 0x7fea7e0e8cd0>, <partitura.score.Part object at 0x7fea7e0bd490>, <partitura.score.Part object at 0x7fea7e0bd510>, <partitura.score.Part object at 0x7fea7e0bd590>], [<partitura.score.Part object at 0x7fea7dfeabd0>, <partitura.score.Part object at 0x7fea7dfb2050>, <partitura.score.Part object at 0x7fea7dfb20d0>, <partitura.score.Part object at 0x7fea7dfb2150>], [<partitura.score.Part object at 0x7fea7deefc10>, <partitura.score.Part object at 0x7fea7deb9490>, <partitura.score.Part object at 0x7fea7deb9510>, <partitura.score.Part object at 0x7fea7deb9590>], [<partitura.score.Part object at 0x7fea7dd8d690>, <partitura.score.Part object at 0x7fea7dd48690>, <partitura.score.Part object at 0x7fea7dd48710>, <partitura.score.Part object at 0x7fea7dd48790>], [<partitura.score.Part object at 0x7fea7dc8c950>, <partitura.score.Part object at 0x7fea7dc42950>, <partitura.score.Part object at 0x7fea7dc429d0>, <partitura.score.Part object at 0x7fea7dc42a50>], [<partitura.score.Part object at 0x7fea7db48150>, <partitura.score.Part object at 0x7fea7db18510>, <partitura.score.Part object at 0x7fea7db18590>, <partitura.score.Part object at 0x7fea7db18610>], [<partitura.score.Part object at 0x7fea7da3d250>, <partitura.score.Part object at 0x7fea7d99c3d0>, <partitura.score.Part object at 0x7fea7d99c450>, <partitura.score.Part object at 0x7fea7d99c4d0>], [<partitura.score.Part object at 0x7fea7d8cc290>, <partitura.score.Part object at 0x7fea7d8f59d0>, <partitura.score.Part object at 0x7fea7d8f5a50>, <partitura.score.Part object at 0x7fea7d8f5ad0>], [<partitura.score.Part object at 0x7fea7d83e990>, <partitura.score.Part object at 0x7fea7d785110>, <partitura.score.Part object at 0x7fea7d785190>, <partitura.score.Part object at 0x7fea7d785210>], [<partitura.score.Part object at 0x7fea7d73bb50>, <partitura.score.Part object at 0x7fea7d6fe0d0>, <partitura.score.Part object at 0x7fea7d6fe150>, <partitura.score.Part object at 0x7fea7d6fe1d0>], [<partitura.score.Part object at 0x7fea7d5830d0>, <partitura.score.Part object at 0x7fea7d54fad0>, <partitura.score.Part object at 0x7fea7d54fb50>, <partitura.score.Part object at 0x7fea7d54fbd0>], [<partitura.score.Part object at 0x7fea7d4eb9d0>, <partitura.score.Part object at 0x7fea7d491d50>, <partitura.score.Part object at 0x7fea7d49c150>, <partitura.score.Part object at 0x7fea7d49c1d0>], [<partitura.score.Part object at 0x7fea7d3c9890>, <partitura.score.Part object at 0x7fea7d383250>, <partitura.score.Part object at 0x7fea7d3832d0>, <partitura.score.Part object at 0x7fea7d383350>], [<partitura.score.Part object at 0x7fea7d2c2710>, <partitura.score.Part object at 0x7fea7d2f9910>, <partitura.score.Part object at 0x7fea7d2f9990>, <partitura.score.Part object at 0x7fea7d2f9a10>], [<partitura.score.Part object at 0x7fea7d19b690>, <partitura.score.Part object at 0x7fea7d1775d0>, <partitura.score.Part object at 0x7fea7d177650>, <partitura.score.Part object at 0x7fea7d1776d0>], [<partitura.score.Part object at 0x7fea7d0b6710>, <partitura.score.Part object at 0x7fea7d06f950>, <partitura.score.Part object at 0x7fea7d06f9d0>, <partitura.score.Part object at 0x7fea7d06fa50>], [<partitura.score.Part object at 0x7fea7cf7e450>, <partitura.score.Part object at 0x7fea7cecd090>, <partitura.score.Part object at 0x7fea7cecd110>, <partitura.score.Part object at 0x7fea7cecd190>], [<partitura.score.Part object at 0x7fea7ce03490>, <partitura.score.Part object at 0x7fea7ce30fd0>, <partitura.score.Part object at 0x7fea7cdcf090>, <partitura.score.Part object at 0x7fea7cdcf110>], [<partitura.score.Part object at 0x7fea8289f8d0>, <partitura.score.Part object at 0x7fea80d61f50>, <partitura.score.Part object at 0x7fea7ccd7090>, <partitura.score.Part object at 0x7fea7ccd7290>], [<partitura.score.Part object at 0x7fea7cbd9a10>, <partitura.score.Part object at 0x7fea7cbabe10>, <partitura.score.Part object at 0x7fea7cbabe90>, <partitura.score.Part object at 0x7fea7cbabf10>], [<partitura.score.Part object at 0x7fea7caff290>, <partitura.score.Part object at 0x7fea7cab9810>, <partitura.score.Part object at 0x7fea7cab9890>, <partitura.score.Part object at 0x7fea7cab9910>], [<partitura.score.Part object at 0x7fea7c99c550>, <partitura.score.Part object at 0x7fea7c95ac50>, <partitura.score.Part object at 0x7fea7c95acd0>, <partitura.score.Part object at 0x7fea7c95ad50>], [<partitura.score.Part object at 0x7fea7c84abd0>, <partitura.score.Part object at 0x7fea7c817810>, <partitura.score.Part object at 0x7fea7c817890>, <partitura.score.Part object at 0x7fea7c817910>], [<partitura.score.Part object at 0x7fea7c75db50>, <partitura.score.Part object at 0x7fea7c722110>, <partitura.score.Part object at 0x7fea7c722190>, <partitura.score.Part object at 0x7fea7c722210>], [<partitura.score.Part object at 0x7fea7c63ad10>, <partitura.score.Part object at 0x7fea7c596490>, <partitura.score.Part object at 0x7fea7c596510>, <partitura.score.Part object at 0x7fea7c596590>], [<partitura.score.Part object at 0x7fea7c45a150>, <partitura.score.Part object at 0x7fea7c3c01d0>, <partitura.score.Part object at 0x7fea7c3c0210>, <partitura.score.Part object at 0x7fea7c3c0290>], [<partitura.score.Part object at 0x7fea7c31d150>, <partitura.score.Part object at 0x7fea7c2db790>, <partitura.score.Part object at 0x7fea7c2db810>, <partitura.score.Part object at 0x7fea7c2db890>], [<partitura.score.Part object at 0x7fea7c1c5050>, <partitura.score.Part object at 0x7fea7c1e5590>, <partitura.score.Part object at 0x7fea7c1e5610>, <partitura.score.Part object at 0x7fea7c1e5690>], [<partitura.score.Part object at 0x7fea7c12df50>, <partitura.score.Part object at 0x7fea7c0f0590>, <partitura.score.Part object at 0x7fea7c0f0610>, <partitura.score.Part object at 0x7fea7c0f0690>], [<partitura.score.Part object at 0x7fea7cc02690>, <partitura.score.Part object at 0x7fea7bfe70d0>, <partitura.score.Part object at 0x7fea7bfff410>, <partitura.score.Part object at 0x7fea7bfff4d0>], [<partitura.score.Part object at 0x7fea7bed5790>, <partitura.score.Part object at 0x7fea7be9b150>, <partitura.score.Part object at 0x7fea7be9b1d0>, <partitura.score.Part object at 0x7fea7be9b250>], [<partitura.score.Part object at 0x7fea7bdf4710>, <partitura.score.Part object at 0x7fea7bdaedd0>, <partitura.score.Part object at 0x7fea7bdaee10>, <partitura.score.Part object at 0x7fea7bdaee90>], [<partitura.score.Part object at 0x7fea7bc62850>, <partitura.score.Part object at 0x7fea7bbc0990>, <partitura.score.Part object at 0x7fea7bbc0a10>, <partitura.score.Part object at 0x7fea7bbc0a90>], [<partitura.score.Part object at 0x7fea7bb3f310>, <partitura.score.Part object at 0x7fea7bafd810>, <partitura.score.Part object at 0x7fea7bafd890>, <partitura.score.Part object at 0x7fea7bafd910>], [<partitura.score.Part object at 0x7fea7b9e9610>, <partitura.score.Part object at 0x7fea7b9a8f10>, <partitura.score.Part object at 0x7fea7b9a8f90>, <partitura.score.Part object at 0x7fea7b94d050>], [<partitura.score.Part object at 0x7fea7b8fb8d0>, <partitura.score.Part object at 0x7fea7b841050>, <partitura.score.Part object at 0x7fea7b8410d0>, <partitura.score.Part object at 0x7fea7b841150>], [<partitura.score.Part object at 0x7fea7b788910>, <partitura.score.Part object at 0x7fea7b74e450>, <partitura.score.Part object at 0x7fea7b74e4d0>, <partitura.score.Part object at 0x7fea7b74e550>], [<partitura.score.Part object at 0x7fea7b6b7c90>, <partitura.score.Part object at 0x7fea7b6016d0>, <partitura.score.Part object at 0x7fea7b601750>, <partitura.score.Part object at 0x7fea7b6017d0>], [<partitura.score.Part object at 0x7fea7b554150>, <partitura.score.Part object at 0x7fea7b50c6d0>, <partitura.score.Part object at 0x7fea7b50c750>, <partitura.score.Part object at 0x7fea7b50c7d0>], [<partitura.score.Part object at 0x7fea7b473f50>, <partitura.score.Part object at 0x7fea7b43ed50>, <partitura.score.Part object at 0x7fea7b43edd0>, <partitura.score.Part object at 0x7fea7b43ee50>], [<partitura.score.Part object at 0x7fea7b314a50>, <partitura.score.Part object at 0x7fea7b2ced50>, <partitura.score.Part object at 0x7fea7b2cedd0>, <partitura.score.Part object at 0x7fea7b2cee50>], [<partitura.score.Part object at 0x7fea7b21c890>, <partitura.score.Part object at 0x7fea7b1d8750>, <partitura.score.Part object at 0x7fea7b1d87d0>, <partitura.score.Part object at 0x7fea7b1d8850>], [<partitura.score.Part object at 0x7fea7b137b10>, <partitura.score.Part object at 0x7fea7b0814d0>, <partitura.score.Part object at 0x7fea7b081550>, <partitura.score.Part object at 0x7fea7b0815d0>], [<partitura.score.Part object at 0x7fea7aff7310>, <partitura.score.Part object at 0x7fea7af41690>, <partitura.score.Part object at 0x7fea7af41710>, <partitura.score.Part object at 0x7fea7af41790>]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate chorales"
      ],
      "metadata": {
        "id": "yphGmsr-NSV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluate chorals"
      ],
      "metadata": {
        "id": "v4TJGKiUs086"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_one_choral(model, train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match\n",
        "                                      \n",
        "            \n",
        "            #if idx > 40: # or idx==2:\n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "                part_3 = part[3]\n",
        "                note_array_3 = part_3.note_array\n",
        "\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "                note_counter_3 += len(note_array_3)\n",
        "\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "                \n",
        "                #print(\"note_array_0\",note_array_0)\n",
        "                   \n",
        "                \n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):\n",
        "                    #print(\"note_array[onset_beat]:\",note_array[\"onset_beat\"])\n",
        "                    \n",
        "                    #### get only indices that are positive\n",
        "\n",
        "                    onset_beat = note_array[\"onset_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "\n",
        "                    if onset_beat[0] < 0:\n",
        "                        #print(\"onset_beat:\",onset_beat)\n",
        "                        onset_beat -= onset_beat[0]  ### if 1st value of onset_beat is negative add the value of this entry to the whole entry (therefore -)\n",
        "                        #print(\"onset_beat after:\",onset_beat)\n",
        "\n",
        "                    #print(\"new onset\", onset_beat)\n",
        "                    duration_beat = note_array[\"duration_beat\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    \n",
        "                    #print(\"duration_beat:\",duration_beat)\n",
        "                    pitch_list = note_array[\"pitch\"]#[note_array[\"onset_beat\"]>=0]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "                    #print(\"note_idx_end:\",note_idx_end)\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "                    \n",
        "                    #print(\"note_idx_start\",note_idx_start)\n",
        "                    #print(\"note_idx_end\",note_idx_end)\n",
        "                    #print(\"pitch_list\",pitch_list)\n",
        "                    \n",
        "\n",
        "                    # do model prediction\n",
        "                    model.eval()\n",
        "                    voices = voices.to(device).float()\n",
        "                    monophonic=True\n",
        "                    with torch.no_grad():\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        #print(\"prediction:\",prediction)\n",
        "                        label = ground_truth_label_list[el_note_arr]\n",
        "\n",
        "                \n",
        "                    for i in range(len(note_idx_start)):\n",
        "\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "\n",
        "                        #print(\"prediction:\",pred_list_first)\n",
        "                        #if pred_list_first.shape == torch.Size([0]):\n",
        "                        #    print(\"empty:\",i)\n",
        "                        \n",
        "\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "                        accordance_dict[str(label)].append(0)\n",
        "\n",
        "\n",
        "                count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "                for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                    counting = 0\n",
        "                    ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                    for j in range(len(total_predictions_dict[i])):\n",
        "                        #print(\"total_predictions_dict[i][j]:\",total_predictions_dict[i][j] )\n",
        "                        #print(i,j)\n",
        "                        #if total_predictions_dict[i][j].shape == torch.Size([0]):\n",
        "                            #print(\"fail indices:\",i,j)\n",
        "\n",
        "                        if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                    count_dict_2[i].append(counting)\n",
        "\n",
        "                acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "                acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "\n",
        "                print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "                print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "\n",
        "                \n",
        "                acc_score_dict[\"0\"].append(acc_0)\n",
        "                acc_score_dict[\"1\"].append(acc_1)\n",
        "                acc_score_dict[\"2\"].append(acc_2)\n",
        "                acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "    print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "    return total_predictions_dict, acc_score_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])\n"
      ],
      "metadata": {
        "id": "UXr2DeiLSyLm"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pred , acc_score_dict, acc_0 , acc_1, acc_2, acc_3 = evaluate_one_choral(model,val_dataloader,part_dic,F1=False)\n",
        "acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghAmXcXTTtD1",
        "outputId": "011eafdb-286d-4bd2-8e02-bb0d91c7da90"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc 0, sample 0: 0.967741935483871\n",
            "acc 1, sample 0: 0.967479674796748\n",
            "acc 2, sample 0: 0.944954128440367\n",
            "acc 3, sample 0: 1.0\n",
            "acc 0, sample 1: 1.0\n",
            "acc 1, sample 1: 0.984375\n",
            "acc 2, sample 1: 1.0\n",
            "acc 3, sample 1: 1.0\n",
            "acc 0, sample 2: 1.0\n",
            "acc 1, sample 2: 1.0\n",
            "acc 2, sample 2: 0.9803921568627451\n",
            "acc 3, sample 2: 1.0\n",
            "acc 0, sample 3: 0.9583333333333334\n",
            "acc 1, sample 3: 0.9591836734693877\n",
            "acc 2, sample 3: 0.9565217391304348\n",
            "acc 3, sample 3: 1.0\n",
            "acc 0, sample 4: 1.0\n",
            "acc 1, sample 4: 0.875\n",
            "acc 2, sample 4: 0.8536585365853658\n",
            "acc 3, sample 4: 1.0\n",
            "acc 0, sample 5: 0.9666666666666667\n",
            "acc 1, sample 5: 0.9885057471264368\n",
            "acc 2, sample 5: 0.9425287356321839\n",
            "acc 3, sample 5: 0.9878048780487805\n",
            "acc 0, sample 6: 0.9906542056074766\n",
            "acc 1, sample 6: 0.9351851851851852\n",
            "acc 2, sample 6: 0.9702970297029703\n",
            "acc 3, sample 6: 1.0\n",
            "acc 0, sample 7: 0.9473684210526315\n",
            "acc 1, sample 7: 0.8666666666666667\n",
            "acc 2, sample 7: 0.9803921568627451\n",
            "acc 3, sample 7: 1.0\n",
            "acc 0, sample 8: 1.0\n",
            "acc 1, sample 8: 1.0\n",
            "acc 2, sample 8: 1.0\n",
            "acc 3, sample 8: 0.9565217391304348\n",
            "acc 0, sample 9: 0.9523809523809523\n",
            "acc 1, sample 9: 0.925\n",
            "acc 2, sample 9: 0.9473684210526315\n",
            "acc 3, sample 9: 1.0\n",
            "acc 0, sample 10: 1.0\n",
            "acc 1, sample 10: 0.9811320754716981\n",
            "acc 2, sample 10: 0.9795918367346939\n",
            "acc 3, sample 10: 1.0\n",
            "acc 0, sample 11: 0.9873417721518988\n",
            "acc 1, sample 11: 1.0\n",
            "acc 2, sample 11: 0.9692307692307692\n",
            "acc 3, sample 11: 1.0\n",
            "acc 0, sample 12: 0.9629629629629629\n",
            "acc 1, sample 12: 0.9166666666666666\n",
            "acc 2, sample 12: 0.9777777777777777\n",
            "acc 3, sample 12: 1.0\n",
            "acc 0, sample 13: 0.9846153846153847\n",
            "acc 1, sample 13: 0.9682539682539683\n",
            "acc 2, sample 13: 1.0\n",
            "acc 3, sample 13: 1.0\n",
            "acc 0, sample 14: 0.9726027397260274\n",
            "acc 1, sample 14: 0.9714285714285714\n",
            "acc 2, sample 14: 0.9354838709677419\n",
            "acc 3, sample 14: 1.0\n",
            "acc 0, sample 15: 0.9803921568627451\n",
            "acc 1, sample 15: 1.0\n",
            "acc 2, sample 15: 0.9591836734693877\n",
            "acc 3, sample 15: 1.0\n",
            "acc 0, sample 16: 0.9807692307692307\n",
            "acc 1, sample 16: 0.9433962264150944\n",
            "acc 2, sample 16: 1.0\n",
            "acc 3, sample 16: 1.0\n",
            "acc 0, sample 17: 1.0\n",
            "acc 1, sample 17: 0.9117647058823529\n",
            "acc 2, sample 17: 0.9473684210526315\n",
            "acc 3, sample 17: 0.967741935483871\n",
            "acc 0, sample 18: 0.9736842105263158\n",
            "acc 1, sample 18: 0.9393939393939394\n",
            "acc 2, sample 18: 1.0\n",
            "acc 3, sample 18: 1.0\n",
            "acc 0, sample 19: 0.9824561403508771\n",
            "acc 1, sample 19: 1.0\n",
            "acc 2, sample 19: 0.9803921568627451\n",
            "acc 3, sample 19: 1.0\n",
            "acc 0, sample 20: 1.0\n",
            "acc 1, sample 20: 0.9090909090909091\n",
            "acc 2, sample 20: 0.8627450980392157\n",
            "acc 3, sample 20: 1.0\n",
            "acc 0, sample 21: 1.0\n",
            "acc 1, sample 21: 0.9230769230769231\n",
            "acc 2, sample 21: 1.0\n",
            "acc 3, sample 21: 1.0\n",
            "acc 0, sample 22: 0.9868421052631579\n",
            "acc 1, sample 22: 1.0\n",
            "acc 2, sample 22: 0.98\n",
            "acc 3, sample 22: 0.9791666666666666\n",
            "acc 0, sample 23: 0.9649122807017544\n",
            "acc 1, sample 23: 0.9787234042553191\n",
            "acc 2, sample 23: 0.9803921568627451\n",
            "acc 3, sample 23: 0.9736842105263158\n",
            "acc 0, sample 24: 1.0\n",
            "acc 1, sample 24: 0.967741935483871\n",
            "acc 2, sample 24: 0.9629629629629629\n",
            "acc 3, sample 24: 0.9811320754716981\n",
            "acc 0, sample 25: 0.9433962264150944\n",
            "acc 1, sample 25: 0.98\n",
            "acc 2, sample 25: 1.0\n",
            "acc 3, sample 25: 1.0\n",
            "acc 0, sample 26: 1.0\n",
            "acc 1, sample 26: 1.0\n",
            "acc 2, sample 26: 0.9210526315789473\n",
            "acc 3, sample 26: 0.9473684210526315\n",
            "acc 0, sample 27: 1.0\n",
            "acc 1, sample 27: 0.972972972972973\n",
            "acc 2, sample 27: 1.0\n",
            "acc 3, sample 27: 1.0\n",
            "acc 0, sample 28: 0.9777777777777777\n",
            "acc 1, sample 28: 0.9512195121951219\n",
            "acc 2, sample 28: 0.9285714285714286\n",
            "acc 3, sample 28: 1.0\n",
            "acc 0, sample 29: 0.975609756097561\n",
            "acc 1, sample 29: 0.9069767441860465\n",
            "acc 2, sample 29: 0.9111111111111111\n",
            "acc 3, sample 29: 0.972972972972973\n",
            "acc 0, sample 30: 1.0\n",
            "acc 1, sample 30: 0.975\n",
            "acc 2, sample 30: 0.9736842105263158\n",
            "acc 3, sample 30: 1.0\n",
            "acc 0, sample 31: 1.0\n",
            "acc 1, sample 31: 1.0\n",
            "acc 2, sample 31: 1.0\n",
            "acc 3, sample 31: 1.0\n",
            "acc 0, sample 32: 0.9785714285714285\n",
            "acc 1, sample 32: 0.9685534591194969\n",
            "acc 2, sample 32: 0.9136690647482014\n",
            "acc 3, sample 32: 0.9655172413793104\n",
            "acc 0, sample 33: 0.9705882352941176\n",
            "acc 1, sample 33: 1.0\n",
            "acc 2, sample 33: 0.9761904761904762\n",
            "acc 3, sample 33: 1.0\n",
            "acc 0, sample 34: 0.9506172839506173\n",
            "acc 1, sample 34: 0.918918918918919\n",
            "acc 2, sample 34: 1.0\n",
            "acc 3, sample 34: 0.9846153846153847\n",
            "acc 0, sample 35: 0.9821428571428571\n",
            "acc 1, sample 35: 0.8775510204081632\n",
            "acc 2, sample 35: 0.9607843137254902\n",
            "acc 3, sample 35: 1.0\n",
            "acc 0, sample 36: 0.9538461538461539\n",
            "acc 1, sample 36: 1.0\n",
            "acc 2, sample 36: 0.9464285714285714\n",
            "acc 3, sample 36: 1.0\n",
            "acc 0, sample 37: 0.9512195121951219\n",
            "acc 1, sample 37: 0.98\n",
            "acc 2, sample 37: 1.0\n",
            "acc 3, sample 37: 1.0\n",
            "acc 0, sample 38: 0.9607843137254902\n",
            "acc 1, sample 38: 0.9245283018867925\n",
            "acc 2, sample 38: 0.9183673469387755\n",
            "acc 3, sample 38: 1.0\n",
            "acc 0, sample 39: 0.9682539682539683\n",
            "acc 1, sample 39: 0.8939393939393939\n",
            "acc 2, sample 39: 0.9242424242424242\n",
            "acc 3, sample 39: 1.0\n",
            "acc 0, sample 40: 0.8727272727272727\n",
            "acc 1, sample 40: 0.8392857142857143\n",
            "acc 2, sample 40: 0.92\n",
            "acc 3, sample 40: 0.9787234042553191\n",
            "acc 0, sample 41: 0.9743589743589743\n",
            "acc 1, sample 41: 0.9390243902439024\n",
            "acc 2, sample 41: 0.9857142857142858\n",
            "acc 3, sample 41: 1.0\n",
            "acc 0, sample 42: 1.0\n",
            "acc 1, sample 42: 1.0\n",
            "acc 2, sample 42: 1.0\n",
            "acc 3, sample 42: 1.0\n",
            "acc 0, sample 43: 1.0\n",
            "acc 1, sample 43: 0.9487179487179487\n",
            "acc 2, sample 43: 0.9736842105263158\n",
            "acc 3, sample 43: 1.0\n",
            "acc 0, sample 44: 1.0\n",
            "acc 1, sample 44: 0.9104477611940298\n",
            "acc 2, sample 44: 0.9666666666666667\n",
            "acc 3, sample 44: 1.0\n",
            "acc 0, sample 45: 1.0\n",
            "acc 1, sample 45: 1.0\n",
            "acc 2, sample 45: 0.9230769230769231\n",
            "acc 3, sample 45: 1.0\n",
            "acc 0, sample 46: 1.0\n",
            "acc 1, sample 46: 1.0\n",
            "acc 2, sample 46: 0.9459459459459459\n",
            "acc 3, sample 46: 1.0\n",
            "acc 0, sample 47: 0.9642857142857143\n",
            "acc 1, sample 47: 0.9818181818181818\n",
            "acc 2, sample 47: 1.0\n",
            "acc 3, sample 47: 1.0\n",
            "acc 0, sample 48: 0.9491525423728814\n",
            "acc 1, sample 48: 0.95\n",
            "acc 2, sample 48: 0.9655172413793104\n",
            "acc 3, sample 48: 1.0\n",
            "acc 0, sample 49: 0.9782608695652174\n",
            "acc 1, sample 49: 0.9767441860465116\n",
            "acc 2, sample 49: 0.9714285714285714\n",
            "acc 3, sample 49: 1.0\n",
            "acc 0, sample 50: 1.0\n",
            "acc 1, sample 50: 0.9629629629629629\n",
            "acc 2, sample 50: 0.9433962264150944\n",
            "acc 3, sample 50: 1.0\n",
            "acc 0, sample 51: 1.0\n",
            "acc 1, sample 51: 0.9811320754716981\n",
            "acc 2, sample 51: 1.0\n",
            "acc 3, sample 51: 1.0\n",
            "acc 0, sample 52: 0.9696969696969697\n",
            "acc 1, sample 52: 0.8205128205128205\n",
            "acc 2, sample 52: 0.9166666666666666\n",
            "acc 3, sample 52: 1.0\n",
            "acc 0, sample 53: 0.9387755102040817\n",
            "acc 1, sample 53: 0.9811320754716981\n",
            "acc 2, sample 53: 1.0\n",
            "acc 3, sample 53: 1.0\n",
            "acc 0, sample 54: 0.9102564102564102\n",
            "acc 1, sample 54: 0.8795180722891566\n",
            "acc 2, sample 54: 0.9305555555555556\n",
            "acc 3, sample 54: 1.0\n",
            "acc 0, sample 55: 1.0\n",
            "acc 1, sample 55: 0.9736842105263158\n",
            "acc 2, sample 55: 1.0\n",
            "acc 3, sample 55: 0.9696969696969697\n",
            "note counters: v0: 3241 v1: 3156 v2: 3000 v3: 2626\n",
            "total_predictions_dict dict_keys(['0', '1', '2', '3'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9773222549141607,\n",
              " 0.9536911784969926,\n",
              " 0.9629999196547713,\n",
              " 0.9940168910589349)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(acc_score_dict[\"0\"],'-o')\n",
        "plt.plot(acc_score_dict[\"1\"],'-o')\n",
        "plt.plot(acc_score_dict[\"2\"],'-o')\n",
        "plt.plot(acc_score_dict[\"3\"],'-o')\n",
        "\n",
        "plt.xlabel('samples')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['accuracy0','accuracy1','accuracy2','accuracy3'])\n",
        "plt.title('Accuracy vs Test set')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LSnAtw0X30Fd",
        "outputId": "3ddd6974-03f5-4597-c574-cbb27889a059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(acc_score_dict[\"0\"],'-o')\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Accuracy0'])\n",
        "plt.title('Accuracy vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J92mdaQG0MXZ",
        "outputId": "fc3fcb3d-196c-4fb3-f301-2a9a3e545bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([-1,-2,1,2,3])\n",
        "c = np.array([5,6,7,8,9])\n",
        "\n",
        "a[a>0], c[a>0]"
      ],
      "metadata": {
        "id": "_pX25-OmlSkN",
        "outputId": "35849b1e-df00-4f3d-9dfe-f6a88821546c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 2, 3]), array([7, 8, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy_for_chorals(model, train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match\n",
        "                                      \n",
        "            \n",
        "            if idx != 1: # or idx==2:\n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "                part_3 = part[3]\n",
        "                note_array_3 = part_3.note_array\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "                note_counter_3 += len(note_array_3)\n",
        "\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "\n",
        "                   \n",
        "                \n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):\n",
        "                    onset_beat = note_array[\"onset_beat\"]\n",
        "                    duration_beat = note_array[\"duration_beat\"]\n",
        "                    pitch_list = note_array[\"pitch\"]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "\n",
        "                               \n",
        "                    # do model prediction\n",
        "                    model.eval()\n",
        "                    voices = voices.to(device).float()\n",
        "                    monophonic=True\n",
        "                    with torch.no_grad():\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        label = ground_truth_label_list[el_note_arr]\n",
        "\n",
        "                \n",
        "                    for i in range(len(note_idx_start)):\n",
        "\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "\n",
        "                        #print(\"prediction:\",pred_list_first)\n",
        "                        \n",
        "\n",
        "\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "                        accordance_dict[str(label)].append(0)\n",
        "\n",
        "\n",
        "                count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "                for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                    counting = 0\n",
        "                    ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                    for j in range(len(total_predictions_dict[i])):\n",
        "                        #print(\"total_predictions_dict[i][j]:\",total_predictions_dict[i][j] )\n",
        "                        if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                    count_dict_2[i].append(counting)\n",
        "\n",
        "                acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "                acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "\n",
        "                print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "                print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "\n",
        "                \n",
        "                acc_score_dict[\"0\"].append(acc_0)\n",
        "                acc_score_dict[\"1\"].append(acc_1)\n",
        "                acc_score_dict[\"2\"].append(acc_2)\n",
        "                acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "    print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "    print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "    return total_predictions_dict, total_truth_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])\n",
        "    #return total_predictions_dict, total_truth_dict"
      ],
      "metadata": {
        "id": "F394uNmtMfLv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pred , dict_gt, acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_chorals(model,val_dataloader,part_dic,F1=False)\n",
        "acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "id": "RWxVG3XAYTcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluate fugues"
      ],
      "metadata": {
        "id": "TzTpXHznL02j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import statistics\n",
        "\n",
        "\n",
        "def evaluate_accuracy_for_all(model, train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match\n",
        "                                      \n",
        "            \n",
        "            #if idx == 0 or idx==2:\n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2]\n",
        "\n",
        "                if len(part)== 4:\n",
        "                    part_3 = part[3]\n",
        "                    note_array_3 = part_3.note_array\n",
        "                    note_counter_3 += len(note_array_3)\n",
        "                    list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "\n",
        "                   \n",
        "                \n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):\n",
        "                    onset_beat = note_array[\"onset_beat\"]\n",
        "                    duration_beat = note_array[\"duration_beat\"]\n",
        "                    pitch_list = note_array[\"pitch\"]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "\n",
        "                               \n",
        "                    # do model prediction\n",
        "                    model.eval()\n",
        "                    voices = voices.to(device).float()\n",
        "                    monophonic=True\n",
        "                    with torch.no_grad():\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        label = ground_truth_label_list[el_note_arr]\n",
        "\n",
        "                \n",
        "                    for i in range(len(note_idx_start)):\n",
        "\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "                        \n",
        "                        if i < len(note_idx_start)-1:\n",
        "                            start_second = note_idx_start[i+1]\n",
        "                            end_second =  note_idx_end[i+1]\n",
        "                            pitch_second = pitch_list[i+1]\n",
        "                            pred_list_second = prediction[start_second:end_second,pitch_second]\n",
        "\n",
        "\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "\n",
        "                        result_second = all(elem == pred_list_second[0] for elem in pred_list_second)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result_second == False:\n",
        "                            major_, major_idx = torch.mode(pred_list_second,0)\n",
        "                            major_ = major_.numpy().tolist()\n",
        "                            pred_list_second = [major_ for i in pred_list_second]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "\n",
        "                            \n",
        "                        if F1 == True:\n",
        "                            if pred_list_first[0] == pred_list_second[0]:   #the list might have diff lenghts as diff notes have diff lengths, so is ito oke to just take first elemet\n",
        "                                accordance_dict[str(label)].append(1)\n",
        "                            else:\n",
        "                                accordance_dict[str(label)].append(0)\n",
        "\n",
        "                if F1 == False:\n",
        "                    count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                    print(\"total_predictions_dict.keys())\",total_predictions_dict.keys())\n",
        "\n",
        "                    for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                      counting = 0\n",
        "                      ### maybe insert if statement: if list_of_note_arrays == 4 oder sowas \n",
        "                      for j in range(len(total_predictions_dict[i])):\n",
        "                          if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                      count_dict_2[i].append(counting)\n",
        "\n",
        "                    acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                    acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                    acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "\n",
        "                    print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                    print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                    print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "\n",
        "                    if len(list_of_note_arrays)==4:\n",
        "                        acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "                        print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "                        acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "                    acc_score_dict[\"0\"].append(acc_0)\n",
        "                    acc_score_dict[\"1\"].append(acc_1)\n",
        "                    acc_score_dict[\"2\"].append(acc_2)\n",
        "\n",
        "                if F1 == True:\n",
        "                    pred_0 = accordance_dict[\"0\"]\n",
        "                    pred_1 = accordance_dict[\"1\"]\n",
        "                    pred_2 = accordance_dict[\"2\"]                   \n",
        "                    truth_0 = [1 for i in range(len(accordance_dict[\"0\"]))]\n",
        "                    truth_1 = [1 for i in range(len(accordance_dict[\"1\"]))]\n",
        "                    truth_2 = [1 for i in range(len(accordance_dict[\"2\"]))]                  \n",
        "                    f1_v0 = sklearn.metrics.f1_score(truth_0, pred_0)\n",
        "                    f1_v1 = sklearn.metrics.f1_score(truth_1, pred_1)\n",
        "                    f1_v2 = sklearn.metrics.f1_score(truth_2, pred_2)                \n",
        "                    f_score_dict[\"0\"].append(f1_v0)\n",
        "                    f_score_dict[\"1\"].append(f1_v1)\n",
        "                    f_score_dict[\"2\"].append(f1_v2)\n",
        "                    if len(part)==4:\n",
        "                      pred_3 = accordance_dict[\"3\"]\n",
        "                      truth_3 = [1 for i in range(len(accordance_dict[\"3\"]))]\n",
        "                      f1_v3 = sklearn.metrics.f1_score(truth_3, pred_3)\n",
        "                      f_score_dict[\"3\"].append(f1_v3)\n",
        "    \n",
        "    if F1 == True:\n",
        "        return statistics.mean(f_score_dict[\"0\"]), statistics.mean(f_score_dict[\"1\"]), statistics.mean(f_score_dict[\"2\"]),statistics.mean(f_score_dict[\"3\"])\n",
        "    \n",
        "    if F1 == False:\n",
        "        print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "        print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "        return total_predictions_dict, total_truth_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])\n",
        "        #return total_predictions_dict, total_truth_dict"
      ],
      "metadata": {
        "id": "0xbN5YU8nGT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pred , dict_gt, acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_all(model,val_dataloader,part_dic,F1=False)\n",
        "acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "id": "20MP5Gk5kc2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 30 epoch, no loss modifier:\n",
        "#ACC:(0.9165209182020722,\n",
        "# 0.7864434689151618,\n",
        "# 0.8130949796045199,\n",
        "# 0.003652274754166715)\n",
        "\n",
        "# 20 epoch, no loss modifier:\n",
        "#(0.7962210840410273, 0.8669639629052727, 0.751302181991106, 0.0)\n",
        "\n",
        "# 20 ep, loss3 *1,5\n",
        "#(0.8721136343927623,\n",
        " 0.8319586824413445,\n",
        " 0.7563218924966578,\n",
        " 0.09029535181592076)"
      ],
      "metadata": {
        "id": "6mCYnJLnHfYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_all(model,train_dataloader,part_dic,F1=False)\n",
        "dict_pred , dict_gt, acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_all(model,val_dataloader,part_dic,F1=False)\n",
        "acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "id": "ygMV28FhKVAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluate fugues F1 score"
      ],
      "metadata": {
        "id": "52P6em3ANb1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_v0, f1_v1, f1_v2, f1_v3 = evaluate_accuracy_for_all(model,val_dataloader,part_dic,F1=True)\n",
        "print(f1_v0, f1_v1, f1_v2, f1_v3)"
      ],
      "metadata": {
        "id": "FLLmyO6o5vW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pred.keys()"
      ],
      "metadata": {
        "id": "79s64i5_lDN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "for gt, i in enumerate(dict_pred.keys()):\n",
        "  counting = 0\n",
        "  for j in range(len(dict_pred[i])):\n",
        "      if dict_pred[i][j][0] == gt:\n",
        "        print(dict_pred[i][j],dict_gt[i][j])\n",
        "        counting +=1\n",
        "\n",
        "      \n",
        "  count_dict_2[i].append(counting)\n",
        "\n",
        "print(count_dict_2[\"0\"],count_dict_2[\"1\"],count_dict_2[\"2\"],count_dict_2[\"3\"])\n",
        "\n",
        "if len(dict_pred.keys())==4:\n",
        "    print(\"accuracy:\",count_dict_2[\"0\"][0]/len(dict_pred[\"0\"]),count_dict_2[\"1\"][0]/len(dict_pred[\"1\"]),count_dict_2[\"2\"][0]/len(dict_pred[\"2\"]),count_dict_2[\"3\"][0]/len(dict_pred[\"3\"]))\n",
        "\n",
        "if len(dict_pred.keys())==3:\n",
        "    print(\"accuracy:\",count_dict_2[\"0\"][0]/len(dict_pred[\"0\"]),count_dict_2[\"1\"][0]/len(dict_pred[\"1\"]),count_dict_2[\"2\"][0]/len(dict_pred[\"2\"]))"
      ],
      "metadata": {
        "id": "VYBpV_hMfGGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### take 0 -> compare to truth of 0,1,2,3 -> overall voice\n",
        "\n",
        "count_list = []\n",
        "\n",
        "count_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "truth_dic = {'0': 0, '1': 1, '2': 2, '3': 3 }\n",
        "\n",
        "voice_entry_list = [\"0\", \"1\", \"2\", \"3\"]\n",
        "for voice_entry_one in voice_entry_list:\n",
        "    for voice_entry_two in voice_entry_list:\n",
        "        count_list = []\n",
        "        #print(\"voices:\",voice_entry_one,voice_entry_two)\n",
        "        for i in range(len(dict_pred[voice_entry_one])):\n",
        "            if dict_pred[voice_entry_one][i][0] == truth_dic[voice_entry_two]:      #dict_truth[voice_entry_two][i][0]:\n",
        "                count_list.append(1)\n",
        "            else:\n",
        "                count_list.append(0)\n",
        "        count_dict[voice_entry_one].append(count_list)\n",
        "\n",
        "dictionary_sum={}\n",
        "for i in voice_entry_list:\n",
        "    v0_match,v1_match,v2_match,v3_match = count_dict[i]\n",
        "    sum_v0 = np.sum(v0_match)\n",
        "    sum_v1 = np.sum(v1_match)\n",
        "    sum_v2 = np.sum(v2_match)\n",
        "    sum_v3 = np.sum(v3_match)\n",
        "    dictionary_sum[\"v0\"] = sum_v0\n",
        "    dictionary_sum[\"v1\"] = sum_v1\n",
        "    dictionary_sum[\"v2\"] = sum_v2\n",
        "    dictionary_sum[\"v3\"] = sum_v3\n",
        "\n",
        "    val_list = list(dictionary_sum.values())\n",
        "    \n",
        "    print(\"voice{} matches with\".format(i))\n",
        "    print(\"dict\",dictionary_sum)\n",
        "\n",
        "    max_sum = max(sum_v0,sum_v1,sum_v2,sum_v3)\n",
        "\n",
        "\n",
        "    print(\"max_sum\", val_list.index(max_sum) )\n",
        "\n",
        "    print(\"accuracy voice{}:\".format(i), max_sum/(sum_v0+sum_v1+sum_v2+sum_v3) )\n",
        "    print(\"________________\")\n",
        "    print(\" \")"
      ],
      "metadata": {
        "id": "BoQcV_i038DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR MONOPHONIC F1\n",
        "\n",
        "# start with GT\n",
        "# look at first note in pred-> save note label\n",
        "# look at second note in pred-> if same note as before : SUCESS if it is not: FAIL\n",
        " # DO This for all 4 voices\n",
        " ## in GT there is always the same voice following -> would always be an array of 1\n",
        "\n",
        "## POLYPHONIC \n",
        "\n",
        "# prbl after 1 note there can be multiple diff voices .. chords\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-bR7gcej90qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "you have the ground truth on the different parts that you get when you import your score. Each part correspond to a voice. So if your note array contains all notes of all voices, you have for each note in your note array a number that is the ground truth voice (that you take from the part) and a number that is the predicted voice (that you take from the maximum vote)."
      ],
      "metadata": {
        "id": "Z5q305YzvjMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "start time, duration , pitch to separate \n",
        "\n",
        "use the onset_beat and duration_beat\n",
        "\n",
        "multiply them according to the values set when producing the pianorolls \n",
        "\n",
        "-> get the position in the pianoroll\n",
        "\n",
        "time_div = 12\n",
        "\n"
      ],
      "metadata": {
        "id": "EmvxtyaVKG27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "A94mchm4LV6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"val_accuracy_v0\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v1\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v2\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v3\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Accuracy0','Accuracy1','Accuracy2','Accuracy3'])\n",
        "plt.title('Accuracy vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1TgJDHaxAgYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"val_accuracy\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend('Accuracy')\n",
        "plt.title('Accuracy vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OxMs8GEfMvPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"train_loss\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Loss'])\n",
        "plt.title('Loss vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqMcJT5aFL01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old training loop - matrix and non matrix format"
      ],
      "metadata": {
        "id": "4olpdwzyG8dQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def training_loop(model,optimizer, train_dataloader, monophonic, epochs=50, val_dataloader=None, device=None, scheduler=None):\n",
        "    if device is None:\n",
        "        device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "        print(f\"Training on device: {device}\")\n",
        "\n",
        "    print(\"monophonic set to:\",monophonic)\n",
        "    model = model.to(device)\n",
        "    history = defaultdict(list)\n",
        "\n",
        "    for i_epoch in range(1, epochs + 1):\n",
        "        loss_sum = 0\n",
        "        #accuracy_v0_sum = 0\n",
        "        #accuracy_v1_sum = 0\n",
        "        #accuracy_v2_sum = 0\n",
        "        #accuracy_v3_sum = 0\n",
        "\n",
        "        accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "        val_accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "\n",
        "        accuracy_v_all_sum = 0\n",
        "        model.train()\n",
        "        accuracy_sum = 0\n",
        "        \n",
        "\n",
        "        for idx, (voices, lens, nbr_voices) in enumerate(train_dataloader):  \n",
        "            \n",
        "            voices = voices.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            loss = model.forward(voices, lens, nbr_voices)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()    \n",
        "\n",
        "            if monophonic == False:\n",
        "                with torch.no_grad():\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                    mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "\n",
        "                    \n",
        "                    single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "                    \"\"\"\n",
        "                    if nbr_voices == 4: \n",
        "                        v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2), torch.tensor(pred_v3)], dim=2)\n",
        "                    if nbr_voices ==3:\n",
        "                        v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2)], dim=2)\n",
        "                    v_pred_argm = v_pred_comb.argmax(dim=2)\n",
        "                    mask_pred = (v_pred_comb.sum(axis=2) == 0).numpy()\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                    print(\"v_pred_flat:\", v_pred_flat.shape)\n",
        "                    \"\"\"\n",
        "                    \"\"\"\n",
        "                    if nbr_voices == 4:                   \n",
        "                        v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu(), np.squeeze(voices[:,:,:,3]).cpu()], dim=2)\n",
        "                    if nbr_voices ==3:\n",
        "                        v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu()], dim=2)\n",
        "                    v_ori_argm = v_ori_comb.argmax(dim=2)\n",
        "                    mask_ori = (v_ori_comb.sum(axis=2) == 0).numpy()\n",
        "                    print(\"old mask\", mask_ori.shape)\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    print(\"v_ori_flat\", v_ori_flat.shape)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)   \n",
        "                    print(\"acc\",acc)                    \n",
        "                    accuracy_sum += acc \n",
        "                    \"\"\"\n",
        "\n",
        "\n",
        "            if monophonic == True:\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                    prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "\n",
        "                    truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "\n",
        "                    acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "\n",
        "                    for i in range(len(prediction[0,:])):\n",
        "                      acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                      accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "                    \n",
        "                    \"\"\"\n",
        "                    pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "\n",
        "                    acc_v0 = accuracy_score(torch.tensor(pred_v0), np.squeeze(voices[:,:,:,0]).argmax(dim=1).cpu())\n",
        "                    acc_v1 = accuracy_score(torch.tensor(pred_v1), np.squeeze(voices[:,:,:,1]).argmax(dim=1).cpu())\n",
        "                    acc_v2 = accuracy_score(torch.tensor(pred_v2), np.squeeze(voices[:,:,:,2]).argmax(dim=1).cpu())\n",
        "                    if nbr_voices == 4:\n",
        "                        acc_v3 = accuracy_score(torch.tensor(pred_v3), np.squeeze(voices[:,:,:,3]).argmax(dim=1).cpu())\n",
        "                    \n",
        "                    # normalize according to the number of sequences in the batch (atm len(lens)==1)\n",
        "                    accuracy_v0_sum += acc_v0 / len(lens)\n",
        "                    accuracy_v1_sum += acc_v1 / len(lens)\n",
        "                    accuracy_v2_sum += acc_v2 / len(lens)\n",
        "                    if nbr_voices == 4:\n",
        "                        accuracy_v3_sum += acc_v3 / len(lens)\n",
        "                    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        train_loss = loss_sum / len(train_dataloader)\n",
        "\n",
        "        # normalize according to the number of batches\n",
        "        if monophonic == True:\n",
        "\n",
        "            train_acc_list = np.array(accuracy_sum_list) / len(train_dataloader)\n",
        "            train_acc_list[3] = accuracy_sum_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "            train_acc_list[4] = accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_acc\"].append(train_acc_list)\n",
        "            print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}, Train Accuracy_4 : {}\".format(train_loss, train_acc_list[0], train_acc_list[1], train_acc_list[2], train_acc_list[3],train_acc_list[4])) \n",
        "\n",
        "\n",
        "            \"\"\"\n",
        "            train_accuracy_v0 = accuracy_v0_sum / len(train_dataloader)\n",
        "            train_accuracy_v1 = accuracy_v1_sum / len(train_dataloader)\n",
        "            train_accuracy_v2 = accuracy_v2_sum / len(train_dataloader)\n",
        "            train_accuracy_v3 = accuracy_v3_sum / 18   ## bc only 18 pieces with len 3\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy_v0\"].append(train_accuracy_v0)\n",
        "            history[\"train_accuracy_v1\"].append(train_accuracy_v1)\n",
        "            history[\"train_accuracy_v2\"].append(train_accuracy_v2)\n",
        "            #if nbr_voices == 4:\n",
        "            history[\"train_accuracy_v3\"].append(train_accuracy_v3)\n",
        "            print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}\".format(train_loss, train_accuracy_v0, train_accuracy_v1, train_accuracy_v2, train_accuracy_v3)) \n",
        "            #else:\n",
        "            #    print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}\".format(train_loss, train_accuracy_v0, train_accuracy_v1, train_accuracy_v2)) \n",
        "            \"\"\"\n",
        "\n",
        "        if monophonic == False:\n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "\n",
        "        if monophonic == True:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_v0_sum = 0\n",
        "                accuracy_v1_sum = 0\n",
        "                accuracy_v2_sum = 0\n",
        "                accuracy_v3_sum = 0\n",
        "\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for voices, lens, nbr_voices in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "\n",
        "                        truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "\n",
        "                        acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "\n",
        "                        for i in range(len(prediction[0,:])):\n",
        "                          acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                          val_accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "\n",
        "                        #print(\"val_accuracy_sum_list[3]\",val_accuracy_sum_list[3])\n",
        "                    #val_acc_list = np.array(val_accuracy_sum_list) / len(train_dataloader)\n",
        "                    #val_acc_list[3] = val_acc_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "                    #val_acc_list[4] = val_acc_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "\n",
        "\n",
        "                #history[\"val_acc_new\"].append(val_acc_list)\n",
        "                #print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "\n",
        "                        # Predict the model's output on a batch\n",
        "                        pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "                            \n",
        "                        # compute the accuracy \n",
        "                        acc_v0 = accuracy_score(torch.tensor(pred_v0), np.squeeze(voices[:,:,:,0]).argmax(dim=1).cpu())\n",
        "                        acc_v1 = accuracy_score(torch.tensor(pred_v1), np.squeeze(voices[:,:,:,1]).argmax(dim=1).cpu())\n",
        "                        acc_v2 = accuracy_score(torch.tensor(pred_v2), np.squeeze(voices[:,:,:,2]).argmax(dim=1).cpu())\n",
        "                        if nbr_voices == 4:\n",
        "                            acc_v3 = accuracy_score(torch.tensor(pred_v3), np.squeeze(voices[:,:,:,3]).argmax(dim=1).cpu())\n",
        "                            \n",
        "                            \n",
        "                        # normalize according to the number of sequences in the batch (atm len(lens)==1)\n",
        "                        accuracy_v0_sum += acc_v0 / len(lens)\n",
        "                        accuracy_v1_sum += acc_v1 / len(lens)\n",
        "                        accuracy_v2_sum += acc_v2 / len(lens)\n",
        "                        if nbr_voices == 4:\n",
        "                            accuracy_v3_sum += acc_v3 / len(lens)\n",
        "\n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy_v0 = accuracy_v0_sum / len(val_dataloader)\n",
        "                    val_accuracy_v1 = accuracy_v1_sum / len(val_dataloader)\n",
        "                    val_accuracy_v2 = accuracy_v2_sum / len(val_dataloader)\n",
        "                    val_accuracy_v3 = accuracy_v3_sum / 18  ##len(val_dataloader). - bc 18 pieces only with voice 3\n",
        "\n",
        "\n",
        "                    val_acc_list = np.array(val_accuracy_sum_list) / len(val_dataloader)\n",
        "                    val_acc_list[3] = val_accuracy_sum_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "                    val_acc_list[4] = val_accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "                    \n",
        "\n",
        "\n",
        "                history[\"val_accuracy_v0\"].append(val_accuracy_v0)\n",
        "                history[\"val_accuracy_v1\"].append(val_accuracy_v1)\n",
        "                history[\"val_accuracy_v2\"].append(val_accuracy_v2)\n",
        "                #if nbr_voices == 4:\n",
        "                history[\"val_accuracy_v3\"].append(val_accuracy_v3)\n",
        "                print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}\".format(val_accuracy_v0, val_accuracy_v1, val_accuracy_v2, val_accuracy_v3))\n",
        "                #else:\n",
        "                #    print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}\".format(val_accuracy_v0, val_accuracy_v1, val_accuracy_v2))\n",
        "\n",
        "\n",
        "                history[\"val_acc_new\"].append(val_acc_list)\n",
        "                print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "        if monophonic == False:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_sum = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    for voices, lens, nbr_voices in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "                        \n",
        "                        # Predict the model's output on a batch\n",
        "\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                        v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                        mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                        \n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "\n",
        "                        \"\"\"\n",
        "                        pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "                        if nbr_voices == 4: \n",
        "                            v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2), torch.tensor(pred_v3)], dim=2)\n",
        "                        if nbr_voices ==3:\n",
        "                            v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2)], dim=2)\n",
        "                        v_pred_argm = v_pred_comb.argmax(dim=2)\n",
        "                        mask_pred = (v_pred_comb.sum(axis=2) == 0).numpy()\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)                      \n",
        "                        if nbr_voices == 4:                   \n",
        "                            v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu(), np.squeeze(voices[:,:,:,3]).cpu()], dim=2)\n",
        "                        if nbr_voices ==3:\n",
        "                            v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu()], dim=2)\n",
        "                        v_ori_argm = v_ori_comb.argmax(dim=2)\n",
        "                        mask_ori = (v_ori_comb.sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)\n",
        "                        accuracy_sum += acc \n",
        "                        \"\"\"\n",
        "                        \n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "\n",
        "                history[\"val_accuracy\"].append(val_accuracy)  \n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # save the model\n",
        "        torch.save(model, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "nfDV8MKGHE3J"
      }
    }
  ]
}