{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Masterproject.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aim56009/AI-MA_project/blob/main/Masterproject_final_tensor_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ],
      "metadata": {
        "id": "SsyC2uB0KfaT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDUwCmeIW8i1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a95826-6849-4f83-a633-27cc0a8e2bea"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import torchvision.transforms.functional as TF \n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import click\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install partitura\n",
        "import partitura"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: partitura in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: lark-parser in /usr/local/lib/python3.7/dist-packages (from partitura) (0.12.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from partitura) (4.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from partitura) (1.4.1)\n",
            "Requirement already satisfied: mido in /usr/local/lib/python3.7/dist-packages (from partitura) (1.2.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from partitura) (1.21.6)\n",
            "Requirement already satisfied: xmlschema in /usr/local/lib/python3.7/dist-packages (from partitura) (1.11.1)\n",
            "Requirement already satisfied: elementpath<3.0.0,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from xmlschema->partitura) (2.5.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsFs8dyqXBx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab6d7b0-699c-432c-fb2e-eab8992358e2"
      },
      "source": [
        "!git clone https://github.com/aim56009/AI-MA_project.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AI-MA_project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYpz1MOIOgtk"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygWXNSrCbRQi"
      },
      "source": [
        "batch_size = 1 \n",
        "PATH_TO_DATA = \"AI-MA_project/bach_pr_fugues\"\n",
        "#PATH_TO_DATA = \"AI-MA_project/pianoroll_88\"\n",
        "workers = 0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1-u8zYd-gyo"
      },
      "source": [
        "class MusicDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        labels = [\"voice_0\", \"voice_1\", \"voice_2\", \"voice_3\", \"voice_all\"]\n",
        "        self.labels = labels\n",
        "        self.pr_dict = {}\n",
        "        len_list = []\n",
        "\n",
        "        for iLabel in range(len(labels)):\n",
        "            \n",
        "            if iLabel == 4:   \n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\")))   \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: ### normal sollte es egal sein wenn voice_4 bei manchen nicht existiert - wenn nicht condition einführen damit das funktioniert\n",
        "                        loaded_obj = pickle.load(f)  \n",
        "                        voice_files.append(loaded_obj) \n",
        "                        len_list.append(len(loaded_obj.T))\n",
        "                        \n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                self.pr_dict[\"length\"] = len_list\n",
        "    \n",
        "            else:\n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: \n",
        "                        loaded_obj = pickle.load(f)     \n",
        "                        voice_files.append(loaded_obj)\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      \n",
        "        return len(self.pr_dict[self.labels[0]])\n",
        "  \n",
        "\n",
        "    def __getitem__(self, idx):          \n",
        "\n",
        "        out_list = []\n",
        "        for key, value in self.pr_dict.items():\n",
        "            out_list.append(self.pr_dict[key][idx])    \n",
        "\n",
        "        v0 = torch.tensor(out_list[0].T)\n",
        "        v1 = torch.tensor(out_list[1].T)\n",
        "        v2 = torch.tensor(out_list[2].T)\n",
        "        v3 = torch.tensor(out_list[3].T)\n",
        "        v_all = torch.tensor(out_list[4].T) \n",
        "        length = self.pr_dict[\"length\"][idx]\n",
        "\n",
        "\n",
        "        return (v0, v1, v2, v3, v_all, length)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicDataset_new(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        self.name_list = [\"1f01\",\"1f02\",\"1f03\",\"1f04\",\"1f05\",\"1f06\",\"1f07\",\"1f08\",\"1f09\",\"1f10\",\"1f11\",\"1f12\",\"1f13\",\"1f14\",\"1f15\",\"1f16\",\"1f17\",\"1f18\",\"1f19\",\"1f20\",\"1f21\",\"1f22\",\"1f23\",\"1f24\",\"2f01\",\"2f02\",\"2f03\",\"2f04\",\"2f05\",\"2f06\",\"2f07\",\"2f08\",\"2f09\",\"2f10\",\"2f11\",\"2f12\",\"2f13\",\"2f14\",\"2f15\",\"2f16\",\"2f17\",\"2f18\",\"2f19\",\"2f20\",\"2f21\",\"2f22\",\"2f23\",\"2f24\"]\n",
        "        self.name_list_voice_3 =  ['1f01', '1f05', '1f12', '1f14', '1f16', '1f17', '1f18', '1f23', '1f24', '2f02', '2f05', '2f07', '2f08', '2f09', '2f16', '2f17',  '2f22', '2f23']\n",
        "        labels = [\"voice_0\", \"voice_1\", \"voice_2\", \"voice_3\", \"voice_all\"]\n",
        "        self.labels = labels\n",
        "        self.pr_dict = {}\n",
        "        len_list = []\n",
        "        nbr_voices_list = []\n",
        "        file_names_list = []\n",
        "\n",
        "        for iLabel in range(len(labels)):\n",
        "            \n",
        "            if iLabel == 4:   \n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\")))   \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: ### normal sollte es egal sein wenn voice_4 bei manchen nicht existiert - wenn nicht condition einführen damit das funktioniert\n",
        "                        loaded_obj = pickle.load(f)  \n",
        "                        voice_files.append(loaded_obj) \n",
        "                        len_list.append(len(loaded_obj.T))\n",
        "\n",
        "                        file_names_list.append(name[-8:-4])\n",
        "\n",
        "                    if \"AI-MA_project/bach_pr_fugues/voice_3/voice_3_\" + name[49:53] + \".pkl\" in sorted(glob.glob(os.path.join(PATH_TO_DATA, \"voice_3\", \"*.pkl\"))):\n",
        "                        nbr_voices_list.append(4)\n",
        "                    else:\n",
        "                        nbr_voices_list.append(3)\n",
        "                        \n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                self.pr_dict[\"length\"] = len_list\n",
        "                self.pr_dict[\"nbr_voices\"] = nbr_voices_list\n",
        "                self.pr_dict[\"name\"] = file_names_list\n",
        "                #print(self.pr_dict[\"name\"])\n",
        "\n",
        "\n",
        "            if iLabel == 3:  \n",
        "                voice_files = []\n",
        "                file_names_3 = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                file_names_2 = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[2], \"*.pkl\")))   \n",
        "                \n",
        "                ###### loop over all filnames in voices_2 and if an element there is not present in voices_3: append \"missing\" to the voice_files of label=3 => important bc. self.pr_dict[voice_3] has then len 42 and otherwise it would only have len 18  .. these \"missing\" el are not considered later in the dataloader (if len=3 is a diff case of get_idx)\n",
        "                for name in file_names_2:\n",
        "                    if name[45:49] in self.name_list_voice_3:\n",
        "                      correct_name_3 = \"AI-MA_project/bach_pr_fugues/voice_3/voice_3_\" + name[45:49] + \".pkl\"\n",
        "                      with open(correct_name_3 ,'rb') as f:  \n",
        "                            loaded_obj = pickle.load(f)  \n",
        "                            voice_files.append(loaded_obj)\n",
        "                    else:\n",
        "                      voice_files.append(\"missing\")\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "                \n",
        "\n",
        "                \n",
        "            else:\n",
        "                voice_files = []\n",
        "                file_names = sorted(glob.glob(os.path.join(PATH_TO_DATA, self.labels[iLabel], \"*.pkl\"))) \n",
        "                for name in file_names:\n",
        "                    with open(name ,'rb') as f: \n",
        "                          loaded_obj = pickle.load(f)     \n",
        "                          voice_files.append(loaded_obj)\n",
        "\n",
        "                self.pr_dict[self.labels[iLabel]] = voice_files \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pr_dict[self.labels[0]])\n",
        "\n",
        "    def __getitem__(self, idx):      \n",
        "        out_list = []\n",
        "        \n",
        "        if self.pr_dict[\"nbr_voices\"][idx] == 4:\n",
        "            for key, value in self.pr_dict.items():\n",
        "              out_list.append(self.pr_dict[key][idx])\n",
        "                              \n",
        "            v0 = torch.tensor(out_list[0].T)\n",
        "            v1 = torch.tensor(out_list[1].T)\n",
        "            v2 = torch.tensor(out_list[2].T)\n",
        "            v3 = torch.tensor(out_list[3].T)\n",
        "            v_all = torch.tensor(out_list[4].T) \n",
        "            length = self.pr_dict[\"length\"][idx]\n",
        "            nbr_voices = self.pr_dict[\"nbr_voices\"][idx]\n",
        "            file_name = self.pr_dict[\"name\"][idx]\n",
        "\n",
        "            voices = torch.stack([v0, v1, v2, v3, v_all], dim=2)\n",
        "            \n",
        "            return (voices, length, nbr_voices, file_name)\n",
        "        \n",
        "        if self.pr_dict[\"nbr_voices\"][idx] == 3:\n",
        "\n",
        "            for key, value in self.pr_dict.items():\n",
        "                if key != \"voice_3\":\n",
        "                  out_list.append(self.pr_dict[key][idx]) \n",
        "            \n",
        "            v0 = torch.tensor(out_list[0].T)\n",
        "            v1 = torch.tensor(out_list[1].T)\n",
        "            v2 = torch.tensor(out_list[2].T)\n",
        "            v3 = torch.zeros(v2.shape)\n",
        "            v_all = torch.tensor(out_list[3].T) \n",
        "            length = self.pr_dict[\"length\"][idx]\n",
        "            nbr_voices = self.pr_dict[\"nbr_voices\"][idx]\n",
        "            file_name = self.pr_dict[\"name\"][idx]\n",
        "            \n",
        "            voices = torch.stack([v0, v1, v2, v3, v_all], dim=2)\n",
        "\n",
        "            \n",
        "            return (voices, length, nbr_voices, file_name)\n",
        "        "
      ],
      "metadata": {
        "id": "3FxK6qr1FqIl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oTPIsBwPAJg"
      },
      "source": [
        "#dataset = MusicDataset(PATH_TO_DATA)\n",
        "dataset = MusicDataset_new(PATH_TO_DATA)\n",
        "loader = torch.utils.data.DataLoader(dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for i, sample_batched in enumerate(loader):\n",
        "    all_voices, length, nbr_voices = sample_batched\n",
        "    if nbr_voices ==3:\n",
        "      print(i,nbr_voices,all_voices.shape)\n",
        "    else:\n",
        "      print(i,nbr_voices)\n",
        "\"\"\"\n",
        "#for i, sample_batched in enumerate(loader):\n",
        "#    all_voices, length, nbr_voices, file_name = sample_batched\n",
        "#    print(file_name[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "LXsRYzQSUuQU",
        "outputId": "70ec9c52-a4cd-4bd9-852e-8cdb818dd592"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor i, sample_batched in enumerate(loader):\\n    all_voices, length, nbr_voices = sample_batched\\n    if nbr_voices ==3:\\n      print(i,nbr_voices,all_voices.shape)\\n    else:\\n      print(i,nbr_voices)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for i, sample_batched in enumerate(loader):\n",
        "    all_voices, length, nbr_voices = sample_batched\n",
        "    if nbr_voices ==3:\n",
        "      print(i,nbr_voices,all_voices.shape)\n",
        "    else:\n",
        "      print(i,nbr_voices)\n",
        "\n",
        "for i, sample_batched in enumerate(loader):\n",
        "  if i ==10:\n",
        "    all_voices, length, nbr_voices, _ = sample_batched\n",
        "    all_voices_pr = all_voices[0,:,:,-1].numpy()\n",
        "    \n",
        "    note_array = partitura.utils.pianoroll_to_notearray(all_voices[0,:,:,-1].numpy(), time_div=12, time_unit='beat')\n",
        "    print(note_array.shape)\n",
        "    print(note_array[:10])\n",
        "    print(note_array.dtype.names)\n",
        "\n",
        "    #print(i,nbr_voices,all_voices.shape)\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "b4QCaMEi3nw7",
        "outputId": "5f7d4959-a4ce-4619-8002-a9245f11eb40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor i, sample_batched in enumerate(loader):\\n    all_voices, length, nbr_voices = sample_batched\\n    if nbr_voices ==3:\\n      print(i,nbr_voices,all_voices.shape)\\n    else:\\n      print(i,nbr_voices)\\n\\nfor i, sample_batched in enumerate(loader):\\n  if i ==10:\\n    all_voices, length, nbr_voices, _ = sample_batched\\n    all_voices_pr = all_voices[0,:,:,-1].numpy()\\n    \\n    note_array = partitura.utils.pianoroll_to_notearray(all_voices[0,:,:,-1].numpy(), time_div=12, time_unit='beat')\\n    print(note_array.shape)\\n    print(note_array[:10])\\n    print(note_array.dtype.names)\\n\\n    #print(i,nbr_voices,all_voices.shape)\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Music - Model\n"
      ],
      "metadata": {
        "id": "JNqxeacDwxNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define UNET "
      ],
      "metadata": {
        "id": "QAIfIM69VHI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels=1, classes=1):\n",
        "        super(UNET, self).__init__()\n",
        "        self.layers = [in_channels, 64, 128, 256, 512, 1024]\n",
        "        \n",
        "        self.double_conv_downs = nn.ModuleList([self.__double_conv(layer, layer_n) for layer, layer_n in zip(self.layers[:-1], self.layers[1:])])\n",
        "        \n",
        "        self.up_trans = nn.ModuleList([nn.ConvTranspose2d(layer, layer_n, kernel_size=2, stride=2) for layer, layer_n in zip(self.layers[::-1][:-2], self.layers[::-1][1:-1])])\n",
        "            \n",
        "        self.double_conv_ups = nn.ModuleList([self.__double_conv(layer, layer//2) for layer in self.layers[::-1][:-2]])\n",
        "        \n",
        "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.final_conv = nn.Conv2d(64, classes, kernel_size=1)\n",
        "\n",
        "        \n",
        "    def __double_conv(self, in_channels, out_channels):\n",
        "        conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        return conv\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # down layers\n",
        "        concat_layers = []\n",
        "        \n",
        "        for down in self.double_conv_downs:\n",
        "            x = down(x)\n",
        "            if down != self.double_conv_downs[-1]:\n",
        "                concat_layers.append(x)\n",
        "                x = self.max_pool_2x2(x)\n",
        "        \n",
        "        concat_layers = concat_layers[::-1]\n",
        "        \n",
        "        # up layers\n",
        "        for up_trans, double_conv_up, concat_layer  in zip(self.up_trans, self.double_conv_ups, concat_layers):\n",
        "            x = up_trans(x)\n",
        "            if x.shape != concat_layer.shape:\n",
        "                x = TF.resize(x, concat_layer.shape[2:])\n",
        "            \n",
        "            concatenated = torch.cat((concat_layer, x), dim=1)\n",
        "            x = double_conv_up(concatenated)\n",
        "            \n",
        "        x = self.final_conv(x)\n",
        "        \n",
        "        return x "
      ],
      "metadata": {
        "id": "XMdlm0_Vyyhc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_0 = []\n",
        "loss_1 = []\n",
        "loss_2 = []\n",
        "loss_3 = []\n",
        "class MusicNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, network_type,output_dim=88, hidden_dim=300, rnn_depth=1, cell_type=\"GRU\"):                 \n",
        "        super(MusicNetwork, self).__init__()\n",
        "\n",
        "        self.network_type = network_type\n",
        "        self.n_out = output_dim\n",
        "        input_dim = output_dim \n",
        "        rnn_cell = nn.GRU\n",
        "        self.rnn = rnn_cell(input_size=input_dim, hidden_size=hidden_dim, num_layers=rnn_depth, batch_first=True)\n",
        "        self.cnn = UNET(in_channels=1, classes=4)\n",
        "        self.top_layer_voice_0 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_1 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_2 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.top_layer_voice_3 = nn.Linear(hidden_dim, self.n_out)\n",
        "        self.loss = nn.CrossEntropyLoss(reduction=\"mean\")                       # use weight parameters maybe take 1/88       \n",
        "\n",
        "    \n",
        "\n",
        "    def compute_outputs(self, sentences, sentences_len):\n",
        "        if self.network_type == \"RNN\":\n",
        "          rnn_out ,_= self.rnn(sentences)     \n",
        "          out_0 = self.top_layer_voice_0(rnn_out)\n",
        "          out_1 = self.top_layer_voice_1(rnn_out)\n",
        "          out_2 = self.top_layer_voice_2(rnn_out)\n",
        "          out_3 = self.top_layer_voice_3(rnn_out)\n",
        "\n",
        "          return torch.stack([out_0, out_1, out_2, out_3], dim=1)\n",
        "\n",
        "        else: \n",
        "          sentences = sentences[:,None]\n",
        "          out = self.cnn(sentences)\n",
        "          return out                      ### squeeze output here before returning                                       \n",
        "        \n",
        "\n",
        "    def forward(self, voices, sentences_len, nbr_voices):            \n",
        "\n",
        "        # Compute the outputs. The shape is (max_len, n_sentences, n_labels).\n",
        "        scores_comb = self.compute_outputs(voices[:,:,:,-1], sentences_len)\n",
        "\n",
        "        # Flatten the outputs and the labels, to compute the loss.\n",
        "        # The input to this loss needs to be one 2-dimensional and one 1-dimensional tensor.\n",
        "        score_0  = scores_comb[:,0,:,:].view(-1, self.n_out)\n",
        "        score_1  = scores_comb[:,1,:,:].view(-1, self.n_out)\n",
        "        score_2  = scores_comb[:,2,:,:].view(-1, self.n_out)\n",
        "        score_3  = scores_comb[:,3,:,:].view(-1, self.n_out)\n",
        "\n",
        "\n",
        "        v0 = voices[:,:,:,0].squeeze()\n",
        "        v1 = voices[:,:,:,1].squeeze()\n",
        "        v2 = voices[:,:,:,2].squeeze()\n",
        "        v3 = voices[:,:,:,3].squeeze()\n",
        "\n",
        "\n",
        "\n",
        "        if nbr_voices==4:\n",
        "            loss = self.loss(score_0, v0) +  self.loss(score_1, v1) +  self.loss(score_2, v2) + 1.5* self.loss(score_3, v3) \n",
        "            \n",
        "            loss_0.append(self.loss(score_0, v0).cpu().detach().numpy())\n",
        "            loss_1.append(self.loss(score_1, v1).cpu().detach().numpy())\n",
        "            loss_2.append(self.loss(score_2, v2).cpu().detach().numpy())\n",
        "            loss_3.append(self.loss(score_3, v3).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_0, v0)\",self.loss(score_0, v0).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_0, v1)\",self.loss(score_1, v1).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_0, v2)\",self.loss(score_2, v2).cpu().detach().numpy())\n",
        "            print(\"self.loss(score_2, v3)\",self.loss(score_3, v3).cpu().detach().numpy())\n",
        "            print(\"loss\",loss)      \n",
        "        else:\n",
        "            loss = self.loss(score_0, v0) + self.loss(score_1, v1) + self.loss(score_2, v2) \n",
        "        \n",
        "        return loss   #change also to matrix version\n",
        "        \n",
        "\n",
        "\n",
        "    def predict(self, sentences, sentences_len,monophonic=True):\n",
        "\n",
        "        # Compute the outputs from the linear units.\n",
        "\n",
        "        scores_comb = self.compute_outputs(sentences, sentences_len)\n",
        "\n",
        "        if monophonic==False:\n",
        "            sum = scores_comb * sentences[:,None,:,:]\n",
        "            return np.squeeze(sum.cpu().numpy())\n",
        "            \n",
        "\n",
        "        else:\n",
        "            # Select the top-scoring labels. The shape is now (max_len, n_sentences).\n",
        "            #predicted = scores_comb.argmax(dim=3)\n",
        "            #return np.squeeze(predicted.cpu().numpy())\n",
        "\n",
        "            sum_tensor = scores_comb * sentences[:,None,:,:]\n",
        "            prediction = np.squeeze(sum_tensor.cpu().numpy())                # prediction is of shape 4,T,88 and contains a probability for the result to belong to one of the 4 voices -> taking argmax: gives the voice with the highes probability\n",
        "            v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "            \n",
        "            mask_pred = np.squeeze(sentences)== 0\n",
        "            v_pred_argm[mask_pred] = -1\n",
        "\n",
        "            return v_pred_argm \n",
        "                       "
      ],
      "metadata": {
        "id": "CviiPTPOPW04"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= \"CNN\"\n",
        "lr = 0.0001  \n",
        "monophonic = True\n",
        "his = start_experiment(10, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "79cPe11WL6J0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ae26352c-14e9-454c-96ae-46c9a0f3eca5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= \"CNN\"\\nlr = 0.0001  \\nmonophonic = True\\nhis = start_experiment(10, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07I2QbRDbUlA"
      },
      "source": [
        "# Define Training Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHESuQEQbVRB"
      },
      "source": [
        "def train(epochs, lr, hidden_dim, momentum, rnn_depth, device, rnn_cell, weight_decay,network_type, train_dataloader, val_dataloader=None):\n",
        "    \n",
        "    output_dim = 88\n",
        "    model = MusicNetwork(network_type, output_dim, hidden_dim, rnn_depth, cell_type)              \n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = lr_scheduler.MultiStepLR(optimizer, [epochs // 2], gamma=0.1, verbose=True)\n",
        "\n",
        "    history = training_loop(model, optimizer, train_dataloader,monophonic, epochs=epochs, val_dataloader=val_dataloader, device=device, scheduler=scheduler)\n",
        "\n",
        "    return model, history"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG_ONds0bkt-"
      },
      "source": [
        "def training_loop(model,optimizer, train_dataloader, monophonic, epochs=50, val_dataloader=None, device=None, scheduler=None):\n",
        "    if device is None:\n",
        "        device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "        print(f\"Training on device: {device}\")\n",
        "\n",
        "    print(\"monophonic set to:\",monophonic)\n",
        "    model = model.to(device)\n",
        "    history = defaultdict(list)\n",
        "\n",
        "    for i_epoch in range(1, epochs + 1):\n",
        "        loss_sum = 0\n",
        "\n",
        "        accuracy_sum_list = [0 for i in range(5)]                                   ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "        val_accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "\n",
        "        accuracy_v_all_sum = 0\n",
        "        model.train()\n",
        "        accuracy_sum = 0\n",
        "        \n",
        "        \n",
        "        for idx, (voices, lens, nbr_voices, _) in enumerate(train_dataloader):  \n",
        "            \n",
        "            voices = voices.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            loss = model.forward(voices, lens, nbr_voices)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()    \n",
        "\n",
        "            if monophonic == False:\n",
        "                with torch.no_grad():\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                    mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                    \n",
        "                    single_voices = voices[:,:,:,:-1]             \n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "\n",
        "            if monophonic == True:\n",
        "                with torch.no_grad():\n",
        "                    ### before\n",
        "                    #prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                    #prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "                    #truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "                    #acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "                    #for i in range(len(prediction[0,:])):\n",
        "                    #  acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                    #  accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "\n",
        "                    #prediction = model.predict(voices, lens, monophonic)                    #for voice vise masking\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)         #for mixed voice masking        \n",
        "\n",
        "\n",
        "                    ## ground truth in shape 1280x88 -> mixed voice\n",
        "                    single_voices = voices[:,:,:,:-1]\n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    truth = v_ori_argm       \n",
        "\n",
        "                    # outsource accurcy to further down -> just a placeholder right now\n",
        "                    v_pred_flat = torch.flatten(prediction, start_dim=0, end_dim=-1)\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "\n",
        "\n",
        "        train_loss = loss_sum / len(train_dataloader)\n",
        "\n",
        "        # normalize according to the number of batches\n",
        "        if monophonic == True:\n",
        "\n",
        "            #train_acc_list = np.array(accuracy_sum_list) / len(train_dataloader)\n",
        "            #train_acc_list[3] = accuracy_sum_list[3] / 18                        ## bc only 18 pieces with len 3\n",
        "            #train_acc_list[4] = accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "            #history[\"train_loss\"].append(train_loss)\n",
        "            #history[\"train_acc\"].append(train_acc_list)\n",
        "            #print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}, Train Accuracy_4 : {}\".format(train_loss, train_acc_list[0], train_acc_list[1], train_acc_list[2], train_acc_list[3],train_acc_list[4])) \n",
        "            \n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "        if monophonic == False:\n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "\n",
        "        if monophonic == True:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for voices, lens, nbr_voices, _ in val_dataloader:\n",
        "                        voices = voices.to(device).float()\n",
        "                        ### before\n",
        "                        #prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        #prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "                        #truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "                        #acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "                        #for i in range(len(prediction[0,:])):\n",
        "                        #  acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                        #  val_accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "                    #val_acc_list = np.array(val_accuracy_sum_list) / len(val_dataloader)\n",
        "                    #val_acc_list[3] = val_accuracy_sum_list[3] / 18                         ## bc only 18 pieces with len 3\n",
        "                    #val_acc_list[4] = val_accuracy_sum_list[4] / 2                          ##### CHECK IF 2 or 3 pieces with len 4\n",
        "                #history[\"val_acc\"].append(val_acc_list)\n",
        "                #print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "\n",
        "                        #prediction = model.predict(voices, lens, monophonic)                #for voice vise masking\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)     # for masking with mixed voice\n",
        "\n",
        "\n",
        "\n",
        "                        ## ground truth in shape 1280x88 -> mixed voice\n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        truth = v_ori_argm       \n",
        "\n",
        "                        # outsource accurcy to further down -> just a placeholder right now\n",
        "                        v_pred_flat = torch.flatten(prediction, start_dim=0, end_dim=-1)\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "                    \n",
        "                history[\"val_acc\"].append(val_accuracy)\n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "\n",
        "        if monophonic == False:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_sum = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    for voices, lens, nbr_voices, _ in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "                        \n",
        "                        # Predict the model's output on a batch\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                        v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                        mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                        \n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "                        \n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "\n",
        "                history[\"val_accuracy\"].append(val_accuracy)  \n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "        \n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "    # save the model\n",
        "    #torch.save(model, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "    torch.save({'model_state_dict': model.state_dict()}, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "\n",
        "    return history"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= \"RNN\"\n",
        "monophonic = True\n",
        "his = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ge8pY70uHxF9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "49480f0a-962d-4585-84ed-d3e81769bfdd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= \"RNN\"\\nmonophonic = True\\nhis = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "network_type= [\"CNN\",\"RNN\"]\n",
        "monophonic_list = [True,False]\n",
        "\n",
        "for net in network_type:\n",
        "    for monophonic in monophonic_list: \n",
        "        print(\"network set to:\",net,\"monophnic:\",monophonic)\n",
        "        start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, net, learn_all)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2Bs6-iNEBu8o",
        "outputId": "cff2a0b5-a785-4c12-f7fe-1472a476c5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnetwork_type= [\"CNN\",\"RNN\"]\\nmonophonic_list = [True,False]\\n\\nfor net in network_type:\\n    for monophonic in monophonic_list: \\n        print(\"network set to:\",net,\"monophnic:\",monophonic)\\n        start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, net, learn_all)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sBoQnA6bo71"
      },
      "source": [
        "def start_experiment( epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell, decay,network_type, learn_all):\n",
        "    \n",
        "    trainer = partial(train,epochs, lr, hidden_dim, momentum, rnn_depth, device, cell, decay, network_type)\n",
        "\n",
        "    if learn_all == True:\n",
        "        print(\"Learning from full dataset\")\n",
        "        train_dataset = MusicDataset_new(PATH_TO_DATA) #MusicDataset(PATH_TO_DATA)\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "                \n",
        "        _, history = trainer(train_dataloader)\n",
        "\n",
        "    \n",
        "    else:\n",
        "        # Divide train and validation set\n",
        "        dataset = MusicDataset_new(PATH_TO_DATA)\n",
        "        \n",
        "        train_dataset, validation_dataset = sklearn.model_selection.train_test_split(dataset, test_size=0.15, random_state=10,)\n",
        "\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "        val_dataloader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "\n",
        "        print(\"train_dataloader\",len(train_dataloader),\"val_dataloader\",len(val_dataloader))\n",
        "\n",
        "        \"\"\"\n",
        "        path_train, path_validation = sklearn.model_selection.train_test_split(PATH_TO_DATA, test_size=0.15, random_state=10,)\n",
        "\n",
        "        print(\"Train and validation lenghts: \", len(path_train), len(path_validation))\n",
        "        #train_dataset = MusicDataset_new(PATH_TO_DATA) #MusicDataset(PATH_TO_DATA)\n",
        "        train_dataset = MusicDataset_new(path_train)\n",
        "        validation_dataset = MusicDataset_new(path_validation) #MusicDataset(path_validation)\n",
        "\n",
        "        \n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "        val_dataloader = torch.utils.data.DataLoader(validation_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "        \"\"\"\n",
        "        \n",
        "        _, history = trainer(train_dataloader, val_dataloader)\n",
        "\n",
        "    return history, val_dataloader"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgtn-a7bMTf7"
      },
      "source": [
        "# Hyperparameter choice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNI9b6jKLpOX"
      },
      "source": [
        "model = MusicNetwork\n",
        "epochs = 20\n",
        "lr = 0.00001 # was 0.001\n",
        "momentum = 0.9\n",
        "decay = 1e-4\n",
        "hidden_dim = 300\n",
        "bs = 1\n",
        "rnn_depth = 2 \n",
        "device = None                 #if None:  choses device automatically\n",
        "cell_type = \"GRU\"\n",
        "optimizer = \"Adam\"\n",
        "learn_all = \"False\"           # False -> uses train and valid set\n",
        "network_type= \"CNN\"\n",
        "\n",
        "monophonic = True"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the Experiment"
      ],
      "metadata": {
        "id": "bdetlQP-LoRX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1LTlFJddpwm",
        "outputId": "4ad36017-c69e-4cda-dfd3-d91c3b9471d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "his, val_dataloader = start_experiment(epochs, lr, hidden_dim, bs, momentum, rnn_depth, device, cell_type, decay, network_type, learn_all)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataloader 34 val_dataloader 7\n",
            "Adjusting learning rate of group 0 to 1.0000e-05.\n",
            "Training on device: cuda\n",
            "monophonic set to: True\n",
            "self.loss(score_0, v0) 3.1206949\n",
            "self.loss(score_0, v1) 3.662265\n",
            "self.loss(score_0, v2) 3.5725923\n",
            "self.loss(score_2, v3) 2.943768\n",
            "loss tensor(14.7712, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.5762932\n",
            "self.loss(score_0, v1) 3.1781898\n",
            "self.loss(score_0, v2) 3.253683\n",
            "self.loss(score_2, v3) 4.181167\n",
            "loss tensor(15.2799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.166333\n",
            "self.loss(score_0, v1) 3.324823\n",
            "self.loss(score_0, v2) 3.4079943\n",
            "self.loss(score_2, v3) 3.2282238\n",
            "loss tensor(14.7415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.3083541\n",
            "self.loss(score_0, v1) 3.2796535\n",
            "self.loss(score_0, v2) 1.9330637\n",
            "self.loss(score_2, v3) 3.4575582\n",
            "loss tensor(13.7074, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.28902\n",
            "self.loss(score_0, v1) 3.2354367\n",
            "self.loss(score_0, v2) 2.8343267\n",
            "self.loss(score_2, v3) 3.0750048\n",
            "loss tensor(13.9713, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.3600287\n",
            "self.loss(score_0, v1) 3.7614713\n",
            "self.loss(score_0, v2) 3.7575698\n",
            "self.loss(score_2, v3) 3.8223126\n",
            "loss tensor(16.6125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.42563\n",
            "self.loss(score_0, v1) 3.0257835\n",
            "self.loss(score_0, v2) 3.0757623\n",
            "self.loss(score_2, v3) 2.9222708\n",
            "loss tensor(13.9106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.688029\n",
            "self.loss(score_0, v1) 3.9100828\n",
            "self.loss(score_0, v2) 3.1974645\n",
            "self.loss(score_2, v3) 1.2758728\n",
            "loss tensor(12.7094, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.620127\n",
            "self.loss(score_0, v1) 3.4671834\n",
            "self.loss(score_0, v2) 3.48014\n",
            "self.loss(score_2, v3) 3.440712\n",
            "loss tensor(15.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.2773314\n",
            "self.loss(score_0, v1) 2.9511647\n",
            "self.loss(score_0, v2) 3.3227978\n",
            "self.loss(score_2, v3) 2.9381762\n",
            "loss tensor(13.9586, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.6282177\n",
            "self.loss(score_0, v1) 3.652405\n",
            "self.loss(score_0, v2) 2.8767076\n",
            "self.loss(score_2, v3) 3.0905437\n",
            "loss tensor(13.7931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.0764506\n",
            "self.loss(score_0, v1) 3.252903\n",
            "self.loss(score_0, v2) 3.2810204\n",
            "self.loss(score_2, v3) 2.6534126\n",
            "loss tensor(13.5905, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.5906923\n",
            "self.loss(score_0, v1) 3.4484339\n",
            "self.loss(score_0, v2) 3.5587428\n",
            "self.loss(score_2, v3) 3.2443242\n",
            "loss tensor(14.4644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.4127543\n",
            "self.loss(score_0, v1) 3.5487137\n",
            "self.loss(score_0, v2) 3.1769261\n",
            "self.loss(score_2, v3) 3.2646341\n",
            "loss tensor(15.0353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 12.266416437485638, Train Accuracy : 0.9782784260777901\n",
            " Validation Accuracy : 5.729920009566743\n",
            "Adjusting learning rate of group 0 to 1.0000e-05.\n",
            "self.loss(score_0, v0) 2.7463574\n",
            "self.loss(score_0, v1) 3.1510499\n",
            "self.loss(score_0, v2) 3.1318305\n",
            "self.loss(score_2, v3) 2.8538346\n",
            "loss tensor(13.3100, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.269798\n",
            "self.loss(score_0, v1) 2.7450323\n",
            "self.loss(score_0, v2) 2.8712282\n",
            "self.loss(score_2, v3) 4.04992\n",
            "loss tensor(13.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.816004\n",
            "self.loss(score_0, v1) 2.9160752\n",
            "self.loss(score_0, v2) 3.041699\n",
            "self.loss(score_2, v3) 3.1413093\n",
            "loss tensor(13.4857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.9403088\n",
            "self.loss(score_0, v1) 2.846015\n",
            "self.loss(score_0, v2) 1.7208157\n",
            "self.loss(score_2, v3) 3.3694818\n",
            "loss tensor(12.5614, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.9153914\n",
            "self.loss(score_0, v1) 2.8110049\n",
            "self.loss(score_0, v2) 2.53148\n",
            "self.loss(score_2, v3) 2.9984765\n",
            "loss tensor(12.7556, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.9671214\n",
            "self.loss(score_0, v1) 3.2733417\n",
            "self.loss(score_0, v2) 3.371215\n",
            "self.loss(score_2, v3) 3.7535892\n",
            "loss tensor(15.2421, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.03488\n",
            "self.loss(score_0, v1) 2.6210468\n",
            "self.loss(score_0, v2) 2.7506146\n",
            "self.loss(score_2, v3) 2.8552642\n",
            "loss tensor(12.6894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.2663374\n",
            "self.loss(score_0, v1) 3.391827\n",
            "self.loss(score_0, v2) 2.8630803\n",
            "self.loss(score_2, v3) 1.2490492\n",
            "loss tensor(11.3948, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.229761\n",
            "self.loss(score_0, v1) 3.0691457\n",
            "self.loss(score_0, v2) 3.1467202\n",
            "self.loss(score_2, v3) 3.3523524\n",
            "loss tensor(14.4742, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.8865874\n",
            "self.loss(score_0, v1) 2.569573\n",
            "self.loss(score_0, v2) 2.9838603\n",
            "self.loss(score_2, v3) 2.8683908\n",
            "loss tensor(12.7426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.2699397\n",
            "self.loss(score_0, v1) 3.1047626\n",
            "self.loss(score_0, v2) 2.5503917\n",
            "self.loss(score_2, v3) 3.0333693\n",
            "loss tensor(12.4751, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.6893146\n",
            "self.loss(score_0, v1) 2.8048065\n",
            "self.loss(score_0, v2) 2.9434764\n",
            "self.loss(score_2, v3) 2.592802\n",
            "loss tensor(12.3268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.2477915\n",
            "self.loss(score_0, v1) 2.984954\n",
            "self.loss(score_0, v2) 3.1955178\n",
            "self.loss(score_2, v3) 3.1597638\n",
            "loss tensor(13.1679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 3.011587\n",
            "self.loss(score_0, v1) 3.077192\n",
            "self.loss(score_0, v2) 2.8726997\n",
            "self.loss(score_2, v3) 3.1750069\n",
            "loss tensor(13.7240, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 10.892971627852496, Train Accuracy : 0.9800486145301169\n",
            " Validation Accuracy : 5.740449450199021\n",
            "Adjusting learning rate of group 0 to 1.0000e-05.\n",
            "self.loss(score_0, v0) 2.3442054\n",
            "self.loss(score_0, v1) 2.6574643\n",
            "self.loss(score_0, v2) 2.8093073\n",
            "self.loss(score_2, v3) 2.76146\n",
            "loss tensor(11.9532, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.9225644\n",
            "self.loss(score_0, v1) 2.314633\n",
            "self.loss(score_0, v2) 2.5832095\n",
            "self.loss(score_2, v3) 3.919321\n",
            "loss tensor(12.6994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.3742828\n",
            "self.loss(score_0, v1) 2.4609492\n",
            "self.loss(score_0, v2) 2.7448065\n",
            "self.loss(score_2, v3) 3.0247302\n",
            "loss tensor(12.1171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.4704978\n",
            "self.loss(score_0, v1) 2.35789\n",
            "self.loss(score_0, v2) 1.5339589\n",
            "self.loss(score_2, v3) 3.2303257\n",
            "loss tensor(11.2078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.4341416\n",
            "self.loss(score_0, v1) 2.3221834\n",
            "self.loss(score_0, v2) 2.2642252\n",
            "self.loss(score_2, v3) 2.881117\n",
            "loss tensor(11.3422, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.4617083\n",
            "self.loss(score_0, v1) 2.717838\n",
            "self.loss(score_0, v2) 3.0313385\n",
            "self.loss(score_2, v3) 3.5929902\n",
            "loss tensor(13.6004, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.5163543\n",
            "self.loss(score_0, v1) 2.1533158\n",
            "self.loss(score_0, v2) 2.4613788\n",
            "self.loss(score_2, v3) 2.7329984\n",
            "loss tensor(11.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.710417\n",
            "self.loss(score_0, v1) 2.799629\n",
            "self.loss(score_0, v2) 2.5550244\n",
            "self.loss(score_2, v3) 1.1847883\n",
            "loss tensor(9.8423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.6965792\n",
            "self.loss(score_0, v1) 2.5965478\n",
            "self.loss(score_0, v2) 2.8344011\n",
            "self.loss(score_2, v3) 3.2079883\n",
            "loss tensor(12.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.3640983\n",
            "self.loss(score_0, v1) 2.1245706\n",
            "self.loss(score_0, v2) 2.6574843\n",
            "self.loss(score_2, v3) 2.7322898\n",
            "loss tensor(11.2446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.8088498\n",
            "self.loss(score_0, v1) 2.4996018\n",
            "self.loss(score_0, v2) 2.261583\n",
            "self.loss(score_2, v3) 2.8655374\n",
            "loss tensor(10.8683, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.1813946\n",
            "self.loss(score_0, v1) 2.2937088\n",
            "self.loss(score_0, v2) 2.619384\n",
            "self.loss(score_2, v3) 2.4505854\n",
            "loss tensor(10.7704, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.8216804\n",
            "self.loss(score_0, v1) 2.4902782\n",
            "self.loss(score_0, v2) 2.844391\n",
            "self.loss(score_2, v3) 2.9750795\n",
            "loss tensor(11.6190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.496435\n",
            "self.loss(score_0, v1) 2.5415459\n",
            "self.loss(score_0, v2) 2.5548885\n",
            "self.loss(score_2, v3) 2.9803798\n",
            "loss tensor(12.0634, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 9.401608046363382, Train Accuracy : 0.9819642097983118\n",
            " Validation Accuracy : 5.7521062487946155\n",
            "Adjusting learning rate of group 0 to 1.0000e-05.\n",
            "self.loss(score_0, v0) 1.8459713\n",
            "self.loss(score_0, v1) 2.12975\n",
            "self.loss(score_0, v2) 2.4523203\n",
            "self.loss(score_2, v3) 2.5727644\n",
            "loss tensor(10.2872, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.4987731\n",
            "self.loss(score_0, v1) 1.8628334\n",
            "self.loss(score_0, v2) 2.2669365\n",
            "self.loss(score_2, v3) 3.6711059\n",
            "loss tensor(11.1352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.8667834\n",
            "self.loss(score_0, v1) 2.0109153\n",
            "self.loss(score_0, v2) 2.3995354\n",
            "self.loss(score_2, v3) 2.8314102\n",
            "loss tensor(10.5243, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.9416885\n",
            "self.loss(score_0, v1) 1.9105707\n",
            "self.loss(score_0, v2) 1.305754\n",
            "self.loss(score_2, v3) 3.0132031\n",
            "loss tensor(9.6778, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.8866667\n",
            "self.loss(score_0, v1) 1.857809\n",
            "self.loss(score_0, v2) 1.9428666\n",
            "self.loss(score_2, v3) 2.6910324\n",
            "loss tensor(9.7239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.878252\n",
            "self.loss(score_0, v1) 2.1871135\n",
            "self.loss(score_0, v2) 2.614728\n",
            "self.loss(score_2, v3) 3.3417008\n",
            "loss tensor(11.6926, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.918983\n",
            "self.loss(score_0, v1) 1.7146746\n",
            "self.loss(score_0, v2) 2.1064868\n",
            "self.loss(score_2, v3) 2.5424113\n",
            "loss tensor(9.5538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.1029153\n",
            "self.loss(score_0, v1) 2.2587798\n",
            "self.loss(score_0, v2) 2.182144\n",
            "self.loss(score_2, v3) 1.0951571\n",
            "loss tensor(8.1866, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 2.093112\n",
            "self.loss(score_0, v1) 2.132756\n",
            "self.loss(score_0, v2) 2.4528658\n",
            "self.loss(score_2, v3) 2.9931018\n",
            "loss tensor(11.1684, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.7825612\n",
            "self.loss(score_0, v1) 1.6998526\n",
            "self.loss(score_0, v2) 2.2533104\n",
            "self.loss(score_2, v3) 2.534822\n",
            "loss tensor(9.5380, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.2903289\n",
            "self.loss(score_0, v1) 1.9607962\n",
            "self.loss(score_0, v2) 1.9143676\n",
            "self.loss(score_2, v3) 2.6268868\n",
            "loss tensor(9.1058, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.6340728\n",
            "self.loss(score_0, v1) 1.8196808\n",
            "self.loss(score_0, v2) 2.2228346\n",
            "self.loss(score_2, v3) 2.2483923\n",
            "loss tensor(9.0492, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.3792564\n",
            "self.loss(score_0, v1) 2.0867882\n",
            "self.loss(score_0, v2) 2.4248676\n",
            "self.loss(score_2, v3) 2.7208905\n",
            "loss tensor(9.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.9556501\n",
            "self.loss(score_0, v1) 2.0666003\n",
            "self.loss(score_0, v2) 2.1735742\n",
            "self.loss(score_2, v3) 2.7188833\n",
            "loss tensor(10.2741, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 7.7643561363220215, Train Accuracy : 0.9849698268650388\n",
            " Validation Accuracy : 5.769702080417993\n",
            "Adjusting learning rate of group 0 to 1.0000e-05.\n",
            "self.loss(score_0, v0) 1.3260057\n",
            "self.loss(score_0, v1) 1.6927866\n",
            "self.loss(score_0, v2) 2.0317144\n",
            "self.loss(score_2, v3) 2.3267524\n",
            "loss tensor(8.5406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.0695393\n",
            "self.loss(score_0, v1) 1.5156548\n",
            "self.loss(score_0, v2) 1.9207476\n",
            "self.loss(score_2, v3) 3.327041\n",
            "loss tensor(9.4965, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.3670418\n",
            "self.loss(score_0, v1) 1.6504924\n",
            "self.loss(score_0, v2) 2.034891\n",
            "self.loss(score_2, v3) 2.551509\n",
            "loss tensor(8.8797, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.4412988\n",
            "self.loss(score_0, v1) 1.5753064\n",
            "self.loss(score_0, v2) 1.0909266\n",
            "self.loss(score_2, v3) 2.700521\n",
            "loss tensor(8.1583, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.3555125\n",
            "self.loss(score_0, v1) 1.491663\n",
            "self.loss(score_0, v2) 1.6239616\n",
            "self.loss(score_2, v3) 2.4080932\n",
            "loss tensor(8.0833, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.3200984\n",
            "self.loss(score_0, v1) 1.7448015\n",
            "self.loss(score_0, v2) 2.18809\n",
            "self.loss(score_2, v3) 2.9820065\n",
            "loss tensor(9.7260, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.3527004\n",
            "self.loss(score_0, v1) 1.3506799\n",
            "self.loss(score_0, v2) 1.7480192\n",
            "self.loss(score_2, v3) 2.2687857\n",
            "loss tensor(7.8546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.5206188\n",
            "self.loss(score_0, v1) 1.7965001\n",
            "self.loss(score_0, v2) 1.8049567\n",
            "self.loss(score_2, v3) 0.969472\n",
            "loss tensor(6.5763, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.5213383\n",
            "self.loss(score_0, v1) 1.7308408\n",
            "self.loss(score_0, v2) 2.0718262\n",
            "self.loss(score_2, v3) 2.6928606\n",
            "loss tensor(9.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.24431\n",
            "self.loss(score_0, v1) 1.3370996\n",
            "self.loss(score_0, v2) 1.8716403\n",
            "self.loss(score_2, v3) 2.2561913\n",
            "loss tensor(7.8373, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.82876563\n",
            "self.loss(score_0, v1) 1.5374984\n",
            "self.loss(score_0, v2) 1.5737308\n",
            "self.loss(score_2, v3) 2.2799182\n",
            "loss tensor(7.3599, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.1462528\n",
            "self.loss(score_0, v1) 1.4351656\n",
            "self.loss(score_0, v2) 1.8546538\n",
            "self.loss(score_2, v3) 1.9604224\n",
            "loss tensor(7.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.98845756\n",
            "self.loss(score_0, v1) 1.7907597\n",
            "self.loss(score_0, v2) 2.068136\n",
            "self.loss(score_2, v3) 2.355364\n",
            "loss tensor(8.3804, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.479002\n",
            "self.loss(score_0, v1) 1.6804509\n",
            "self.loss(score_0, v2) 1.8545028\n",
            "self.loss(score_2, v3) 2.3428042\n",
            "loss tensor(8.5282, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 6.178471866775961, Train Accuracy : 0.9892352077373201\n",
            " Validation Accuracy : 5.793894561038085\n",
            "Adjusting learning rate of group 0 to 1.0000e-05.\n",
            "self.loss(score_0, v0) 0.9051869\n",
            "self.loss(score_0, v1) 1.3448876\n",
            "self.loss(score_0, v2) 1.6812863\n",
            "self.loss(score_2, v3) 1.9717388\n",
            "loss tensor(6.8890, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.7303468\n",
            "self.loss(score_0, v1) 1.2459772\n",
            "self.loss(score_0, v2) 1.6602137\n",
            "self.loss(score_2, v3) 2.8347094\n",
            "loss tensor(7.8886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.99460757\n",
            "self.loss(score_0, v1) 1.3697621\n",
            "self.loss(score_0, v2) 1.7566143\n",
            "self.loss(score_2, v3) 2.1633325\n",
            "loss tensor(7.3660, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.0712413\n",
            "self.loss(score_0, v1) 1.3241767\n",
            "self.loss(score_0, v2) 0.9594834\n",
            "self.loss(score_2, v3) 2.2664907\n",
            "loss tensor(6.7546, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.97736716\n",
            "self.loss(score_0, v1) 1.2125815\n",
            "self.loss(score_0, v2) 1.395061\n",
            "self.loss(score_2, v3) 2.0208068\n",
            "loss tensor(6.6162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.9298449\n",
            "self.loss(score_0, v1) 1.3833942\n",
            "self.loss(score_0, v2) 1.858545\n",
            "self.loss(score_2, v3) 2.4993036\n",
            "loss tensor(7.9207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.9547424\n",
            "self.loss(score_0, v1) 1.0487657\n",
            "self.loss(score_0, v2) 1.4636811\n",
            "self.loss(score_2, v3) 1.9054235\n",
            "loss tensor(6.3253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.0880855\n",
            "self.loss(score_0, v1) 1.4276595\n",
            "self.loss(score_0, v2) 1.4683797\n",
            "self.loss(score_2, v3) 0.79935217\n",
            "loss tensor(5.1832, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.1316261\n",
            "self.loss(score_0, v1) 1.4044967\n",
            "self.loss(score_0, v2) 1.7493926\n",
            "self.loss(score_2, v3) 2.3095062\n",
            "loss tensor(7.7498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.8777112\n",
            "self.loss(score_0, v1) 1.0465227\n",
            "self.loss(score_0, v2) 1.5696375\n",
            "self.loss(score_2, v3) 1.8960509\n",
            "loss tensor(6.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5336068\n",
            "self.loss(score_0, v1) 1.2093501\n",
            "self.loss(score_0, v2) 1.3142583\n",
            "self.loss(score_2, v3) 1.8362503\n",
            "loss tensor(5.8116, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.82572883\n",
            "self.loss(score_0, v1) 1.1393278\n",
            "self.loss(score_0, v2) 1.5742384\n",
            "self.loss(score_2, v3) 1.6016363\n",
            "loss tensor(5.9417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.7255222\n",
            "self.loss(score_0, v1) 1.5684092\n",
            "self.loss(score_0, v2) 1.857534\n",
            "self.loss(score_2, v3) 1.9072018\n",
            "loss tensor(7.0123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 1.1423788\n",
            "self.loss(score_0, v1) 1.3855144\n",
            "self.loss(score_0, v2) 1.6519356\n",
            "self.loss(score_2, v3) 1.8864202\n",
            "loss tensor(7.0095, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 4.839598641676061, Train Accuracy : 0.9920368710936929\n",
            " Validation Accuracy : 5.80833075001381\n",
            "Adjusting learning rate of group 0 to 1.0000e-05.\n",
            "self.loss(score_0, v0) 0.640815\n",
            "self.loss(score_0, v1) 1.078275\n",
            "self.loss(score_0, v2) 1.4379766\n",
            "self.loss(score_2, v3) 1.5546889\n",
            "loss tensor(5.4891, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5191874\n",
            "self.loss(score_0, v1) 1.0340647\n",
            "self.loss(score_0, v2) 1.5197558\n",
            "self.loss(score_2, v3) 2.2707193\n",
            "loss tensor(6.4791, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.7546561\n",
            "self.loss(score_0, v1) 1.1245843\n",
            "self.loss(score_0, v2) 1.5784695\n",
            "self.loss(score_2, v3) 1.7331191\n",
            "loss tensor(6.0574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.82627577\n",
            "self.loss(score_0, v1) 1.1172577\n",
            "self.loss(score_0, v2) 0.90405416\n",
            "self.loss(score_2, v3) 1.7814243\n",
            "loss tensor(5.5197, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.7365087\n",
            "self.loss(score_0, v1) 0.990849\n",
            "self.loss(score_0, v2) 1.2600796\n",
            "self.loss(score_2, v3) 1.5950397\n",
            "loss tensor(5.3800, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.6871159\n",
            "self.loss(score_0, v1) 1.085273\n",
            "self.loss(score_0, v2) 1.6278492\n",
            "self.loss(score_2, v3) 1.9772214\n",
            "loss tensor(6.3661, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.7081157\n",
            "self.loss(score_0, v1) 0.8055784\n",
            "self.loss(score_0, v2) 1.2618561\n",
            "self.loss(score_2, v3) 1.509127\n",
            "loss tensor(5.0392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.81484663\n",
            "self.loss(score_0, v1) 1.1283156\n",
            "self.loss(score_0, v2) 1.1788633\n",
            "self.loss(score_2, v3) 0.6225185\n",
            "loss tensor(4.0558, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.89176303\n",
            "self.loss(score_0, v1) 1.1342317\n",
            "self.loss(score_0, v2) 1.488765\n",
            "self.loss(score_2, v3) 1.9071848\n",
            "loss tensor(6.3755, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.6531985\n",
            "self.loss(score_0, v1) 0.8078182\n",
            "self.loss(score_0, v2) 1.33797\n",
            "self.loss(score_2, v3) 1.5164535\n",
            "loss tensor(5.0737, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3635254\n",
            "self.loss(score_0, v1) 0.92455715\n",
            "self.loss(score_0, v2) 1.1282964\n",
            "self.loss(score_2, v3) 1.3788598\n",
            "loss tensor(4.4847, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.6276645\n",
            "self.loss(score_0, v1) 0.89940315\n",
            "self.loss(score_0, v2) 1.373805\n",
            "self.loss(score_2, v3) 1.2348503\n",
            "loss tensor(4.7531, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5560542\n",
            "self.loss(score_0, v1) 1.3664895\n",
            "self.loss(score_0, v2) 1.7406306\n",
            "self.loss(score_2, v3) 1.4572384\n",
            "loss tensor(5.8490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.90865874\n",
            "self.loss(score_0, v1) 1.1263603\n",
            "self.loss(score_0, v2) 1.5147815\n",
            "self.loss(score_2, v3) 1.4466827\n",
            "loss tensor(5.7198, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 3.7868997559827915, Train Accuracy : 0.9928803210160129\n",
            " Validation Accuracy : 5.812601972427515\n",
            "Adjusting learning rate of group 0 to 1.0000e-05.\n",
            "self.loss(score_0, v0) 0.4726733\n",
            "self.loss(score_0, v1) 0.8488195\n",
            "self.loss(score_0, v2) 1.2703973\n",
            "self.loss(score_2, v3) 1.1561954\n",
            "loss tensor(4.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3838462\n",
            "self.loss(score_0, v1) 0.8533341\n",
            "self.loss(score_0, v2) 1.4430135\n",
            "self.loss(score_2, v3) 1.7370187\n",
            "loss tensor(5.2857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5929908\n",
            "self.loss(score_0, v1) 0.89109355\n",
            "self.loss(score_0, v2) 1.4331563\n",
            "self.loss(score_2, v3) 1.3475428\n",
            "loss tensor(4.9386, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.65441847\n",
            "self.loss(score_0, v1) 0.90444094\n",
            "self.loss(score_0, v2) 0.85294694\n",
            "self.loss(score_2, v3) 1.3412791\n",
            "loss tensor(4.4237, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5726617\n",
            "self.loss(score_0, v1) 0.7848836\n",
            "self.loss(score_0, v2) 1.1528755\n",
            "self.loss(score_2, v3) 1.2120107\n",
            "loss tensor(4.3284, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.53017604\n",
            "self.loss(score_0, v1) 0.8234092\n",
            "self.loss(score_0, v2) 1.4362708\n",
            "self.loss(score_2, v3) 1.5130204\n",
            "loss tensor(5.0594, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5490453\n",
            "self.loss(score_0, v1) 0.595195\n",
            "self.loss(score_0, v2) 1.1014166\n",
            "self.loss(score_2, v3) 1.1574405\n",
            "loss tensor(3.9818, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.64179003\n",
            "self.loss(score_0, v1) 0.87916464\n",
            "self.loss(score_0, v2) 0.9575493\n",
            "self.loss(score_2, v3) 0.4763708\n",
            "loss tensor(3.1931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.7382566\n",
            "self.loss(score_0, v1) 0.90121955\n",
            "self.loss(score_0, v2) 1.2928103\n",
            "self.loss(score_2, v3) 1.5462109\n",
            "loss tensor(5.2516, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5136691\n",
            "self.loss(score_0, v1) 0.60605294\n",
            "self.loss(score_0, v2) 1.1570147\n",
            "self.loss(score_2, v3) 1.1797761\n",
            "loss tensor(4.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2647198\n",
            "self.loss(score_0, v1) 0.6672586\n",
            "self.loss(score_0, v2) 0.9728969\n",
            "self.loss(score_2, v3) 0.99315524\n",
            "loss tensor(3.3946, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5037207\n",
            "self.loss(score_0, v1) 0.7038674\n",
            "self.loss(score_0, v2) 1.2143596\n",
            "self.loss(score_2, v3) 0.9296562\n",
            "loss tensor(3.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.44269267\n",
            "self.loss(score_0, v1) 1.1479236\n",
            "self.loss(score_0, v2) 1.6036144\n",
            "self.loss(score_2, v3) 1.0904558\n",
            "loss tensor(4.8299, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.7412201\n",
            "self.loss(score_0, v1) 0.8899594\n",
            "self.loss(score_0, v2) 1.3605751\n",
            "self.loss(score_2, v3) 1.0982171\n",
            "loss tensor(4.6391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 2.9716739935033463, Train Accuracy : 0.9934617774560914\n",
            " Validation Accuracy : 5.8151843549654965\n",
            "Adjusting learning rate of group 0 to 1.0000e-05.\n",
            "self.loss(score_0, v0) 0.3633266\n",
            "self.loss(score_0, v1) 0.6138434\n",
            "self.loss(score_0, v2) 1.0925658\n",
            "self.loss(score_2, v3) 0.86285263\n",
            "loss tensor(3.3640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.29391295\n",
            "self.loss(score_0, v1) 0.68079287\n",
            "self.loss(score_0, v2) 1.352692\n",
            "self.loss(score_2, v3) 1.3221772\n",
            "loss tensor(4.3107, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.47640434\n",
            "self.loss(score_0, v1) 0.6579425\n",
            "self.loss(score_0, v2) 1.2511333\n",
            "self.loss(score_2, v3) 1.0672752\n",
            "loss tensor(3.9864, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.532748\n",
            "self.loss(score_0, v1) 0.6991152\n",
            "self.loss(score_0, v2) 0.7642065\n",
            "self.loss(score_2, v3) 1.0205584\n",
            "loss tensor(3.5269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.45143735\n",
            "self.loss(score_0, v1) 0.5723517\n",
            "self.loss(score_0, v2) 1.0163275\n",
            "self.loss(score_2, v3) 0.9306315\n",
            "loss tensor(3.4361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.42276782\n",
            "self.loss(score_0, v1) 0.5992042\n",
            "self.loss(score_0, v2) 1.2417123\n",
            "self.loss(score_2, v3) 1.1792226\n",
            "loss tensor(4.0325, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.44204572\n",
            "self.loss(score_0, v1) 0.40818447\n",
            "self.loss(score_0, v2) 0.945702\n",
            "self.loss(score_2, v3) 0.89793277\n",
            "loss tensor(3.1428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.52261156\n",
            "self.loss(score_0, v1) 0.6687568\n",
            "self.loss(score_0, v2) 0.77735597\n",
            "self.loss(score_2, v3) 0.37664878\n",
            "loss tensor(2.5337, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.6302374\n",
            "self.loss(score_0, v1) 0.6971764\n",
            "self.loss(score_0, v2) 1.1287322\n",
            "self.loss(score_2, v3) 1.2600108\n",
            "loss tensor(4.3462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.420381\n",
            "self.loss(score_0, v1) 0.44255137\n",
            "self.loss(score_0, v2) 0.99595624\n",
            "self.loss(score_2, v3) 0.9288885\n",
            "loss tensor(3.2522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.20323537\n",
            "self.loss(score_0, v1) 0.44299334\n",
            "self.loss(score_0, v2) 0.8187496\n",
            "self.loss(score_2, v3) 0.7292806\n",
            "loss tensor(2.5589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.4210125\n",
            "self.loss(score_0, v1) 0.5461905\n",
            "self.loss(score_0, v2) 1.0649806\n",
            "self.loss(score_2, v3) 0.7092698\n",
            "loss tensor(3.0961, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3480718\n",
            "self.loss(score_0, v1) 0.84582996\n",
            "self.loss(score_0, v2) 1.3958445\n",
            "self.loss(score_2, v3) 0.8427967\n",
            "loss tensor(3.8539, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.60754174\n",
            "self.loss(score_0, v1) 0.6716975\n",
            "self.loss(score_0, v2) 1.1600796\n",
            "self.loss(score_2, v3) 0.8644704\n",
            "loss tensor(3.7360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 2.3315376358873703, Train Accuracy : 0.9941615389073476\n",
            " Validation Accuracy : 5.81857792385658\n",
            "Adjusting learning rate of group 0 to 1.0000e-05.\n",
            "self.loss(score_0, v0) 0.28729624\n",
            "self.loss(score_0, v1) 0.41511542\n",
            "self.loss(score_0, v2) 0.89791304\n",
            "self.loss(score_2, v3) 0.6791139\n",
            "loss tensor(2.6190, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22752711\n",
            "self.loss(score_0, v1) 0.4899013\n",
            "self.loss(score_0, v2) 1.222629\n",
            "self.loss(score_2, v3) 1.0206406\n",
            "loss tensor(3.4710, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3910475\n",
            "self.loss(score_0, v1) 0.48391053\n",
            "self.loss(score_0, v2) 1.0779828\n",
            "self.loss(score_2, v3) 0.87155044\n",
            "loss tensor(3.2603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.45286146\n",
            "self.loss(score_0, v1) 0.5693746\n",
            "self.loss(score_0, v2) 0.6825013\n",
            "self.loss(score_2, v3) 0.77903855\n",
            "loss tensor(2.8733, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.36090744\n",
            "self.loss(score_0, v1) 0.41382092\n",
            "self.loss(score_0, v2) 0.8964397\n",
            "self.loss(score_2, v3) 0.72973675\n",
            "loss tensor(2.7658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.34609556\n",
            "self.loss(score_0, v1) 0.44438183\n",
            "self.loss(score_0, v2) 1.0560272\n",
            "self.loss(score_2, v3) 0.95163375\n",
            "loss tensor(3.2740, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.36751312\n",
            "self.loss(score_0, v1) 0.29129186\n",
            "self.loss(score_0, v2) 0.80478877\n",
            "self.loss(score_2, v3) 0.70473075\n",
            "loss tensor(2.5207, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.43217766\n",
            "self.loss(score_0, v1) 0.5162283\n",
            "self.loss(score_0, v2) 0.637866\n",
            "self.loss(score_2, v3) 0.30364102\n",
            "loss tensor(2.0417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5433216\n",
            "self.loss(score_0, v1) 0.5485804\n",
            "self.loss(score_0, v2) 0.99075335\n",
            "self.loss(score_2, v3) 1.0357854\n",
            "loss tensor(3.6363, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.35003662\n",
            "self.loss(score_0, v1) 0.33079168\n",
            "self.loss(score_0, v2) 0.8582909\n",
            "self.loss(score_2, v3) 0.7424697\n",
            "loss tensor(2.6528, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15981963\n",
            "self.loss(score_0, v1) 0.3090668\n",
            "self.loss(score_0, v2) 0.6826752\n",
            "self.loss(score_2, v3) 0.54999834\n",
            "loss tensor(1.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.35531092\n",
            "self.loss(score_0, v1) 0.4266482\n",
            "self.loss(score_0, v2) 0.94965684\n",
            "self.loss(score_2, v3) 0.54714215\n",
            "loss tensor(2.5523, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.26802295\n",
            "self.loss(score_0, v1) 0.5427331\n",
            "self.loss(score_0, v2) 1.1739473\n",
            "self.loss(score_2, v3) 0.6830348\n",
            "loss tensor(3.0093, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5079814\n",
            "self.loss(score_0, v1) 0.53414327\n",
            "self.loss(score_0, v2) 0.97177696\n",
            "self.loss(score_2, v3) 0.7114514\n",
            "loss tensor(3.0811, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.8506962709567125, Train Accuracy : 0.9947999118032865\n",
            " Validation Accuracy : 5.82208496894223\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.23176773\n",
            "self.loss(score_0, v1) 0.2960419\n",
            "self.loss(score_0, v2) 0.7459598\n",
            "self.loss(score_2, v3) 0.5451992\n",
            "loss tensor(2.0916, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.18499966\n",
            "self.loss(score_0, v1) 0.29057166\n",
            "self.loss(score_0, v2) 0.9581293\n",
            "self.loss(score_2, v3) 0.8354324\n",
            "loss tensor(2.6868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3445778\n",
            "self.loss(score_0, v1) 0.39677685\n",
            "self.loss(score_0, v2) 0.9723867\n",
            "self.loss(score_2, v3) 0.7018492\n",
            "loss tensor(2.7665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.42775092\n",
            "self.loss(score_0, v1) 0.47659206\n",
            "self.loss(score_0, v2) 0.5597659\n",
            "self.loss(score_2, v3) 0.6157432\n",
            "loss tensor(2.3877, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3214005\n",
            "self.loss(score_0, v1) 0.33887032\n",
            "self.loss(score_0, v2) 0.8242234\n",
            "self.loss(score_2, v3) 0.58434886\n",
            "loss tensor(2.3610, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.32311806\n",
            "self.loss(score_0, v1) 0.42300582\n",
            "self.loss(score_0, v2) 1.05184\n",
            "self.loss(score_2, v3) 0.7475068\n",
            "loss tensor(2.9192, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3404874\n",
            "self.loss(score_0, v1) 0.30349317\n",
            "self.loss(score_0, v2) 0.8443126\n",
            "self.loss(score_2, v3) 0.5550388\n",
            "loss tensor(2.3209, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.41579866\n",
            "self.loss(score_0, v1) 0.5025336\n",
            "self.loss(score_0, v2) 0.6671378\n",
            "self.loss(score_2, v3) 0.2244952\n",
            "loss tensor(1.9222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5436458\n",
            "self.loss(score_0, v1) 0.5933427\n",
            "self.loss(score_0, v2) 1.1089857\n",
            "self.loss(score_2, v3) 0.8355801\n",
            "loss tensor(3.4993, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3414347\n",
            "self.loss(score_0, v1) 0.38275787\n",
            "self.loss(score_0, v2) 0.9873206\n",
            "self.loss(score_2, v3) 0.6135825\n",
            "loss tensor(2.6319, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16412593\n",
            "self.loss(score_0, v1) 0.31908527\n",
            "self.loss(score_0, v2) 0.71436685\n",
            "self.loss(score_2, v3) 0.4699217\n",
            "loss tensor(1.9025, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.34489235\n",
            "self.loss(score_0, v1) 0.39780143\n",
            "self.loss(score_0, v2) 0.8836954\n",
            "self.loss(score_2, v3) 0.5092093\n",
            "loss tensor(2.3902, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.26713789\n",
            "self.loss(score_0, v1) 0.41593435\n",
            "self.loss(score_0, v2) 0.98501277\n",
            "self.loss(score_2, v3) 0.7141474\n",
            "loss tensor(2.7393, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.4651192\n",
            "self.loss(score_0, v1) 0.4629247\n",
            "self.loss(score_0, v2) 0.85901254\n",
            "self.loss(score_2, v3) 0.7501489\n",
            "loss tensor(2.9123, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.6463641874930437, Train Accuracy : 0.9949506868309905\n",
            " Validation Accuracy : 5.823612912253894\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.22181793\n",
            "self.loss(score_0, v1) 0.28028694\n",
            "self.loss(score_0, v2) 0.7234886\n",
            "self.loss(score_2, v3) 0.5421582\n",
            "loss tensor(2.0388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.17773402\n",
            "self.loss(score_0, v1) 0.27806082\n",
            "self.loss(score_0, v2) 0.9315106\n",
            "self.loss(score_2, v3) 0.8477068\n",
            "loss tensor(2.6589, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.33317405\n",
            "self.loss(score_0, v1) 0.38947937\n",
            "self.loss(score_0, v2) 0.9574186\n",
            "self.loss(score_2, v3) 0.6977102\n",
            "loss tensor(2.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.4184015\n",
            "self.loss(score_0, v1) 0.46260136\n",
            "self.loss(score_0, v2) 0.5339173\n",
            "self.loss(score_2, v3) 0.61056167\n",
            "loss tensor(2.3308, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.31156617\n",
            "self.loss(score_0, v1) 0.3202507\n",
            "self.loss(score_0, v2) 0.78785574\n",
            "self.loss(score_2, v3) 0.5812501\n",
            "loss tensor(2.2915, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.31325024\n",
            "self.loss(score_0, v1) 0.39956897\n",
            "self.loss(score_0, v2) 1.0082211\n",
            "self.loss(score_2, v3) 0.7480882\n",
            "loss tensor(2.8432, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3361571\n",
            "self.loss(score_0, v1) 0.29691362\n",
            "self.loss(score_0, v2) 0.8120817\n",
            "self.loss(score_2, v3) 0.5470859\n",
            "loss tensor(2.2658, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.40705076\n",
            "self.loss(score_0, v1) 0.47753707\n",
            "self.loss(score_0, v2) 0.6294296\n",
            "self.loss(score_2, v3) 0.22407812\n",
            "loss tensor(1.8501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5322684\n",
            "self.loss(score_0, v1) 0.56239974\n",
            "self.loss(score_0, v2) 1.0564371\n",
            "self.loss(score_2, v3) 0.83120567\n",
            "loss tensor(3.3979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.33480933\n",
            "self.loss(score_0, v1) 0.36382407\n",
            "self.loss(score_0, v2) 0.94192624\n",
            "self.loss(score_2, v3) 0.6056184\n",
            "loss tensor(2.5490, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16080196\n",
            "self.loss(score_0, v1) 0.30249825\n",
            "self.loss(score_0, v2) 0.67329574\n",
            "self.loss(score_2, v3) 0.46830845\n",
            "loss tensor(1.8391, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.34241745\n",
            "self.loss(score_0, v1) 0.3848049\n",
            "self.loss(score_0, v2) 0.8564909\n",
            "self.loss(score_2, v3) 0.5057452\n",
            "loss tensor(2.3423, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2608854\n",
            "self.loss(score_0, v1) 0.39923766\n",
            "self.loss(score_0, v2) 0.94901234\n",
            "self.loss(score_2, v3) 0.72186023\n",
            "loss tensor(2.6919, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.45715317\n",
            "self.loss(score_0, v1) 0.4533073\n",
            "self.loss(score_0, v2) 0.8338398\n",
            "self.loss(score_2, v3) 0.74867505\n",
            "loss tensor(2.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.5986897507134605, Train Accuracy : 0.995226888681748\n",
            " Validation Accuracy : 5.8249118708469965\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.21716236\n",
            "self.loss(score_0, v1) 0.27291614\n",
            "self.loss(score_0, v2) 0.707012\n",
            "self.loss(score_2, v3) 0.5350564\n",
            "loss tensor(1.9997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1748117\n",
            "self.loss(score_0, v1) 0.26871538\n",
            "self.loss(score_0, v2) 0.9128338\n",
            "self.loss(score_2, v3) 0.82867825\n",
            "loss tensor(2.5994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.32773346\n",
            "self.loss(score_0, v1) 0.38362235\n",
            "self.loss(score_0, v2) 0.9466991\n",
            "self.loss(score_2, v3) 0.6817051\n",
            "loss tensor(2.6806, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.4124445\n",
            "self.loss(score_0, v1) 0.4555083\n",
            "self.loss(score_0, v2) 0.53149545\n",
            "self.loss(score_2, v3) 0.59337896\n",
            "loss tensor(2.2895, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.30426148\n",
            "self.loss(score_0, v1) 0.31183425\n",
            "self.loss(score_0, v2) 0.77887666\n",
            "self.loss(score_2, v3) 0.56724507\n",
            "loss tensor(2.2458, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.30612868\n",
            "self.loss(score_0, v1) 0.38590685\n",
            "self.loss(score_0, v2) 0.9896132\n",
            "self.loss(score_2, v3) 0.7350216\n",
            "loss tensor(2.7842, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.32815972\n",
            "self.loss(score_0, v1) 0.28184202\n",
            "self.loss(score_0, v2) 0.79520714\n",
            "self.loss(score_2, v3) 0.53522986\n",
            "loss tensor(2.2081, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.39539513\n",
            "self.loss(score_0, v1) 0.45899102\n",
            "self.loss(score_0, v2) 0.61234736\n",
            "self.loss(score_2, v3) 0.22147644\n",
            "loss tensor(1.7989, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5181598\n",
            "self.loss(score_0, v1) 0.5337468\n",
            "self.loss(score_0, v2) 1.0300579\n",
            "self.loss(score_2, v3) 0.8203475\n",
            "loss tensor(3.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3249769\n",
            "self.loss(score_0, v1) 0.34779212\n",
            "self.loss(score_0, v2) 0.92941964\n",
            "self.loss(score_2, v3) 0.5872499\n",
            "loss tensor(2.4831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15523528\n",
            "self.loss(score_0, v1) 0.2914745\n",
            "self.loss(score_0, v2) 0.6726313\n",
            "self.loss(score_2, v3) 0.44495624\n",
            "loss tensor(1.7868, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.33504215\n",
            "self.loss(score_0, v1) 0.3694991\n",
            "self.loss(score_0, v2) 0.8549241\n",
            "self.loss(score_2, v3) 0.48990276\n",
            "loss tensor(2.2943, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2540459\n",
            "self.loss(score_0, v1) 0.38652053\n",
            "self.loss(score_0, v2) 0.9386191\n",
            "self.loss(score_2, v3) 0.703406\n",
            "loss tensor(2.6343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.44836748\n",
            "self.loss(score_0, v1) 0.44086835\n",
            "self.loss(score_0, v2) 0.82083184\n",
            "self.loss(score_2, v3) 0.73398495\n",
            "loss tensor(2.8110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.559638459892834, Train Accuracy : 0.9953517163931207\n",
            " Validation Accuracy : 5.825507305853371\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.21301065\n",
            "self.loss(score_0, v1) 0.26682454\n",
            "self.loss(score_0, v2) 0.6910393\n",
            "self.loss(score_2, v3) 0.5285893\n",
            "loss tensor(1.9638, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1716681\n",
            "self.loss(score_0, v1) 0.25698513\n",
            "self.loss(score_0, v2) 0.8880012\n",
            "self.loss(score_2, v3) 0.8165743\n",
            "loss tensor(2.5415, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.32206166\n",
            "self.loss(score_0, v1) 0.37128988\n",
            "self.loss(score_0, v2) 0.9221182\n",
            "self.loss(score_2, v3) 0.6735698\n",
            "loss tensor(2.6258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.4092096\n",
            "self.loss(score_0, v1) 0.4434888\n",
            "self.loss(score_0, v2) 0.51437646\n",
            "self.loss(score_2, v3) 0.58427227\n",
            "loss tensor(2.2435, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.29869285\n",
            "self.loss(score_0, v1) 0.30191034\n",
            "self.loss(score_0, v2) 0.76263785\n",
            "self.loss(score_2, v3) 0.5574254\n",
            "loss tensor(2.1994, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.30011258\n",
            "self.loss(score_0, v1) 0.37357244\n",
            "self.loss(score_0, v2) 0.9649742\n",
            "self.loss(score_2, v3) 0.727142\n",
            "loss tensor(2.7294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.32257926\n",
            "self.loss(score_0, v1) 0.27371517\n",
            "self.loss(score_0, v2) 0.7787861\n",
            "self.loss(score_2, v3) 0.5244221\n",
            "loss tensor(2.1617, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3862885\n",
            "self.loss(score_0, v1) 0.4449492\n",
            "self.loss(score_0, v2) 0.59643126\n",
            "self.loss(score_2, v3) 0.21911904\n",
            "loss tensor(1.7563, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.5073867\n",
            "self.loss(score_0, v1) 0.51458734\n",
            "self.loss(score_0, v2) 1.0071034\n",
            "self.loss(score_2, v3) 0.8095056\n",
            "loss tensor(3.2433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.31739166\n",
            "self.loss(score_0, v1) 0.33836922\n",
            "self.loss(score_0, v2) 0.9175169\n",
            "self.loss(score_2, v3) 0.5735326\n",
            "loss tensor(2.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1509555\n",
            "self.loss(score_0, v1) 0.28418502\n",
            "self.loss(score_0, v2) 0.666481\n",
            "self.loss(score_2, v3) 0.4297494\n",
            "loss tensor(1.7462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3281607\n",
            "self.loss(score_0, v1) 0.35556972\n",
            "self.loss(score_0, v2) 0.8516187\n",
            "self.loss(score_2, v3) 0.47610638\n",
            "loss tensor(2.2495, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.24701308\n",
            "self.loss(score_0, v1) 0.37622836\n",
            "self.loss(score_0, v2) 0.92922574\n",
            "self.loss(score_2, v3) 0.68515676\n",
            "loss tensor(2.5802, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.4399698\n",
            "self.loss(score_0, v1) 0.42946413\n",
            "self.loss(score_0, v2) 0.8087451\n",
            "self.loss(score_2, v3) 0.71911186\n",
            "loss tensor(2.7568, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.524514782078126, Train Accuracy : 0.9954866857543309\n",
            " Validation Accuracy : 5.826192572486748\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.20866226\n",
            "self.loss(score_0, v1) 0.26023418\n",
            "self.loss(score_0, v2) 0.67784667\n",
            "self.loss(score_2, v3) 0.5189767\n",
            "loss tensor(1.9252, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16858421\n",
            "self.loss(score_0, v1) 0.24787362\n",
            "self.loss(score_0, v2) 0.8675748\n",
            "self.loss(score_2, v3) 0.8017892\n",
            "loss tensor(2.4867, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.31704634\n",
            "self.loss(score_0, v1) 0.36198795\n",
            "self.loss(score_0, v2) 0.9019712\n",
            "self.loss(score_2, v3) 0.66366184\n",
            "loss tensor(2.5765, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.40559047\n",
            "self.loss(score_0, v1) 0.43322855\n",
            "self.loss(score_0, v2) 0.50045437\n",
            "self.loss(score_2, v3) 0.57350445\n",
            "loss tensor(2.1995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.29318857\n",
            "self.loss(score_0, v1) 0.29245105\n",
            "self.loss(score_0, v2) 0.7460543\n",
            "self.loss(score_2, v3) 0.5474057\n",
            "loss tensor(2.1528, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.29470056\n",
            "self.loss(score_0, v1) 0.36254296\n",
            "self.loss(score_0, v2) 0.9414067\n",
            "self.loss(score_2, v3) 0.71829176\n",
            "loss tensor(2.6761, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3172083\n",
            "self.loss(score_0, v1) 0.26447788\n",
            "self.loss(score_0, v2) 0.7602018\n",
            "self.loss(score_2, v3) 0.51384336\n",
            "loss tensor(2.1127, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.37767684\n",
            "self.loss(score_0, v1) 0.43197638\n",
            "self.loss(score_0, v2) 0.5807802\n",
            "self.loss(score_2, v3) 0.21680634\n",
            "loss tensor(1.7156, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.4977911\n",
            "self.loss(score_0, v1) 0.49713874\n",
            "self.loss(score_0, v2) 0.9843236\n",
            "self.loss(score_2, v3) 0.7988723\n",
            "loss tensor(3.1776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.31049132\n",
            "self.loss(score_0, v1) 0.32780287\n",
            "self.loss(score_0, v2) 0.90237087\n",
            "self.loss(score_2, v3) 0.56005496\n",
            "loss tensor(2.3807, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14704354\n",
            "self.loss(score_0, v1) 0.27631697\n",
            "self.loss(score_0, v2) 0.6567652\n",
            "self.loss(score_2, v3) 0.41689762\n",
            "loss tensor(1.7055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.32252777\n",
            "self.loss(score_0, v1) 0.34359467\n",
            "self.loss(score_0, v2) 0.84524393\n",
            "self.loss(score_2, v3) 0.46403655\n",
            "loss tensor(2.2074, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.24152325\n",
            "self.loss(score_0, v1) 0.36657783\n",
            "self.loss(score_0, v2) 0.91735137\n",
            "self.loss(score_2, v3) 0.66932696\n",
            "loss tensor(2.5294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.43230557\n",
            "self.loss(score_0, v1) 0.41921368\n",
            "self.loss(score_0, v2) 0.7965365\n",
            "self.loss(score_2, v3) 0.7049658\n",
            "loss tensor(2.7055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.4911472411716686, Train Accuracy : 0.9956199854284447\n",
            " Validation Accuracy : 5.826879046569699\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.20446022\n",
            "self.loss(score_0, v1) 0.25367868\n",
            "self.loss(score_0, v2) 0.6659758\n",
            "self.loss(score_2, v3) 0.50789183\n",
            "loss tensor(1.8860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16570501\n",
            "self.loss(score_0, v1) 0.2403574\n",
            "self.loss(score_0, v2) 0.8501529\n",
            "self.loss(score_2, v3) 0.7860298\n",
            "loss tensor(2.4353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.31223992\n",
            "self.loss(score_0, v1) 0.35393775\n",
            "self.loss(score_0, v2) 0.8855658\n",
            "self.loss(score_2, v3) 0.65226346\n",
            "loss tensor(2.5301, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.40163398\n",
            "self.loss(score_0, v1) 0.42387387\n",
            "self.loss(score_0, v2) 0.4892159\n",
            "self.loss(score_2, v3) 0.561754\n",
            "loss tensor(2.1574, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.28789082\n",
            "self.loss(score_0, v1) 0.2841958\n",
            "self.loss(score_0, v2) 0.7314316\n",
            "self.loss(score_2, v3) 0.53689945\n",
            "loss tensor(2.1089, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.28968155\n",
            "self.loss(score_0, v1) 0.35315025\n",
            "self.loss(score_0, v2) 0.9207169\n",
            "self.loss(score_2, v3) 0.70796466\n",
            "loss tensor(2.6255, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.31194496\n",
            "self.loss(score_0, v1) 0.2565309\n",
            "self.loss(score_0, v2) 0.7436252\n",
            "self.loss(score_2, v3) 0.5029064\n",
            "loss tensor(2.0665, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.36956927\n",
            "self.loss(score_0, v1) 0.42044592\n",
            "self.loss(score_0, v2) 0.56607705\n",
            "self.loss(score_2, v3) 0.21435611\n",
            "loss tensor(1.6776, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.48889926\n",
            "self.loss(score_0, v1) 0.48167315\n",
            "self.loss(score_0, v2) 0.96283853\n",
            "self.loss(score_2, v3) 0.7881821\n",
            "loss tensor(3.1157, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3039963\n",
            "self.loss(score_0, v1) 0.31731322\n",
            "self.loss(score_0, v2) 0.88629854\n",
            "self.loss(score_2, v3) 0.5470336\n",
            "loss tensor(2.3282, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.14324172\n",
            "self.loss(score_0, v1) 0.26813635\n",
            "self.loss(score_0, v2) 0.6450472\n",
            "self.loss(score_2, v3) 0.40545943\n",
            "loss tensor(1.6646, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3173655\n",
            "self.loss(score_0, v1) 0.3330037\n",
            "self.loss(score_0, v2) 0.83692443\n",
            "self.loss(score_2, v3) 0.45294422\n",
            "loss tensor(2.1667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23697346\n",
            "self.loss(score_0, v1) 0.35715458\n",
            "self.loss(score_0, v2) 0.9037899\n",
            "self.loss(score_2, v3) 0.6546511\n",
            "loss tensor(2.4799, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.42505777\n",
            "self.loss(score_0, v1) 0.4097784\n",
            "self.loss(score_0, v2) 0.783969\n",
            "self.loss(score_2, v3) 0.69155264\n",
            "loss tensor(2.6561, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.4590169752345366, Train Accuracy : 0.9957490363835094\n",
            " Validation Accuracy : 5.82753274797539\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.20041192\n",
            "self.loss(score_0, v1) 0.24734624\n",
            "self.loss(score_0, v2) 0.65438247\n",
            "self.loss(score_2, v3) 0.4965907\n",
            "loss tensor(1.8470, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.16292627\n",
            "self.loss(score_0, v1) 0.23361532\n",
            "self.loss(score_0, v2) 0.8335395\n",
            "self.loss(score_2, v3) 0.7701057\n",
            "loss tensor(2.3852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.30751958\n",
            "self.loss(score_0, v1) 0.346472\n",
            "self.loss(score_0, v2) 0.8707806\n",
            "self.loss(score_2, v3) 0.6401477\n",
            "loss tensor(2.4850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3974228\n",
            "self.loss(score_0, v1) 0.41487128\n",
            "self.loss(score_0, v2) 0.47918108\n",
            "self.loss(score_2, v3) 0.54967433\n",
            "loss tensor(2.1160, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.28271043\n",
            "self.loss(score_0, v1) 0.27680933\n",
            "self.loss(score_0, v2) 0.7180353\n",
            "self.loss(score_2, v3) 0.5260996\n",
            "loss tensor(2.0667, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.28488863\n",
            "self.loss(score_0, v1) 0.34484547\n",
            "self.loss(score_0, v2) 0.9017493\n",
            "self.loss(score_2, v3) 0.6966113\n",
            "loss tensor(2.5764, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3066382\n",
            "self.loss(score_0, v1) 0.24939154\n",
            "self.loss(score_0, v2) 0.7283826\n",
            "self.loss(score_2, v3) 0.49188867\n",
            "loss tensor(2.0222, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.36183187\n",
            "self.loss(score_0, v1) 0.4101568\n",
            "self.loss(score_0, v2) 0.552114\n",
            "self.loss(score_2, v3) 0.21178652\n",
            "loss tensor(1.6418, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.480601\n",
            "self.loss(score_0, v1) 0.46809825\n",
            "self.loss(score_0, v2) 0.94279236\n",
            "self.loss(score_2, v3) 0.7773059\n",
            "loss tensor(3.0575, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.29779628\n",
            "self.loss(score_0, v1) 0.30737916\n",
            "self.loss(score_0, v2) 0.87018573\n",
            "self.loss(score_2, v3) 0.5344298\n",
            "loss tensor(2.2770, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1395971\n",
            "self.loss(score_0, v1) 0.26026732\n",
            "self.loss(score_0, v2) 0.6326012\n",
            "self.loss(score_2, v3) 0.39483434\n",
            "loss tensor(1.6247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3123807\n",
            "self.loss(score_0, v1) 0.323301\n",
            "self.loss(score_0, v2) 0.82770556\n",
            "self.loss(score_2, v3) 0.4423252\n",
            "loss tensor(2.1269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.23284154\n",
            "self.loss(score_0, v1) 0.34804535\n",
            "self.loss(score_0, v2) 0.8895867\n",
            "self.loss(score_2, v3) 0.64044553\n",
            "loss tensor(2.4311, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.4180331\n",
            "self.loss(score_0, v1) 0.40085098\n",
            "self.loss(score_0, v2) 0.7714821\n",
            "self.loss(score_2, v3) 0.6782892\n",
            "loss tensor(2.6078, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.4279314121779274, Train Accuracy : 0.9958806766696573\n",
            " Validation Accuracy : 5.828193033954724\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.1964598\n",
            "self.loss(score_0, v1) 0.24121639\n",
            "self.loss(score_0, v2) 0.6429633\n",
            "self.loss(score_2, v3) 0.48530376\n",
            "loss tensor(1.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.1602055\n",
            "self.loss(score_0, v1) 0.22743544\n",
            "self.loss(score_0, v2) 0.81734157\n",
            "self.loss(score_2, v3) 0.7542779\n",
            "loss tensor(2.3364, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.30292717\n",
            "self.loss(score_0, v1) 0.33936545\n",
            "self.loss(score_0, v2) 0.85661083\n",
            "self.loss(score_2, v3) 0.6278999\n",
            "loss tensor(2.4408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3931745\n",
            "self.loss(score_0, v1) 0.4058778\n",
            "self.loss(score_0, v2) 0.4696162\n",
            "self.loss(score_2, v3) 0.53756\n",
            "loss tensor(2.0750, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2775976\n",
            "self.loss(score_0, v1) 0.2698549\n",
            "self.loss(score_0, v2) 0.70506394\n",
            "self.loss(score_2, v3) 0.5152813\n",
            "loss tensor(2.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.28024796\n",
            "self.loss(score_0, v1) 0.33711526\n",
            "self.loss(score_0, v2) 0.8836622\n",
            "self.loss(score_2, v3) 0.6848327\n",
            "loss tensor(2.5283, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.30125412\n",
            "self.loss(score_0, v1) 0.24259675\n",
            "self.loss(score_0, v2) 0.7136763\n",
            "self.loss(score_2, v3) 0.4809873\n",
            "loss tensor(1.9790, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3543064\n",
            "self.loss(score_0, v1) 0.400724\n",
            "self.loss(score_0, v2) 0.5387793\n",
            "self.loss(score_2, v3) 0.20916653\n",
            "loss tensor(1.6076, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.47271684\n",
            "self.loss(score_0, v1) 0.45583105\n",
            "self.loss(score_0, v2) 0.92365164\n",
            "self.loss(score_2, v3) 0.7664323\n",
            "loss tensor(3.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.29181635\n",
            "self.loss(score_0, v1) 0.29782498\n",
            "self.loss(score_0, v2) 0.8540173\n",
            "self.loss(score_2, v3) 0.52221185\n",
            "loss tensor(2.2270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13606855\n",
            "self.loss(score_0, v1) 0.25269705\n",
            "self.loss(score_0, v2) 0.6197838\n",
            "self.loss(score_2, v3) 0.3847871\n",
            "loss tensor(1.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3074919\n",
            "self.loss(score_0, v1) 0.31423104\n",
            "self.loss(score_0, v2) 0.8179796\n",
            "self.loss(score_2, v3) 0.4321039\n",
            "loss tensor(2.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22899988\n",
            "self.loss(score_0, v1) 0.3392371\n",
            "self.loss(score_0, v2) 0.87488574\n",
            "self.loss(score_2, v3) 0.6266375\n",
            "loss tensor(2.3831, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.41120028\n",
            "self.loss(score_0, v1) 0.39238122\n",
            "self.loss(score_0, v2) 0.7591026\n",
            "self.loss(score_2, v3) 0.6652098\n",
            "loss tensor(2.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.3977125812979305, Train Accuracy : 0.9960083853604829\n",
            " Validation Accuracy : 5.828850506814057\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.19261484\n",
            "self.loss(score_0, v1) 0.235339\n",
            "self.loss(score_0, v2) 0.6315527\n",
            "self.loss(score_2, v3) 0.47413284\n",
            "loss tensor(1.7707, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15755616\n",
            "self.loss(score_0, v1) 0.22162831\n",
            "self.loss(score_0, v2) 0.8012156\n",
            "self.loss(score_2, v3) 0.738786\n",
            "loss tensor(2.2886, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.29846135\n",
            "self.loss(score_0, v1) 0.3325009\n",
            "self.loss(score_0, v2) 0.84268796\n",
            "self.loss(score_2, v3) 0.61569107\n",
            "loss tensor(2.3972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.388978\n",
            "self.loss(score_0, v1) 0.39672542\n",
            "self.loss(score_0, v2) 0.46009022\n",
            "self.loss(score_2, v3) 0.5256266\n",
            "loss tensor(2.0342, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.27263883\n",
            "self.loss(score_0, v1) 0.26328236\n",
            "self.loss(score_0, v2) 0.69229054\n",
            "self.loss(score_2, v3) 0.5045232\n",
            "loss tensor(1.9850, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2757637\n",
            "self.loss(score_0, v1) 0.3299161\n",
            "self.loss(score_0, v2) 0.8662706\n",
            "self.loss(score_2, v3) 0.6727169\n",
            "loss tensor(2.4810, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.29593033\n",
            "self.loss(score_0, v1) 0.23619622\n",
            "self.loss(score_0, v2) 0.6994007\n",
            "self.loss(score_2, v3) 0.47022787\n",
            "loss tensor(1.9369, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.34701324\n",
            "self.loss(score_0, v1) 0.39201593\n",
            "self.loss(score_0, v2) 0.52598107\n",
            "self.loss(score_2, v3) 0.20647441\n",
            "loss tensor(1.5747, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.46520457\n",
            "self.loss(score_0, v1) 0.44474015\n",
            "self.loss(score_0, v2) 0.90538245\n",
            "self.loss(score_2, v3) 0.755613\n",
            "loss tensor(2.9487, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.28608075\n",
            "self.loss(score_0, v1) 0.28877726\n",
            "self.loss(score_0, v2) 0.83794844\n",
            "self.loss(score_2, v3) 0.51038593\n",
            "loss tensor(2.1784, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.13268046\n",
            "self.loss(score_0, v1) 0.24547625\n",
            "self.loss(score_0, v2) 0.6067682\n",
            "self.loss(score_2, v3) 0.3752042\n",
            "loss tensor(1.5477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.30270183\n",
            "self.loss(score_0, v1) 0.30573627\n",
            "self.loss(score_0, v2) 0.8080009\n",
            "self.loss(score_2, v3) 0.4221401\n",
            "loss tensor(2.0496, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22538884\n",
            "self.loss(score_0, v1) 0.33074272\n",
            "self.loss(score_0, v2) 0.86008763\n",
            "self.loss(score_2, v3) 0.6129223\n",
            "loss tensor(2.3356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.40453935\n",
            "self.loss(score_0, v1) 0.3843329\n",
            "self.loss(score_0, v2) 0.74689096\n",
            "self.loss(score_2, v3) 0.6522124\n",
            "loss tensor(2.5141, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.368279283537584, Train Accuracy : 0.9961304650139929\n",
            " Validation Accuracy : 5.829476877895635\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n",
            "self.loss(score_0, v0) 0.18888998\n",
            "self.loss(score_0, v1) 0.22968647\n",
            "self.loss(score_0, v2) 0.6202693\n",
            "self.loss(score_2, v3) 0.46296304\n",
            "loss tensor(1.7333, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.15496333\n",
            "self.loss(score_0, v1) 0.21622588\n",
            "self.loss(score_0, v2) 0.7852578\n",
            "self.loss(score_2, v3) 0.72347933\n",
            "loss tensor(2.2417, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.29408488\n",
            "self.loss(score_0, v1) 0.32590145\n",
            "self.loss(score_0, v2) 0.8292245\n",
            "self.loss(score_2, v3) 0.6033997\n",
            "loss tensor(2.3543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.38477996\n",
            "self.loss(score_0, v1) 0.38749087\n",
            "self.loss(score_0, v2) 0.4508089\n",
            "self.loss(score_2, v3) 0.51383066\n",
            "loss tensor(1.9938, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.26776576\n",
            "self.loss(score_0, v1) 0.25704432\n",
            "self.loss(score_0, v2) 0.6798727\n",
            "self.loss(score_2, v3) 0.49383116\n",
            "loss tensor(1.9454, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.27140915\n",
            "self.loss(score_0, v1) 0.32314792\n",
            "self.loss(score_0, v2) 0.84951943\n",
            "self.loss(score_2, v3) 0.66035575\n",
            "loss tensor(2.4346, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.29063684\n",
            "self.loss(score_0, v1) 0.23007129\n",
            "self.loss(score_0, v2) 0.6854802\n",
            "self.loss(score_2, v3) 0.45967185\n",
            "loss tensor(1.8957, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3399347\n",
            "self.loss(score_0, v1) 0.38390565\n",
            "self.loss(score_0, v2) 0.5135785\n",
            "self.loss(score_2, v3) 0.20377012\n",
            "loss tensor(1.5431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.45799854\n",
            "self.loss(score_0, v1) 0.43459827\n",
            "self.loss(score_0, v2) 0.88788766\n",
            "self.loss(score_2, v3) 0.74475443\n",
            "loss tensor(2.8976, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2805665\n",
            "self.loss(score_0, v1) 0.28015026\n",
            "self.loss(score_0, v2) 0.8219528\n",
            "self.loss(score_2, v3) 0.4989167\n",
            "loss tensor(2.1310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.12940547\n",
            "self.loss(score_0, v1) 0.23856089\n",
            "self.loss(score_0, v2) 0.59372354\n",
            "self.loss(score_2, v3) 0.36595607\n",
            "loss tensor(1.5106, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.2979682\n",
            "self.loss(score_0, v1) 0.2977018\n",
            "self.loss(score_0, v2) 0.79767877\n",
            "self.loss(score_2, v3) 0.41249955\n",
            "loss tensor(2.0121, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.22195296\n",
            "self.loss(score_0, v1) 0.32254806\n",
            "self.loss(score_0, v2) 0.84516376\n",
            "self.loss(score_2, v3) 0.5993984\n",
            "loss tensor(2.2888, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "self.loss(score_0, v0) 0.3980007\n",
            "self.loss(score_0, v1) 0.37663332\n",
            "self.loss(score_0, v2) 0.73482966\n",
            "self.loss(score_2, v3) 0.6393592\n",
            "loss tensor(2.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Train Loss: 1.3395496422753614, Train Accuracy : 0.996243977245859\n",
            " Validation Accuracy : 5.830021126788881\n",
            "Adjusting learning rate of group 0 to 1.0000e-06.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_0,'-o')\n",
        "plt.plot(loss_1,'-o')\n",
        "plt.plot(loss_2,'-o')\n",
        "plt.plot(loss_3,'-o')\n",
        "plt.xlabel('sample')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['loss 0','loss 1','loss 2','loss 3'])\n",
        "plt.title('loss vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UPfmfthBjSZw",
        "outputId": "7e4f8843-14f9-4975-e286-a2f3a1c85f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy evalutaion F-scores"
      ],
      "metadata": {
        "id": "sJbWsH72N2Mb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. create folder with part object of all pieces \n",
        "2. load a piece from dataloader with true labels, the mixed piece and the part object \n",
        "3. create notearray from part object\n",
        "4. take 1 note from notearrray - input -> find corresponding frame by looking at time and pitch\n",
        "\n",
        "\n",
        "Output: pianoroll\n",
        "\n",
        "1 note in notearray could be mulitple bins\n",
        "\n",
        "take 1 note from notearrray - input -> find corresponding frame by looking at time and pitch\n",
        "\n",
        "note start at same time with different pitch -> different notes\n",
        "\n",
        "for each note array find corresponding matrix -> \n",
        "\n",
        "\n",
        "if note is only composed by 1 bin: save indx of vocie -> save it to note array\n",
        "\n",
        "if more than 1: look what are idx that compose this note -> majority note -> save it for the note array (if its 50/50 take it random -> count how often this happens) \n",
        "\n",
        "\n",
        "with idx : in note_array find which note corresponds to what voice"
      ],
      "metadata": {
        "id": "CFClch37N6nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MusicDataset_new(PATH_TO_DATA) #MusicDataset(PATH_TO_DATA)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=False, num_workers=workers, drop_last=True)\n",
        "\n",
        "val_dataloader "
      ],
      "metadata": {
        "id": "afYHFVNMlMnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e00f57be-945b-43cb-b8cd-e6c3117eaf45"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fe15838b7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim = 88\n",
        "model = MusicNetwork(network_type, output_dim, hidden_dim, rnn_depth, cell_type)  \n",
        "checkpoint = torch.load(\"./AI-MA_project/model_temp_epoch20.pkl\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "4TAhTQcpmx8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create dic with key:filename, val: part_obj"
      ],
      "metadata": {
        "id": "5RVmMv6Q9CJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_parts = \"AI-MA_project/bach_fugues\"\n",
        "part_dic = {}\n",
        "\n",
        "#### create a list with all filenames in the right order ####\n",
        "file_names_part = []\n",
        "for filename in sorted(os.listdir(path_parts)):\n",
        "    if not filename.endswith('.mid'): continue\n",
        "    file_names_part.append(filename[3:7])\n",
        "#print(file_names_part)\n",
        "\n",
        "#### create a list with all part objects in the right order ####\n",
        "part_list = []\n",
        "for filename in sorted(os.listdir(path_parts)):\n",
        "    if not filename.endswith('.mid'): continue\n",
        "    fullname = os.path.join(path_parts, filename)\n",
        "    part = partitura.load_score_midi(fullname)\n",
        "    part_list.append(part)\n",
        "#print(part_list)\n",
        "\n",
        "#### create a dict with keys:filenames , values: part object ####\n",
        "for i in range(len(file_names_part)):\n",
        "      part_dic[file_names_part[i]] = part_list[i]"
      ],
      "metadata": {
        "id": "_XYM_KWu2qkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "part_dic.keys(),part_dic.values()"
      ],
      "metadata": {
        "id": "Tt3uHTJY9Ojj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b9e50b-6fa8-49ce-d564-39f88c354acb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict_keys(['1f01', '1f02', '1f03', '1f04', '1f05', '1f06', '1f07', '1f08', '1f09', '1f10', '1f11', '1f12', '1f13', '1f14', '1f15', '1f16', '1f17', '1f18', '1f19', '1f20', '1f21', '1f22', '1f23', '1f24', '2f01', '2f02', '2f03', '2f04', '2f05', '2f06', '2f07', '2f08', '2f09', '2f10', '2f11', '2f12', '2f13', '2f14', '2f15', '2f16', '2f17', '2f18', '2f19', '2f20', '2f21', '2f22', '2f23', '2f24']),\n",
              " dict_values([[<partitura.score.Part object at 0x7fe150a02d50>, <partitura.score.Part object at 0x7fe150991510>, <partitura.score.Part object at 0x7fe1508c8090>, <partitura.score.Part object at 0x7fe1507ff850>], [<partitura.score.Part object at 0x7fe1506df710>, <partitura.score.Part object at 0x7fe1506701d0>, <partitura.score.Part object at 0x7fe150597910>], [<partitura.score.Part object at 0x7fe150b6cf90>, <partitura.score.Part object at 0x7fe1583777d0>, <partitura.score.Part object at 0x7fe15007b510>], [<partitura.score.Part object at 0x7fe139d9a210>, <partitura.score.Part object at 0x7fe139b549d0>, <partitura.score.Part object at 0x7fe139a1e490>, <partitura.score.Part object at 0x7fe1398d6d10>, <partitura.score.Part object at 0x7fe1397fc910>], [<partitura.score.Part object at 0x7fe150424f90>, <partitura.score.Part object at 0x7fe13954fb10>, <partitura.score.Part object at 0x7fe13948c710>, <partitura.score.Part object at 0x7fe139d9eb10>], [<partitura.score.Part object at 0x7fe139e3e590>, <partitura.score.Part object at 0x7fe139399a90>, <partitura.score.Part object at 0x7fe139280410>], [<partitura.score.Part object at 0x7fe139083c10>, <partitura.score.Part object at 0x7fe1390d6110>, <partitura.score.Part object at 0x7fe138eb7090>], [<partitura.score.Part object at 0x7fe138c49b10>, <partitura.score.Part object at 0x7fe138c12c10>, <partitura.score.Part object at 0x7fe1388c4a10>], [<partitura.score.Part object at 0x7fe138c50d50>, <partitura.score.Part object at 0x7fe13867ded0>, <partitura.score.Part object at 0x7fe13855c4d0>], [<partitura.score.Part object at 0x7fe1383cb3d0>, <partitura.score.Part object at 0x7fe1382c4710>], [<partitura.score.Part object at 0x7fe15042b7d0>, <partitura.score.Part object at 0x7fe1380bedd0>, <partitura.score.Part object at 0x7fde69eca250>], [<partitura.score.Part object at 0x7fde69c99790>, <partitura.score.Part object at 0x7fde69add090>, <partitura.score.Part object at 0x7fde69ced050>, <partitura.score.Part object at 0x7fe138ccfc90>], [<partitura.score.Part object at 0x7fde69de4b10>, <partitura.score.Part object at 0x7fde697e2750>, <partitura.score.Part object at 0x7fde6960a690>], [<partitura.score.Part object at 0x7fde69c973d0>, <partitura.score.Part object at 0x7fde69442890>, <partitura.score.Part object at 0x7fde69221090>, <partitura.score.Part object at 0x7fde691727d0>], [<partitura.score.Part object at 0x7fde68d3ed10>, <partitura.score.Part object at 0x7fde68f1f590>, <partitura.score.Part object at 0x7fde68b38810>], [<partitura.score.Part object at 0x7fde68fb10d0>, <partitura.score.Part object at 0x7fde68824f50>, <partitura.score.Part object at 0x7fde686c20d0>, <partitura.score.Part object at 0x7fde6936fe50>], [<partitura.score.Part object at 0x7fde685ff1d0>, <partitura.score.Part object at 0x7fde68481550>, <partitura.score.Part object at 0x7fde6863bdd0>, <partitura.score.Part object at 0x7fde68356490>], [<partitura.score.Part object at 0x7fde68589e50>, <partitura.score.Part object at 0x7fde680e3090>, <partitura.score.Part object at 0x7fde681dd090>, <partitura.score.Part object at 0x7fde67fa7950>], [<partitura.score.Part object at 0x7fde69d82410>, <partitura.score.Part object at 0x7fde69066990>, <partitura.score.Part object at 0x7fde67b4dbd0>], [<partitura.score.Part object at 0x7fde6785e1d0>, <partitura.score.Part object at 0x7fde67742410>, <partitura.score.Part object at 0x7fde6737e050>, <partitura.score.Part object at 0x7fde686c2050>], [<partitura.score.Part object at 0x7fde6793ac50>, <partitura.score.Part object at 0x7fde678e5750>, <partitura.score.Part object at 0x7fde66db5090>], [<partitura.score.Part object at 0x7fde66bfffd0>, <partitura.score.Part object at 0x7fde66aee390>, <partitura.score.Part object at 0x7fde66b33a50>, <partitura.score.Part object at 0x7fde669e5c10>, <partitura.score.Part object at 0x7fde66912e50>], [<partitura.score.Part object at 0x7fde667c0790>, <partitura.score.Part object at 0x7fde666d1f90>, <partitura.score.Part object at 0x7fde666bbad0>, <partitura.score.Part object at 0x7fde665968d0>], [<partitura.score.Part object at 0x7fde6787e550>, <partitura.score.Part object at 0x7fde66356050>, <partitura.score.Part object at 0x7fde65f5e0d0>, <partitura.score.Part object at 0x7fde65d50550>], [<partitura.score.Part object at 0x7fde66445fd0>, <partitura.score.Part object at 0x7fde66452390>, <partitura.score.Part object at 0x7fde6594c450>], [<partitura.score.Part object at 0x7fde667abf90>, <partitura.score.Part object at 0x7fde65755890>, <partitura.score.Part object at 0x7fde656f7cd0>, <partitura.score.Part object at 0x7fde6562e1d0>], [<partitura.score.Part object at 0x7fde685fca90>, <partitura.score.Part object at 0x7fde66bc6610>, <partitura.score.Part object at 0x7fde66ba80d0>], [<partitura.score.Part object at 0x7fde65105910>, <partitura.score.Part object at 0x7fde64f66210>, <partitura.score.Part object at 0x7fde64dc4b90>], [<partitura.score.Part object at 0x7fde655b6a90>, <partitura.score.Part object at 0x7fde64a23a10>, <partitura.score.Part object at 0x7fde649b40d0>, <partitura.score.Part object at 0x7fde648b5090>], [<partitura.score.Part object at 0x7fde655be690>, <partitura.score.Part object at 0x7fde646ad410>, <partitura.score.Part object at 0x7fde6454f750>], [<partitura.score.Part object at 0x7fde64384ad0>, <partitura.score.Part object at 0x7fde64366050>, <partitura.score.Part object at 0x7fde64286b90>, <partitura.score.Part object at 0x7fde641e9a50>], [<partitura.score.Part object at 0x7fde63f85e50>, <partitura.score.Part object at 0x7fde6404ea50>, <partitura.score.Part object at 0x7fde63e6f990>, <partitura.score.Part object at 0x7fde63d2b050>], [<partitura.score.Part object at 0x7fde655ac5d0>, <partitura.score.Part object at 0x7fde63a56b10>, <partitura.score.Part object at 0x7fde664429d0>, <partitura.score.Part object at 0x7fde64ac6310>], [<partitura.score.Part object at 0x7fde63ebbc50>, <partitura.score.Part object at 0x7fde6349ac90>, <partitura.score.Part object at 0x7fde632a7610>], [<partitura.score.Part object at 0x7fde62f429d0>, <partitura.score.Part object at 0x7fde62e1e910>, <partitura.score.Part object at 0x7fde62d4b590>], [<partitura.score.Part object at 0x7fde62aeffd0>, <partitura.score.Part object at 0x7fde629c2350>, <partitura.score.Part object at 0x7fde6287b590>], [<partitura.score.Part object at 0x7fde6396a6d0>, <partitura.score.Part object at 0x7fde624c5a90>, <partitura.score.Part object at 0x7fde6239fc90>], [<partitura.score.Part object at 0x7fde6263b290>, <partitura.score.Part object at 0x7fde61fef5d0>, <partitura.score.Part object at 0x7fde61d87690>], [<partitura.score.Part object at 0x7fde655bbc10>, <partitura.score.Part object at 0x7fde61ddbfd0>, <partitura.score.Part object at 0x7fde6195bcd0>], [<partitura.score.Part object at 0x7fde637466d0>, <partitura.score.Part object at 0x7fde62b07090>, <partitura.score.Part object at 0x7fde638678d0>, <partitura.score.Part object at 0x7fde6148ec90>], [<partitura.score.Part object at 0x7fde612457d0>, <partitura.score.Part object at 0x7fde6106e190>, <partitura.score.Part object at 0x7fde60f75150>, <partitura.score.Part object at 0x7fde60e3b850>], [<partitura.score.Part object at 0x7fde60b81b90>, <partitura.score.Part object at 0x7fde60be9dd0>, <partitura.score.Part object at 0x7fde606985d0>], [<partitura.score.Part object at 0x7fde61b3e590>, <partitura.score.Part object at 0x7fde602ee710>, <partitura.score.Part object at 0x7fde6025e510>], [<partitura.score.Part object at 0x7fde60054b10>, <partitura.score.Part object at 0x7fde5ff4b150>, <partitura.score.Part object at 0x7fde600227d0>], [<partitura.score.Part object at 0x7fde5fcc4d50>, <partitura.score.Part object at 0x7fde5fd21fd0>, <partitura.score.Part object at 0x7fde5fac9090>], [<partitura.score.Part object at 0x7fde5f5bc590>, <partitura.score.Part object at 0x7fde5f51d450>, <partitura.score.Part object at 0x7fde5f318c50>, <partitura.score.Part object at 0x7fde5f16e850>], [<partitura.score.Part object at 0x7fde5fdfae10>, <partitura.score.Part object at 0x7fde5ede8fd0>, <partitura.score.Part object at 0x7fde5f688b10>, <partitura.score.Part object at 0x7fde60b52fd0>], [<partitura.score.Part object at 0x7fde5ec34650>, <partitura.score.Part object at 0x7fde5eb46790>, <partitura.score.Part object at 0x7fde5ea19190>]]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "geht gerade nur für monophonic True"
      ],
      "metadata": {
        "id": "v4TJGKiUs086"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import statistics\n",
        "\n",
        "\n",
        "def evaluate_accuracy_for_all(model, train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match\n",
        "                                      \n",
        "            \n",
        "            #if idx == 0 or idx==2:\n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "\n",
        "\n",
        "                if len(part)== 4:\n",
        "                    part_3 = part[3]\n",
        "                    note_array_3 = part_3.note_array\n",
        "\n",
        "                    note_counter_3 += len(note_array_3)\n",
        "\n",
        "                    list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "                    ground_truth_label_list = [0,1,2,3]              \n",
        "                    total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                    total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                    accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                \n",
        "                if len(part)== 3:\n",
        "                    list_of_note_arrays = [note_array_0,note_array_1,note_array_2]\n",
        "                    ground_truth_label_list = [0,1,2]\n",
        "                    total_predictions_dict = {'0': [], '1': [], '2': [] }\n",
        "                    total_truth_dict = {'0': [], '1': [], '2': [] }\n",
        "                    accordance_dict = {'0': [], '1': [], '2': []}\n",
        "\n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):\n",
        "                    onset_beat = note_array[\"onset_beat\"]\n",
        "                    duration_beat = note_array[\"duration_beat\"]\n",
        "                    pitch_list = note_array[\"pitch\"]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "\n",
        "                               \n",
        "                    # do model prediction\n",
        "                    model.eval()\n",
        "                    voices = voices.to(device).float()\n",
        "                    monophonic=True\n",
        "                    with torch.no_grad():\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        label = ground_truth_label_list[el_note_arr]\n",
        "\n",
        "                \n",
        "                    for i in range(len(note_idx_start)):\n",
        "\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "                        \n",
        "                        if i < len(note_idx_start)-1:\n",
        "                            start_second = note_idx_start[i+1]\n",
        "                            end_second =  note_idx_end[i+1]\n",
        "                            pitch_second = pitch_list[i+1]\n",
        "                            pred_list_second = prediction[start_second:end_second,pitch_second]\n",
        "\n",
        "\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "\n",
        "                        result_second = all(elem == pred_list_second[0] for elem in pred_list_second)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result_second == False:\n",
        "                            major_, major_idx = torch.mode(pred_list_second,0)\n",
        "                            major_ = major_.numpy().tolist()\n",
        "                            pred_list_second = [major_ for i in pred_list_second]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "\n",
        "                            \n",
        "\n",
        "                        if F1 == True:\n",
        "                            if pred_list_first[0] == pred_list_second[0]:   #the list might have diff lenghts as diff notes have diff lengths, so is ito oke to just take first elemet\n",
        "                                accordance_dict[str(label)].append(1)\n",
        "                            else:\n",
        "                                accordance_dict[str(label)].append(0)\n",
        "\n",
        "                if F1 == False:\n",
        "                    count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "                    for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                      counting = 0\n",
        "                      for j in range(len(total_predictions_dict[i])):\n",
        "                          if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                      count_dict_2[i].append(counting)\n",
        "\n",
        "                    acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                    acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                    acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "\n",
        "                    print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                    print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                    print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "\n",
        "                    if len(total_predictions_dict.keys())==4:\n",
        "                        acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "                        print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "                        acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "                    acc_score_dict[\"0\"].append(acc_0)\n",
        "                    acc_score_dict[\"1\"].append(acc_1)\n",
        "                    acc_score_dict[\"2\"].append(acc_2)\n",
        "\n",
        "                if F1 == True:\n",
        "                    pred_0 = accordance_dict[\"0\"]\n",
        "                    pred_1 = accordance_dict[\"1\"]\n",
        "                    pred_2 = accordance_dict[\"2\"]                   \n",
        "                    truth_0 = [1 for i in range(len(accordance_dict[\"0\"]))]\n",
        "                    truth_1 = [1 for i in range(len(accordance_dict[\"1\"]))]\n",
        "                    truth_2 = [1 for i in range(len(accordance_dict[\"2\"]))]                  \n",
        "                    f1_v0 = sklearn.metrics.f1_score(truth_0, pred_0)\n",
        "                    f1_v1 = sklearn.metrics.f1_score(truth_1, pred_1)\n",
        "                    f1_v2 = sklearn.metrics.f1_score(truth_2, pred_2)                \n",
        "                    f_score_dict[\"0\"].append(f1_v0)\n",
        "                    f_score_dict[\"1\"].append(f1_v1)\n",
        "                    f_score_dict[\"2\"].append(f1_v2)\n",
        "                    if len(part)==4:\n",
        "                      pred_3 = accordance_dict[\"3\"]\n",
        "                      truth_3 = [1 for i in range(len(accordance_dict[\"3\"]))]\n",
        "                      f1_v3 = sklearn.metrics.f1_score(truth_3, pred_3)\n",
        "                      f_score_dict[\"3\"].append(f1_v3)\n",
        "    \n",
        "    if F1 == True:\n",
        "        return statistics.mean(f_score_dict[\"0\"]), statistics.mean(f_score_dict[\"1\"]), statistics.mean(f_score_dict[\"2\"]),statistics.mean(f_score_dict[\"3\"])\n",
        "    \n",
        "    if F1 == False:\n",
        "        print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "        print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "        return total_predictions_dict, total_truth_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])\n",
        "        #return total_predictions_dict, total_truth_dict"
      ],
      "metadata": {
        "id": "RWxVG3XAYTcC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lower version trys to only intitialize dicts once not for every nbr of voices often"
      ],
      "metadata": {
        "id": "vAmMZksrnG8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import statistics\n",
        "\n",
        "\n",
        "def evaluate_accuracy_for_all(model, train_dataloader, part_dic,F1):\n",
        "    #print(\"part_dic:\",part_dic)\n",
        "\n",
        "    f_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    acc_score_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "    note_counter_0 = 0\n",
        "    note_counter_1 = 0\n",
        "    note_counter_2 = 0\n",
        "    note_counter_3 = 0\n",
        "    for idx, (voices, lens, nbr_voices, file_name) in enumerate(train_dataloader):\n",
        "            #check if elements match\n",
        "                                      \n",
        "            \n",
        "            #if idx == 0 or idx==2:\n",
        "                if nbr_voices[0]!=len(part_dic[file_name[0]]):\n",
        "                  print(\"ERROR: nbr_voices from part DOES NOT MATCH data loader:\" ) \n",
        "                \n",
        "                # load correct part object\n",
        "                file_name = file_name[0]\n",
        "                part = part_dic[file_name]\n",
        "                part_0 = part[0]\n",
        "                note_array_0 = part_0.note_array\n",
        "                part_1 = part[1]\n",
        "                note_array_1 = part_1.note_array\n",
        "                part_2 = part[2]\n",
        "                note_array_2 = part_2.note_array\n",
        "\n",
        "                note_counter_0 += len(note_array_0)\n",
        "                note_counter_1 += len(note_array_1)\n",
        "                note_counter_2 += len(note_array_2)\n",
        "\n",
        "                list_of_note_arrays = [note_array_0,note_array_1,note_array_2]\n",
        "\n",
        "                if len(part)== 4:\n",
        "                    part_3 = part[3]\n",
        "                    note_array_3 = part_3.note_array\n",
        "                    note_counter_3 += len(note_array_3)\n",
        "                    list_of_note_arrays = [note_array_0,note_array_1,note_array_2,note_array_3]\n",
        "\n",
        "                   \n",
        "                \n",
        "                ground_truth_label_list = [0,1,2,3]              \n",
        "                total_predictions_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                total_truth_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                accordance_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "            \n",
        "\n",
        "                for el_note_arr, note_array in enumerate(list_of_note_arrays):\n",
        "                    onset_beat = note_array[\"onset_beat\"]\n",
        "                    duration_beat = note_array[\"duration_beat\"]\n",
        "                    pitch_list = note_array[\"pitch\"]\n",
        "                    pitch_list = pitch_list - 21             \n",
        "                    note_idx_start = 12 * onset_beat\n",
        "                    note_idx_end = 12 * (onset_beat+duration_beat)\n",
        "\n",
        "                    ### round every entry up to next integer for the starting idx ###\n",
        "                    note_idx_start = [int(np.ceil(num)) for num in note_idx_start]                      # do this fur whole np array np.ceil(note_idx_start)\n",
        "                    ### round every entry down to next integer for the ending idx###\n",
        "                    note_idx_end = [int(np.floor(num)) for num in note_idx_end]\n",
        "\n",
        "                               \n",
        "                    # do model prediction\n",
        "                    model.eval()\n",
        "                    voices = voices.to(device).float()\n",
        "                    monophonic=True\n",
        "                    with torch.no_grad():\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        label = ground_truth_label_list[el_note_arr]\n",
        "\n",
        "                \n",
        "                    for i in range(len(note_idx_start)):\n",
        "\n",
        "                        start_first = note_idx_start[i]\n",
        "                        end_first =  note_idx_end[i]\n",
        "                        pitch_first = pitch_list[i]\n",
        "                        pred_list_first = prediction[start_first:end_first,pitch_first]\n",
        "                        \n",
        "                        if i < len(note_idx_start)-1:\n",
        "                            start_second = note_idx_start[i+1]\n",
        "                            end_second =  note_idx_end[i+1]\n",
        "                            pitch_second = pitch_list[i+1]\n",
        "                            pred_list_second = prediction[start_second:end_second,pitch_second]\n",
        "\n",
        "\n",
        "                        truth_list = [label for i in range(len(pred_list_first))]\n",
        "\n",
        "                    \n",
        "                        result = all(elem == pred_list_first[0] for elem in pred_list_first)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result == False:\n",
        "                            major, major_idx = torch.mode(pred_list_first,0)\n",
        "                            major = major.numpy().tolist()\n",
        "                            pred_list_first = [major for i in pred_list_first]\n",
        "\n",
        "                        result_second = all(elem == pred_list_second[0] for elem in pred_list_second)\n",
        "                        # do majority vote if not all predictions are for same voice\n",
        "                        if result_second == False:\n",
        "                            major_, major_idx = torch.mode(pred_list_second,0)\n",
        "                            major_ = major_.numpy().tolist()\n",
        "                            pred_list_second = [major_ for i in pred_list_second]\n",
        "                        \n",
        "                        total_predictions_dict[str(label)].append(pred_list_first)\n",
        "                        total_truth_dict[str(label)].append(truth_list)\n",
        "\n",
        "                            \n",
        "                        if F1 == True:\n",
        "                            if pred_list_first[0] == pred_list_second[0]:   #the list might have diff lenghts as diff notes have diff lengths, so is ito oke to just take first elemet\n",
        "                                accordance_dict[str(label)].append(1)\n",
        "                            else:\n",
        "                                accordance_dict[str(label)].append(0)\n",
        "\n",
        "                if F1 == False:\n",
        "                    count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "                    print(\"total_predictions_dict.keys())\",total_predictions_dict.keys())\n",
        "\n",
        "                    for gt, i in enumerate(total_predictions_dict.keys()):\n",
        "                      counting = 0\n",
        "                      for j in range(len(total_predictions_dict[i])):\n",
        "                          if total_predictions_dict[i][j][0] == gt:\n",
        "                            counting +=1  \n",
        "                      count_dict_2[i].append(counting)\n",
        "\n",
        "                    acc_0 = count_dict_2[\"0\"][0]/len(total_predictions_dict[\"0\"])\n",
        "                    acc_1 = count_dict_2[\"1\"][0]/len(total_predictions_dict[\"1\"])\n",
        "                    acc_2 = count_dict_2[\"2\"][0]/len(total_predictions_dict[\"2\"])\n",
        "\n",
        "                    print(\"acc 0, sample {}:\".format(idx),acc_0)\n",
        "                    print(\"acc 1, sample {}:\".format(idx),acc_1)\n",
        "                    print(\"acc 2, sample {}:\".format(idx),acc_2)\n",
        "\n",
        "                    if len(list_of_note_arrays)==4:\n",
        "                        acc_3 = count_dict_2[\"3\"][0]/len(total_predictions_dict[\"3\"])\n",
        "                        print(\"acc 3, sample {}:\".format(idx),acc_3)\n",
        "                        acc_score_dict[\"3\"].append(acc_3)\n",
        "\n",
        "\n",
        "                    acc_score_dict[\"0\"].append(acc_0)\n",
        "                    acc_score_dict[\"1\"].append(acc_1)\n",
        "                    acc_score_dict[\"2\"].append(acc_2)\n",
        "\n",
        "                if F1 == True:\n",
        "                    pred_0 = accordance_dict[\"0\"]\n",
        "                    pred_1 = accordance_dict[\"1\"]\n",
        "                    pred_2 = accordance_dict[\"2\"]                   \n",
        "                    truth_0 = [1 for i in range(len(accordance_dict[\"0\"]))]\n",
        "                    truth_1 = [1 for i in range(len(accordance_dict[\"1\"]))]\n",
        "                    truth_2 = [1 for i in range(len(accordance_dict[\"2\"]))]                  \n",
        "                    f1_v0 = sklearn.metrics.f1_score(truth_0, pred_0)\n",
        "                    f1_v1 = sklearn.metrics.f1_score(truth_1, pred_1)\n",
        "                    f1_v2 = sklearn.metrics.f1_score(truth_2, pred_2)                \n",
        "                    f_score_dict[\"0\"].append(f1_v0)\n",
        "                    f_score_dict[\"1\"].append(f1_v1)\n",
        "                    f_score_dict[\"2\"].append(f1_v2)\n",
        "                    if len(part)==4:\n",
        "                      pred_3 = accordance_dict[\"3\"]\n",
        "                      truth_3 = [1 for i in range(len(accordance_dict[\"3\"]))]\n",
        "                      f1_v3 = sklearn.metrics.f1_score(truth_3, pred_3)\n",
        "                      f_score_dict[\"3\"].append(f1_v3)\n",
        "    \n",
        "    if F1 == True:\n",
        "        return statistics.mean(f_score_dict[\"0\"]), statistics.mean(f_score_dict[\"1\"]), statistics.mean(f_score_dict[\"2\"]),statistics.mean(f_score_dict[\"3\"])\n",
        "    \n",
        "    if F1 == False:\n",
        "        print(\"note counters:\",\"v0:\",note_counter_0,\"v1:\",note_counter_1,\"v2:\",note_counter_2,\"v3:\",note_counter_3)\n",
        "        print(\"total_predictions_dict\",total_predictions_dict.keys())\n",
        "        return total_predictions_dict, total_truth_dict, statistics.mean(acc_score_dict[\"0\"]), statistics.mean(acc_score_dict[\"1\"]), statistics.mean(acc_score_dict[\"2\"]),statistics.mean(acc_score_dict[\"3\"])\n",
        "        #return total_predictions_dict, total_truth_dict"
      ],
      "metadata": {
        "id": "0xbN5YU8nGT0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pred , dict_gt, acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_all(model,val_dataloader,part_dic,F1=False)\n",
        "acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "id": "20MP5Gk5kc2X",
        "outputId": "a31ddd65-dc5e-4682-ad2c-05d86a16094d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_predictions_dict.keys()) dict_keys(['0', '1', '2', '3'])\n",
            "acc 0, sample 0: 0.8554502369668247\n",
            "acc 1, sample 0: 0.8565121412803532\n",
            "acc 2, sample 0: 0.9561904761904761\n",
            "total_predictions_dict.keys()) dict_keys(['0', '1', '2', '3'])\n",
            "acc 0, sample 1: 0.9428571428571428\n",
            "acc 1, sample 1: 0.9214659685863874\n",
            "acc 2, sample 1: 0.6877637130801688\n",
            "acc 3, sample 1: 0.07509881422924901\n",
            "total_predictions_dict.keys()) dict_keys(['0', '1', '2', '3'])\n",
            "acc 0, sample 2: 0.8860294117647058\n",
            "acc 1, sample 2: 0.711943793911007\n",
            "acc 2, sample 2: 0.625\n",
            "acc 3, sample 2: 0.1196808510638298\n",
            "total_predictions_dict.keys()) dict_keys(['0', '1', '2', '3'])\n",
            "acc 0, sample 3: 0.8401639344262295\n",
            "acc 1, sample 3: 0.8429752066115702\n",
            "acc 2, sample 3: 0.55\n",
            "acc 3, sample 3: 0.09454545454545454\n",
            "total_predictions_dict.keys()) dict_keys(['0', '1', '2', '3'])\n",
            "acc 0, sample 4: 0.8316831683168316\n",
            "acc 1, sample 4: 0.782608695652174\n",
            "acc 2, sample 4: 0.9212598425196851\n",
            "total_predictions_dict.keys()) dict_keys(['0', '1', '2', '3'])\n",
            "acc 0, sample 5: 0.8981132075471698\n",
            "acc 1, sample 5: 0.7754318618042226\n",
            "acc 2, sample 5: 0.6047058823529412\n",
            "acc 3, sample 5: 0.0718562874251497\n",
            "total_predictions_dict.keys()) dict_keys(['0', '1', '2', '3'])\n",
            "acc 0, sample 6: 0.8504983388704319\n",
            "acc 1, sample 6: 0.9327731092436975\n",
            "acc 2, sample 6: 0.9493333333333334\n",
            "note counters: v0: 2282 v1: 2323 v2: 2236 v3: 1238\n",
            "total_predictions_dict dict_keys(['0', '1', '2', '3'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8721136343927623,\n",
              " 0.8319586824413445,\n",
              " 0.7563218924966578,\n",
              " 0.09029535181592076)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 30 epoch, no loss modifier:\n",
        "#ACC:(0.9165209182020722,\n",
        "# 0.7864434689151618,\n",
        "# 0.8130949796045199,\n",
        "# 0.003652274754166715)\n",
        "\n",
        "# 20 epoch, no loss modifier:\n",
        "#(0.7962210840410273, 0.8669639629052727, 0.751302181991106, 0.0)\n",
        "\n",
        "# 20 ep, loss3 *1,5\n",
        "#(0.8721136343927623,\n",
        " 0.8319586824413445,\n",
        " 0.7563218924966578,\n",
        " 0.09029535181592076)"
      ],
      "metadata": {
        "id": "6mCYnJLnHfYB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_all(model,train_dataloader,part_dic,F1=False)\n",
        "dict_pred , dict_gt, acc_0 , acc_1, acc_2, acc_3 = evaluate_accuracy_for_all(model,val_dataloader,part_dic,F1=False)\n",
        "acc_0 , acc_1, acc_2, acc_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygMV28FhKVAW",
        "outputId": "01cea9a3-357a-4c48-c20d-580c28abefb4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc 0, sample 0: 0.8554502369668247\n",
            "acc 1, sample 0: 0.8565121412803532\n",
            "acc 2, sample 0: 0.9561904761904761\n",
            "acc 0, sample 1: 0.9428571428571428\n",
            "acc 1, sample 1: 0.9214659685863874\n",
            "acc 2, sample 1: 0.6877637130801688\n",
            "acc 3, sample 1: 0.07509881422924901\n",
            "acc 0, sample 3: 0.8401639344262295\n",
            "acc 1, sample 3: 0.8429752066115702\n",
            "acc 2, sample 3: 0.55\n",
            "acc 3, sample 3: 0.09454545454545454\n",
            "acc 0, sample 4: 0.8316831683168316\n",
            "acc 1, sample 4: 0.782608695652174\n",
            "acc 2, sample 4: 0.9212598425196851\n",
            "acc 0, sample 5: 0.8981132075471698\n",
            "acc 1, sample 5: 0.7754318618042226\n",
            "acc 2, sample 5: 0.6047058823529412\n",
            "acc 3, sample 5: 0.0718562874251497\n",
            "acc 0, sample 6: 0.8504983388704319\n",
            "acc 1, sample 6: 0.9327731092436975\n",
            "acc 2, sample 6: 0.9493333333333334\n",
            "note counters: v0: 2282 v1: 2323 v2: 2236 v3: 1238\n",
            "total_predictions_dict dict_keys(['0', '1', '2', '3'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8721136343927623,\n",
              " 0.8319586824413445,\n",
              " 0.7563218924966578,\n",
              " 0.09029535181592076)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_v0, f1_v1, f1_v2, f1_v3 = evaluate_accuracy_for_all(model,val_dataloader,part_dic,F1=True)\n",
        "print(f1_v0, f1_v1, f1_v2, f1_v3)"
      ],
      "metadata": {
        "id": "FLLmyO6o5vW5",
        "outputId": "f5992752-1544-4e8c-9ee7-2d001ad26b30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8917759623665967 0.9053146484994993 0.9060250549534754 0.9076221235975899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_pred.keys()"
      ],
      "metadata": {
        "id": "79s64i5_lDN0",
        "outputId": "6fa86adb-7dfb-4649-f061-d8fa71b1cb1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['0', '1', '2', '3'])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_dict_2 = {'0': [], '1': [], '2': [], '3': [] }\n",
        "\n",
        "for gt, i in enumerate(dict_pred.keys()):\n",
        "  counting = 0\n",
        "  for j in range(len(dict_pred[i])):\n",
        "      if dict_pred[i][j][0] == gt:\n",
        "        print(dict_pred[i][j],dict_gt[i][j])\n",
        "        counting +=1\n",
        "\n",
        "      \n",
        "  count_dict_2[i].append(counting)\n",
        "\n",
        "print(count_dict_2[\"0\"],count_dict_2[\"1\"],count_dict_2[\"2\"],count_dict_2[\"3\"])\n",
        "\n",
        "if len(dict_pred.keys())==4:\n",
        "    print(\"accuracy:\",count_dict_2[\"0\"][0]/len(dict_pred[\"0\"]),count_dict_2[\"1\"][0]/len(dict_pred[\"1\"]),count_dict_2[\"2\"][0]/len(dict_pred[\"2\"]),count_dict_2[\"3\"][0]/len(dict_pred[\"3\"]))\n",
        "\n",
        "if len(dict_pred.keys())==3:\n",
        "    print(\"accuracy:\",count_dict_2[\"0\"][0]/len(dict_pred[\"0\"]),count_dict_2[\"1\"][0]/len(dict_pred[\"1\"]),count_dict_2[\"2\"][0]/len(dict_pred[\"2\"]))"
      ],
      "metadata": {
        "id": "VYBpV_hMfGGY",
        "outputId": "fef7999c-5382-485c-c06c-a399fc39250b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "[0, 0, 0] [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0]) [0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0]\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1] [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "[1, 1, 1, 1, 1, 1] [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "[1, 1, 1] [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[1, 1, 1] [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "[1, 1, 1] [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "[1, 1, 1] [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1]) [1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1, 1] [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1, 1] [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1, 1] [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2, 2, 2, 2] [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "[2, 2, 2, 2, 2, 2] [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2] [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "tensor([2, 2, 2]) [2, 2, 2]\n",
            "[2, 2, 2, 2, 2, 2] [2, 2, 2, 2, 2, 2]\n",
            "[2, 2, 2, 2, 2, 2] [2, 2, 2, 2, 2, 2]\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "[256] [333] [356] [0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f49c574c4ccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount_dict_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount_dict_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount_dict_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount_dict_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### take 0 -> compare to truth of 0,1,2,3 -> overall voice\n",
        "\n",
        "count_list = []\n",
        "\n",
        "count_dict = {'0': [], '1': [], '2': [], '3': [] }\n",
        "truth_dic = {'0': 0, '1': 1, '2': 2, '3': 3 }\n",
        "\n",
        "voice_entry_list = [\"0\", \"1\", \"2\", \"3\"]\n",
        "for voice_entry_one in voice_entry_list:\n",
        "    for voice_entry_two in voice_entry_list:\n",
        "        count_list = []\n",
        "        #print(\"voices:\",voice_entry_one,voice_entry_two)\n",
        "        for i in range(len(dict_pred[voice_entry_one])):\n",
        "            if dict_pred[voice_entry_one][i][0] == truth_dic[voice_entry_two]:      #dict_truth[voice_entry_two][i][0]:\n",
        "                count_list.append(1)\n",
        "            else:\n",
        "                count_list.append(0)\n",
        "        count_dict[voice_entry_one].append(count_list)\n",
        "\n",
        "dictionary_sum={}\n",
        "for i in voice_entry_list:\n",
        "    v0_match,v1_match,v2_match,v3_match = count_dict[i]\n",
        "    sum_v0 = np.sum(v0_match)\n",
        "    sum_v1 = np.sum(v1_match)\n",
        "    sum_v2 = np.sum(v2_match)\n",
        "    sum_v3 = np.sum(v3_match)\n",
        "    dictionary_sum[\"v0\"] = sum_v0\n",
        "    dictionary_sum[\"v1\"] = sum_v1\n",
        "    dictionary_sum[\"v2\"] = sum_v2\n",
        "    dictionary_sum[\"v3\"] = sum_v3\n",
        "\n",
        "    val_list = list(dictionary_sum.values())\n",
        "    \n",
        "    print(\"voice{} matches with\".format(i))\n",
        "    print(\"dict\",dictionary_sum)\n",
        "\n",
        "    max_sum = max(sum_v0,sum_v1,sum_v2,sum_v3)\n",
        "\n",
        "\n",
        "    print(\"max_sum\", val_list.index(max_sum) )\n",
        "\n",
        "    print(\"accuracy voice{}:\".format(i), max_sum/(sum_v0+sum_v1+sum_v2+sum_v3) )\n",
        "    print(\"________________\")\n",
        "    print(\" \")"
      ],
      "metadata": {
        "id": "BoQcV_i038DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR MONOPHONIC F1\n",
        "\n",
        "# start with GT\n",
        "# look at first note in pred-> save note label\n",
        "# look at second note in pred-> if same note as before : SUCESS if it is not: FAIL\n",
        " # DO This for all 4 voices\n",
        " ## in GT there is always the same voice following -> would always be an array of 1\n",
        "\n",
        "## POLYPHONIC \n",
        "\n",
        "# prbl after 1 note there can be multiple diff voices .. chords\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-bR7gcej90qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "you have the ground truth on the different parts that you get when you import your score. Each part correspond to a voice. So if your note array contains all notes of all voices, you have for each note in your note array a number that is the ground truth voice (that you take from the part) and a number that is the predicted voice (that you take from the maximum vote)."
      ],
      "metadata": {
        "id": "Z5q305YzvjMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "start time, duration , pitch to separate \n",
        "\n",
        "use the onset_beat and duration_beat\n",
        "\n",
        "multiply them according to the values set when producing the pianorolls \n",
        "\n",
        "-> get the position in the pianoroll\n",
        "\n",
        "time_div = 12\n",
        "\n"
      ],
      "metadata": {
        "id": "EmvxtyaVKG27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "A94mchm4LV6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"val_accuracy_v0\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v1\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v2\"],'-o')\n",
        "plt.plot(his[\"val_accuracy_v3\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Accuracy0','Accuracy1','Accuracy2','Accuracy3'])\n",
        "plt.title('Accuracy vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1TgJDHaxAgYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"val_accuracy\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend('Accuracy')\n",
        "plt.title('Accuracy vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OxMs8GEfMvPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(his[\"train_loss\"],'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Loss'])\n",
        "plt.title('Loss vs Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqMcJT5aFL01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old training loop - matrix and non matrix format"
      ],
      "metadata": {
        "id": "4olpdwzyG8dQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def training_loop(model,optimizer, train_dataloader, monophonic, epochs=50, val_dataloader=None, device=None, scheduler=None):\n",
        "    if device is None:\n",
        "        device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "        print(f\"Training on device: {device}\")\n",
        "\n",
        "    print(\"monophonic set to:\",monophonic)\n",
        "    model = model.to(device)\n",
        "    history = defaultdict(list)\n",
        "\n",
        "    for i_epoch in range(1, epochs + 1):\n",
        "        loss_sum = 0\n",
        "        #accuracy_v0_sum = 0\n",
        "        #accuracy_v1_sum = 0\n",
        "        #accuracy_v2_sum = 0\n",
        "        #accuracy_v3_sum = 0\n",
        "\n",
        "        accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "        val_accuracy_sum_list = [0 for i in range(5)]                               ########## FIXED FOR 5 voices MAX right now - b.c. FUGUES have max 5 voices\n",
        "\n",
        "        accuracy_v_all_sum = 0\n",
        "        model.train()\n",
        "        accuracy_sum = 0\n",
        "        \n",
        "\n",
        "        for idx, (voices, lens, nbr_voices) in enumerate(train_dataloader):  \n",
        "            \n",
        "            voices = voices.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            loss = model.forward(voices, lens, nbr_voices)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_sum += loss.item()    \n",
        "\n",
        "            if monophonic == False:\n",
        "                with torch.no_grad():\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                    v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                    mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "\n",
        "                    \n",
        "                    single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                    v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                    mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                    accuracy_sum += acc \n",
        "\n",
        "                    \"\"\"\n",
        "                    if nbr_voices == 4: \n",
        "                        v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2), torch.tensor(pred_v3)], dim=2)\n",
        "                    if nbr_voices ==3:\n",
        "                        v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2)], dim=2)\n",
        "                    v_pred_argm = v_pred_comb.argmax(dim=2)\n",
        "                    mask_pred = (v_pred_comb.sum(axis=2) == 0).numpy()\n",
        "                    v_pred_argm[mask_pred] = -1\n",
        "                    v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                    print(\"v_pred_flat:\", v_pred_flat.shape)\n",
        "                    \"\"\"\n",
        "                    \"\"\"\n",
        "                    if nbr_voices == 4:                   \n",
        "                        v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu(), np.squeeze(voices[:,:,:,3]).cpu()], dim=2)\n",
        "                    if nbr_voices ==3:\n",
        "                        v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu()], dim=2)\n",
        "                    v_ori_argm = v_ori_comb.argmax(dim=2)\n",
        "                    mask_ori = (v_ori_comb.sum(axis=2) == 0).numpy()\n",
        "                    print(\"old mask\", mask_ori.shape)\n",
        "                    v_ori_argm[mask_ori] = -1\n",
        "                    v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                    print(\"v_ori_flat\", v_ori_flat.shape)\n",
        "                    acc = accuracy_score(v_pred_flat,v_ori_flat)   \n",
        "                    print(\"acc\",acc)                    \n",
        "                    accuracy_sum += acc \n",
        "                    \"\"\"\n",
        "\n",
        "\n",
        "            if monophonic == True:\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                    prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "\n",
        "                    truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "\n",
        "                    acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "\n",
        "                    for i in range(len(prediction[0,:])):\n",
        "                      acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                      accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "                    \n",
        "                    \"\"\"\n",
        "                    pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "\n",
        "                    acc_v0 = accuracy_score(torch.tensor(pred_v0), np.squeeze(voices[:,:,:,0]).argmax(dim=1).cpu())\n",
        "                    acc_v1 = accuracy_score(torch.tensor(pred_v1), np.squeeze(voices[:,:,:,1]).argmax(dim=1).cpu())\n",
        "                    acc_v2 = accuracy_score(torch.tensor(pred_v2), np.squeeze(voices[:,:,:,2]).argmax(dim=1).cpu())\n",
        "                    if nbr_voices == 4:\n",
        "                        acc_v3 = accuracy_score(torch.tensor(pred_v3), np.squeeze(voices[:,:,:,3]).argmax(dim=1).cpu())\n",
        "                    \n",
        "                    # normalize according to the number of sequences in the batch (atm len(lens)==1)\n",
        "                    accuracy_v0_sum += acc_v0 / len(lens)\n",
        "                    accuracy_v1_sum += acc_v1 / len(lens)\n",
        "                    accuracy_v2_sum += acc_v2 / len(lens)\n",
        "                    if nbr_voices == 4:\n",
        "                        accuracy_v3_sum += acc_v3 / len(lens)\n",
        "                    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        train_loss = loss_sum / len(train_dataloader)\n",
        "\n",
        "        # normalize according to the number of batches\n",
        "        if monophonic == True:\n",
        "\n",
        "            train_acc_list = np.array(accuracy_sum_list) / len(train_dataloader)\n",
        "            train_acc_list[3] = accuracy_sum_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "            train_acc_list[4] = accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_acc\"].append(train_acc_list)\n",
        "            print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}, Train Accuracy_4 : {}\".format(train_loss, train_acc_list[0], train_acc_list[1], train_acc_list[2], train_acc_list[3],train_acc_list[4])) \n",
        "\n",
        "\n",
        "            \"\"\"\n",
        "            train_accuracy_v0 = accuracy_v0_sum / len(train_dataloader)\n",
        "            train_accuracy_v1 = accuracy_v1_sum / len(train_dataloader)\n",
        "            train_accuracy_v2 = accuracy_v2_sum / len(train_dataloader)\n",
        "            train_accuracy_v3 = accuracy_v3_sum / 18   ## bc only 18 pieces with len 3\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy_v0\"].append(train_accuracy_v0)\n",
        "            history[\"train_accuracy_v1\"].append(train_accuracy_v1)\n",
        "            history[\"train_accuracy_v2\"].append(train_accuracy_v2)\n",
        "            #if nbr_voices == 4:\n",
        "            history[\"train_accuracy_v3\"].append(train_accuracy_v3)\n",
        "            print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}, Train Accuracy_3 : {}\".format(train_loss, train_accuracy_v0, train_accuracy_v1, train_accuracy_v2, train_accuracy_v3)) \n",
        "            #else:\n",
        "            #    print(\"Train Loss: {}, Train Accuracy_0 : {}, Train Accuracy_1 : {},Train Accuracy_2 : {}\".format(train_loss, train_accuracy_v0, train_accuracy_v1, train_accuracy_v2)) \n",
        "            \"\"\"\n",
        "\n",
        "        if monophonic == False:\n",
        "            train_accuracy = accuracy_sum / len(train_dataloader)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"train_accuracy\"].append(train_accuracy)\n",
        "            print(\"Train Loss: {}, Train Accuracy : {}\".format(train_loss, train_accuracy)) \n",
        "\n",
        "\n",
        "        if monophonic == True:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_v0_sum = 0\n",
        "                accuracy_v1_sum = 0\n",
        "                accuracy_v2_sum = 0\n",
        "                accuracy_v3_sum = 0\n",
        "\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    for voices, lens, nbr_voices in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)  \n",
        "                        prediction = torch.swapaxes(torch.tensor(prediction), 0, 1)\n",
        "\n",
        "                        truth = np.squeeze(voices[:,:,:,:-1]).argmax(dim=1).cpu()\n",
        "\n",
        "                        acc_list = [0 for i in range(len(prediction[0,:]))]\n",
        "\n",
        "                        for i in range(len(prediction[0,:])):\n",
        "                          acc_list[i] = accuracy_score(prediction[:,i], truth[:,i])\n",
        "                          val_accuracy_sum_list[i] += acc_list[i]/len(lens)\n",
        "\n",
        "\n",
        "                        #print(\"val_accuracy_sum_list[3]\",val_accuracy_sum_list[3])\n",
        "                    #val_acc_list = np.array(val_accuracy_sum_list) / len(train_dataloader)\n",
        "                    #val_acc_list[3] = val_acc_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "                    #val_acc_list[4] = val_acc_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "\n",
        "\n",
        "                #history[\"val_acc_new\"].append(val_acc_list)\n",
        "                #print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "\n",
        "                        # Predict the model's output on a batch\n",
        "                        pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "                            \n",
        "                        # compute the accuracy \n",
        "                        acc_v0 = accuracy_score(torch.tensor(pred_v0), np.squeeze(voices[:,:,:,0]).argmax(dim=1).cpu())\n",
        "                        acc_v1 = accuracy_score(torch.tensor(pred_v1), np.squeeze(voices[:,:,:,1]).argmax(dim=1).cpu())\n",
        "                        acc_v2 = accuracy_score(torch.tensor(pred_v2), np.squeeze(voices[:,:,:,2]).argmax(dim=1).cpu())\n",
        "                        if nbr_voices == 4:\n",
        "                            acc_v3 = accuracy_score(torch.tensor(pred_v3), np.squeeze(voices[:,:,:,3]).argmax(dim=1).cpu())\n",
        "                            \n",
        "                            \n",
        "                        # normalize according to the number of sequences in the batch (atm len(lens)==1)\n",
        "                        accuracy_v0_sum += acc_v0 / len(lens)\n",
        "                        accuracy_v1_sum += acc_v1 / len(lens)\n",
        "                        accuracy_v2_sum += acc_v2 / len(lens)\n",
        "                        if nbr_voices == 4:\n",
        "                            accuracy_v3_sum += acc_v3 / len(lens)\n",
        "\n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy_v0 = accuracy_v0_sum / len(val_dataloader)\n",
        "                    val_accuracy_v1 = accuracy_v1_sum / len(val_dataloader)\n",
        "                    val_accuracy_v2 = accuracy_v2_sum / len(val_dataloader)\n",
        "                    val_accuracy_v3 = accuracy_v3_sum / 18  ##len(val_dataloader). - bc 18 pieces only with voice 3\n",
        "\n",
        "\n",
        "                    val_acc_list = np.array(val_accuracy_sum_list) / len(val_dataloader)\n",
        "                    val_acc_list[3] = val_accuracy_sum_list[3] / 18                       ## bc only 18 pieces with len 3\n",
        "                    val_acc_list[4] = val_accuracy_sum_list[4] / 2                         ##### CHECK IF 2 or 3 pieces with len 4\n",
        "                    \n",
        "\n",
        "\n",
        "                history[\"val_accuracy_v0\"].append(val_accuracy_v0)\n",
        "                history[\"val_accuracy_v1\"].append(val_accuracy_v1)\n",
        "                history[\"val_accuracy_v2\"].append(val_accuracy_v2)\n",
        "                #if nbr_voices == 4:\n",
        "                history[\"val_accuracy_v3\"].append(val_accuracy_v3)\n",
        "                print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}\".format(val_accuracy_v0, val_accuracy_v1, val_accuracy_v2, val_accuracy_v3))\n",
        "                #else:\n",
        "                #    print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}\".format(val_accuracy_v0, val_accuracy_v1, val_accuracy_v2))\n",
        "\n",
        "\n",
        "                history[\"val_acc_new\"].append(val_acc_list)\n",
        "                print(\" Validation Accuracy_0 : {}, Validation Accuracy_1 : {}, Validation Accuracy_2 : {}, Validation Accuracy_3 : {}, Validation Accuracy_4 : {}\".format(val_acc_list[0], val_acc_list[1], val_acc_list[2], val_acc_list[3],val_acc_list[4]))\n",
        "\n",
        "\n",
        "        if monophonic == False:\n",
        "            if val_dataloader is not None:\n",
        "                # Evaluate on the validation set\n",
        "                model.eval()\n",
        "                accuracy_sum = 0\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    for voices, lens, nbr_voices in val_dataloader:\n",
        "\n",
        "                        voices = voices.to(device).float()\n",
        "                        \n",
        "                        # Predict the model's output on a batch\n",
        "\n",
        "                        prediction = model.predict(voices[:,:,:,-1], lens, monophonic)                      \n",
        "\n",
        "                        v_pred_argm = torch.tensor(np.argmax(prediction,axis=0))\n",
        "                        mask_pred = (prediction.sum(axis=0) == 0)\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)\n",
        "                        \n",
        "                        single_voices = voices[:,:,:,:-1]\n",
        "\n",
        "                        v_ori_argm = torch.argmax(np.squeeze(single_voices,axis=0).cpu(),axis=2)\n",
        "                        mask_ori = ((np.squeeze(single_voices,axis=0).cpu()).sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)  \n",
        "                        accuracy_sum += acc \n",
        "\n",
        "                        \"\"\"\n",
        "                        pred_v0, pred_v1, pred_v2, pred_v3 = model.predict(voices[:,:,:,-1], lens,monophonic)\n",
        "                        if nbr_voices == 4: \n",
        "                            v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2), torch.tensor(pred_v3)], dim=2)\n",
        "                        if nbr_voices ==3:\n",
        "                            v_pred_comb = torch.stack([torch.tensor(pred_v0), torch.tensor(pred_v1), torch.tensor(pred_v2)], dim=2)\n",
        "                        v_pred_argm = v_pred_comb.argmax(dim=2)\n",
        "                        mask_pred = (v_pred_comb.sum(axis=2) == 0).numpy()\n",
        "                        v_pred_argm[mask_pred] = -1\n",
        "                        v_pred_flat = torch.flatten(v_pred_argm, start_dim=0, end_dim=-1)                      \n",
        "                        if nbr_voices == 4:                   \n",
        "                            v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu(), np.squeeze(voices[:,:,:,3]).cpu()], dim=2)\n",
        "                        if nbr_voices ==3:\n",
        "                            v_ori_comb = torch.stack([np.squeeze(voices[:,:,:,0]).cpu(), np.squeeze(voices[:,:,:,1]).cpu(), np.squeeze(voices[:,:,:,2]).cpu()], dim=2)\n",
        "                        v_ori_argm = v_ori_comb.argmax(dim=2)\n",
        "                        mask_ori = (v_ori_comb.sum(axis=2) == 0).numpy()\n",
        "                        v_ori_argm[mask_ori] = -1\n",
        "                        v_ori_flat = torch.flatten(v_ori_argm, start_dim=0, end_dim=-1)\n",
        "\n",
        "                        acc = accuracy_score(v_pred_flat,v_ori_flat)\n",
        "                        accuracy_sum += acc \n",
        "                        \"\"\"\n",
        "                        \n",
        "                    # normalize according to the number of batches\n",
        "                    val_accuracy = accuracy_sum / len(val_dataloader)\n",
        "\n",
        "                history[\"val_accuracy\"].append(val_accuracy)  \n",
        "                print(\" Validation Accuracy : {}\".format(val_accuracy))\n",
        "\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # save the model\n",
        "        torch.save(model, Path(\"./AI-MA_project/model_temp_epoch{}.pkl\".format(i_epoch)))\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "nfDV8MKGHE3J"
      }
    }
  ]
}