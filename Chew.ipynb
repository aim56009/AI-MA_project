{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chew.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PYfyIi8Z7ytAu4eGoCLbpqd0N0Rrhjal",
      "authorship_tag": "ABX9TyMhtztLpbha8NdW0A1asZrB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aim56009/AI-MA_project/blob/main/Chew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install partitura\n",
        "import partitura\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "SU_SAxSe8xL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aim56009/AI-MA_project.git"
      ],
      "metadata": {
        "id": "zxC0_I1s7HTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9fada3-4319-4f26-e7d0-e34359996366"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI-MA_project'...\n",
            "remote: Enumerating objects: 2953, done.\u001b[K\n",
            "remote: Counting objects: 100% (2953/2953), done.\u001b[K\n",
            "remote: Compressing objects: 100% (832/832), done.\u001b[K\n",
            "remote: Total 2953 (delta 2202), reused 2802 (delta 2119), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2953/2953), 4.87 MiB | 8.22 MiB/s, done.\n",
            "Resolving deltas: 100% (2202/2202), done.\n",
            "Checking out files: 100% (3184/3184), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chew\n"
      ],
      "metadata": {
        "id": "_IXxqGxk8j_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation_chew():\n",
        "\n",
        "    history = defaultdict(list)\n",
        "    path = \"AI-MA_project/chorales_converted\"\n",
        "\n",
        "    ### load the chorales in xml format ###\n",
        "    for filename in os.listdir(path):\n",
        "        if not filename.endswith('.xml'): continue\n",
        "        fullname = os.path.join(path, filename)\n",
        "        \n",
        "\n",
        "        part = partitura.load_musicxml(fullname)\n",
        "            \n",
        "\n",
        "        ### apply chews method ### \n",
        "        chew_sep = partitura.musicanalysis.estimate_voices(part, monophonic_voices=True)\n",
        "\n",
        "\n",
        "        ### seperate the results -> e.g. pos_zero = all positions where chew prediction says voice 0 ####\n",
        "        pos_zero = np.where(chew_sep==1)\n",
        "        pos_one = np.where(chew_sep==2)\n",
        "        pos_two = np.where(chew_sep==3)\n",
        "        pos_three = np.where(chew_sep==4)\n",
        "\n",
        "\n",
        "        ### create notearray object that contain only the corresponding voice ###\n",
        "        note_array_zero = partitura.utils.ensure_notearray(part)[pos_zero]\n",
        "        note_array_one = partitura.utils.ensure_notearray(part)[pos_one]\n",
        "        note_array_two = partitura.utils.ensure_notearray(part)[pos_two]\n",
        "        note_array_three = partitura.utils.ensure_notearray(part)[pos_three]\n",
        "\n",
        "\n",
        "        ### create pr representation of all voices ###\n",
        "        pr_zero = partitura.utils.compute_pianoroll(note_array_zero,time_unit = \"beat\",time_div = 12)\n",
        "        pr_zero = pr_zero.toarray()\n",
        "\n",
        "        pr_one = partitura.utils.compute_pianoroll(note_array_one,time_unit = \"beat\",time_div = 12)\n",
        "        pr_one = pr_one.toarray()\n",
        "\n",
        "        pr_two = partitura.utils.compute_pianoroll(note_array_two,time_unit = \"beat\",time_div = 12)\n",
        "        pr_two = pr_two.toarray()\n",
        "\n",
        "        pr_three = partitura.utils.compute_pianoroll(note_array_three,time_unit = \"beat\",time_div = 12)\n",
        "        pr_three = pr_three.toarray()\n",
        "\n",
        "\n",
        "        ### get original data (as labels) ###\n",
        "        part_zero = part[0]\n",
        "        part_one = part[1]\n",
        "        part_two = part[2]\n",
        "        part_three = part[3]\n",
        "\n",
        "\n",
        "        ### compute pianoroll representation of original data for computing acc ###\n",
        "        pr_zero_ori = partitura.utils.compute_pianoroll(part_zero, time_unit = \"beat\",time_div = 12)\n",
        "        v0 = pr_zero_ori.toarray()\n",
        "\n",
        "        pr_one_ori = partitura.utils.compute_pianoroll(part_one, time_unit = \"beat\",time_div = 12)\n",
        "        v1 = pr_one_ori.toarray()\n",
        "\n",
        "        pr_two_ori = partitura.utils.compute_pianoroll(part_two, time_unit = \"beat\",time_div = 12)\n",
        "        v2 = pr_two_ori.toarray()\n",
        "\n",
        "        pr_three_ori = partitura.utils.compute_pianoroll(part_three, time_unit = \"beat\",time_div = 12)\n",
        "        v3 = pr_three_ori.toarray()\n",
        "\n",
        "        if pr_zero.shape == pr_one.shape == pr_two.shape == pr_three.shape  :\n",
        "            ### compute accuracy ###\n",
        "            acc_v0 = accuracy_score(torch.tensor(pr_zero), v0)\n",
        "            acc_v1 = accuracy_score(torch.tensor(pr_one), v1)\n",
        "            acc_v2 = accuracy_score(torch.tensor(pr_two),v2)\n",
        "            acc_v3 = accuracy_score(torch.tensor(pr_three), v3)\n",
        "\n",
        "            history[\"accuracy_v0\"].append(acc_v0)\n",
        "            history[\"accuracy_v1\"].append(acc_v1)\n",
        "            history[\"accuracy_v2\"].append(acc_v2)\n",
        "            history[\"accuracy_v3\"].append(acc_v3)\n",
        "            \n",
        "        else: print(\"pr shape does not match for:\", filename)\n",
        "        \n",
        "    return history"
      ],
      "metadata": {
        "id": "E9cWSLeL-05q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_acc =  evaluation_chew()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgJCl6Mx-nF4",
        "outputId": "5740563d-0a78-459c-faa9-cd4043552b01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pr shape does not match for: chor074.xml\n",
            "pr shape does not match for: chor056.xml\n",
            "pr shape does not match for: chor245.xml\n",
            "pr shape does not match for: chor043.xml\n",
            "pr shape does not match for: chor286.xml\n",
            "pr shape does not match for: chor283.xml\n",
            "pr shape does not match for: chor133.xml\n",
            "pr shape does not match for: chor252.xml\n",
            "pr shape does not match for: chor089.xml\n",
            "pr shape does not match for: chor348.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_len = len(hist_acc[\"accuracy_v0\"])\n",
        "accuracy_v0 = np.sum(hist_acc[\"accuracy_v0\"])/total_len\n",
        "accuracy_v1 = np.sum(hist_acc[\"accuracy_v1\"])/total_len\n",
        "accuracy_v2 = np.sum(hist_acc[\"accuracy_v2\"])/total_len\n",
        "accuracy_v3 = np.sum(hist_acc[\"accuracy_v3\"])/total_len\n",
        "\n",
        "print(\"accuracy of v0-v3:\",accuracy_v0,accuracy_v1,accuracy_v2,accuracy_v3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4UzqvcEE2gm",
        "outputId": "f71662d7-de58-48bb-c9db-1a27b22e7aae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of v0-v3: 0.9886067708333334 0.9805338541666667 0.9843532986111111 0.9956597222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HMM approach"
      ],
      "metadata": {
        "id": "wKTWlxty2JrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## This block was to save the xml files to midi and download it to put it in the right folder on github ###\n",
        "\"\"\"\n",
        "#path = \"AI-MA_project/chorales_converted\"\n",
        "path = \"chorales_converted\"\n",
        "\n",
        "\n",
        "for filename in os.listdir(path):\n",
        "    if not filename.endswith('.xml'): continue\n",
        "    fullname = os.path.join(path, filename)\n",
        "    part = partitura.load_musicxml(fullname)\n",
        "    try:\n",
        "      partitura.save_score_midi(part,out= \"midi_test/\"+filename[:8]+\"mid\",part_voice_assign_mode=4)\n",
        "    except:\n",
        "      print(filename[:8]+\"mid\")\n",
        "\n",
        "\n",
        "#path = \"midi_test/\"\n",
        "#for filename in os.listdir(path):\n",
        "#    files.download(path + filename) \n",
        "\n",
        "#!zip -r /content/file.zip midi_test\n",
        "#files.download(\"/content/midi_zip_file.zip\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NT_cg-w59ahz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HMM loop"
      ],
      "metadata": {
        "id": "XE0iMK4F42N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation_hmm():\n",
        "    history_ = defaultdict(list)\n",
        "\n",
        "    path = \"AI-MA_project/hmm_sep\"\n",
        "\n",
        "    for filename in os.listdir(path):\n",
        "        if not filename.endswith('.mid'): continue\n",
        "        fullname = os.path.join(path, filename)\n",
        "\n",
        "        part_hmm = partitura.load_score_midi(fullname,part_voice_assign_mode=2)\n",
        "        voice_info = partitura.utils.note_array_from_part(part_hmm)[\"voice\"]\n",
        "\n",
        "        ### seperate the results -> e.g. pos_zero = all positions where chew prediction says voice 0 ####\n",
        "        pos_0 = np.where(voice_info==1)\n",
        "        pos_1 = np.where(voice_info==2)\n",
        "        pos_2 = np.where(voice_info==3)\n",
        "        pos_3 = np.where(voice_info==4)\n",
        "\n",
        "        ### create notearray object that contain only the corresponding voice ###\n",
        "        note_array_0= partitura.utils.ensure_notearray(part_hmm)[pos_0]\n",
        "        note_array_1 = partitura.utils.ensure_notearray(part_hmm)[pos_1]\n",
        "        note_array_2 = partitura.utils.ensure_notearray(part_hmm)[pos_2]\n",
        "        note_array_3 = partitura.utils.ensure_notearray(part_hmm)[pos_3]\n",
        "\n",
        "        if len(note_array_3) !=0 and len(note_array_2) !=0 and len(note_array_1) !=0 and len(note_array_0) !=0:\n",
        "            ### create pr representation of all voices ###\n",
        "            pr_0 = partitura.utils.compute_pianoroll(note_array_0,time_unit = \"beat\",time_div = 12)\n",
        "            pr_0 = pr_0.toarray()\n",
        "\n",
        "            pr_1 = partitura.utils.compute_pianoroll(note_array_1,time_unit = \"beat\",time_div = 12)\n",
        "            pr_1 = pr_1.toarray()\n",
        "\n",
        "            pr_2 = partitura.utils.compute_pianoroll(note_array_2,time_unit = \"beat\",time_div = 12)\n",
        "            pr_2 = pr_2.toarray()\n",
        "\n",
        "            pr_3 = partitura.utils.compute_pianoroll(note_array_3,time_unit = \"beat\",time_div = 12)\n",
        "            pr_3 = pr_3.toarray()\n",
        "\n",
        "\n",
        "            fullname_ = os.path.join(\"AI-MA_project/chorales_converted\", filename[:8] + \"xml\")\n",
        "            part_ = partitura.load_musicxml(fullname_)\n",
        "\n",
        "            ### get original data (as labels) ###\n",
        "            part_zero = part_[0]\n",
        "            part_one = part_[1]\n",
        "            part_two = part_[2]\n",
        "            part_three = part_[3]\n",
        "\n",
        "\n",
        "            ### compute pianoroll representation of original data for computing acc ###\n",
        "            pr_zero_ori = partitura.utils.compute_pianoroll(part_zero, time_unit = \"beat\",time_div = 12)\n",
        "            v0 = pr_zero_ori.toarray()\n",
        "\n",
        "            pr_one_ori = partitura.utils.compute_pianoroll(part_one, time_unit = \"beat\",time_div = 12)\n",
        "            v1 = pr_one_ori.toarray()\n",
        "\n",
        "            pr_two_ori = partitura.utils.compute_pianoroll(part_two, time_unit = \"beat\",time_div = 12)\n",
        "            v2 = pr_two_ori.toarray()\n",
        "\n",
        "            pr_three_ori = partitura.utils.compute_pianoroll(part_three, time_unit = \"beat\",time_div = 12)\n",
        "            v3 = pr_three_ori.toarray()\n",
        "\n",
        "            if pr_0.shape == pr_1.shape == pr_2.shape == pr_3.shape  :\n",
        "                ### compute accuracy ###\n",
        "                acc_v0 = accuracy_score(torch.tensor(pr_0), v0)\n",
        "                acc_v1 = accuracy_score(torch.tensor(pr_1), v1)\n",
        "                acc_v2 = accuracy_score(torch.tensor(pr_2),v2)\n",
        "                acc_v3 = accuracy_score(torch.tensor(pr_3), v3)\n",
        "\n",
        "                history_[\"accuracy_v0\"].append(acc_v0)\n",
        "                history_[\"accuracy_v1\"].append(acc_v1)\n",
        "                history_[\"accuracy_v2\"].append(acc_v2)\n",
        "                history_[\"accuracy_v3\"].append(acc_v3)\n",
        "            else:\n",
        "              print(\"size does not match\",filename)\n",
        "        \n",
        "    return history_"
      ],
      "metadata": {
        "id": "rNEoXK7K415q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_acc_hmm =  evaluation_hmm()"
      ],
      "metadata": {
        "id": "m7Gqo3Fi5sFC",
        "outputId": "3fb1ae48-128a-4a06-87d9-db1941a2683d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size does not match chor043.mid\n",
            "size does not match chor283.mid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_len_hmm = len(hist_acc_hmm[\"accuracy_v0\"])\n",
        "\n",
        "accuracy_v0_hmm = np.sum(hist_acc_hmm[\"accuracy_v0\"])/total_len_hmm\n",
        "accuracy_v1_hmm = np.sum(hist_acc_hmm[\"accuracy_v1\"])/total_len_hmm\n",
        "accuracy_v2_hmm = np.sum(hist_acc_hmm[\"accuracy_v2\"])/total_len_hmm\n",
        "accuracy_v3_hmm = np.sum(hist_acc_hmm[\"accuracy_v3\"])/total_len_hmm\n",
        "\n",
        "print(\"accuracy of v0-v3 -HMM:\",accuracy_v0_hmm,accuracy_v1_hmm,accuracy_v2_hmm,accuracy_v3_hmm)"
      ],
      "metadata": {
        "id": "AAN-Sdza6Ght",
        "outputId": "b4b3f737-37ab-4f62-e4d3-53c4744528f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of v0-v3 -HMM: 0.99189453125 0.982470703125 0.987744140625 0.9976806640625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy comparison\n"
      ],
      "metadata": {
        "id": "UGew_n3OCmdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy of v0-v3 -UNET:  0.985 0.975 0.970 0.990"
      ],
      "metadata": {
        "id": "57II9z7rCoy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy of v0-v3 -HMM: 0.992 0.982 0.988 0.998\n"
      ],
      "metadata": {
        "id": "daeaj23xDORn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy of v0-v3 -CHEW: 0.989 0.980 0.984 0.996\n"
      ],
      "metadata": {
        "id": "nsG4Xj2lDQkg"
      }
    }
  ]
}