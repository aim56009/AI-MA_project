{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Wgan-gp_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aim56009/AI-MA_project/blob/main/Masterarbeit_WGAN_GP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8k9AL_3HW8I"
      },
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXZBmpZ3DhvB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2640724c-524a-47ad-9535-e1e3c3172eff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!pip install nilearn\n",
        "!pip install wandb -q\n",
        "!pip install nltools\n",
        "\n",
        "%cd \"/content/gdrive/MyDrive/Masterarbeit\"\n",
        "%pylab inline\n",
        "\n",
        "import scipy\n",
        "import numpy as np\n",
        "import os\n",
        "import nibabel as nib\n",
        "import datetime\n",
        "import glob\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from scipy.ndimage import zoom\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from nilearn import plotting\n",
        "from utils_wgan_gp import gradient_penalty, save_checkpoint, load_checkpoint\n",
        "from torch.nn import functional as F\n",
        "from torch import autograd\n",
        "from torch.autograd import Variable\n",
        "from tqdm.notebook import tqdm\n",
        "from nltools.data import Brain_Data\n",
        "\n",
        "from model_wgan_gp_tanh import Discriminator, Generator, initialize_weights"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Collecting nilearn\n",
            "  Downloading nilearn-0.8.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0 MB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.0.1)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: nibabel>=2.5 in /usr/local/lib/python3.7/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.1.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->nilearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->nilearn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->nilearn) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->nilearn) (3.0.0)\n",
            "Installing collected packages: nilearn\n",
            "Successfully installed nilearn-0.8.1\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 8.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 54.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 65.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nltools\n",
            "  Downloading nltools-0.4.5-py2.py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from nltools) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from nltools) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from nltools) (1.4.1)\n",
            "Collecting pynv\n",
            "  Downloading pynv-0.2-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: nibabel>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from nltools) (3.0.2)\n",
            "Collecting deepdish>=0.3.6\n",
            "  Downloading deepdish-0.3.7-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: seaborn>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from nltools) (0.11.2)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.7/dist-packages (from nltools) (1.19.5)\n",
            "Requirement already satisfied: nilearn>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from nltools) (0.8.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from nltools) (1.1.5)\n",
            "Requirement already satisfied: joblib>=0.15 in /usr/local/lib/python3.7/dist-packages (from nltools) (1.1.0)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from deepdish>=0.3.6->nltools) (3.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.0->nltools) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.0->nltools) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.0->nltools) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.0->nltools) (2.8.2)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn>=0.6.0->nltools) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->nltools) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2.0->nltools) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn>=0.6.0->nltools) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn>=0.6.0->nltools) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn>=0.6.0->nltools) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn>=0.6.0->nltools) (2021.10.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->nltools) (3.0.0)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.7/dist-packages (from tables->deepdish>=0.3.6->nltools) (2.7.3)\n",
            "Installing collected packages: pynv, deepdish, nltools\n",
            "Successfully installed deepdish-0.3.7 nltools-0.4.5 pynv-0.2\n",
            "/content/gdrive/MyDrive/Masterarbeit\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nilearn/datasets/__init__.py:96: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
            "  \"Numpy arrays.\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxyWRZFF2Dbb"
      },
      "source": [
        "# HP wgan_gp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiED3ecy2GIm"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LEARNING_RATE = 2e-4\n",
        "BATCH_SIZE = 4\n",
        "IMAGE_SIZE = 64\n",
        "CHANNELS_IMG = 1\n",
        "Z_DIM = 1000\n",
        "NUM_EPOCHS = 101\n",
        "FEATURES_CRITIC = 32\n",
        "FEATURES_GEN = 32\n",
        "CRITIC_ITERATIONS = 5\n",
        "LAMBDA_GP = 10\n",
        "load_pretrained = False"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZdGmBkSIZod"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC730WgwIZoe"
      },
      "source": [
        "cfg = {\n",
        "    'env': 'COLAB',\n",
        "    'usr': \"MICHAEL\",\n",
        "    'version_name': 'v3.1',\n",
        "    'epochs': NUM_EPOCHS,                 #  epoch = (Number of iterations * batch size) / total number of images in training\n",
        "    'batch_size': BATCH_SIZE, \n",
        "    'learning_rate':  LEARNING_RATE,\n",
        "    'dbg_rescaled': 0,\n",
        "    'labels': ['footright'],\n",
        "    'smoothing': '0mm', \n",
        "    'latent_dim': Z_DIM,}\n",
        "    \n",
        "#DO NOT EDIT\n",
        "cfg['expid'] = cfg['usr'] + '_' + cfg['version_name'] + '_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_' + '_'.join(cfg['labels'])  + '_SS' + cfg['smoothing']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9CYFgKOIZof",
        "outputId": "044a8560-6f50-4bd4-a8c8-51bdb7bc3240"
      },
      "source": [
        "tags=['Brain_GAN', 'Initial Run', '_'.join(cfg['labels']), 'SS'+cfg['smoothing'],\n",
        "      'latentdim'+str(cfg['latent_dim']), 'batch_size'+str(cfg['batch_size'])]\n",
        "print(tags)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Brain_GAN', 'Initial Run', 'footright', 'SS0mm', 'latentdim1000', 'batch_size4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRbX9EZOIZoh"
      },
      "source": [
        "gpu = True\n",
        "workers = 0\n",
        "LAMBDA= LAMBDA_GP\n",
        "_eps = 1e-15\n",
        "\n",
        "PROJECT_DIR=\"/content/gdrive/MyDrive/Masterarbeit\"\n",
        "PATH_TO_DATA=\"/content/gdrive/MyDrive/Masterarbeit/tstat_\"+ cfg['smoothing']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls3-Wv39IZoi"
      },
      "source": [
        "Create directory for saving models when training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqrppWY53YEY",
        "outputId": "340208f3-9e80-4588-a711-8abecc192ebb"
      },
      "source": [
        "imgREF = nib.load(os.path.join(PROJECT_DIR, 'tstat_' + cfg['smoothing'], cfg['labels'][0], 'sub100307.nii.gz'))\n",
        "\n",
        "PATH_CHECKPOINT_MOD = os.path.join(PROJECT_DIR, 'checkpoint_models', cfg['expid'])\n",
        "\n",
        "if not os.path.isdir(PATH_CHECKPOINT_MOD):\n",
        "    print('Creating directory: ', PATH_CHECKPOINT_MOD)\n",
        "    os.makedirs(PATH_CHECKPOINT_MOD)\n",
        "\n",
        "\n",
        "#PATH_CHECKPOINT_IMG = os.path.join(PROJECT_DIR, 'checkpoint_images', cfg['expid'])\n",
        "#if not os.path.isdir(PATH_CHECKPOINT_IMG):\n",
        "#    print('Creating directory: ', PATH_CHECKPOINT_IMG)\n",
        "#    os.makedirs(PATH_CHECKPOINT_IMG)\n",
        "\n",
        "#for fl in glob.glob(os.path.join(PATH_CHECKPOINT_IMG, '*.nii.gz')):\n",
        "#    print('removing ', fl)\n",
        "#    os.remove(fl)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating directory:  /content/gdrive/MyDrive/Masterarbeit/checkpoint_models/MICHAEL_v3.1_20211130-125857_footright_SS0mm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaAHECl9UjHc"
      },
      "source": [
        "def do_log(i, some_dict):\n",
        "    wandb.log(some_dict)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2uLgi-h8CUM"
      },
      "source": [
        "# **Dataloader** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaP4oetE8Mpv"
      },
      "source": [
        "class NiftiDataset_(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, labels, n, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.mask = np.load(\"mask_dil64.npy\")\n",
        "\n",
        "        # get the files\n",
        "        for iLabel in range(len(labels)):\n",
        "            file_names = sorted(glob.glob(os.path.join(data_dir, labels[iLabel], \"*.nii.gz\")))\n",
        "\n",
        "            if iLabel == 0:\n",
        "                self.data = np.array(file_names[:n])\n",
        "                self.labels = np.array(np.repeat(labels[iLabel], len(self.data)))\n",
        "            else:\n",
        "                self.data = np.append(self.data, file_names[:n])\n",
        "                self.labels = np.append(self.labels, np.repeat(labels[iLabel], len(self.data)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img = np.nan_to_num(nib.load(self.data[idx]).get_fdata())  \n",
        "        img[np.isnan(img)] = 0\n",
        "\n",
        "        dims = img.shape\n",
        "        img_ = zoom(img, (64/dims[0], 64/dims[1], 64/dims[2]))\n",
        "\n",
        "        img_ = (img_-np.min(img_))/(np.max(img_)-np.min(img_))\n",
        "        img_ = 2*img_-1\n",
        "\n",
        "        mask_img = img_ * self.mask\n",
        "\n",
        "        mask_img = torch.tensor(mask_img)\n",
        "        mask_img = mask_img.unsqueeze(0)\n",
        "        \n",
        "\n",
        "\n",
        "        sample = {'img': mask_img.float(), 'label': self.labels[idx]}\n",
        "        return sample"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdoVqfRTXz73"
      },
      "source": [
        "dataset = NiftiDataset_(PATH_TO_DATA, cfg['labels'], 802) # was 709 for handleft"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHMjMxHq4yvN"
      },
      "source": [
        "loader = torch.utils.data.DataLoader(dataset,batch_size=cfg['batch_size'], shuffle=True, num_workers=workers, drop_last=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bqhZaJDszSQ"
      },
      "source": [
        "# **Training**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCs3094HLTu"
      },
      "source": [
        "Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsFlFbH0WA4I"
      },
      "source": [
        "def calc_gradient_penalty(model, x, x_gen, w=10):\n",
        "    assert x.size()==x_gen.size()                                               # check if real and sample size match\n",
        "    alpha_size = tuple((len(x), *(1,)*(x.dim()-1)))\n",
        "    alpha_t = torch.cuda.FloatTensor if x.is_cuda else torch.Tensor\n",
        "    alpha = alpha_t(*alpha_size).uniform_()\n",
        "    x_hat = x.data*alpha + x_gen.data*(1-alpha)\n",
        "    x_hat = Variable(x_hat, requires_grad=True)\n",
        "\n",
        "    def eps_norm(x):\n",
        "        x = x.view(len(x), -1)\n",
        "        return (x*x+_eps).sum(-1).sqrt()\n",
        "    def bi_penalty(x):\n",
        "        return (x-1)**2\n",
        "\n",
        "    grad_xhat = torch.autograd.grad(model(x_hat).sum(), x_hat, create_graph=True, only_inputs=True)[0]\n",
        "    penalty = w*bi_penalty(eps_norm(grad_xhat)).mean()\n",
        "    return penalty"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIZlfcFApbTf"
      },
      "source": [
        "def saveResampledNifti(generatedData64, imgREF, fNameOut):\n",
        "    dims = imgREF.shape\n",
        "    generatedDataOrgRes = zoom(generatedData64, (dims[0]/64, dims[1]/64, dims[2]/64))\n",
        "    imgRes = nib.Nifti1Image(generatedDataOrgRes, affine = imgREF.affine)\n",
        "    nib.save(imgRes, fNameOut)\n",
        "\n",
        "def generate_fake(generator, z_dim, output_dir, n_fakes=100, batch_size=1):\n",
        "                print('saving into %s' % output_dir)\n",
        "                for k in tqdm(range(n_fakes)):\n",
        "\n",
        "                    noise = torch.randn(batch_size, z_dim, 1, 1, 1).to(device)\n",
        "                    dat = generator(noise)\n",
        "\n",
        "                    fNameOut = os.path.join(output_dir,'fake'+'{:03}'.format(k+1) + '.nii.gz')\n",
        "                    generatedData64 = np.squeeze(dat.data.cpu().numpy())\n",
        "                    saveResampledNifti(generatedData64, imgREF, fNameOut)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEDdaqg75ZBy"
      },
      "source": [
        "Initialize the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEUwj3m_soRW"
      },
      "source": [
        "gen = Generator(cfg['latent_dim'], CHANNELS_IMG, FEATURES_GEN).to(device)\n",
        "critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n",
        "\n",
        "if load_pretrained:\n",
        "    gen.load_state_dict(torch.load(\"checkpoint_models/tanh/ckpt_gen_iter000100.pth\"))\n",
        "    critic.load_state_dict(torch.load(\"checkpoint_models/tanh/ckpt_critic_iter000100.pth\"))\n",
        "\n",
        "initialize_weights(gen)\n",
        "initialize_weights(critic)\n",
        "\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=cfg['learning_rate'], betas=(0.0, 0.9))\n",
        "opt_critic = optim.Adam(critic.parameters(), lr=cfg['learning_rate'], betas=(0.0, 0.9))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rLQ-Kg96J1S"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1svzDGt-CFa"
      },
      "source": [
        "def train(nbr_models_saved=10):\n",
        "    \n",
        "    gen.train()\n",
        "    critic.train()\n",
        "\n",
        "    \n",
        "    wandb.init(\n",
        "    entity=\"ml4ni\",\n",
        "    project='alpha-wgan',\n",
        "    name=cfg['expid'], \n",
        "    notes='https://colab.research.google.com/drive/10hVK7wxbZRzynuxahMx5L2ziLwjdQx89#scrollTo=zIt_iSG52ug4', \n",
        "    tags=tags,\n",
        "    config=cfg)\n",
        "\n",
        "    config = wandb.config\n",
        "    \n",
        "\n",
        "    for epoch in range(config['epochs']):\n",
        "        for batch_idx, real in enumerate(loader):\n",
        "\n",
        "            real = real[\"img\"].to(device)\n",
        "            cur_batch_size = real.shape[0]\n",
        "\n",
        "            # Train Critic: max E[critic(real)] - E[critic(fake)] equivalent to minimizing the negative of that\n",
        "            for _ in range(CRITIC_ITERATIONS):\n",
        "                noise = torch.randn(cur_batch_size, Z_DIM, 1, 1,1).to(device)\n",
        "                fake = gen(noise)\n",
        "                critic_real = critic(real).reshape(-1)\n",
        "                critic_fake = critic(fake).reshape(-1)\n",
        "                gp = calc_gradient_penalty(critic, real, fake)\n",
        "                loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp  \n",
        "                               \n",
        "                \n",
        "                critic.zero_grad()\n",
        "                loss_critic.backward(retain_graph=True)\n",
        "                opt_critic.step()\n",
        "\n",
        "\n",
        "            # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
        "            \n",
        "            gen_fake = critic(fake).reshape(-1)\n",
        "            loss_gen = -torch.mean(gen_fake) \n",
        "            gen.zero_grad()\n",
        "            loss_gen.backward()\n",
        "            opt_gen.step()\n",
        "            \n",
        "            if batch_idx % cur_batch_size == 0 and batch_idx > 0:\n",
        "                print(f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n",
        "                      Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\")\n",
        "\n",
        "            do_log(epoch, { \"D:\":loss_critic, \"G:\":loss_gen})\n",
        "\n",
        "        if epoch%nbr_models_saved ==0:\n",
        "            fNameOut = os.path.join(PATH_CHECKPOINT_MOD, 'ckpt_gen_iter' + '{:06}'.format(epoch+1) + '.pth')\n",
        "            print('Saving ', fNameOut)\n",
        "            torch.save(gen.state_dict(), fNameOut)\n",
        "              \n",
        "            fNameOut = os.path.join(PATH_CHECKPOINT_MOD, 'ckpt_critic_iter' + '{:06}'.format(epoch+1) + '.pth')\n",
        "            print('Saving ', fNameOut)\n",
        "            torch.save(critic.state_dict(), fNameOut)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX4IczIXjgSl"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kSJB7T2_PM4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}